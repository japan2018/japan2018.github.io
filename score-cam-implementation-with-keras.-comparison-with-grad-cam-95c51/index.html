<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  <meta name="generator" content="Hugo 0.72.0" />

  
  <meta name="description" content="Some description">
  

  
  <link rel="apple-touch-icon" sizes="180x180" href="https://memotut.com/apple-touch-icon.png">

  
  <link rel="icon" type="image/png" sizes="32x32" href="https://memotut.com/favicon-32x32.png">

  
  <link rel="icon" type="image/png" sizes="16x16" href="https://memotut.com/favicon-16x16.png">

  
  <link rel="manifest" href="https://memotut.com/site.webmanifest">

  
  <link rel="mask-icon" href="https://memotut.com/safari-pinned-tab.svg" color="#5bbad5">

  <meta name="msapplication-TileColor" content="#da532c">

  <meta name="theme-color" content="#ffffff">

  
  <link rel="stylesheet" href="https://memotut.com/css/bootstrap.min.css" />

  
  <title>Score-CAM implementation with keras. Comparison with Grad-CAM | Memo Tut</title>
  

  <style>
body {
  min-width: 300px;
}

.custom-navbar {
  margin-bottom: 1em;
  height: 60px;
}

.custom-navbar a {
  display: inline-block; 
  padding: 18px 0;
  margin-right: 1em; 
  font-weight: bold; 
}

.custom-navbar a:hover,
.custom-navbar a:focus {
  text-decoration: none; 
}

@media print {
  .custom-navbar {
    display: none;
  }
}

article {
  padding-bottom: 1em;
}

img {
  max-width: 100%;
}


body {
  background-color: #fff;
}



body {
  color: #212529;
}



a {
  color: #007bff;
}



a:hover,
a:focus {
  color: #0056b3;
}



.custom-navbar {
  background-color: #212529;
}



.custom-navbar a {
  color: rgba(255, 255, 255, 0.75);
}



.custom-navbar a:hover,
.custom-navbar a:focus {
  color: rgba(255, 255, 255, 1);
}



.container {
  max-width: 800px;
}



pre {
  display: block;
  padding: 9.5px;
  word-break: break-all;
  word-wrap: break-word;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre code {
  padding: 0;
  font-size: inherit;
  color: inherit; 
  white-space: pre-wrap;
  background-color: transparent;
  border: none;
  border-radius: 0;
}

code {
  padding: 2px 4px;
  color: inherit; 
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
  font-size: .9em;
}



blockquote,
.blockquote {
  padding: 10px 20px;
  margin: 0 0 20px;
  font-size: 1em;
  border-left: 5px solid #6c757d;
}

</style>
</head>

<body>
  <nav class="custom-navbar">
  <div class="container">
    
    <a href="/">Posts</a>
    
    <a href="/tags/">Tags</a>
    
    <a href="/about/">About</a>
    
    <a href="/index.xml">RSS</a>
    
  </div>
</nav>
  
  <div class="container">
    <article>
      <h1>Score-CAM implementation with keras. Comparison with Grad-CAM</h1>
<p>
  <small class="text-secondary">
  
  
  Nov 4, 2019
  </small>
  

<small><code><a href="https://memotut.com/tags/python">Python</a></code></small>


<small><code><a href="https://memotut.com/tags/machine-learning"> Machine Learning</a></code></small>


<small><code><a href="https://memotut.com/tags/deep-learning"> Deep Learning</a></code></small>


<small><code><a href="https://memotut.com/tags/keras"> Keras</a></code></small>

</p>
<pre><code># Overview
</code></pre>
<ul>
<li>Implemented the method &ldquo;<strong>Score-CAM</strong>&rdquo; of <a href="https://arxiv.org/pdf/1910.01279.pdf">Paper</a> posted on arxiv on October 3, 2019 with keras.</li>
<li><strong>Comparison with Grad-CAM, Grad-CAM++</strong>.</li>
<li>Implemented the independently accelerated <strong>Faster Score-CAM</strong>.</li>
<li>Applied to the model trained on <strong>DAGM dataset</strong>.</li>
<li>The code can be found on <a href="https://github.com/tabayashi0117/Score-CAM">github</a>.</li>
</ul>
<img width="1000" alt="compare.png" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/193401/aee957cd-d07c-b5ed-9518-2b41364f4879.png">
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/193401/bb9047ef-b266-142e-f97f-6a4afcc53296.jpeg" alt="class6.jpg"></p>
<p>What is # <a href="https://arxiv.org/pdf/1910.01279.pdf">Score-CAM</a>?</p>
<ul>
<li>One of the visualization methods of the basis of judgment of CNN
-There is a wonderful summary on <a href="https://qiita.com/icoxfog417/items/8689f943fd1225e24358">here</a> for understanding the judgment basis.</li>
<li>Previous research includes <a href="https://arxiv.org/abs/1610.02391">Grad-CAM</a>,<a href="https://arxiv.org/abs/1710.11063">Grad-CAM++</a></li>
<li>Reduced noise, improved stability, and is no longer dependent on gradient calculations**</li>
</ul>
<p>#Environment</p>
<ul>
<li>Python 3.6.8</li>
<li>Keras 2.2.4</li>
<li>tensorflow-gpu 1.14.0</li>
</ul>
<h1 id="score-cam-procedure">Score-CAM procedure</h1>
<ol>
<li>Get the activation map and expand it to the same size as the first input with bilinear interpolation</li>
<li>Normalize each channel to the interval [0,1]</li>
<li>For the input image, prepare a masked image by multiplying the number of channels for each channel.</li>
<li>Pass each masked image through CNN to get the array after softmax operation</li>
<li>Define the importance of each channel by the score of the target class after softmax</li>
<li>The final score map is obtained by adding the above-mentioned degrees of importance to each channel, adding them together, and applying the ReLU operation. (Because I am not interested in negative elements, I pass ReLU)</li>
</ol>
<p>Implemented with # keras</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> cv2
<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">from</span> keras.models <span style="color:#f92672">import</span> Model

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">ScoreCam</span>(model, img_array, layer_name, max_N<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>):

    cls <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>argmax(model<span style="color:#f92672">.</span>predict(img_array))
    act_map_array <span style="color:#f92672">=</span> Model(inputs<span style="color:#f92672">=</span>model<span style="color:#f92672">.</span>input, outputs<span style="color:#f92672">=</span>model<span style="color:#f92672">.</span>get_layer(layer_name)<span style="color:#f92672">.</span>output)<span style="color:#f92672">.</span>predict(img_array)
    
    <span style="color:#75715e"># extract effective maps</span>
    <span style="color:#66d9ef">if</span> max_N <span style="color:#f92672">!=</span> <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>:
        act_map_std_list <span style="color:#f92672">=</span> [np<span style="color:#f92672">.</span>std(act_map_array[<span style="color:#ae81ff">0</span>,:,:,k]) <span style="color:#66d9ef">for</span> k <span style="color:#f92672">in</span> range(act_map_array<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">3</span>])]
        unsorted_max_indices <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>argpartition(<span style="color:#f92672">-</span>np<span style="color:#f92672">.</span>array(act_map_std_list), max_N)[:max_N]
        max_N_indices <span style="color:#f92672">=</span> unsorted_max_indices[np<span style="color:#f92672">.</span>argsort(<span style="color:#f92672">-</span>np<span style="color:#f92672">.</span>array(act_map_std_list)[unsorted_max_indices])]]
        act_map_array <span style="color:#f92672">=</span> act_map_array[:,:,:,max_N_indices]

    input_shape <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>layers[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>output_shape[<span style="color:#ae81ff">1</span>:] <span style="color:#75715e"># get input shape</span>
    <span style="color:#75715e"># 1. upsampled to original input size</span>
    act_map_resized_list <span style="color:#f92672">=</span> [cv2<span style="color:#f92672">.</span>resize(act_map_array[<span style="color:#ae81ff">0</span>,:,:,k], input_shape[:<span style="color:#ae81ff">2</span>], interpolation<span style="color:#f92672">=</span>cv2<span style="color:#f92672">.</span>INTER_LINEAR) <span style="color:#66d9ef">for</span> k <span style="color:#f92672">in</span> range(act_map_array<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">3</span>])]
    <span style="color:#75715e"># 2. normalize the raw activation value in each activation map into [0, 1]</span>
    act_map_normalized_list <span style="color:#f92672">=</span> []
    <span style="color:#66d9ef">for</span> act_map_resized <span style="color:#f92672">in</span> act_map_resized_list:
        <span style="color:#66d9ef">if</span> np<span style="color:#f92672">.</span>max(act_map_resized)<span style="color:#f92672">-</span>np<span style="color:#f92672">.</span>min(act_map_resized) <span style="color:#f92672">!=</span> <span style="color:#ae81ff">0</span>:
            act_map_normalized <span style="color:#f92672">=</span> act_map_resized <span style="color:#f92672">/</span> (np<span style="color:#f92672">.</span>max(act_map_resized)<span style="color:#f92672">-</span>np<span style="color:#f92672">.</span>min(act_map_resized))
        <span style="color:#66d9ef">else</span>:
            act_map_normalized <span style="color:#f92672">=</span> act_map_resized
        act_map_normalized_list<span style="color:#f92672">.</span>append(act_map_normalized)
    <span style="color:#75715e"># 3. project highlighted area in the activation map to original input space by multiplying the normalized activation map</span>
    masked_input_list <span style="color:#f92672">=</span> []
    <span style="color:#66d9ef">for</span> act_map_normalized <span style="color:#f92672">in</span> act_map_normalized_list:
        masked_input <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>copy(img_array)
        <span style="color:#66d9ef">for</span> k <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">3</span>):
            masked_input[<span style="color:#ae81ff">0</span>,:,:,k] <span style="color:#f92672">*=</span> act_map_normalized
        masked_input_list<span style="color:#f92672">.</span>append(masked_input)
    masked_input_array <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>concatenate(masked_input_list, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)
    <span style="color:#75715e"># 4. feed masked inputs into CNN model and softmax</span>
    pred_from_masked_input_array <span style="color:#f92672">=</span> softmax(model<span style="color:#f92672">.</span>predict(masked_input_array))
    <span style="color:#75715e"># 5. define weight as the score of target class</span>
    weights <span style="color:#f92672">=</span> pred_from_masked_input_array[:,cls]
    <span style="color:#75715e"># 6. get final class discriminative localization map as linear weighted combination of all activation maps</span>
    cam <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>dot(act_map_array[<span style="color:#ae81ff">0</span>,:,:,:], weights)
    cam <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>maximum(<span style="color:#ae81ff">0</span>, cam) <span style="color:#75715e"># Passing through ReLU</span>
    cam <span style="color:#f92672">/=</span> np<span style="color:#f92672">.</span>max(cam) <span style="color:#75715e"># scale 0 to 1.0</span>
    
    <span style="color:#66d9ef">return</span> cam

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">softmax</span>(x):
    f <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>exp(x)<span style="color:#f92672">/</span>np<span style="color:#f92672">.</span>sum(np<span style="color:#f92672">.</span>exp(x), axis <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>, keepdims <span style="color:#f92672">=</span> True)
    <span style="color:#66d9ef">return</span> f
</code></pre></div><h1 id="vgg16-in-score-cam">VGG16 in Score-CAM</h1>
<p>Let&rsquo;s apply it to VGG16 which has been learned with ImageNet.</p>
<h4 id="read-image">Read image</h4>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> keras.preprocessing.image <span style="color:#f92672">import</span> load_img
<span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#f92672">as</span> plt

orig_img <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(load_img(<span style="color:#e6db74">&#39;./image/hummingbird.jpg&#39;</span>),dtype<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>uint8)
plt<span style="color:#f92672">.</span>imshow(orig_img)
plt<span style="color:#f92672">.</span>show()
</code></pre></div><p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/193401/2219075e-28fc-5c7e-6855-f04603d4320e.png" alt="hummingbird.png"></p>
<h4 id="score-map-obtained-by-cam">Score-Map obtained by CAM</h4>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> keras.applications.vgg16 <span style="color:#f92672">import</span> VGG16
<span style="color:#f92672">from</span> gradcamutils <span style="color:#f92672">import</span> read_and_preprocess_img
<span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#f92672">as</span> plt

model <span style="color:#f92672">=</span> VGG16(include_top<span style="color:#f92672">=</span>True, weights<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;imagenet&#39;</span>)
layer_name <span style="color:#f92672">=</span><span style="color:#e6db74">&#39;block5_conv3&#39;</span>
img_array <span style="color:#f92672">=</span> read_and_preprocess_img(<span style="color:#e6db74">&#39;./image/hummingbird.jpg&#39;</span>, size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">224</span>,<span style="color:#ae81ff">224</span>))

score_cam <span style="color:#f92672">=</span> ScoreCam(model,img_array,layer_name)

plt<span style="color:#f92672">.</span>imshow(score_cam)
plt<span style="color:#f92672">.</span>show()
</code></pre></div><p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/193401/094222f7-f411-8cad-e5b2-a849fcb7bce9.png" alt="heatmap.png"></p>
<h2 id="argument-explanation">Argument explanation</h2>
<ul>
<li>model: model instance of keras</li>
<li>img_array: Pre-processed data of the image for which you want to determine the gaze area. Must be in a form that can immediately execute <code>predict</code>, such as <code>model.predict(img_array)</code></li>
<li>layer_name: Name of the activation layer immediately after the final convolution layer. If the activation layer is included in the convolution layer, the name of the convolution layer is enough. You can check the layer name with <code>model.summary()</code>.-max_N: Setting value for speedup that I implemented arbitrarily. If <code>-1</code>, it is the original Score-CAM. Specifying a natural number reduces the number of CNN inferences to that number. Recommended value is about 10. A large value only increases the processing time and does not affect the heat map so much, but if it is made too small, the heat map will change.</li>
</ul>
<h3 id="other-notes">Other notes</h3>
<ul>
<li>Assumes a model that has 3 channel images such as RGB and BGR as input.</li>
<li>In a model with many layers, the coordinates of the array in the final convolution layer may differ from the vertical and horizontal coordinates in the input image **, and a good heat map may not appear. When using famous models such as ResNet, Xception and MobileNet, <strong>be careful of the layer depth</strong>.</li>
</ul>
<p>Compared with #Grad-CAM, Grad-CAM++</p>
<p>Let&rsquo;s display the heat map obtained above overlaid on the original image.</p>
<p>For Grad-CAM and Grad-CAM++, I used the code of <a href="https://github.com/totti0223/gradcamplusplus">gradcam++ for keras</a>.</p>
<p>The execution code can be found on <a href="https://github.com/tabayashi0117/Score-CAM/blob/master/Score-CAM.ipynb">github</a>.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/193401/c4964101-617c-2e76-8fce-157466105117.png" alt="sample_outputs.png"></p>
<ul>
<li>The image displayed as <code>emphasized</code> is the one that shows the point of interest more clearly by applying threshold processing to the heat map.</li>
<li>Score-CAM seems to pick up the gaze area evenly.</li>
<li>Guided Backpropagation is posted for the time being, but as pointed out in <a href="https://qiita.com/tsu-gawa/items/e3e4480a7adbc6d1ee17">here</a>, <strong>Neural net information is not reflected. There is suspicion</strong>.</li>
<li>If you are extracting the contour you are gazing at, it is still better to display the gradient as an image **, so the grading as an image is calculated and overlaid is the bottom image.</li>
</ul>
<p>Only the results are displayed for other images.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/193401/a3acf8d4-762d-b2b2-d68d-f23dbae225c6.png" alt="dog.png"></p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/193401/be3ed80b-fb50-6cd6-6b0e-397218a26e5b.png" alt="spoonbill.png"></p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/193401/96568b18-3e2d-e7f7-ff7c-dd022a5a7649.png" alt="border_collie.png"></p>
<p>#Comparison of processing speed</p>
<p>Measure the processing speed with Google cola boratory. Uses GPU.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Grad-CAM&#34;</span>)
<span style="color:#f92672">%</span>timeit grad_cam <span style="color:#f92672">=</span> GradCam(model, img_array, layer_name)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Grad-CAM++&#34;</span>)
<span style="color:#f92672">%</span>timeit grad_cam_plus_plus <span style="color:#f92672">=</span> GradCamPlusPlus(model, img_array, layer_name)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Score-Cam&#34;</span>)
<span style="color:#f92672">%</span>timeit score_cam <span style="color:#f92672">=</span> ScoreCam(model, img_array, layer_name)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Faster-Score-Cam N=10&#34;</span>)
<span style="color:#f92672">%</span>timeit faster_score_cam <span style="color:#f92672">=</span> ScoreCam(model, img_array, layer_name, max_N<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Faster-Score-Cam N=3&#34;</span>)
<span style="color:#f92672">%</span>timeit faster_score_cam <span style="color:#f92672">=</span> ScoreCam(model, img_array, layer_name, max_N<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Guided-BP}&#34;</span>)
<span style="color:#f92672">%</span>timeit saliency <span style="color:#f92672">=</span> GuidedBackPropagation(guided_model, img_array, layer_name)
</code></pre></div><pre><code class="language-output" data-lang="output">Grad-CAM
1 loop, best of 3: 196 ms per loop
Grad-CAM++
1 loop, best of 3: 221 ms per loop
Score-Cam
1 loop, best of 3: 5.24 s per loop
Faster-Score-Cam N=10
1 loop, best of 3: 307 ms per loop
Faster-Score-Cam N=3
The slowest run took 4.45 times longer than the fastest.This could mean that an intermediate result is being cached.
1 loop, best of 3: 238 ms per loop
Guided-BP}
1 loop, best of 3: 415 ms per loop
</code></pre><p>As you can see, <strong>Score-CAM is very heavy processing</strong>. <strong>It takes 25 times more time than Grad-CAM</strong>.</p>
<h1 id="improved-processing-speed-faster-score-cam">Improved processing speed (Faster-Score-CAM)</h1>
<p>An experiment using the output of the final convolution layer (512 channels for VGG16) shows that several channels are dominant in the final heat map generation. Faster-Score-CAM is the one that is added the process of preferentially using a mask image with a large map variance**. (The name is arbitrary. If you set <code>max_N=-1</code>, it becomes the original Score-CAM.)</p>
<p>The effect is as described in <strong>Comparison of processing speed</strong>, and it is possible to speed up more than 10 times**.
Still, Grad-CAM++ is faster.</p>
<h1 id="when-using-your-own-model">When using your own model</h1>
<p>In order to confirm the practicality, Score-CAM is applied to the own model trained by the open data set.</p>
<p><a href="https://resources.mpi-inf.mpg.de/conference/dagm/2007/prizes.html">DAGM Dataset</a>isusedasadataset,andResNet(ashallowonewithabout80layers) is used as a model.</p>
<h2 id="dagm-data-set-preparation">DAGM data set preparation</h2>
<p>Download <a href="https://resources.mpi-inf.mpg.de/conference/dagm/2007/prizes.html">DAGM Dataset</a> and unzip it. Please rewrite the path <code>dagm_path</code>.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> keras.utils <span style="color:#f92672">import</span> to_categorical
<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">import</span> glob
<span style="color:#f92672">from</span> sklearn.model_selection <span style="color:#f92672">import</span> train_test_split
<span style="color:#f92672">from</span> gradcamutils <span style="color:#f92672">import</span> read_and_preprocess_img

num_classes <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>
img_size <span style="color:#f92672">=</span> (<span style="color:#ae81ff">224</span>,<span style="color:#ae81ff">224</span>)
dagm_path <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;./DAGM&#34;</span>

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">get_dagm_data</span>(names):
    x <span style="color:#f92672">=</span> []
    y <span style="color:#f92672">=</span> []
    <span style="color:#66d9ef">for</span> i, name <span style="color:#f92672">in</span> enumerate(names):
        <span style="color:#66d9ef">for</span> path <span style="color:#f92672">in</span> glob<span style="color:#f92672">.</span>glob(f<span style="color:#e6db74">&#34;{dagm_path}/{name}/*.png&#34;</span>):
            img_array <span style="color:#f92672">=</span> read_and_preprocess_img(path, size<span style="color:#f92672">=</span>img_size)
            x<span style="color:#f92672">.</span>append(img_array)
            y<span style="color:#f92672">.</span>append(i)

    x <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>concatenate(x, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)
    y <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(y)

    x_train, x_test, y_train, y_test <span style="color:#f92672">=</span> train_test_split(x, y, test_size<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">111</span>)

    y_train <span style="color:#f92672">=</span> to_categorical(y_train, num_classes)
    y_test <span style="color:#f92672">=</span> to_categorical(y_test, num_classes)

    <span style="color:#66d9ef">print</span>(x_train<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>],<span style="color:#e6db74">&#39;train samples&#39;</span>)
    <span style="color:#66d9ef">print</span>(x_test<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>],<span style="color:#e6db74">&#39;test samples&#39;</span>)
    <span style="color:#66d9ef">return</span> x_train, x_test, y_train, y_test

x_train, x_test, y_train, y_test <span style="color:#f92672">=</span> get_dagm_data([<span style="color:#e6db74">&#34;Class1&#34;</span>,<span style="color:#e6db74">&#34;Class1_def&#34;</span>])
</code></pre></div><h2 id="resnet-preparation">ResNet preparation</h2>
<p>Please use the one that is cut off from ResNet included in applications of keras. (It&rsquo;s not very good, but it works, so it&rsquo;s good.)</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> keras.applications.resnet50 <span style="color:#f92672">import</span> ResNet50
<span style="color:#f92672">from</span> keras.models <span style="color:#f92672">import</span> Model
<span style="color:#f92672">from</span> keras.optimizers <span style="color:#f92672">import</span> Adam
<span style="color:#f92672">from</span> keras.layers <span style="color:#f92672">import</span> Dense, Input, Activation, GlobalAveragePooling2D
<span style="color:#f92672">from</span> keras.callbacks <span style="color:#f92672">import</span> EarlyStopping, ModelCheckpoint

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">build_ResNet</span>():
    model <span style="color:#f92672">=</span> ResNet50(include_top<span style="color:#f92672">=</span>True, input_tensor<span style="color:#f92672">=</span>Input(shape<span style="color:#f92672">=</span>(img_size[<span style="color:#ae81ff">0</span>],img_size[<span style="color:#ae81ff">1</span>],<span style="color:#ae81ff">3</span>)))

    x <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>layers[<span style="color:#f92672">-</span><span style="color:#ae81ff">98</span>]<span style="color:#f92672">.</span>output
    x <span style="color:#f92672">=</span> Activation(<span style="color:#e6db74">&#39;relu&#39;</span>, name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;act_last&#34;</span>)(x)
    x <span style="color:#f92672">=</span> GlobalAveragePooling2D()(x)
    x <span style="color:#f92672">=</span> Dense(<span style="color:#ae81ff">2</span>, name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;dense_out&#34;</span>)(x)
    outputs <span style="color:#f92672">=</span> Activation(<span style="color:#e6db74">&#39;softmax&#39;</span>)(x)

    model <span style="color:#f92672">=</span> Model(model<span style="color:#f92672">.</span>input, outputs)
    <span style="color:#75715e"># model.summary()model.compile(loss=&#39;binary_crossentropy&#39;,</span>
                  optimizer<span style="color:#f92672">=</span>Adam(amsgrad<span style="color:#f92672">=</span>True),
                  metrics<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;accuracy&#39;</span>])
    <span style="color:#66d9ef">return</span> model

model <span style="color:#f92672">=</span> build_ResNet()

es_cb <span style="color:#f92672">=</span> EarlyStopping(monitor<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;val_loss&#39;</span>, patience<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>, verbose<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>, mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;auto&#39;</span>)
chkpt <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;./resnet_weight_DAGM.h5&#39;</span>
cp_cb <span style="color:#f92672">=</span> ModelCheckpoint(filepath <span style="color:#f92672">=</span> chkpt, monitor<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;val_loss&#39;</span>, verbose<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>, save_best_only<span style="color:#f92672">=</span>True, save_weights_only<span style="color:#f92672">=</span>True, mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;auto&#39;</span>)

epochs <span style="color:#f92672">=</span> <span style="color:#ae81ff">15</span>
batch_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">32</span>

history <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>fit(x_train, y_train,
                    batch_size<span style="color:#f92672">=</span>batch_size,
                    epochs<span style="color:#f92672">=</span>epochs,
                    validation_data<span style="color:#f92672">=</span>(x_test, y_test),
                    callbacks<span style="color:#f92672">=</span>[es_cb,cp_cb],
                    class_weight<span style="color:#f92672">=</span>{<span style="color:#ae81ff">0</span>: <span style="color:#ae81ff">1.</span>, <span style="color:#ae81ff">1</span>: <span style="color:#ae81ff">6.</span>},
                    shuffle<span style="color:#f92672">=</span>True)

<span style="color:#75715e"># 重みをロード</span>
model<span style="color:#f92672">.</span>load_weights(<span style="color:#e6db74">&#39;./resnet_weight_DAGM.h5&#39;</span>)
</code></pre></div><h2 id="傷あり画像に対してgrad-cam--score-cam適用">傷あり画像に対してGrad-CAM, ++, Score-CAM適用</h2>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#f92672">as</span> plt
<span style="color:#f92672">import</span> cv2
<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">from</span> gradcamutils <span style="color:#f92672">import</span> GradCam, GradCamPlusPlus, ScoreCam, GuidedBackPropagation, superimpose, read_and_preprocess_img

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">build_ResNet_and_load</span>():
    model <span style="color:#f92672">=</span> build_ResNet()
    model<span style="color:#f92672">.</span>load_weights(<span style="color:#e6db74">&#39;./resnet_weight_DAGM.h5&#39;</span>)
    <span style="color:#66d9ef">return</span> model

img_path <span style="color:#f92672">=</span> f<span style="color:#e6db74">&#39;{dagm_path}/Class1_def/12.png&#39;</span>
orig_img <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(load_img(img_path),dtype<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>uint8)
img_array <span style="color:#f92672">=</span> read_and_preprocess_img(img_path, size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">224</span>,<span style="color:#ae81ff">224</span>))

layer_name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;act_last&#34;</span>

grad_cam<span style="color:#f92672">=</span>GradCam(model,img_array,layer_name)
grad_cam_superimposed <span style="color:#f92672">=</span> superimpose(img_path, grad_cam)
grad_cam_emphasized <span style="color:#f92672">=</span> superimpose(img_path, grad_cam, emphasize<span style="color:#f92672">=</span>True)

grad_cam_plus_plus<span style="color:#f92672">=</span>GradCamPlusPlus(model,img_array,layer_name)
grad_cam_plus_plus_superimposed <span style="color:#f92672">=</span> superimpose(img_path, grad_cam_plus_plus)
grad_cam_plus_plus_emphasized <span style="color:#f92672">=</span> superimpose(img_path, grad_cam_plus_plus, emphasize<span style="color:#f92672">=</span>True)

score_cam<span style="color:#f92672">=</span>ScoreCam(model,img_array,layer_name)
score_cam_superimposed <span style="color:#f92672">=</span> superimpose(img_path, score_cam)
score_cam_emphasized <span style="color:#f92672">=</span> superimpose(img_path, score_cam, emphasize<span style="color:#f92672">=</span>True)

faster_score_cam<span style="color:#f92672">=</span>ScoreCam(model,img_array,layer_name, max_N<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>)
faster_score_cam_superimposed <span style="color:#f92672">=</span> superimpose(img_path, faster_score_cam)
faster_score_cam_emphasized <span style="color:#f92672">=</span> superimpose(img_path, faster_score_cam, emphasize<span style="color:#f92672">=</span>True)

guided_model <span style="color:#f92672">=</span> build_guided_model(build_ResNet_and_load)
saliency <span style="color:#f92672">=</span> GuidedBackPropagation(guided_model, img_array, layer_name)
saliency_resized <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>resize(saliency, (orig_img<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">1</span>], orig_img<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>]))

grad_cam_resized <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>resize(grad_cam, (orig_img<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">1</span>], orig_img<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>]))
guided_grad_cam <span style="color:#f92672">=</span> saliency_resized <span style="color:#f92672">*</span> grad_cam_resized[<span style="color:#f92672">...</span>, np<span style="color:#f92672">.</span>newaxis]

grad_cam_plus_plus_resized <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>resize(grad_cam_plus_plus, (orig_img<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">1</span>], orig_img<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>]))
guided_grad_cam_plus_plus <span style="color:#f92672">=</span> saliency_resized <span style="color:#f92672">*</span> grad_cam_plus_plus_resized[<span style="color:#f92672">...</span>, np<span style="color:#f92672">.</span>newaxis]

score_cam_resized <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>resize(score_cam, (orig_img<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">1</span>], orig_img<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>]))
guided_score_cam <span style="color:#f92672">=</span> saliency_resized <span style="color:#f92672">*</span> score_cam_resized[<span style="color:#f92672">...</span>, np<span style="color:#f92672">.</span>newaxis]

faster_score_cam_resized <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>resize(faster_score_cam, (orig_img<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">1</span>], orig_img<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>]))
guided_faster_score_cam <span style="color:#f92672">=</span> saliency_resized <span style="color:#f92672">*</span> faster_score_cam_resized[<span style="color:#f92672">...</span>, np<span style="color:#f92672">.</span>newaxis]

img_gray <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>imread(img_path, <span style="color:#ae81ff">0</span>)
dx <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>Sobel(img_gray, cv2<span style="color:#f92672">.</span>CV_64F, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">0</span>, ksize<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>)
dy <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>Sobel(img_gray, cv2<span style="color:#f92672">.</span>CV_64F, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, ksize<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>)
grad <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>sqrt(dx <span style="color:#f92672">**</span> <span style="color:#ae81ff">2</span> <span style="color:#f92672">+</span> dy <span style="color:#f92672">**</span> <span style="color:#ae81ff">2</span>)  <span style="color:#75715e"># 画像の勾配を取得</span>
grad <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>dilate(grad,kernel<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>ones((<span style="color:#ae81ff">5</span>,<span style="color:#ae81ff">5</span>)), iterations<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)  <span style="color:#75715e"># 太らせる処理</span>
grad <span style="color:#f92672">-=</span> np<span style="color:#f92672">.</span>min(grad)
grad <span style="color:#f92672">/=</span> np<span style="color:#f92672">.</span>max(grad)  <span style="color:#75715e"># scale 0. to 1.</span>

grad_times_grad_cam <span style="color:#f92672">=</span> grad <span style="color:#f92672">*</span> grad_cam_resized
grad_times_grad_cam_plus_plus <span style="color:#f92672">=</span> grad <span style="color:#f92672">*</span> grad_cam_plus_plus_resized
grad_times_score_cam <span style="color:#f92672">=</span> grad <span style="color:#f92672">*</span> score_cam_resized
grad_times_faster_score_cam <span style="color:#f92672">=</span> grad <span style="color:#f92672">*</span> faster_score_cam_resized

fig, ax <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>subplots(nrows<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span>,ncols<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>, figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">18</span>, <span style="color:#ae81ff">16</span>))
ax[<span style="color:#ae81ff">0</span>,<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>imshow(orig_img)
ax[<span style="color:#ae81ff">0</span>,<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>set_title(<span style="color:#e6db74">&#34;input image&#34;</span>)
ax[<span style="color:#ae81ff">0</span>,<span style="color:#ae81ff">1</span>]<span style="color:#f92672">.</span>imshow(grad_cam_superimposed)
ax[<span style="color:#ae81ff">0</span>,<span style="color:#ae81ff">1</span>]<span style="color:#f92672">.</span>set_title(<span style="color:#e6db74">&#34;Grad-CAM&#34;</span>)
ax[<span style="color:#ae81ff">0</span>,<span style="color:#ae81ff">2</span>]<span style="color:#f92672">.</span>imshow(grad_cam_plus_plus_superimposed)
ax[<span style="color:#ae81ff">0</span>,<span style="color:#ae81ff">2</span>]<span style="color:#f92672">.</span>set_title(<span style="color:#e6db74">&#34;Grad-CAM++&#34;</span>)
ax[<span style="color:#ae81ff">0</span>,<span style="color:#ae81ff">3</span>]<span style="color:#f92672">.</span>imshow(score_cam_superimposed)
ax[<span style="color:#ae81ff">0</span>,<span style="color:#ae81ff">3</span>]<span style="color:#f92672">.</span>set_title(<span style="color:#e6db74">&#34;Score-CAM&#34;</span>)
ax[<span style="color:#ae81ff">0</span>,<span style="color:#ae81ff">4</span>]<span style="color:#f92672">.</span>imshow(faster_score_cam_superimposed)
ax[<span style="color:#ae81ff">0</span>,<span style="color:#ae81ff">4</span>]<span style="color:#f92672">.</span>set_title(<span style="color:#e6db74">&#34;Faster-Score-CAM&#34;</span>)
ax[<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>imshow(orig_img)
ax[<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>set_title(<span style="color:#e6db74">&#34;input image&#34;</span>)
ax[<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">1</span>]<span style="color:#f92672">.</span>imshow(grad_cam_emphasized)
ax[<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">1</span>]<span style="color:#f92672">.</span>set_title(<span style="color:#e6db74">&#34;Grad-CAM emphasized&#34;</span>)
ax[<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">2</span>]<span style="color:#f92672">.</span>imshow(grad_cam_plus_plus_emphasized)
ax[<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">2</span>]<span style="color:#f92672">.</span>set_title(<span style="color:#e6db74">&#34;Grad-CAM++ emphasized&#34;</span>)
ax[<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">3</span>]<span style="color:#f92672">.</span>imshow(score_cam_emphasized)
ax[<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">3</span>]<span style="color:#f92672">.</span>set_title(<span style="color:#e6db74">&#34;Score-CAM emphasized&#34;</span>)
ax[<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">4</span>]<span style="color:#f92672">.</span>imshow(faster_score_cam_emphasized)
ax[<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">4</span>]<span style="color:#f92672">.</span>set_title(<span style="color:#e6db74">&#34;Faster-Score-CAM emphasized&#34;</span>)
ax[<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>imshow(saliency_resized)
ax[<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>set_title(<span style="color:#e6db74">&#34;Guided-BP&#34;</span>)
ax[<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">1</span>]<span style="color:#f92672">.</span>imshow(guided_grad_cam)
ax[<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">1</span>]<span style="color:#f92672">.</span>set_title(<span style="color:#e6db74">&#34;Guided-Grad-CAM&#34;</span>)
ax[<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">2</span>]<span style="color:#f92672">.</span>imshow(guided_grad_cam_plus_plus)
ax[<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">2</span>]<span style="color:#f92672">.</span>set_title(<span style="color:#e6db74">&#34;Guided-Grad-CAM++&#34;</span>)
ax[<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">3</span>]<span style="color:#f92672">.</span>imshow(guided_score_cam)
ax[<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">3</span>]<span style="color:#f92672">.</span>set_title(<span style="color:#e6db74">&#34;Guided-Score-CAM&#34;</span>)
ax[<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">4</span>]<span style="color:#f92672">.</span>imshow(guided_faster_score_cam)
ax[<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">4</span>]<span style="color:#f92672">.</span>set_title(<span style="color:#e6db74">&#34;Guided-Faster-Score-CAM&#34;</span>)
ax[<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>imshow(grad, <span style="color:#e6db74">&#39;gray&#39;</span>)
ax[<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>set_title(<span style="color:#e6db74">&#34;grad&#34;</span>)
ax[<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">1</span>]<span style="color:#f92672">.</span>imshow(grad_times_grad_cam, <span style="color:#e6db74">&#39;gray&#39;</span>)
ax[<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">1</span>]<span style="color:#f92672">.</span>set_title(<span style="color:#e6db74">&#34;grad * Grad-CAM&#34;</span>)
ax[<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">2</span>]<span style="color:#f92672">.</span>imshow(grad_times_grad_cam_plus_plus, <span style="color:#e6db74">&#39;gray&#39;</span>)ax[<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">2</span>]<span style="color:#f92672">.</span>set_title(<span style="color:#e6db74">&#34;grad * Grad-CAM++&#34;</span>)
ax[<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">3</span>]<span style="color:#f92672">.</span>imshow(grad_times_score_cam,<span style="color:#e6db74">&#39;gray&#39;</span>)
ax[<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">3</span>]<span style="color:#f92672">.</span>set_title(<span style="color:#e6db74">&#34;grad * Score-CAM&#34;</span>)
ax[<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">4</span>]<span style="color:#f92672">.</span>imshow(grad_times_faster_score_cam,<span style="color:#e6db74">&#39;gray&#39;</span>)
ax[<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">4</span>]<span style="color:#f92672">.</span>set_title(<span style="color:#e6db74">&#34;grad * Faster-Score-CAM&#34;</span>)
<span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">4</span>):
    <span style="color:#66d9ef">for</span> j <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">5</span>):
        ax[i,j]<span style="color:#f92672">.</span>axis(<span style="color:#e6db74">&#39;off&#39;</span>)
plt<span style="color:#f92672">.</span>show()
</code></pre></div><p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/193401/4aa31872-81e4-cd61-4e34-cbe8592244f2.png" alt="class1.png"></p>
<ul>
<li>Every method seems to be able to detect the position of the flaw well.</li>
<li>It seems that it is difficult to display only the scratches. (Since the information of the final conv layer is taken out, there is no help for it)</li>
</ul>
<h2 id="from-class-2-to-class-6">From Class 2 to Class 6</h2>
<p>Only 5 results for each class will be posted.</p>
<h4 id="class2">Class2</h4>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/193401/a97a2561-a5b5-aabe-22b9-86b14def5b1e.png" alt="Class2_result_0.png"></p>
<h4 id="class3">Class3</h4>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/193401/11226b45-87e7-3a07-b356-7a87e5bbceba.png" alt="Class3_result_0.png"></p>
<h4 id="class4">Class4</h4>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/193401/25c27c56-06ea-ddbb-0bea-675d01e9dbc0.png" alt="Class4_result_0.png"></p>
<h4 id="class5">Class5</h4>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/193401/9f4189c5-b497-3699-0590-05c07837aca8.png" alt="Class5_result_0.png"></p>
<h4 id="class6">Class6</h4>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/193401/8518a26b-7d8a-65e3-d97c-e2f6ea367b32.png" alt="Class6_result_0.png"></p>
<p>It seems that the position of the wound can be expressed almost correctly.</p>
<p>#Remarks</p>
<ul>
<li>In <strong>anomaly detection</strong>, it can be used for rough visualization of anomalous parts.</li>
<li>It is very inconvenient to use <strong>limited models</strong> in any of Grad-CAM, ++, and Score-CAM.
-It is difficult to use a model with many layers because the coordinates of the final conv layer and the coordinates of the input image must correspond well.</li>
</ul>
<h1 id="reference">Reference</h1>
<ul>
<li><a href="https://arxiv.org/abs/1910.01279">Original Paper</a></li>
<li><a href="https://github.com/totti0223/gradcamplusplus">gradcam++ for keras</a></li>
</ul>

    </article>
  </div>

  
  
  
  <script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-169005401-1', 'auto');
  ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  

  
<link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.css" />
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#216942",
      "text": "#b2d192"
    },
    "button": {
      "background": "#afed71"
    }
  }
})});
</script>

</body>

</html>
