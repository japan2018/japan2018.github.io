<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  <meta name="generator" content="Hugo 0.72.0" />

  
  <meta name="description" content="Some description">
  

  
  <link rel="apple-touch-icon" sizes="180x180" href="https://memotut.com/apple-touch-icon.png">

  
  <link rel="icon" type="image/png" sizes="32x32" href="https://memotut.com/favicon-32x32.png">

  
  <link rel="icon" type="image/png" sizes="16x16" href="https://memotut.com/favicon-16x16.png">

  
  <link rel="manifest" href="https://memotut.com/site.webmanifest">

  
  <link rel="mask-icon" href="https://memotut.com/safari-pinned-tab.svg" color="#5bbad5">

  <meta name="msapplication-TileColor" content="#da532c">

  <meta name="theme-color" content="#ffffff">

  
  <link rel="stylesheet" href="https://memotut.com/css/bootstrap.min.css" />

  
  <title>[Python] Can AI distinguish Carlos Ghosn and Mr. Bean (Face recognition using face landmark) | Memo Tut</title>
  

  <style>
body {
  min-width: 300px;
}

.custom-navbar {
  margin-bottom: 1em;
  height: 60px;
}

.custom-navbar a {
  display: inline-block; 
  padding: 18px 0;
  margin-right: 1em; 
  font-weight: bold; 
}

.custom-navbar a:hover,
.custom-navbar a:focus {
  text-decoration: none; 
}

@media print {
  .custom-navbar {
    display: none;
  }
}

article {
  padding-bottom: 1em;
}

img {
  max-width: 100%;
}


body {
  background-color: #fff;
}



body {
  color: #212529;
}



a {
  color: #007bff;
}



a:hover,
a:focus {
  color: #0056b3;
}



.custom-navbar {
  background-color: #212529;
}



.custom-navbar a {
  color: rgba(255, 255, 255, 0.75);
}



.custom-navbar a:hover,
.custom-navbar a:focus {
  color: rgba(255, 255, 255, 1);
}



.container {
  max-width: 800px;
}



pre {
  display: block;
  padding: 9.5px;
  word-break: break-all;
  word-wrap: break-word;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre code {
  padding: 0;
  font-size: inherit;
  color: inherit; 
  white-space: pre-wrap;
  background-color: transparent;
  border: none;
  border-radius: 0;
}

code {
  padding: 2px 4px;
  color: inherit; 
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
  font-size: .9em;
}



blockquote,
.blockquote {
  padding: 10px 20px;
  margin: 0 0 20px;
  font-size: 1em;
  border-left: 5px solid #6c757d;
}

</style>
</head>

<body>
  <nav class="custom-navbar">
  <div class="container">
    
    <a href="/">Posts</a>
    
    <a href="/tags/">Tags</a>
    
    <a href="/about/">About</a>
    
    <a href="/index.xml">RSS</a>
    
  </div>
</nav>
  
  <div class="container">
    <article>
      <h1>[Python] Can AI distinguish Carlos Ghosn and Mr. Bean (Face recognition using face landmark)</h1>
<p>
  <small class="text-secondary">
  
  
  Jan 1, 2020
  </small>
  

<small><code><a href="https://memotut.com/tags/python">Python</a></code></small>


<small><code><a href="https://memotut.com/tags/opencv"> OpenCV</a></code></small>


<small><code><a href="https://memotut.com/tags/machine-learning"> machine learning</a></code></small>


<small><code><a href="https://memotut.com/tags/material"> material</a></code></small>


<small><code><a href="https://memotut.com/tags/image-recognition"> image recognition</a></code></small>

</p>
<pre><code>#Introduction
</code></pre>
<p>The news is about the news that Carlos Ghosn, the former chairman of Nissan Motor Co., Ltd., broke bail conditions and traveled to Lebanon.
I&rsquo;ve been thinking for a long time, but it&rsquo;s similar to Mr. Bean&hellip;
<img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/246881/364f6dda-1069-f61b-ab6e-33ab79ffb174.jpeg" alt="images.jpeg"></p>
<p>Left: [Carlos Ghosn](<a href="https://www.google.com/search?q=Carlos+Ghosn&amp;sxsrf=ACYBGNS1gsNQxqfqi7GRWUUeSSZ6CRix8w:1577813710879&amp;source=lnms&amp;tbm=isch&amp;Ah&amp;EqjQAQBQ&amp;QAQBQBQ&amp;QAQBQ&amp;QB">https://www.google.com/search?q=Carlos+Ghosn&amp;sxsrf=ACYBGNS1gsNQxqfqi7GRWUUeSSZ6CRix8w:1577813710879&amp;source=lnms&amp;tbm=isch&amp;Ah&amp;EqjQAQBQ&amp;QAQBQBQ&amp;QAQBQ&amp;QB</a>
Right: [Mr. Bean (Rowan Atkinson)](<a href="https://www.google.com/search?q=rowan+atkinson&amp;biw=1386&amp;bih=710&amp;sxsrf=ACYBGNTsdddnLF7jgPr9RTePeEMGgREpyA:1577813660092&amp;source=lnms&amp;tbm=isch&amp;saQ&amp;isch&amp;saq">https://www.google.com/search?q=rowan+atkinson&amp;biw=1386&amp;bih=710&amp;sxsrf=ACYBGNTsdddnLF7jgPr9RTePeEMGgREpyA:1577813660092&amp;source=lnms&amp;tbm=isch&amp;saQ&amp;isch&amp;saq</a></p>
<p>It was a year-end and New Year holiday, so I made a little classifier using a neural network.
If you google it, a lot of images of the two people will appear, so it was good for CNN, but
This time, as another approach, I would like to perform classification based on the position of landmarks on the face.</p>
<p>Please note that coding is rough.</p>
<p>The source code and the image data used are given on GitHub.
<a href="https://github.com/KoutaOhishi/face_identification">face_identification</a></p>
<h2 id="environment">Environment</h2>
<ul>
<li>Ubuntu 16.04</li>
<li>Python 2.7</li>
<li>Keras 1.14.0</li>
<li>OpenCV 3.4.2</li>
</ul>
<p>#Processing flow</p>
<ol>
<li>Face detection using Cascade of OpenCV</li>
<li>Estimate 68 landmarks using dlib based on the detected face area</li>
<li>Input the position of 68 points to the classifier</li>
<li>Carlos if output is 0, Mr. Bean if output is 1.</li>
</ol>
<p>#Create dataset
Prepare 10 photos of Carlos and Bean each.
Since it is unforgivable if there are only 20 images, I resize each image and pad it.</p>
<p>We use opencv&rsquo;s cascade for face recognition and dlib for landmark estimation.
*Landmark estimation is based on this article. (<a href="https://qiita.com/s-kajioka/items/b9207812fc968161f78b">I tried OpenCV face recognition with Python</a>))</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-dataset_generator.py" data-lang="dataset_generator.py"><span style="color:#75715e">#!/usr/bin/env python</span>
<span style="color:#75715e">#coding:utf-8</span>
<span style="color:#f92672">import</span> cv2
<span style="color:#f92672">import</span> dlib
<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np

cascade_path <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;~/face_identification/model/haarcascade_frontalface_alt.xml&#34;</span>
cascade <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>CascadeClassifier(cascade_path)

model_path <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;~/face_identification/model/shape_predictor_68_face_landmarks.dat&#34;</span>
predictor <span style="color:#f92672">=</span> dlib<span style="color:#f92672">.</span>shape_predictor(model_path)
detector <span style="color:#f92672">=</span> dlib<span style="color:#f92672">.</span>get_frontal_face_detector()

image_file_dir <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;~/face_identification/images/carlos/&#34;</span>
<span style="color:#75715e">#image_file_dir = &#34;~/face_identification/images/rowan/&#34;</span>

save_file_path <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;~/face_identification/dataset/carlos.csv&#34;</span>
<span style="color:#75715e">#save_file_path = &#34;~/face_identification/dataset/rowan.csv&#34;</span>

face_landmarks <span style="color:#f92672">=</span> []
<span style="color:#66d9ef">for</span> n <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">10</span>):
<span style="color:#75715e">#image_file_name = &#34;carlos&#34;+str(n)+&#34;.jpeg&#34;</span>
image_file_name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;rowan&#34;</span><span style="color:#f92672">+</span>str(n)<span style="color:#f92672">+</span><span style="color:#e6db74">&#34;.jpeg&#34;</span>
It<span style="color:#e6db74">&#39;s a sequel.</span>
raw_img <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>imread(image_file_dir<span style="color:#f92672">+</span>image_file_name)
original_width, original_height <span style="color:#f92672">=</span> raw_img<span style="color:#f92672">.</span>shape[:<span style="color:#ae81ff">2</span>]
multiple_list <span style="color:#f92672">=</span> [<span style="color:#ae81ff">0.5</span>, <span style="color:#ae81ff">0.75</span>, <span style="color:#ae81ff">1.0</span>, <span style="color:#ae81ff">1.25</span>, <span style="color:#ae81ff">1.5</span>, <span style="color:#ae81ff">1.75</span>, <span style="color:#ae81ff">2.0</span>]
<span style="color:#66d9ef">for</span> m <span style="color:#f92672">in</span> multiple_list:
size <span style="color:#f92672">=</span> (int(original_height<span style="color:#f92672">*</span>m), int(original_width<span style="color:#f92672">*</span>m))
img <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>resize(raw_img, size)

gray_img <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>cvtColor(img, cv2<span style="color:#f92672">.</span>COLOR_RGB2GRAY)
faces <span style="color:#f92672">=</span> cascade<span style="color:#f92672">.</span>detectMultiScale(gray_img)

<span style="color:#66d9ef">if</span> len(faces) <span style="color:#f92672">!=</span> <span style="color:#ae81ff">0</span>:
<span style="color:#66d9ef">for</span>(x, y, width, height) <span style="color:#f92672">in</span> faces:
cv2<span style="color:#f92672">.</span>rectangle(img, (x, y), (x<span style="color:#f92672">+</span>width, y<span style="color:#f92672">+</span>height), (<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">255</span>), <span style="color:#ae81ff">1</span>)
rects <span style="color:#f92672">=</span> detector(gray_img, <span style="color:#ae81ff">1</span>)
landmarks <span style="color:#f92672">=</span> []
<span style="color:#66d9ef">for</span> rect <span style="color:#f92672">in</span> rects:
landmarks<span style="color:#f92672">.</span>append(np<span style="color:#f92672">.</span>array([[p<span style="color:#f92672">.</span>x, p<span style="color:#f92672">.</span>y] <span style="color:#66d9ef">for</span> p <span style="color:#f92672">in</span> predictor(gray_img, rect)<span style="color:#f92672">.</span>parts()]))
It<span style="color:#e6db74">&#39;s a sequel.</span>
<span style="color:#66d9ef">for</span> landmark <span style="color:#f92672">in</span> landmarks:
face_landmark <span style="color:#f92672">=</span> []
<span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(len(landmark)):
cv2<span style="color:#f92672">.</span>drawMarker(img, (landmark[i][<span style="color:#ae81ff">0</span>], landmark[i][<span style="color:#ae81ff">1</span>]), (<span style="color:#ae81ff">21</span>, <span style="color:#ae81ff">255</span>, <span style="color:#ae81ff">12</span>))
                                                <span style="color:#75715e"># Normalize position of coordinates landmark_x = (landmark[i][0]-x)*100.00/width</span>
landmark_y <span style="color:#f92672">=</span> (landmark[i][<span style="color:#ae81ff">1</span>]<span style="color:#f92672">-</span>y)<span style="color:#f92672">*</span><span style="color:#ae81ff">100.00</span><span style="color:#f92672">/</span>height
face_landmark<span style="color:#f92672">.</span>append(landmark_x)
face_landmark<span style="color:#f92672">.</span>append(landmark_y)
face_landmarks<span style="color:#f92672">.</span>append(np<span style="color:#f92672">.</span>array(face_landmark)<span style="color:#f92672">.</span>flatten())
It<span style="color:#e6db74">&#39;s a sequel.</span>

cv2<span style="color:#f92672">.</span>imshow(<span style="color:#e6db74">&#34;viewer&#34;</span>, img)
key <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>waitKey(<span style="color:#ae81ff">100</span>)
It<span style="color:#e6db74">&#39;s a sequel.</span>
<span style="color:#66d9ef">print</span> <span style="color:#e6db74">&#34;finish&#34;</span>
np_dataset <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(face_landmarks)
np<span style="color:#f92672">.</span>savetxt(save_file_path, np_dataset)
</code></pre></div><p>The landmarks of Carlos and Gone, respectively, are output to a csv file.
(Please replace the commented out part of dataset_generator.py and execute it twice.)</p>
<Img width = "321" alt = "68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f3237333436322f66613562353639632d613130662d396462382d396566632d6562376132333232633230372e706e67.png" src = "https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/246881/3e39d90c-8cb6-ba35-ac62 -004d014b6674.png">
<p>You can get 68 landmarks on your face.
The x and y coordinates of each point are stored in an array in order (so the value that can be taken from one face is 68 × 2 = 136)
In addition, the coordinate values vary greatly depending on the size of the face, so they are normalized.
Understanding Coco is still subtle. (Please tell me if there is a good method)</p>
<h1 id="network-configuration">Network configuration</h1>
<p>Create a simple feed forward type neural network with Keras.
The middle tier has three simple configurations.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-network_model.py" data-lang="network_model.py"><span style="color:#75715e">#!/usr/bin/env python</span>
<span style="color:#75715e">#coding:utf-8</span>
<span style="color:#f92672">from</span> keras.models <span style="color:#f92672">import</span> Sequential
<span style="color:#f92672">from</span> keras.layers <span style="color:#f92672">import</span> Activation, Dense, Dropout

<span style="color:#66d9ef">class</span> <span style="color:#a6e22e">DNNModel</span>():
    <span style="color:#66d9ef">def</span> __init__(self):
        self<span style="color:#f92672">.</span>model <span style="color:#f92672">=</span> Sequential()
        self<span style="color:#f92672">.</span>model<span style="color:#f92672">.</span>add(Dense(<span style="color:#ae81ff">1024</span>, input_dim<span style="color:#f92672">=</span><span style="color:#ae81ff">136</span>))
        self<span style="color:#f92672">.</span>model<span style="color:#f92672">.</span>add(Activation(<span style="color:#e6db74">&#39;relu&#39;</span>))
        self<span style="color:#f92672">.</span>model<span style="color:#f92672">.</span>add(Dropout(<span style="color:#ae81ff">0.1</span>))

        self<span style="color:#f92672">.</span>model<span style="color:#f92672">.</span>add(Dense(<span style="color:#ae81ff">512</span>))
        self<span style="color:#f92672">.</span>model<span style="color:#f92672">.</span>add(Activation(<span style="color:#e6db74">&#39;relu&#39;</span>))
        self<span style="color:#f92672">.</span>model<span style="color:#f92672">.</span>add(Dropout(<span style="color:#ae81ff">0.1</span>))

        self<span style="color:#f92672">.</span>model<span style="color:#f92672">.</span>add(Dense(<span style="color:#ae81ff">256</span>))
        self<span style="color:#f92672">.</span>model<span style="color:#f92672">.</span>add(Activation(<span style="color:#e6db74">&#39;relu&#39;</span>))
        self<span style="color:#f92672">.</span>model<span style="color:#f92672">.</span>add(Dropout(<span style="color:#ae81ff">0.1</span>))

        self<span style="color:#f92672">.</span>model<span style="color:#f92672">.</span>add(Dense(<span style="color:#ae81ff">2</span>))<span style="color:#75715e"># Match with the number of correct labels</span>
        self<span style="color:#f92672">.</span>model<span style="color:#f92672">.</span>add(Activation(<span style="color:#e6db74">&#39;softmax&#39;</span>))
</code></pre></div><p>#Learning</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-train.py" data-lang="train.py"><span style="color:#75715e">#!/usr/bin/env python</span>
<span style="color:#75715e">#coding:utf-8</span>
<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">import</span> keras

<span style="color:#f92672">from</span> network_model <span style="color:#f92672">import</span> DNNModel
<span style="color:#f92672">from</span> keras.optimizers <span style="color:#f92672">import</span> RMSprop, SGD, Adam
<span style="color:#f92672">from</span> keras.utils <span style="color:#f92672">import</span> to_categorical
<span style="color:#f92672">from</span> keras.utils <span style="color:#f92672">import</span> np_utils

carlos_data_path <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;~/face_identification/dataset/carlos.csv&#34;</span>rowan_data_path <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;~/face_identification/dataset/rowan.csv&#34;</span>

weight_file_path <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;~/face_identification/model/weight.hdf5&#34;</span>

landmarks <span style="color:#f92672">=</span> []
labels <span style="color:#f92672">=</span> []

<span style="color:#66d9ef">with</span> open(carlos_data_path, <span style="color:#e6db74">&#34;r&#34;</span>) <span style="color:#66d9ef">as</span> f:
 carlos_lines <span style="color:#f92672">=</span> f<span style="color:#f92672">.</span>read()<span style="color:#f92672">.</span>split(<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>) 
 f<span style="color:#f92672">.</span>close()

<span style="color:#66d9ef">with</span> open(rowan_data_path, <span style="color:#e6db74">&#34;r&#34;</span>) <span style="color:#66d9ef">as</span> f:
 rowan_lines <span style="color:#f92672">=</span> f<span style="color:#f92672">.</span>read()<span style="color:#f92672">.</span>split(<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>)
 f<span style="color:#f92672">.</span>close()

<span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(len(carlos_lines)<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>):
 carlos_line <span style="color:#f92672">=</span> carlos_lines[i]<span style="color:#f92672">.</span>split(<span style="color:#e6db74">&#34; &#34;</span>)
 landmarks<span style="color:#f92672">.</span>append(np<span style="color:#f92672">.</span>array(carlos_line)<span style="color:#f92672">.</span>flatten())
 labels<span style="color:#f92672">.</span>append(<span style="color:#ae81ff">0</span>) <span style="color:#75715e">#カルロスは0</span>

<span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(len(rowan_lines)<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>):
 rowan_line <span style="color:#f92672">=</span> rowan_lines[i]<span style="color:#f92672">.</span>split(<span style="color:#e6db74">&#34; &#34;</span>)
 landmarks<span style="color:#f92672">.</span>append(np<span style="color:#f92672">.</span>array(rowan_line)<span style="color:#f92672">.</span>flatten())
 labels<span style="color:#f92672">.</span>append(<span style="color:#ae81ff">1</span>) <span style="color:#75715e">#Mr.ビーンは1</span>

landmarks <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>asarray(landmarks)<span style="color:#f92672">.</span>astype(<span style="color:#e6db74">&#34;float32&#34;</span>)
labels <span style="color:#f92672">=</span> np_utils<span style="color:#f92672">.</span>to_categorical(labels, <span style="color:#ae81ff">2</span>)

model <span style="color:#f92672">=</span> DNNModel()<span style="color:#f92672">.</span>model
model<span style="color:#f92672">.</span>summary()
model<span style="color:#f92672">.</span>compile(loss<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;binary_crossentropy&#39;</span>, optimizer<span style="color:#f92672">=</span>Adam(lr<span style="color:#f92672">=</span><span style="color:#ae81ff">0.0001</span>), metrics<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;accuracy&#39;</span>])

history <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>fit(landmarks, labels,
    batch_size<span style="color:#f92672">=</span><span style="color:#ae81ff">64</span>,
    epochs<span style="color:#f92672">=</span><span style="color:#ae81ff">3000</span>)

model<span style="color:#f92672">.</span>save_weights(weight_file_path)
<span style="color:#66d9ef">print</span> <span style="color:#e6db74">&#34;model was saved.&#34;</span>
</code></pre></div><p>学習は5分もかからずに終わると思います。</p>
<h1 id="結果">結果</h1>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/246881/882553cd-aed1-e5d8-7597-0270944080a3.jpeg" alt="result0.jpeg">
正解
<img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/246881/a7f66f40-ce7f-dfb8-752c-958c49352ef5.jpeg" alt="result2.jpeg">
正解</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/246881/8f5968c8-7bae-0bd0-1ad3-420f2d4b0d78.jpeg" alt="result4.jpeg">
正解</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/246881/96395474-f9c5-afb5-6ab8-b263456d916b.jpeg" alt="result_.jpeg">
正解</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/246881/9b218d01-e7dd-2441-4dcb-9325cf2462ab.jpeg" alt="result1.jpeg">
失敗
カルロスは顔検出に失敗。
Mr.ビーンは分類に失敗。</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/246881/f2220ee7-386c-646e-8d3a-6a4eb40350f9.jpeg" alt="result3.jpeg">
失敗</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-test.py" data-lang="test.py"><span style="color:#75715e">#!/usr/bin/env python</span>
<span style="color:#75715e">#coding:utf-8</span>
<span style="color:#f92672">import</span> cv2
<span style="color:#f92672">import</span> dlib
<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">import</span> tensorflow <span style="color:#f92672">as</span> tf

<span style="color:#f92672">from</span> network_model <span style="color:#f92672">import</span> DNNModel

cascade_path <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;~/face_identification/model/haarcascade_frontalface_alt.xml&#34;</span>
cascade <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>CascadeClassifier(cascade_path)

model_path <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;~/face_identification/model/shape_predictor_68_face_landmarks.dat&#34;</span>
predictor <span style="color:#f92672">=</span> dlib<span style="color:#f92672">.</span>shape_predictor(model_path)
detector <span style="color:#f92672">=</span> dlib<span style="color:#f92672">.</span>get_frontal_face_detector()

trained_model_path <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;~/face_identification/model/weight.hdf5&#34;</span>
model <span style="color:#f92672">=</span> DNNModel()<span style="color:#f92672">.</span>model    
model<span style="color:#f92672">.</span>load_weights(trained_model_path)
graph <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>get_default_graph()

test_image_path <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;~/face_identification/images/test.jpeg&#34;</span>
result_image_path <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;~/face_identification/images/result.jpeg&#34;</span>

img <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>imread(test_image_path)
gray_img <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>cvtColor(img, cv2<span style="color:#f92672">.</span>COLOR_RGB2GRAY)
faces <span style="color:#f92672">=</span> cascade<span style="color:#f92672">.</span>detectMultiScale(gray_img, minSize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">30</span>, <span style="color:#ae81ff">30</span>))

<span style="color:#66d9ef">if</span> len(faces) <span style="color:#f92672">!=</span> <span style="color:#ae81ff">0</span>:
 <span style="color:#66d9ef">for</span>(x, y, width, height) <span style="color:#f92672">in</span> faces:
  cv2<span style="color:#f92672">.</span>rectangle(img, (x, y), (x<span style="color:#f92672">+</span>width, y<span style="color:#f92672">+</span>height), (<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">255</span>), <span style="color:#ae81ff">1</span>)
  rects <span style="color:#f92672">=</span> detector(gray_img, <span style="color:#ae81ff">1</span>)
  landmarks <span style="color:#f92672">=</span> []
  <span style="color:#66d9ef">for</span> rect <span style="color:#f92672">in</span> rects:
   landmarks<span style="color:#f92672">.</span>append(np<span style="color:#f92672">.</span>array([[p<span style="color:#f92672">.</span>x, p<span style="color:#f92672">.</span>y] <span style="color:#66d9ef">for</span> p <span style="color:#f92672">in</span> predictor(gray_img, rect)<span style="color:#f92672">.</span>parts()]))

  <span style="color:#66d9ef">for</span> landmark <span style="color:#f92672">in</span> landmarks:
   input_data <span style="color:#f92672">=</span> [] 
   face_landmark <span style="color:#f92672">=</span> []
   <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(len(landmark)):
    landmark_x <span style="color:#f92672">=</span> (landmark[i][<span style="color:#ae81ff">0</span>]<span style="color:#f92672">-</span>x)<span style="color:#f92672">*</span><span style="color:#ae81ff">100.00</span><span style="color:#f92672">/</span>width
    landmark_y <span style="color:#f92672">=</span> (landmark[i][<span style="color:#ae81ff">1</span>]<span style="color:#f92672">-</span>y)<span style="color:#f92672">*</span><span style="color:#ae81ff">100.00</span><span style="color:#f92672">/</span>height
    face_landmark<span style="color:#f92672">.</span>append(landmark_x)
    face_landmark<span style="color:#f92672">.</span>append(landmark_y)
   
   face_landmark <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(face_landmark)<span style="color:#f92672">.</span>flatten()   
   input_data<span style="color:#f92672">.</span>append(face_landmark)
   <span style="color:#66d9ef">with</span> graph<span style="color:#f92672">.</span>as_default():
    pred <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>predict(np<span style="color:#f92672">.</span>array(input_data))
   
   result_idx <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>argmax(pred[<span style="color:#ae81ff">0</span>])
   <span style="color:#66d9ef">if</span> result_idx <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span>:
    text <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;Carlos:&#34;</span> <span style="color:#f92672">+</span> str(pred[<span style="color:#ae81ff">0</span>][result_idx])
   <span style="color:#66d9ef">else</span>:
    text <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;Rowan:&#34;</span> <span style="color:#f92672">+</span> str(pred[<span style="color:#ae81ff">0</span>][result_idx])
   
  <span style="color:#75715e">#文字の書き込み</span>
  cv2<span style="color:#f92672">.</span>putText(img, text, (x, y), cv2<span style="color:#f92672">.</span>FONT_HERSHEY_SIMPLEX, <span style="color:#ae81ff">0.5</span>,(<span style="color:#ae81ff">0</span>,<span style="color:#ae81ff">0</span>,<span style="color:#ae81ff">255</span>))

   
<span style="color:#75715e">#cv2.imshow(&#34;viewer&#34;, img)</span>
cv2<span style="color:#f92672">.</span>imwrite(result_image_path, img)
</code></pre></div><h1 id="終わりに">終わりに</h1>
<p>カルロス・ゴーンは手強い。</p>

    </article>
  </div>

  
  
  
  <script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-169005401-1', 'auto');
  ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  

  
<link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.css" />
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#216942",
      "text": "#b2d192"
    },
    "button": {
      "background": "#afed71"
    }
  }
})});
</script>

</body>

</html>
