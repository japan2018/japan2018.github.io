<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>svm on Memo Tut</title>
    <link>https://memotut.com/tags/svm/</link>
    <description>Recent content in svm on Memo Tut</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 26 Sep 2014 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://memotut.com/tags/svm/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>[Python] Calculation of support vector machine (SVM) (using cvxopt)</title>
      <link>https://memotut.com/calculation-of-support-vector-machine-svm-using-cvxopt-faba9/</link>
      <pubDate>Fri, 26 Sep 2014 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/calculation-of-support-vector-machine-svm-using-cvxopt-faba9/</guid>
      <description>Hello.  The calculation of the support vector machine (SVM) is based on the procedure (using cvxopt) of Discontinuation creation &amp;ldquo;soft margin SVM&amp;rdquo; about artificial intelligenceIfyoufollowitexactly,youwillfeelalittlelikecalculatingthesolutionyourself.Inthefollowing1,theconvergentsolutionofLagrangemultiplieralpha,tabplot,etc.arealsoplotted(```class√óprediction==1``Highlightthedatathatbecomes`.prediction==0istheboundaryline).
$ ./svm.py file = classification.txt (len=200) cvxopt result status: optimal delta = 5.684342e-14 class = (&#39;-1&#39;,&#39;+1&#39;) confusion matrix: [[96 7] [34 63]] #!/usr/bin/env python # -*- coding: utf-8 -*- # support vector machine (SVM) calculation Use # cvxopt.solvers.qp (Quadratic Programming) from __future__ import print_function import numpy as np import cvxopt Ccoeff = [30, 30] # soft margin coefficients of class SIGMA = 1.</description>
    </item>
    
  </channel>
</rss>