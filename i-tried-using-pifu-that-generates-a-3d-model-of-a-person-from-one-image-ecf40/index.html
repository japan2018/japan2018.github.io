<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  <meta name="generator" content="Hugo 0.72.0" />

  
  <meta name="description" content="Some description">
  

  
  <link rel="apple-touch-icon" sizes="180x180" href="https://memotut.com/apple-touch-icon.png">

  
  <link rel="icon" type="image/png" sizes="32x32" href="https://memotut.com/favicon-32x32.png">

  
  <link rel="icon" type="image/png" sizes="16x16" href="https://memotut.com/favicon-16x16.png">

  
  <link rel="manifest" href="https://memotut.com/site.webmanifest">

  
  <link rel="mask-icon" href="https://memotut.com/safari-pinned-tab.svg" color="#5bbad5">

  <meta name="msapplication-TileColor" content="#da532c">

  <meta name="theme-color" content="#ffffff">

  
  <link rel="stylesheet" href="https://memotut.com/css/bootstrap.min.css" />

  
  <title>I tried using PIFu that generates a 3D model of a person from one image | Memo Tut</title>
  

  <style>
body {
  min-width: 300px;
}

.custom-navbar {
  margin-bottom: 1em;
  height: 60px;
}

.custom-navbar a {
  display: inline-block; 
  padding: 18px 0;
  margin-right: 1em; 
  font-weight: bold; 
}

.custom-navbar a:hover,
.custom-navbar a:focus {
  text-decoration: none; 
}

@media print {
  .custom-navbar {
    display: none;
  }
}

article {
  padding-bottom: 1em;
}

img {
  max-width: 100%;
}


body {
  background-color: #fff;
}



body {
  color: #212529;
}



a {
  color: #007bff;
}



a:hover,
a:focus {
  color: #0056b3;
}



.custom-navbar {
  background-color: #212529;
}



.custom-navbar a {
  color: rgba(255, 255, 255, 0.75);
}



.custom-navbar a:hover,
.custom-navbar a:focus {
  color: rgba(255, 255, 255, 1);
}



.container {
  max-width: 800px;
}



pre {
  display: block;
  padding: 9.5px;
  word-break: break-all;
  word-wrap: break-word;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre code {
  padding: 0;
  font-size: inherit;
  color: inherit; 
  white-space: pre-wrap;
  background-color: transparent;
  border: none;
  border-radius: 0;
}

code {
  padding: 2px 4px;
  color: inherit; 
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
  font-size: .9em;
}



blockquote,
.blockquote {
  padding: 10px 20px;
  margin: 0 0 20px;
  font-size: 1em;
  border-left: 5px solid #6c757d;
}

</style>
</head>

<body>
  <nav class="custom-navbar">
  <div class="container">
    
    <a href="/">Posts</a>
    
    <a href="/tags/">Tags</a>
    
    <a href="/about/">About</a>
    
    <a href="/index.xml">RSS</a>
    
  </div>
</nav>
  
  <div class="container">
    <article>
      <h1>I tried using PIFu that generates a 3D model of a person from one image</h1>
<p>
  <small class="text-secondary">
  
  
  Mar 4, 2020
  </small>
  

<small><code><a href="https://memotut.com/tags/python">Python</a></code></small>


<small><code><a href="https://memotut.com/tags/machine-learning"> machine learning</a></code></small>


<small><code><a href="https://memotut.com/tags/deeplearning"> DeepLearning</a></code></small>


<small><code><a href="https://memotut.com/tags/pytorch"> PyTorch</a></code></small>


<small><code><a href="https://memotut.com/tags/sumire-uesaka"> Sumire Uesaka</a></code></small>

</p>
<pre><code>What is #PIFu
</code></pre>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/139643/a3dcb90a-12e7-9994-a1a2-089a528d2480.png" alt="image.png">
Image quote (left): <a href="https://lineblog.me/uesaka_sumire/archives/9388291.html">Sumire Uesaka Official Blog Nekomori Meeting</a></p>
<p><a href="https://shunsukesaito.github.io/PIFu/">PIFu: Pixel-Aligned Implicit Function for High-Resolution Clothed Human Digitization</a></p>
<p>If you explain roughly,</p>
<p><strong>A machine learning model that generates a 3D model of a person with clothes from a single image</strong></p>
<p>is.</p>
<blockquote>
<p>We introduce Pixel-aligned Implicit Function (PIFu), a highly effective implicit representation that locally aligns pixels of 2D images with the global context of their corresponding 3D object.Using PIFu, we propose an end-to-end deep learning method for digitizing highly detailed clothed humans that can infer both 3D surface and texture from a single image, and optionally, multiple input images.Highly intricate shapes, such as hairstyles, clothing, as well as their variations and deformations can be digitized in a unified way.</p>
</blockquote>
<blockquote>
<p>Introduce Pixel-aligned Implicit Function (PIFu). This is a very effective implicit representation that locally aligns the pixels of a 2D image to the global context of the corresponding 3D object. Using PIFu, we propose an end-to-end deep learning method for digitizing highly detailed clothes that can infer both 3D surfaces and textures from a single image and optionally multiple input images .. Very complex shapes such as hairstyles, clothes, and their variations and deformations can be digitized in a unified way.</p>
</blockquote>
<h1 id="introduction--tutorial">Introduction &amp; Tutorial</h1>
<p>The introduction method is simple.</p>
<pre><code>$ git clone https://github.com/shunsukesaito/PIFu.git
$ cd PIFu
$ pip install -r requirements.txt
$ sh ./scripts/download_trained_model.sh
</code></pre><p>PIFu comes with a sample data set, so you can run it simply by running it.</p>
<pre><code>$ sh ./scripts/test.sh
</code></pre><p>By doing so, the file <code>results/pifu_demo/result_ryota.obj</code> will be output.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/139643/8e9ccb94-3376-3f66-4b93-37d8ee819956.png" alt="image.png"></p>
<p><a href="http://www.meshlab.net/">MeshLab</a> is recommended for viewing 3D models.
The reason is that the model output by PIFu has no texture and is colored by VertexColor. There are few viewers that can see the model colored with this Vertex Color, so it is recommended that you can easily see it.</p>
<h1 id="generate-3d-model-with-specified-image">Generate 3D model with specified image</h1>
<p>There are two things you need to do to generate a 3D model in PIFu.</p>
<ol>
<li>Prepare a square image</li>
<li>Preparation of mask image</li>
</ol>
<p>This time, from the free material Pakutaso (<a href="http://www.pakutaso.com">www.pakutaso.com</a>), <a href="https://www.pakutaso.com/20120703195post-1716.html">Free image (photo) of Yukata glasses boy (whole body) putting his hands on the sleeve</a>.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/139643/668cca69-b54c-1d2e-35ad-757a5279e99c.png" alt="image.png"></p>
<p>Since the original image is vertically long, add a band to make it a square image. This is called <code>kimono.png</code>.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/139643/60d75554-cd4e-2724-3daa-0d612f1563de.png" alt="image.png"></p>
<p>Then generate a mask image. This is called <code>kimono_mask.png</code>.
**Here the name is important. Be sure to add <code>_mask</code> to the mask image. **</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/139643/a3b94d09-75ad-1151-4ca4-3b5f25d48da6.png" alt="image.png"></p>
<p>Then create a <code>kimono/</code> folder and copy the two files.</p>
<pre><code>mkdir kimono/
cp kimono.png kimono/
cp kimono_mask.png kimono/
</code></pre><p>Create the following contents as <code>scripts/eval.sh</code>.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash:scripts/eval.sh" data-lang="bash:scripts/eval.sh"><span style="color:#75715e">#!/usr/bin/env bash
</span><span style="color:#75715e"></span>set -ex

<span style="color:#75715e"># Training</span>
GPU_ID<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>
DISPLAY_ID<span style="color:#f92672">=</span><span style="color:#66d9ef">$((</span>GPU_ID*10+10<span style="color:#66d9ef">))</span>
NAME<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;pifu_demo&#39;</span>

<span style="color:#75715e"># Network configuration</span>

BATCH_SIZE<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>
MLP_DIM<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;257 1024 512 256 128 1&#39;</span>
MLP_DIM_COLOR<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;513 1024 512 256 128 3&#39;</span>

TEST_FOLDER_PATH<span style="color:#f92672">=</span>$1
shift

<span style="color:#75715e"># Reconstruction resolution</span>
<span style="color:#75715e"># NOTE: one can change here to reconstruct mesh in a different resolution.</span>
VOL_RES<span style="color:#f92672">=</span>$1
shift

CHECKPOINTS_NETG_PATH<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;./checkpoints/net_G&#39;</span>
CHECKPOINTS_NETC_PATH<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;./checkpoints/net_C&#39;</span>

<span style="color:#75715e"># command</span>
CUDA_VISIBLE_DEVICES<span style="color:#f92672">=</span><span style="color:#e6db74">${</span>GPU_ID<span style="color:#e6db74">}</span> python ./apps/eval.py <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>    --name <span style="color:#e6db74">${</span>NAME<span style="color:#e6db74">}</span> <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>    --batch_size <span style="color:#e6db74">${</span>BATCH_SIZE<span style="color:#e6db74">}</span> <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>    --mlp_dim <span style="color:#e6db74">${</span>MLP_DIM<span style="color:#e6db74">}</span> <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>    --mlp_dim_color <span style="color:#e6db74">${</span>MLP_DIM_COLOR<span style="color:#e6db74">}</span> <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>    --num_stack <span style="color:#ae81ff">4</span> <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>    --num_hourglass <span style="color:#ae81ff">2</span> <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>    --resolution <span style="color:#e6db74">${</span>VOL_RES<span style="color:#e6db74">}</span> <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>    --hg_down<span style="color:#e6db74">&#39;ave_pool&#39;</span> <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>    --norm<span style="color:#e6db74">&#39;group&#39;</span> <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>    --norm_color<span style="color:#e6db74">&#39;group&#39;</span> <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>    --test_folder_path <span style="color:#e6db74">${</span>TEST_FOLDER_PATH<span style="color:#e6db74">}</span> <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>    --load_netG_checkpoint_path <span style="color:#e6db74">${</span>CHECKPOINTS_NETG_PATH<span style="color:#e6db74">}</span> <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>    --load_netC_checkpoint_path <span style="color:#e6db74">${</span>CHECKPOINTS_NETC_PATH<span style="color:#e6db74">}</span>
</code></pre></div><p>Finally,</p>
<pre><code>$ sh scripts/eval_default.sh kimono/ 256
</code></pre><p>By doing so, <code>results/pifu_demo/result_kimono.obj</code> will be generated.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/139643/62bf6e68-39ac-78a3-b2be-f8b560366243.png" alt="image.png"></p>
<h1 id="outlaw-pifu">Outlaw PIFu</h1>
<p>There is a method called PIFu. This is a PIFu** I can make high quality textures. (I just named it properly to distinguish it from the original.)
It&rsquo;s just an outlaw, so there are some things that are not true. Well, there are various circumstances, so I will explain later.</p>
<p>Left: Original image
Medium: PIFu default
Right: Outlaw PIFu</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/139643/22a13b1d-167a-92c5-24e7-6956d3be3ffb.png" alt="image.png"></p>
<p>This is the branch called 2_phase_generate in my PIFu repository.</p>
<p><a href="https://github.com/kotauchisunsun/PIFu/tree/2_phase_generate">https://github.com/kotauchisunsun/PIFu/tree/2_phase_generate</a></p>
<p>In this branch you can output it with <code>scripts/eval_two_phase.sh</code>.
As usage,</p>
<pre><code>./scripts/eval_two_phase.sh IMAGE_DIR/ VOXEL_RESOLUTION VOXEL_LOAD_SIZE TEX_LOAD_SIZE
</code></pre><p>I feel that. IMAGE_DIR/ is the directory that contains the images. VOXEL_RESOLUTION is recommended around 512,1024. If it is 1024, it will bring about 20GB of memory, so that area should match the machine.
We recommend that VOXEL_LOAD_SIZE be fixed at 512.
Set TEX_LOAD_SIZE to 1024 or 2048 according to the texture resolution.
This is a high quality texture model.</p>
<p>So which area is illegal? Is a story. Well, it&rsquo;s like <strong>using non-canonical behavior</strong>.
For details, I wrote in the <a href="https://github.com/shunsukesaito/PIFu/pull/6">pull request</a> that I published, but originally VOXEL_LOAD_SIZE and TEX_LOAD_SIZE should not be set to anything other than 512. about it. However, when I try to output with TEX_LOAD_SIZE set to 1024, the troublesome thing is that <strong>a pretty model has been created</strong>.At first, I thought that &ldquo;I would die if I entered an invalid value for TEX_LOAD_SIZE&rdquo; or &ldquo;I think that the texture would be shredded even if it moves&rdquo;, but I remodeled it appropriately, but something like that It came out clean. It came out. So I made a pull-lick, but it seems that it wasn&rsquo;t originally.
In fact, the texture behind is rather shredded.
Left: PIFu
Right: Outlaw PIFu</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/139643/f61fd348-3307-c56f-b038-a8300decaebc.png" alt="image.png"></p>
<p>As the author says, if you want a high quality texture, simply project it? Well, that may be true. Actually, PIFu also has a function to project textures, but I think that modification is essential because I can see the code and output at high resolution is impossible.</p>
<p>#Impression</p>
<p>I was satisfied because I was able to introduce Sumipe. PIFu knew its existence from last year and thought when the code would be released, but I was surprised that it came out unexpectedly early. Also, it was easy to move, so it was nice to be able to do it quickly. However, I am wondering if I can feel a little better. Sonic Boom Sonic Boom Usakakawai.</p>

    </article>
  </div>

  
  
  
  <script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-169005401-1', 'auto');
  ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  

  
<link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.css" />
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#216942",
      "text": "#b2d192"
    },
    "button": {
      "background": "#afed71"
    }
  }
})});
</script>

</body>

</html>
