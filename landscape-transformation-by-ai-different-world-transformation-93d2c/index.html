<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  <meta name="generator" content="Hugo 0.72.0" />

  
  <meta name="description" content="Some description">
  

  
  <link rel="apple-touch-icon" sizes="180x180" href="https://memotut.com/apple-touch-icon.png">

  
  <link rel="icon" type="image/png" sizes="32x32" href="https://memotut.com/favicon-32x32.png">

  
  <link rel="icon" type="image/png" sizes="16x16" href="https://memotut.com/favicon-16x16.png">

  
  <link rel="manifest" href="https://memotut.com/site.webmanifest">

  
  <link rel="mask-icon" href="https://memotut.com/safari-pinned-tab.svg" color="#5bbad5">

  <meta name="msapplication-TileColor" content="#da532c">

  <meta name="theme-color" content="#ffffff">

  
  <link rel="stylesheet" href="https://memotut.com/css/bootstrap.min.css" />

  
  <title>Landscape transformation by AI † Different world transformation † | Memo Tut</title>
  

  <style>
body {
  min-width: 300px;
}

.custom-navbar {
  margin-bottom: 1em;
  height: 60px;
}

.custom-navbar a {
  display: inline-block; 
  padding: 18px 0;
  margin-right: 1em; 
  font-weight: bold; 
}

.custom-navbar a:hover,
.custom-navbar a:focus {
  text-decoration: none; 
}

@media print {
  .custom-navbar {
    display: none;
  }
}

article {
  padding-bottom: 1em;
}

img {
  max-width: 100%;
}


body {
  background-color: #fff;
}



body {
  color: #212529;
}



a {
  color: #007bff;
}



a:hover,
a:focus {
  color: #0056b3;
}



.custom-navbar {
  background-color: #212529;
}



.custom-navbar a {
  color: rgba(255, 255, 255, 0.75);
}



.custom-navbar a:hover,
.custom-navbar a:focus {
  color: rgba(255, 255, 255, 1);
}



.container {
  max-width: 800px;
}



pre {
  display: block;
  padding: 9.5px;
  word-break: break-all;
  word-wrap: break-word;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre code {
  padding: 0;
  font-size: inherit;
  color: inherit; 
  white-space: pre-wrap;
  background-color: transparent;
  border: none;
  border-radius: 0;
}

code {
  padding: 2px 4px;
  color: inherit; 
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
  font-size: .9em;
}



blockquote,
.blockquote {
  padding: 10px 20px;
  margin: 0 0 20px;
  font-size: 1em;
  border-left: 5px solid #6c757d;
}

</style>
</head>

<body>
  <nav class="custom-navbar">
  <div class="container">
    
    <a href="/">Posts</a>
    
    <a href="/tags/">Tags</a>
    
    <a href="/about/">About</a>
    
    <a href="/index.xml">RSS</a>
    
  </div>
</nav>
  
  <div class="container">
    <article>
      <h1>Landscape transformation by AI † Different world transformation †</h1>
<p>
  <small class="text-secondary">
  
  
  Feb 24, 2020
  </small>
  

<small><code><a href="https://memotut.com/tags/python">Python</a></code></small>


<small><code><a href="https://memotut.com/tags/deeplearning">DeepLearning</a></code></small>


<small><code><a href="https://memotut.com/tags/gan">GAN</a></code></small>


<small><code><a href="https://memotut.com/tags/cyclegan">CycleGAN</a></code></small>


<small><code><a href="https://memotut.com/tags/colaboratory">colaboratory</a></code></small>

</p>
<pre><code># Introduction († horror transformation †)
</code></pre>
<table>
<thead>
<tr>
<th align="center">Before conversion</th>
<th align="center">After conversion</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">! <img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/247671/0ac59d9a-0351-d6ad-f465-cd90338e83e7.png" alt="tenmonkan_A.png"></td>
<td align="center"><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/247671/ba6bebc4-88c8-3f4b-5c97-6d1f36f5919a.png" alt="tenmonkan_B.png"></td>
</tr>
</tbody>
</table>
<p>Did you understand?</p>
<p>This uses GAN (Hostile Generation Network) to add <strong>&ldquo;horror&rdquo;</strong> features to photos and <strong>convert</strong> them.</p>
<p>Let&rsquo;s leave the principle behind for now, and take a look at the possibilities of GAN!</p>
<h2 id="seasonal-conversion-aurora-conversion-fireworks-conversion">Seasonal conversion, Aurora conversion, Fireworks conversion</h2>
<table>
<thead>
<tr>
<th align="center">Before conversion</th>
<th align="center">After conversion</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">! <img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/247671/db646e75-2e42-27d6-f4a8-de970c61ca52.png" alt="epoch100_real_A.png"></td>
<td align="center"><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/247671/84849c69-0321-4eae-5159-c915e0b78610.png" alt="epoch100_fake_B.png"></td>
</tr>
<tr>
<td align="center">! <img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/247671/4ebc0e91-f1d9-8804-d03a-cf77f299790d.png" alt="IMG_20161001_220428_real.png"></td>
<td align="center"><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/247671/dadb3cce-95a5-afc4-7a0a-b61e82f71124.png" alt="auroraB.png"></td>
</tr>
<tr>
<td align="center">! <img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/247671/d3e05a3a-0ea6-0dee-70bc-38062a6182c2.png" alt="epoch027_real_A.png"></td>
<td align="center"><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/247671/39f2ae88-5f53-c3de-faac-eb70c9b24fa9.png" alt="epoch027_fake_B.png"></td>
</tr>
<tr>
<td align="center"><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/247671/547f19e4-c250-f168-5703-ceab7c839f77.png" alt="IMG_20161001_220428_real.png"></td>
<td align="center"><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/247671/1a5e6f98-6479-6a84-eb71-3bdbf2c2e45f.png" alt="IMG_20161001_220428_fake.png"></td>
</tr>
</tbody>
</table>
<p>Using <a href="https://arxiv.org/abs/1703.10593">CycleGAN</a>[1], pairs such as &ldquo;summer and spring,&rdquo; &ldquo;cloud and aurora,&rdquo; &ldquo;sky and fireworks,&rdquo; *<em>replacement of features</em> We are doing *
Not just changing the color, so to speak, conversion is performed while maintaining the original form like &ldquo;image translation (conversion)&rdquo;.</p>
<p>If you want to know more about the principle of CycleGAN, please refer to <a href="https://qiita.com/itok_msi/items/b6b615bc28b1a720afd7">this article</a>. I am very grateful to you.</p>
<h1 id="scenery--different-world-transformation-">Scenery † Different World Transformation †</h1>
<p>This time, I applied this technology to the <strong>&ldquo;Landscape conversion&rdquo;</strong> in the picture&hellip; No! !</p>
<p>We used it for &ldquo;** Different World Transformation †&rdquo; **! !</p>
<p>Check out the four months of hard work and the results.</p>
<p>##† Fantasy conversion †
The first is †fantasy conversion†.
I created and learned a dataset with a pair of &ldquo;landscape (Kagoshima)&rdquo; and &ldquo;fantasy/fantastic&rdquo;.
After all, abstract expression is difficult, and I had a hard time selecting images.</p>
<table>
<thead>
<tr>
<th align="center">Before conversion</th>
<th align="center">After conversion</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">! <img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/247671/b47c916f-4125-61e0-0952-7194e8684d2f.png" alt="kagoshimaA.png"></td>
<td align="center"><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/247671/bec5dff0-cf40-c149-102a-3dd132dbb167.png" alt="kagoshimaB.png"></td>
</tr>
<tr>
<td align="center">! <img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/247671/74728cad-a278-6ecc-46c3-bd04a592a731.png" alt="epoch100_real_A_real.png"></td>
<td align="center"><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/247671/68774729-3c30-b35c-7d6f-b3d935c92095.png" alt="epoch100_real_A_fake.png"></td>
</tr>
<tr>
<td align="center"><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/247671/41ddf8a5-79b3-22ec-ee97-f60c20ae4e83.png" alt="BP19-113432D_real.png"></td>
<td align="center"><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/247671/14dcefee-113a-ea29-bdfd-804b9d4a87c5.png" alt="BP19-113432D_fake.png"></td>
</tr>
</tbody>
</table>
<p>came out!
The beautiful scenery of Kagoshima is even more fantastic and mysterious! ?
Is the grain of light &ldquo;just noise&rdquo;?
No, no, to my eyes it looks like &ldquo;a fairy is flying&rdquo; **.
Overall <strong>Blue is very beautiful</strong>.</p>
<h2 id="-horror-transformation-">† Horror transformation †</h2>
<p>Next is the † horror transformation † introduced at the beginning.</p>
<p><strong>※※※ Please read carefully ※※※</strong>.</p>
<table>
<thead>
<tr>
<th align="center">Before conversion</th>
<th align="center">After conversion</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">! <img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/247671/0ac59d9a-0351-d6ad-f465-cd90338e83e7.png" alt="tenmonkan_A.png"></td>
<td align="center"><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/247671/ba6bebc4-88c8-3f4b-5c97-6d1f36f5919a.png" alt="tenmonkan_B.png"></td>
</tr>
<tr>
<td align="center">! <img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/247671/063e2270-ee9c-3372-a17f-2db8638286e2.png" alt="epoch111_real_a.png"></td>
<td align="center"><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/247671/6b500189-1208-1b74-499e-281d5a1f47dd.png" alt="epoch111_fake_b.png"></td>
</tr>
<tr>
<td align="center">! <img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/247671/8878e477-f7d4-d206-1553-9493c5f7f7d2.png" alt="epoch171_real_a_360.png"></td>
<td align="center"><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/247671/0393995a-281a-4f5f-9a33-6757cc6a097b.png" alt="epoch171_real_a_360_fake(1).png"></td>
</tr>
</tbody>
</table>
<p>Please take a look at this cityscape&hellip;! !
**Do you have the courage to step in? **
I want to use it as it is as a texture for horror games.</p>
<p>Here, we learned by creating a data set with a pair of &ldquo;cityscape&rdquo; and &ldquo;horror video&rdquo;.
More specifically, I continued to show the learning screens of &ldquo;SIREN&rdquo; and &ldquo;Silent Hill&rdquo; to the learning AI.
This is the reason why the cityscape as a whole is <strong>reddish black</strong> (I tried a few, but the river did not turn red. Sorry).</p>
<h2 id="-submarine-city-conversion-">† Submarine city conversion †</h2>
<p>Next is †Undersea City-Atlantis-Transformation†.
**Maybe if we combine the features of &ldquo;underwater&rdquo; with &ldquo;landscape&rdquo;, we will become a &ldquo;submarine city&rdquo;. ] **
I created a data set and learned from the easy idea.</p>
<table>
<thead>
<tr>
<th align="center">Before conversion</th>
<th align="center">After conversion</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">! <img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/247671/a0862fe2-e8be-bae6-9784-331c74ab9182.png" alt="atlantisA.png"></td>
<td align="center"><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/247671/084b4f20-2084-dd30-72cc-6ca6359ad093.png" alt="atlantisB.png"></td>
</tr>
<tr>
<td align="center">! <img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/247671/4eb55a79-b087-4523-5d3a-c140938a50a0.png" alt="epoch126_real_A.png"></td>
<td align="center"><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/247671/5df6ec34-ed27-97d3-1d1d-f6905099fd00.png" alt="epoch126_fake_B.png"></td>
</tr>
</tbody>
</table>
<p>That&rsquo;s amazing&hellip;!
<strong>The entrance to Ryugu Castle</strong>……Shall we say that?
The tree behind is also like a coral reef.
**Water God……Thank you. **
† Undersea City-Atlantis-Conversion † In &ldquo;Underwater&rdquo; images, as well as &ldquo;Diving&rdquo; images,
I was able to create an excellent data set.</p>
<p>##† Iceberg conversion †
The other day, there was a campaign for &ldquo;Mt. Fuji and Sakurajima to be frozen in ice&rdquo; as a special event for Anna Snow 2.
**What if I do the same thing with GAN? **
I created and learned a dataset with a pair of &ldquo;Sakurajima&rdquo; and &ldquo;Iceberg&rdquo;!</p>
<table>
<thead>
<tr>
<th align="center">Before conversion</th>
<th align="center">After conversion</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">! <img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/247671/bcfa3d3e-8428-3c01-d4aa-0590486bb25f.png" alt="epoch055_real_A.png"></td>
<td align="center"><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/247671/1962ad2c-41dd-effd-3dc1-e8160c95a3a2.png" alt="epoch055_fake_B.png"></td>
</tr>
<tr>
<td align="center">! <img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/247671/a897c4ce-7a98-2783-ca86-d2c560e71893.png" alt="epoch085_real_A.png"></td>
<td align="center"><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/247671/2f3030c5-babb-8fb8-a3b2-6b8eed6772b7.png" alt="epoch085_fake_B.png"></td>
</tr>
<tr>
<td align="center">! <img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/247671/6513d49a-4497-c183-5222-a423d30727fc.png" alt="epoch086_real_A.png"></td>
<td align="center"><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/247671/7403f527-f788-f2aa-9d0b-b6f5b58f3e4f.png" alt="epoch086_fake_B.png"></td>
</tr>
</tbody>
</table>
<p>**No, it&rsquo;s overkill. **
When I went to see the conversion result with excitement, I was crying because it was in the first ice age and I was too scared.</p>
<p>Is this the rebellion of AI&hellip;?
If you made the dataset more carefully and learned the shape of the mountain, it may not have been such a horrifying result.
If it reopens with <strong>† Ice Age conversion †</strong>, it is a perfect completion.</p>
<h1 id="about-learning-method">About learning method</h1>
<h2 id="image-collection-for-learning-dataset">Image collection for learning dataset</h2>
<p>CycleGAN is <strong>Unsupervised Learning</strong>. No labeling is required.
Even if the background and composition are different, it is a great place of CycleGAN that you can learn well if you have the same number.
In this conversion, we are collecting images with the aim of <strong>1,000 each</strong> to create a data set.
The usual 1000 streetscapes are called &ldquo;train A&rdquo; and the 1000 different townscapes are called &ldquo;train B&rdquo;.</p>
<p>That being said, I&rsquo;m not a <strong>inhabitant of a different world</strong>, so I don&rsquo;t have a thousand different world pictures** in my camera&hellip;</p>
<p>Therefore, I mainly created the training data set using the following two methods.</p>
<h3 id="-collect-images-by-google-image-search">① Collect images by Google image search</h3>
<p>The python library &ldquo;icrawler&rdquo; is convenient.
For details, please see <a href="https://qiita.com/tkt989/items/84c6581dfa1d9a42dc2d">this article</a>. Thank you for all the help you have given me.</p>
<p>Images were searched using keywords such as &ldquo;Aurora&rdquo; and a dataset was created.</p>
<hr>
<h3 id="-take-a-video-and-cut-out-the-image-in-frame-units">② Take a video and cut out the image in frame units</h3>
<p>With method (1), noise data is mixed too much depending on the search word, which makes it very difficult to select learning images.
In such a case, it will be easier to convert the video that is the image of style conversion with OpenCV etc. into frame units.
For details, please see <a href="https://qiita.com/sayo0/items/3f9a1a42bd5caadd2c0d">this article</a>. Thank you for all the help you have given me.</p>
<p>For example, in &ldquo;Horror conversion,&rdquo; I recorded the most scary scene in a horror game for a total of about 30 minutes, and cut out the image from about 1,000.</p>
<h2 id="study-with-cyclegan">Study with CycleGAN</h2>
<p>Finally, I&rsquo;m learning with CycleGAN.
It&rsquo;s good to play around with your own PC, but <strong>Google Colabratory</strong> is amazing.
A service that allows you to use Jupyter Notebook in the cloud.
For more information, please see <a href="https://qiita.com/tomo_makes/items/b3c60b10f7b25a0a5935">this article</a>. Thank you for all the help you have given me.</p>
<p>Roughly speaking, it is a cloud IDE that ** lends a GPU for free. Wow.
If you are lucky, Tesla P100 (a GPU of about 900,000 yen) can be borrowed for free. Wow.
As it is a cloud IDE, it does not depend on the location or your machine specifications. You can study as much as you want in the background. Wow.
It was too comfortable and I charged Google Drive. I love google.</p>
<h3 id="source-code">Source code</h3>
<p><a href="https://colab.research.google.com/drive/1KmwC-eOU3Z02ZiCmgFv-rDG4HxzK-8zG">https://colab.research.google.com/drive/1KmwC-eOU3Z02ZiCmgFv-rDG4HxzK-8zG</a>
↑ Here are the notes I was actually using to study <strong>† Different World Transformation †</strong>.
<a href="https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix">Pytorch version of CycleGAN</a>[2] is implemented on Google Colabratory.
I still don&rsquo;t know much about it, but I&rsquo;d appreciate it if you could refer to it because I have commentary on the notes to myself!
First of all, please come from the standard &ldquo;Uma → Zebra&rdquo; style conversion of the sample.</p>
<h1 id="web-application-publishing">Web application publishing</h1>
<p>I&rsquo;ll be writing soon
ngrok is amazing!</p>
<h1 id="references">References</h1>
<p>[1] Jun-Yan Zhu, Taesung Park, Phillip Isola, Alexei A. Efros, Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks, arXiv preprint arxiv:1703.10593, 2017.</p>
<p>[2]@inproceedings{CycleGAN2017,
title={Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networkss},
author={Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A},
booktitle={Computer Vision (ICCV), 2017 IEEE International Conference on},
year={2017}
}
@inproceedings{isola2017image,
title={Image-to-Image Translation with Conditional Adversarial Networks},
author={Isola, Phillip and Zhu, Jun-Yan and Zhou, Tinghui and Efros, Alexei A},
booktitle={Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on},
year={2017}
}</p>

    </article>
  </div>

  
  
  
  <script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-169005401-1', 'auto');
  ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  

  
<link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.css" />
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#216942",
      "text": "#b2d192"
    },
    "button": {
      "background": "#afed71"
    }
  }
})});
</script>

</body>

</html>
