<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  <meta name="generator" content="Hugo 0.72.0" />

  
  <meta name="description" content="Some description">
  

  
  <link rel="apple-touch-icon" sizes="180x180" href="https://memotut.com/apple-touch-icon.png">

  
  <link rel="icon" type="image/png" sizes="32x32" href="https://memotut.com/favicon-32x32.png">

  
  <link rel="icon" type="image/png" sizes="16x16" href="https://memotut.com/favicon-16x16.png">

  
  <link rel="manifest" href="https://memotut.com/site.webmanifest">

  
  <link rel="mask-icon" href="https://memotut.com/safari-pinned-tab.svg" color="#5bbad5">

  <meta name="msapplication-TileColor" content="#da532c">

  <meta name="theme-color" content="#ffffff">

  
  <link rel="stylesheet" href="https://memotut.com/css/bootstrap.min.css" />

  
  <title>Use Cloud Dataflow to dynamically change the destination depending on the data value and save it in GCS | Memo Tut</title>
  

  <style>
body {
  min-width: 300px;
}

.custom-navbar {
  margin-bottom: 1em;
  height: 60px;
}

.custom-navbar a {
  display: inline-block; 
  padding: 18px 0;
  margin-right: 1em; 
  font-weight: bold; 
}

.custom-navbar a:hover,
.custom-navbar a:focus {
  text-decoration: none; 
}

@media print {
  .custom-navbar {
    display: none;
  }
}

article {
  padding-bottom: 1em;
}

img {
  max-width: 100%;
}


body {
  background-color: #fff;
}



body {
  color: #212529;
}



a {
  color: #007bff;
}



a:hover,
a:focus {
  color: #0056b3;
}



.custom-navbar {
  background-color: #212529;
}



.custom-navbar a {
  color: rgba(255, 255, 255, 0.75);
}



.custom-navbar a:hover,
.custom-navbar a:focus {
  color: rgba(255, 255, 255, 1);
}



.container {
  max-width: 800px;
}



pre {
  display: block;
  padding: 9.5px;
  word-break: break-all;
  word-wrap: break-word;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre code {
  padding: 0;
  font-size: inherit;
  color: inherit; 
  white-space: pre-wrap;
  background-color: transparent;
  border: none;
  border-radius: 0;
}

code {
  padding: 2px 4px;
  color: inherit; 
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
  font-size: .9em;
}



blockquote,
.blockquote {
  padding: 10px 20px;
  margin: 0 0 20px;
  font-size: 1em;
  border-left: 5px solid #6c757d;
}

</style>
</head>

<body>
  <nav class="custom-navbar">
  <div class="container">
    
    <a href="/">Posts</a>
    
    <a href="/tags/">Tags</a>
    
    <a href="/about/">About</a>
    
    <a href="/index.xml">RSS</a>
    
  </div>
</nav>
  
  <div class="container">
    <article>
      <h1>Use Cloud Dataflow to dynamically change the destination depending on the data value and save it in GCS</h1>
<p>
  <small class="text-secondary">
  
  
  Dec 23, 2019
  </small>
  

<small><code><a href="https://memotut.com/tags/python">Python</a></code></small>


<small><code><a href="https://memotut.com/tags/gcp"> gcp</a></code></small>


<small><code><a href="https://memotut.com/tags/clouddataflow"> CloudDataflow</a></code></small>

</p>
<pre><code>#Introduction
</code></pre>
<p>This article is the 23rd day article of <a href="https://qiita.com/advent-calendar/2019/classi">Classi Advent Calendar 2019</a>.</p>
<p>Hello, this is @tomoyanamekawa of data AI part of Classi.
Usually, I mainly build a data analysis platform on GCP.</p>
<p>Recently, there was something like &ldquo;I want to divide the data in BigQuery into files according to the value inside and save it in GCS&rdquo;, and at that time I was indebted to Cloud Dataflow.
There seems to be demand for other people, and there are few implementation examples in Python, so I will summarize.</p>
<h1 id="this-time-goal">This time goal</h1>
<p>Execute the process of exporting a specific table in BigQuery to Google Cloud Storage (GCS) on a daily basis.
However, I want to change the save destination directory depending on the value of a certain column.
The file format is json.</p>
<h2 id="example">Example</h2>
<p>The reservations table in BigQuery
<img width="400" alt="reservations table" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/256675/4163bef3-2780-9fe2-f7ca-76447b494f98.png">
In this way, I want to save by GCS separately for each date/shop_id.
<img width="400" alt="reservations_GCS" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/256675/3ba3762a-9b47-867a-9e2a-6f0e17ed622c.png"></p>
<h2 id="completion-drawing">Completion drawing</h2>
<img width="400" alt="Completion drawing" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/256675/f1461996-ccda-fea3-f94c-8d8159050f91.png">
<h2 id="environment">Environment</h2>
<ul>
<li>Python 3.7.3</li>
<li>apache-beam==2.16.0</li>
</ul>
<p>What is #Cloud Dataflow
It is a service provided by GCP that enables serverless ETL processing.
Since <a href="https://beam.apache.org/">Apache Beam</a> is running on the back side, it can be said that Apache Beam can be used without a server.
Since parallel processing can be performed, processing can be performed at high speed even for large-scale data.</p>
<p>It supports both stream processing and batch processing, but this time uses batch processing.
For details, see <a href="https://cloud.google.com/dataflow/?hl=ja">Official Page</a>.</p>
<p>If you want to be able to use it for the time being, I think <a href="https://speakerdeck.com/yuzutas0/20190719?slide=49">this procedure</a>inthepresentationmaterialofMr.Yuzutasoisgood(IalsocatchitwiththisIuploadedit).</p>
<p>#Create custom template
Cloud Dataflow uses what is called a &ldquo;template&rdquo; to create ETL processing.
For general processing, use <a href="https://cloud.google.com/dataflow/docs/guides/templates/provided-templates?hl=ja">Google-provided template</a> to easily create a GUI. I can do it.
However, I can not do what I want to do this time, so I will create a custom template myself.</p>
<p>By the way, the programming language can be Java or Python.
This time I&rsquo;ll write in Python, but Java is richer in features and documentation, so I think Java is better if you or your team members can write Java and there are no maintenance issues.</p>
<p>Here is the contents of the custom template.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python:test_template.py" data-lang="python:test_template.py"><span style="color:#f92672">import</span> os
<span style="color:#f92672">import</span> json
<span style="color:#f92672">import</span> datetime

<span style="color:#f92672">import</span> apache_beam <span style="color:#f92672">as</span> beam
<span style="color:#f92672">from</span> apache_beam.io <span style="color:#f92672">import</span> fileio
<span style="color:#f92672">from</span> apache_beam.options.pipeline_options <span style="color:#f92672">import</span> PipelineOptions, StandardOptions, GoogleCloudOptions

        
<span style="color:#66d9ef">class</span> <span style="color:#a6e22e">JsonSink</span>(fileio<span style="color:#f92672">.</span>TextSink):
    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">write</span>(self, record):
      self<span style="color:#f92672">.</span>_fh<span style="color:#f92672">.</span>write(json<span style="color:#f92672">.</span>dumps(record)<span style="color:#f92672">.</span>encode(<span style="color:#e6db74">&#39;utf8&#39;</span>))
      self<span style="color:#f92672">.</span>_fh<span style="color:#f92672">.</span>write(<span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span><span style="color:#f92672">.</span>encode(<span style="color:#e6db74">&#39;utf8&#39;</span>))


<span style="color:#66d9ef">if</span> __name__ <span style="color:#f92672">==</span><span style="color:#e6db74">&#39;__main__&#39;</span>:
    now <span style="color:#f92672">=</span> datetime<span style="color:#f92672">.</span>datetime<span style="color:#f92672">.</span>now()<span style="color:#f92672">.</span>strftime(<span style="color:#e6db74">&#39;%Y%m</span><span style="color:#e6db74">%d</span><span style="color:#e6db74">&#39;</span>)
    project_id <span style="color:#f92672">=</span><span style="color:#e6db74">&#39;your_project&#39;</span>
    dataset_name <span style="color:#f92672">=</span><span style="color:#e6db74">&#39;your_dataset&#39;</span>
    table_name <span style="color:#f92672">=</span><span style="color:#e6db74">&#39;your_table&#39;</span>
    bucket_name <span style="color:#f92672">=</span><span style="color:#e6db74">&#39;your_bucket&#39;</span>

    <span style="color:#75715e"># Option</span>
    pipeline_options <span style="color:#f92672">=</span> PipelineOptions()
    google_cloud_options <span style="color:#f92672">=</span> pipeline_options<span style="color:#f92672">.</span>view_as(GoogleCloudOptions)
    google_cloud_options<span style="color:#f92672">.</span>project <span style="color:#f92672">=</span> project_id
    google_cloud_options<span style="color:#f92672">.</span>job_name <span style="color:#f92672">=</span><span style="color:#e6db74">&#39;myjob&#39;</span>
    google_cloud_options<span style="color:#f92672">.</span>staging_location <span style="color:#f92672">=</span> f<span style="color:#e6db74">&#39;gs://{bucket_name}/staging&#39;</span>
    google_cloud_options<span style="color:#f92672">.</span>temp_location <span style="color:#f92672">=</span> f<span style="color:#e6db74">&#39;gs://{bucket_name}/temp&#39;</span>
    google_cloud_options<span style="color:#f92672">.</span>template_location <span style="color:#f92672">=</span> f<span style="color:#e6db74">&#39;gs://{bucket_name}/templates/test_template&#39;</span>
    pipeline_options<span style="color:#f92672">.</span>view_as(StandardOptions)<span style="color:#f92672">.</span>runner <span style="color:#f92672">=</span><span style="color:#e6db74">&#39;DataflowRunner&#39;</span>
        
    <span style="color:#75715e">#Create pipeline</span>
    pipeline <span style="color:#f92672">=</span> beam<span style="color:#f92672">.</span>Pipeline(options<span style="color:#f92672">=</span>pipeline_options)
    (pipeline
        <span style="color:#f92672">|</span><span style="color:#e6db74">&#39;read&#39;</span> <span style="color:#f92672">&gt;&gt;</span> beam<span style="color:#f92672">.</span>io<span style="color:#f92672">.</span>Read(beam<span style="color:#f92672">.</span>io<span style="color:#f92672">.</span>BigQuerySource(
            project<span style="color:#f92672">=</span>project_id,
            use_standard_sql<span style="color:#f92672">=</span>True,
            query<span style="color:#f92672">=</span>f<span style="color:#e6db74">&#39;select * from `{project_id}.{dataset_name}.{table_name}`&#39;</span>
        ))
        <span style="color:#f92672">|</span><span style="color:#e6db74">&#39;write&#39;</span> <span style="color:#f92672">&gt;&gt;</span> beam<span style="color:#f92672">.</span>io<span style="color:#f92672">.</span>fileio<span style="color:#f92672">.</span>WriteToFiles(
            path<span style="color:#f92672">=</span>f<span style="color:#e6db74">&#39;gs://{bucket_name}/{now}&#39;</span>,
            destination<span style="color:#f92672">=</span><span style="color:#66d9ef">lambda</span> record, table_name<span style="color:#f92672">=</span>table_name: f<span style="color:#e6db74">&#34;shop_id_{record[&#39;shop_id&#39;]}/&#34;</span>,
            sink<span style="color:#f92672">=</span>JsonSink(),
            file_naming<span style="color:#f92672">=</span>beam<span style="color:#f92672">.</span>io<span style="color:#f92672">.</span>fileio<span style="color:#f92672">.</span>destination_prefix_naming()
        )
    )

    pipeline<span style="color:#f92672">.</span>run()
</code></pre></div><p>The point is that the function called <a href="https://beam.apache.org/releases/pydoc/2.16.0/apache_beam.io.fileio.html#dynamic-destinations">Dynamic Destinations</a> is used here.
Since the value for each record is stored in the variable called record, you can change the destination (file name of the save destination) for each record with <code>record['shop_id']</code>.</p>
<p>The created template needs to be placed on GCS, so execute this command.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">python -m test_template
</code></pre></div><p>Then the template will be placed in the location specified in <code>google_cloud_options.template_location</code>.
<a href="https://cloud.google.com/dataflow/docs/guides/templates/creating-templates?hl=ja#header_3">You can also set the location of the template at runtime</a>.</p>
<h1 id="daily-work">daily work</h1>
<p>Cloud Dataflow itself does not have a scheduler function, so it must be run externally to run daily.
Therefore, this time we will be able to execute serverless with Cloud Scheduler + Cloud Pub/Sub + Cloud Functions.
<img width="400" alt="scheduler configuration" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/256675/1d4af4d9-7dc4-c145-adae-d242c51491e8.png"></p>
<p>Register the following script in Cloud Functions.
This script will execute the custom template for you.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> googleapiclient.discovery <span style="color:#f92672">import</span> build
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">main</span>(data, context):
    job <span style="color:#f92672">=</span><span style="color:#e6db74">&#39;my_job&#39;</span>
    dataflow <span style="color:#f92672">=</span> build(<span style="color:#e6db74">&#39;dataflow&#39;</span>,<span style="color:#e6db74">&#39;v1b3&#39;</span>)
    request <span style="color:#f92672">=</span> dataflow<span style="color:#f92672">.</span>projects()<span style="color:#f92672">.</span>templates()<span style="color:#f92672">.</span>launch(
        projectId<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;your_project&#39;</span>,
        gcsPath<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;gs://your_bucket/templates/test_template&#39;</span>
    )
    response <span style="color:#f92672">=</span> request<span style="color:#f92672">.</span>execute()
</code></pre></div><p>The trigger for Cloud Functions is Pub/Sub.
Also, if you want to use Pub/Sub as a trigger, you need to receive two arguments, so it is called <code>main(data, context)</code>.</p>
<p>After that, create the Pub/Sub Topic that is the trigger and publish it from Cloud Scheduler daily!If you set up Cloud Composer or a server and schedule it with other workflow engine or cron, you can execute the custom template from the following gcloud command.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">gcloud dataflow jobs run my_job <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>         --gcs-location gs://your_bucket/templates/test_template <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>         --region<span style="color:#f92672">=</span>asia-northeast1
</code></pre></div><h1 id="in-conclusion">in conclusion</h1>
<p>Cloud Dataflow is very convenient because it would be very troublesome to implement a system that can perform such processing on a large scale in a short time.
It&rsquo;s just a little expensive, so I think that it is necessary to choose a place of use so that it does not say &ldquo;I tried xx million yen with Cloud Dataflow&rdquo;.</p>
<p>Tomorrow is @tetsuya0617. looking forward to!</p>

    </article>
  </div>

  
  
  
  <script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-169005401-1', 'auto');
  ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  

  
<link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.css" />
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#216942",
      "text": "#b2d192"
    },
    "button": {
      "background": "#afed71"
    }
  }
})});
</script>

</body>

</html>
