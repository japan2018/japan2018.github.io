<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  <meta name="generator" content="Hugo 0.72.0" />

  
  <meta name="description" content="Some description">
  

  
  <link rel="apple-touch-icon" sizes="180x180" href="https://japan2018.github.io/apple-touch-icon.png">

  
  <link rel="icon" type="image/png" sizes="32x32" href="https://japan2018.github.io/favicon-32x32.png">

  
  <link rel="icon" type="image/png" sizes="16x16" href="https://japan2018.github.io/favicon-16x16.png">

  
  <link rel="manifest" href="https://japan2018.github.io/site.webmanifest">

  
  <link rel="mask-icon" href="https://japan2018.github.io/safari-pinned-tab.svg" color="#5bbad5">

  <meta name="msapplication-TileColor" content="#da532c">

  <meta name="theme-color" content="#ffffff">

  
  <link rel="stylesheet" href="https://japan2018.github.io/css/bootstrap.min.css" />

  
  <title>Probability prediction of imbalanced data | Some Title</title>
  

  <style>
body {
  min-width: 300px;
}

.custom-navbar {
  margin-bottom: 1em;
  height: 60px;
}

.custom-navbar a {
  display: inline-block; 
  padding: 18px 0;
  margin-right: 1em; 
  font-weight: bold; 
}

.custom-navbar a:hover,
.custom-navbar a:focus {
  text-decoration: none; 
}

@media print {
  .custom-navbar {
    display: none;
  }
}

article {
  padding-bottom: 1em;
}

img {
  max-width: 100%;
}


body {
  background-color: #fff;
}



body {
  color: #212529;
}



a {
  color: #007bff;
}



a:hover,
a:focus {
  color: #0056b3;
}



.custom-navbar {
  background-color: #212529;
}



.custom-navbar a {
  color: rgba(255, 255, 255, 0.75);
}



.custom-navbar a:hover,
.custom-navbar a:focus {
  color: rgba(255, 255, 255, 1);
}



.container {
  max-width: 800px;
}



pre {
  display: block;
  padding: 9.5px;
  word-break: break-all;
  word-wrap: break-word;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre code {
  padding: 0;
  font-size: inherit;
  color: inherit; 
  white-space: pre-wrap;
  background-color: transparent;
  border: none;
  border-radius: 0;
}

code {
  padding: 2px 4px;
  color: inherit; 
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
  font-size: .9em;
}



blockquote,
.blockquote {
  padding: 10px 20px;
  margin: 0 0 20px;
  font-size: 1em;
  border-left: 5px solid #6c757d;
}

</style>
</head>

<body>
  <nav class="custom-navbar">
  <div class="container">
    
    <a href="/">Posts</a>
    
    <a href="/tags/">Tags</a>
    
    <a href="/about/">About</a>
    
    <a href="/index.xml">RSS</a>
    
  </div>
</nav>
  
  <div class="container">
    <article>
      <h1>Probability prediction of imbalanced data</h1>
<p>
  <small class="text-secondary">
  
  
  Jan 15, 2020
  </small>
  

<small><code><a href="https://japan2018.github.io/tags/python">Python</a></code></small>


<small><code><a href="https://japan2018.github.io/tags/machine-learning"> machine learning</a></code></small>


<small><code><a href="https://japan2018.github.io/tags/probability"> probability</a></code></small>

</p>
<pre><code>#Introduction
</code></pre>
<p>When classifying by machine learning, it is sometimes desirable to obtain the probability of belonging to those classes as well as the classification result.
When the number of data for positive cases is extremely small compared to the number of data for negative cases (such data is called imbalanced data), if the prediction model is constructed using all of those data, the prediction result will also be negative. Often, it tends to be difficult to accurately classify positive data. Therefore, a model is often constructed using undersampled data so that the number of negative example data becomes equal to the number of positive example data. This makes it possible to classify positive example data with high accuracy, but the balance between the number of positive example data and negative example data is different from the original data, and bias due to undersampling occurs in the probability prediction result. I will end up.</p>
<p>Some people have already summarized how to deal with this problem in the following blogs, etc., but I will summarize as a memo about how to remove the bias of the probability output by the model constructed with undersampled data and correct it. .. In this article, we simply use the logistic regression model as a model for probability prediction.</p>
<ul>
<li><a href="https://tjo.hatenablog.com/entry/2019/08/04/150431">Correct the bias of prediction probability when dealing with imbalanced data with Undersampling + bagging and visualize the result</a></li>
<li><a href="https://pompom168.hatenablog.com/entry/2019/07/22/113433">Bias of prediction probability by downsampling</a></li>
</ul>
<h1 id="bias-correction-method-by-undersampling">Bias correction method by undersampling</h1>
<p>For the bias correction method by undersampling, see [Calibrating Probability with Undersampling for Unbalanced Classification]
(<a href="https://www3.nd.edu/~dial/publications/dalpozzolo2015calibrating.pdf)">https://www3.nd.edu/~dial/publications/dalpozzolo2015calibrating.pdf)</a>.</p>
<p>Now consider a binary classification task that predicts the objective variable $Y$ (where $Y$ has a value of 0 or 1) from the explanatory variable $X$.
The original data set $(X, Y)$ is set as unbalanced data with extremely small number of positive cases, and undersampling sets the number of negative cases equal to the number of positive cases to $(X_s , Y_s)$. It also takes 1 if some data (sample) contained in $(X, Y)$ is also contained in $(X_s, Y_s)$, and 0 if it is not contained in $(X_s, Y_s)$. Introduce a sampling variable $s$ that takes.</p>
<p>When an explanatory variable is given to a model constructed using the original dataset $(X, Y)$, the probability of predicting a positive case is expressed as $p(y=1|x)$. Also, when an explanatory variable is given to a model constructed using the undersampled data set $(X_s, Y_s)$, the probability of predicting a positive example is $p(y=1|x,s=1)$. Is expressed. If $p=p(y=1|x), p_s=p(y|x,s=1)$, the relation between $p$ and $p_s$ is as follows.</p>
<pre><code class="language-math" data-lang="math">p=\frac{\beta p_s}{\beta p_s-p_s+1}
</code></pre><p>Where $\beta=N^+/N^-$ (where $N^+$ is the number of positive examples and $N^-$ is the number of negative examples).</p>
<h5 id="derivation">Derivation</h5>
<p>The following is a detailed explanation of the formula, so if you are not interested, please skip it.</p>
<p>From Bayes&rsquo; theorem and $p(s|y,x)=p(s|y)$, the probability predicted by the model constructed using the undersampled data set $(X_s, Y_s)$ is as follows. Can be written.</p>
<pre><code class="language-math" data-lang="math">p(y=1|x,s=1)=\frac{p(s=1|y=1)p(y=1|x)}{p(s=1|y=1)p(y= 1|x)+p(s=1|y=0)p(y=0|x)}
</code></pre><p>Now, the number of data in the positive example is extremely small, and all the data with $y=1$ are sampled, so if $p(s=1|y=1)=1$,</p>
<pre><code class="language-math" data-lang="math">p(y=1|x,s=1)=\frac{p(y=1|x)}{p(y=1|x)+p(s=1|y=0)p(y=0 |x)}
</code></pre><p>Can be written as
Furthermore, if $p=p(y=1|x), p_s=p(y|x,s=1), \beta=p(s=1|y=0)$,</p>
<pre><code class="language-math" data-lang="math">p_s=\frac{p}{p+\beta(1-p)}
</code></pre><p>Will be. Finally, if you transform so that $p$ is on the left side,</p>
<pre><code class="language-math" data-lang="math">p=\frac{\beta p_s}{\beta p_s-p_s+1}
</code></pre><p>Will be.
The last equation means that the probability that a model constructed using the undersampled data predicts $p_s$ to remove the bias, and the probability that the model constructed using the original data predicts $p_s$. It means that you can calculate p$.</p>
<p>Where $\beta=p(s=1|y=0)$ represents the probability that the sample negative data is sampled. Now, the negative example data is sampled by the same number as the positive example data, so $\beta=N^+/N^-$ ($N^+$ is the number of positive example data and $N^-$ is The number of data in the negative example) can be approximated.</p>
<p>#Code example
In the following, we will show an actual code example and perform an experiment to correct the prediction probability. (Operating environment of the following code is Python 3.7.3, pandas 0.24.2, scikit-learn 0.20.3.)</p>
<p>The experiment is performed according to the following flow.</p>
<ol>
<li>Build a model using unbalanced data as it is and verify classification accuracy.</li>
<li>Build a model using undersampled data and verify that classification accuracy improves but probability prediction accuracy is low.</li>
<li>Verify whether the accuracy of probability prediction is improved by applying the correction that removes the bias due to undersampling.</li>
</ol>
<p>Here, <a href="http://archive.ics.uci.http://archive.ics.uci.edu/ml/index.php">Adult Dataset</a>publishedat<a href="http://archive.ics.uci.edu/ml/machine-learning-databases/adult/">UCIMachineLearningRepository</a>. This dataset is a dataset for classifying whether an individual&rsquo;s annual income is 50,000$ or more based on data such as gender and age.</p>
<p>First, load the data you want to use. Here, <a href="http://archive.ics.uci.edu/ml/machine-learning-databases/adult/">Adult dataset</a>
Adult.data and adult.test are saved locally as a CSV file, and the former is used as learning data and the latter is used as verification data.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">import</span> pandas <span style="color:#f92672">as</span> pd

<span style="color:#75715e">#Read data</span>
train_data <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>read_csv(<span style="color:#e6db74">&#39;./adult_data.csv&#39;</span>, names<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;age&#39;</span>,<span style="color:#e6db74">&#39;workclass&#39;</span>,<span style="color:#e6db74">&#39;fnlwgt&#39;</span>,<span style="color:#e6db74">&#39;education&#39;</span>,<span style="color:#e6db74">&#39;education-num&#39;</span>,
                                         <span style="color:#e6db74">&#39;marital-status&#39;</span>,<span style="color:#e6db74">&#39;occupation&#39;</span>,<span style="color:#e6db74">&#39;relationship&#39;</span>,<span style="color:#e6db74">&#39;race&#39;</span>,<span style="color:#e6db74">&#39;sex&#39;</span>,
                                         <span style="color:#e6db74">&#39;capital-gain&#39;</span>,<span style="color:#e6db74">&#39;capital-loss&#39;</span>,<span style="color:#e6db74">&#39;hours-per-week&#39;</span>,<span style="color:#e6db74">&#39;native-country&#39;</span>,<span style="color:#e6db74">&#39;obj&#39;</span>])
test_data <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>read_csv(<span style="color:#e6db74">&#39;./adult_test.csv&#39;</span>, names<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;age&#39;</span>,<span style="color:#e6db74">&#39;workclass&#39;</span>,<span style="color:#e6db74">&#39;fnlwgt&#39;</span>,<span style="color:#e6db74">&#39;education&#39;</span>,<span style="color:#e6db74">&#39;education-num&#39;</span>,
                                         <span style="color:#e6db74">&#39;marital-status&#39;</span>,<span style="color:#e6db74">&#39;occupation&#39;</span>,<span style="color:#e6db74">&#39;relationship&#39;</span>,<span style="color:#e6db74">&#39;race&#39;</span>,<span style="color:#e6db74">&#39;sex&#39;</span>,
                                         <span style="color:#e6db74">&#39;capital-gain&#39;</span>,<span style="color:#e6db74">&#39;capital-loss&#39;</span>,<span style="color:#e6db74">&#39;hours-per-week&#39;</span>,<span style="color:#e6db74">&#39;native-country&#39;</span>,<span style="color:#e6db74">&#39;obj&#39;</span>],
                       skiprows<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
data <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>concat([train_data, test_data])

<span style="color:#75715e">#Processing of explanatory variable X and objective variable Y</span>
X <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>get_dummies(data<span style="color:#f92672">.</span>drop(<span style="color:#e6db74">&#39;obj&#39;</span>, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>))
Y <span style="color:#f92672">=</span> data[<span style="color:#e6db74">&#39;obj&#39;</span>]<span style="color:#f92672">.</span>map(<span style="color:#66d9ef">lambda</span> x: <span style="color:#ae81ff">1</span> <span style="color:#66d9ef">if</span> x<span style="color:#f92672">==</span><span style="color:#e6db74">&#39; &gt;50K&#39;</span> <span style="color:#f92672">or</span> x<span style="color:#f92672">==</span><span style="color:#e6db74">&#39; &gt;50K.&#39;</span> <span style="color:#66d9ef">else</span> <span style="color:#ae81ff">0</span>) <span style="color:#75715e"># Objective variable is 1 or 0</span>

<span style="color:#75715e"># Split into learning data and verification data</span>
train_size <span style="color:#f92672">=</span> len(train_data)
X_train, X_test <span style="color:#f92672">=</span> X<span style="color:#f92672">.</span>iloc[:train_size], X<span style="color:#f92672">.</span>iloc[train_size:]
Y_train, Y_test <span style="color:#f92672">=</span> Y<span style="color:#f92672">.</span>iloc[:train_size], Y<span style="color:#f92672">.</span>iloc[train_size:]
</code></pre></div><p>Looking at the percentage of positive cases in the training data, it is about 24%, which is smaller than the negative cases and can be said to be imbalanced data.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;positive ratio = {:.2f}%&#39;</span><span style="color:#f92672">.</span>format((len(Y_train[Y_train<span style="color:#f92672">==</span><span style="color:#ae81ff">1</span>])<span style="color:#f92672">/</span>len(Y_train))<span style="color:#f92672">*</span><span style="color:#ae81ff">100</span>))
<span style="color:#75715e">#Output =&gt; positive ratio = 24.08%</span>
</code></pre></div><p>If you build a model using this learning data as it is, you can see that the classification accuracy is low at AUC=0.57 and the recall (Recall) is low at 0.26. It is considered that the number of negative examples in the training data is large, the prediction result is often negative examples, and the recall rate (the rate at which positive example data can be correctly classified as positive examples) is low.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> sklearn.linear_model <span style="color:#f92672">import</span> LogisticRegression
<span style="color:#f92672">from</span> sklearn.metrics <span style="color:#f92672">import</span> roc_auc_score, recall_score

<span style="color:#75715e"># Model building</span>
lr <span style="color:#f92672">=</span> LogisticRegression(random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)
lr<span style="color:#f92672">.</span>fit(X_train, Y_train)

<span style="color:#75715e"># Verify classification accuracy</span>
prob <span style="color:#f92672">=</span> lr<span style="color:#f92672">.</span>predict_proba(X_test)[:, <span style="color:#ae81ff">1</span>] <span style="color:#75715e"># predict the probability that the objective variable is 1</span>
pred <span style="color:#f92672">=</span> lr<span style="color:#f92672">.</span>predict(X_test) <span style="color:#75715e"># 1 or 0</span>
auc <span style="color:#f92672">=</span> roc_auc_score(y_true<span style="color:#f92672">=</span>Y_test, y_score<span style="color:#f92672">=</span>prob)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;AUC = {:.2f}&#39;</span><span style="color:#f92672">.</span>format(auc))
recall <span style="color:#f92672">=</span> recall_score(y_true<span style="color:#f92672">=</span>Y_test, y_pred<span style="color:#f92672">=</span>pred)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;recall = {:.2f}&#39;</span><span style="color:#f92672">.</span>format(recall))

<span style="color:#75715e">#Output =&gt; AUC = 0.57</span>
<span style="color:#75715e">#Output =&gt; recall = 0.26</span>
<span style="color:#e6db74">``</span><span style="color:#960050;background-color:#1e0010">`</span>Next, undersampling <span style="color:#f92672">is</span> performed so that the number of negative examples <span style="color:#f92672">in</span> the training data <span style="color:#f92672">is</span> equal to the number of positive examples, <span style="color:#f92672">and</span> a model <span style="color:#f92672">is</span> constructed using this data, the classification accuracy <span style="color:#f92672">is</span> greatly improved to AUC<span style="color:#f92672">=</span><span style="color:#ae81ff">0.90</span>, recall<span style="color:#f92672">=</span><span style="color:#ae81ff">0.86</span><span style="color:#f92672">.</span> You can see that

<span style="color:#e6db74">``</span><span style="color:#960050;background-color:#1e0010">`</span>python
<span style="color:#75715e"># Undersampling</span>
pos_idx <span style="color:#f92672">=</span> Y_train[Y_train<span style="color:#f92672">==</span><span style="color:#ae81ff">1</span>]<span style="color:#f92672">.</span>index
neg_idx <span style="color:#f92672">=</span> Y_train[Y_train<span style="color:#f92672">==</span><span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>sample(n<span style="color:#f92672">=</span>len(Y_train[Y_train<span style="color:#f92672">==</span><span style="color:#ae81ff">1</span>]), replace<span style="color:#f92672">=</span>False, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)<span style="color:#f92672">.</span>index
idx <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>concatenate([pos_idx, neg_idx])
X_train_sampled <span style="color:#f92672">=</span> X_train<span style="color:#f92672">.</span>iloc[idx]
Y_train_sampled <span style="color:#f92672">=</span> Y_train<span style="color:#f92672">.</span>iloc[idx]

<span style="color:#75715e"># Model building</span>
lr <span style="color:#f92672">=</span> LogisticRegression(random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)
lr<span style="color:#f92672">.</span>fit(X_train_sampled, Y_train_sampled)

<span style="color:#75715e"># Verify classification accuracy</span>
prob <span style="color:#f92672">=</span> lr<span style="color:#f92672">.</span>predict_proba(X_test)[:, <span style="color:#ae81ff">1</span>]
pred <span style="color:#f92672">=</span> lr<span style="color:#f92672">.</span>predict(X_test)
auc <span style="color:#f92672">=</span> roc_auc_score(y_true<span style="color:#f92672">=</span>Y_test, y_score<span style="color:#f92672">=</span>prob)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;AUC = {:.2f}&#39;</span><span style="color:#f92672">.</span>format(auc))
recall <span style="color:#f92672">=</span> recall_score(y_true<span style="color:#f92672">=</span>Y_test, y_pred<span style="color:#f92672">=</span>pred)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;recall = {:.2f}&#39;</span><span style="color:#f92672">.</span>format(recall))

<span style="color:#75715e">#Output =&gt; AUC = 0.90</span>
<span style="color:#75715e">#Output =&gt; recall = 0.86</span>
</code></pre></div><p>At this time, let&rsquo;s look at the prediction accuracy of probability. You can see that the log loss is 0.41 and the calibration plot is below the 45 degree line. Passing the calibration plot below the 45-degree line means that the predicted probability is greater than the actual probability. Since the model is constructed using the undersampled data so that the number of negative example data is equal to the number of positive example data, learning is performed in the state where the ratio of the number of positive example data is larger than the actual one. It is thought that the probability is predicted to be large.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#f92672">as</span> plt
<span style="color:#f92672">%</span>matplotlib inline
<span style="color:#f92672">from</span> sklearn.calibration <span style="color:#f92672">import</span> calibration_curve
<span style="color:#f92672">from</span> sklearn.metrics <span style="color:#f92672">import</span> log_loss

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">calibration_plot</span>(y_true, y_prob):
    prob_true, prob_pred <span style="color:#f92672">=</span> calibration_curve(y_true<span style="color:#f92672">=</span>y_true, y_prob<span style="color:#f92672">=</span>y_prob, n_bins<span style="color:#f92672">=</span><span style="color:#ae81ff">20</span>)

    fig, ax1 <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>subplots()
    ax1<span style="color:#f92672">.</span>plot(prob_pred, prob_true, marker<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;s&#39;</span>, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;calibration plot&#39;</span>, color<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;skyblue&#39;</span>) <span style="color:#75715e"># create a calibration plot</span>
    ax1<span style="color:#f92672">.</span>plot([<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>], [<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>], linestyle<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;--&#39;</span>, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;ideal&#39;</span>, color<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;limegreen&#39;</span>) <span style="color:#75715e"># plot 45 degree line</span>
    ax1<span style="color:#f92672">.</span>legend(bbox_to_anchor<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1.12</span>, <span style="color:#ae81ff">1</span>), loc<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;upper left&#39;</span>)
    plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#39;predicted probability&#39;</span>)
    plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#39;actual probability&#39;</span>)
    
    ax2 <span style="color:#f92672">=</span> ax1<span style="color:#f92672">.</span>twinx() <span style="color:#75715e"># add 2 axes</span>
    ax2<span style="color:#f92672">.</span>hist(prob, bins<span style="color:#f92672">=</span><span style="color:#ae81ff">20</span>, histtype<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;step&#39;</span>, color<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;orangered&#39;</span>) <span style="color:#75715e"># Score histogram also plotted</span>
    plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#39;frequency&#39;</span>)
    plt<span style="color:#f92672">.</span>show()

prob <span style="color:#f92672">=</span> lr<span style="color:#f92672">.</span>predict_proba(X_test)[:, <span style="color:#ae81ff">1</span>]
loss <span style="color:#f92672">=</span> log_loss(y_true<span style="color:#f92672">=</span>Y_test, y_pred<span style="color:#f92672">=</span>prob)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;log loss = {:.2f}&#39;</span><span style="color:#f92672">.</span>format(loss))
calibration_plot(y_true<span style="color:#f92672">=</span>Y_test, y_prob<span style="color:#f92672">=</span>prob)

<span style="color:#75715e"># Output =&gt; log loss = 0.41</span>
</code></pre></div><p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/258694/9565e0cd-42ef-2a14-9f2f-233a6f183768.png" alt="image.png"></p>
<p>Now, try removing the bias due to undersampling and correcting the probability. Calculate $\beta$, $
When the probability is corrected according to p=\beta p_s/(\beta p_s-p_s+1$), the log loss improves to 0.32, and it can be seen that the calibration plot is also on the 45-degree line. Note that $\beta$ uses the number of positive/negative examples of training data (the number of positive/negative examples of verification data is unknown).</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">beta <span style="color:#f92672">=</span> len(Y_train[Y_train<span style="color:#f92672">==</span><span style="color:#ae81ff">1</span>]) <span style="color:#f92672">/</span> len(Y_train[Y_train<span style="color:#f92672">==</span><span style="color:#ae81ff">0</span>])
prob_corrected <span style="color:#f92672">=</span> beta<span style="color:#f92672">*</span>prob <span style="color:#f92672">/</span> (beta<span style="color:#f92672">*</span>prob<span style="color:#f92672">-</span>prob <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>)

loss <span style="color:#f92672">=</span> log_loss(y_true<span style="color:#f92672">=</span>Y_test, y_pred<span style="color:#f92672">=</span>prob_corrected)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;log loss = {:.2f}&#39;</span><span style="color:#f92672">.</span>format(loss))
calibration_plot(y_true<span style="color:#f92672">=</span>Y_test, y_prob<span style="color:#f92672">=</span>prob_corrected)

<span style="color:#75715e">#Output =&gt; log loss = 0.32</span>
</code></pre></div><p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/258694/4c7fe85e-ffe0-3fc4-7337-910841e43e45.png" alt="image.png"></p>
<p>It was confirmed that the bias due to undersampling can be removed and the probability can be corrected. That is all for verification.</p>
<h1 id="in-conclusion">in conclusion</h1>
<p>In this article, I briefly summarized how to correct the probability predicted by a model built using undersampled data. If you have any mistakes, I would appreciate it if you could point me out.</p>
<p>#Reference</p>
<ul>
<li><a href="https://gihyo.jp/book/2018/978-4-7741-9647-3">SQL/R/Python practice technique for preprocessing Daizen data analysis</a></li>
<li>[Andrea Dal Pozzolo, et al. &ldquo;Calibrating Probability with Undersampling for Unbalanced Classification&rdquo;, in Proceedings of IEEE Symposium Series on Computational Intelligence, pp.159-166, Dec. 2015.]
(<a href="https://www3.nd.edu/~dial/publications/dalpozzolo2015calibrating.pdf">https://www3.nd.edu/~dial/publications/dalpozzolo2015calibrating.pdf</a>)</li>
</ul>

    </article>
  </div>

  
  
  
  <script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-123456789-1', 'auto');
  ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  

  
<link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.css" />
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#216942",
      "text": "#b2d192"
    },
    "button": {
      "background": "#afed71"
    }
  }
})});
</script>

</body>

</html>
