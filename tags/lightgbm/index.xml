<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>lightgbm on Memo Tut</title>
    <link>https://memotut.com/tags/lightgbm/</link>
    <description>Recent content in lightgbm on Memo Tut</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 29 Apr 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://memotut.com/tags/lightgbm/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>[Python] Data analysis started with python (data preprocessing-machine learning)</title>
      <link>https://memotut.com/b7dc768d1/</link>
      <pubDate>Wed, 29 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/b7dc768d1/</guid>
      <description>#Introduction  For beginners, I would like to explain from data preprocessing in python to machine learning model construction. Use gradient boosting for machine learning.
Source code https://gitlab.com/ceml/qiita/-/blob/master/src/python/notebook/first_time_ml.ipynb
Content of this article table of contents  Data preprocessing 1-1. Read data 1-2. Combine data 1-3. Compensation for missing areas 1-4. Feature creation 1-5. Data division Machine learning 2-1. Dataset creation and model definition 2-2. Model training and evaluation 2-3. Check the importance of features  About dataset ・Provided by: California Institute of Technology ・Contents: Heart disease test data ・URL: https://archive.</description>
    </item>
    
    <item>
      <title>[Python] For those who look at the log while learning with machine learning ~ Muscle training with LightGBM ~</title>
      <link>https://memotut.com/fbe575011/</link>
      <pubDate>Mon, 23 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/fbe575011/</guid>
      <description>What do you guys do when learning models with machine learning?  Did you just look at the log output to the console? &amp;ldquo;Oh, it was lower than I expected!&amp;rdquo; &amp;ldquo;Oh, the accuracy is getting worse, do your best!!&amp;rdquo; It&amp;rsquo;s surprisingly fun to think, though.
But when I cheered up, the model doesn&amp;rsquo;t do its best, and there is no dramatic development, so it&amp;rsquo;s a waste of time to look at it.</description>
    </item>
    
    <item>
      <title>[Python] I don&#39;t want to search for high para because it is IQ1 (how to use lightgbm_tuner)</title>
      <link>https://memotut.com/dee7f7e61/</link>
      <pubDate>Sun, 01 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/dee7f7e61/</guid>
      <description>This article is posted on [IQ1&#39;s 2nd Advent Calendar 2019](https://adventar.org/calendars/4711).  IQ1 machine learning For machine learning, data preprocessing and model hyper search are inevitable. However, I have an IQ of 1, so I don&amp;rsquo;t want to do it if I can do preprocessing of data and high-para search. If you put the preprocessing of data into this modern gradient boosting tree system algorithm (such as lightgbm), you can handle the missing values as they are and you do not have to preprocess the categorical variables, so it will be a world relatively friendly to IQ1.</description>
    </item>
    
  </channel>
</rss>