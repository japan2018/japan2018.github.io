<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>pandas on Some Title</title>
    <link>https://japan2018.github.io/tags/pandas/</link>
    <description>Recent content in pandas on Some Title</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 31 May 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://japan2018.github.io/tags/pandas/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>[Python] Format when to_csv with pandas</title>
      <link>https://japan2018.github.io/python-format-when-to_csv-with-pandas-f9102/</link>
      <pubDate>Sun, 31 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://japan2018.github.io/python-format-when-to_csv-with-pandas-f9102/</guid>
      <description>I googled the same thing over and over again, so make a note of it yourself. Used when storing data in pandas and saving to a file as to_csv. It is used when you want to make the format nice to publish and want to arrange the number of digits.  Format the float  To specify the whole float, you can set the argument of to_csv as float_format=&amp;quot;%10.4f&amp;quot; You can use round().</description>
    </item>
    
    <item>
      <title>Python Basic - Pandas, Numpy -</title>
      <link>https://japan2018.github.io/python-basic-pandas-numpy-fc9e2/</link>
      <pubDate>Wed, 29 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://japan2018.github.io/python-basic-pandas-numpy-fc9e2/</guid>
      <description># 0. Introduction of Numpy  NumPy is a Python package. It stands for &amp;lsquo;Numerical Python&amp;rsquo;, and Numpy is a linear algebra library to work with dimensional arrays, which contains useful linear algebra routines and random number capabilities.
1. Numpy arrange() method The arange() method in the Numpy module in Python is used to generate linear sequence of numbers. If does it on the basis of the pre-provide starting and ending points along with a constant step size.</description>
    </item>
    
    <item>
      <title>pandasのto_datetimeで「TypeError: Unrecognized value type: &lt;class &#39;str&#39;&gt;」</title>
      <link>https://japan2018.github.io/pandas%E3%81%AEto_datetime%E3%81%A7typeerror-unrecognized-value-type-class-str-fa2a0/</link>
      <pubDate>Fri, 17 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://japan2018.github.io/pandas%E3%81%AEto_datetime%E3%81%A7typeerror-unrecognized-value-type-class-str-fa2a0/</guid>
      <description>This error occurs when a character string that cannot be recognized as a date is included.  I am addicted to it, so I have summarized it in an article.
When creating a DataFrame, if a &amp;ldquo;value that is not a date&amp;rdquo; is entered between date strings, it will be read as an object. (Note that if it consists of all strings that can be interpreted as a date, it can be read as datetime.</description>
    </item>
    
    <item>
      <title>7rep - Insert Dataframe To Elasticsearch</title>
      <link>https://japan2018.github.io/7rep-insert-dataframe-to-elasticsearch-fe1b5/</link>
      <pubDate>Sat, 11 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://japan2018.github.io/7rep-insert-dataframe-to-elasticsearch-fe1b5/</guid>
      <description>#TSV(CSV) code sample to insert into Elasicsearch  from elasticsearch import Elasticsearch from elasticsearch import helpers import pandas as pd import datetime import time import json import random from pandas.io.json import json_normalize # Elasticsearch es = Elasticsearch(&amp;#34;{ES_IP}&amp;#34;) INDEX = &amp;#34;{ES_Index_Name}&amp;#34; fname=&amp;#34;{FileName}&amp;#34; reader = pd.read_csv(fname, chunksize=1000, sep=&amp;#39;\t&amp;#39;,low_memory = False) df_all = reader.get_chunk() # chunk the dataframe # json df_lines = df_all.to_json(force_ascii=False, orient=&amp;#39;records&amp;#39;, lines=True) # Bulk inser actions = [] for i in iter(df_lines.</description>
    </item>
    
    <item>
      <title>[Pandas 1.0.1 Memorial] Fierce battle with Cookbook</title>
      <link>https://japan2018.github.io/pandas-1.0.1-memorial-fierce-battle-with-cookbook-faf24/</link>
      <pubDate>Mon, 09 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://japan2018.github.io/pandas-1.0.1-memorial-fierce-battle-with-cookbook-faf24/</guid>
      <description>#Background   Every time there is a Google search, it is bloody and not flesh due to temporary understanding. Fragmental knowledge alone is not enough to apply when it is difficult to apply. In order to overcome the weakened memory, it is necessary to move it, understand it, and explain it to the brain. I would like to carry out a dictum from the predecessors, &amp;ldquo;Please read the official manual&amp;rdquo;.</description>
    </item>
    
    <item>
      <title>pandas series part 1</title>
      <link>https://japan2018.github.io/pandas-series-part-1-fc2b7/</link>
      <pubDate>Sat, 29 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://japan2018.github.io/pandas-series-part-1-fc2b7/</guid>
      <description>Series is a one-dimensional data structure.  import pandas as pd series = pd.Series([3, 6, 9]) print(series) Execution result of ```:1 0 3 1 6 2 9 dtype: int64
 There is an index in the leftmost column. To change the index, write as follows ```py:2 import pandas as pd names = [&amp;quot;Tanaka&amp;quot;, &amp;quot;Yamada&amp;quot;, &amp;quot;Takahashi&amp;quot;] series1 = pd.Series(names) series2 = pd.Series(names, index=[&#39;a&#39;,&#39;b&#39;,&#39;c&#39;]) print(series1) print(series2) Execution result of ```:2 0 Tanaka 1 Yamada 2 Takahashi dtype: object a Tanaka b Yamada c Takahashi dtype: object</description>
    </item>
    
    <item>
      <title>Analyzing Twitter Data | Trend Analysis編</title>
      <link>https://japan2018.github.io/analyzing-twitter-data-trend-analysis%E7%B7%A8-fee64/</link>
      <pubDate>Thu, 20 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://japan2018.github.io/analyzing-twitter-data-trend-analysis%E7%B7%A8-fee64/</guid>
      <description>This article is a trend analysis of Twitter Data analysis. I will deepen this series later. Since this is my first article, I will explain this case in detail after briefly analyzing Twitter Data. Because Japanese is tight, I will change it to English. [Git Repository](https://github.com/Bing-Violet/Real-Time-insights-from-social-media/blob/master/notebook.ipynb)   ###Why Analyze Twitter Data? Twitter data analysis is used in a wide range of areas including but not restricted to analyzing the mentions of each political party in an election, detecting the reactions to the introduction of a new product, understanding the geographical scope of discussion of a news story.</description>
    </item>
    
    <item>
      <title>Try to write aggregation processing for a certain period using pandas × groupby × Grouper</title>
      <link>https://japan2018.github.io/try-to-write-aggregation-processing-for-a-certain-period-using-pandas-groupby-grouper-fafc1/</link>
      <pubDate>Thu, 12 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://japan2018.github.io/try-to-write-aggregation-processing-for-a-certain-period-using-pandas-groupby-grouper-fafc1/</guid>
      <description>I wrote this article from the motivation &amp;quot;I want to write a process to create a feature amount that aggregates a certain column for N days in pandas, what should I do?&amp;quot;  Sample code is excerpted from Google Colabratory linked below. GoogleColab-pandas × groupby × Grouper sample
In addition, the data here (kaggle Datasets-Bitcoin Historical Data) is used.
First of all, from the pre-processing of data, convert the Timestamp column to datetime type for the previous processing.</description>
    </item>
    
    <item>
      <title>Feature generation with pandas group by</title>
      <link>https://japan2018.github.io/feature-generation-with-pandas-group-by-fa15c/</link>
      <pubDate>Wed, 11 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://japan2018.github.io/feature-generation-with-pandas-group-by-fa15c/</guid>
      <description>I want to create features with group by #pandas  When you want to add a statistic for each attribute of a column to a feature, you may not need to create a dict with collections or groupby and merge it. Although it is easy to simply output statistics, I left it as a memo because I struggled with how to use pandas.DataFrame.groupby when I wanted to add it to a record as a feature.</description>
    </item>
    
    <item>
      <title>I tried VS Code Jupyter notebook</title>
      <link>https://japan2018.github.io/i-tried-vs-code-jupyter-notebook-fd079/</link>
      <pubDate>Thu, 21 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://japan2018.github.io/i-tried-vs-code-jupyter-notebook-fd079/</guid>
      <description>I tried #VSCode&#39;s Jupyter notebook.  There was an article of VS Code Jupyter notebook in the magazine, so I tried it. I made a Jupyter notebook experience very easily, so I will make a note of my footsteps.
Assumption  Tried on Mac. Homebrew has python installed as python3. When I put python3, pip3 is also included  ###python3
$ which python3 /usr/local/bin/python3 $python3 --version Python 3.7.5 ###pip3
$ which pip3 /usr/local/bin/pip3 $ pip3 --version pip 19.</description>
    </item>
    
    <item>
      <title>How to speed up Pandas apply method with just one sentence (with verification calculation)</title>
      <link>https://japan2018.github.io/how-to-speed-up-pandas-apply-method-with-just-one-sentence-with-verification-calculation-fc4d2/</link>
      <pubDate>Thu, 14 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://japan2018.github.io/how-to-speed-up-pandas-apply-method-with-just-one-sentence-with-verification-calculation-fc4d2/</guid>
      <description>#Conclusion  Just add swifter method before Pandas apply method
Concrete example import pandas as pd import numpy as np import swifter # Create a suitable DataFrame df = pd.DataFrame({&amp;#39;col&amp;#39;: np.random.normal(size=10000000)}) # Add swifter method before apply method. %time df[&amp;#39;col2&amp;#39;] = df[&amp;#39;col&amp;#39;].swifter.apply(lambda x: x**2) # Wall time: 50 ms # For comparison (normal pandas apply method) %time df[&amp;#39;col2&amp;#39;] = df[&amp;#39;col&amp;#39;].apply(lambda x: x**2) # Wall time: 3.48 s How to install $ pip install -U pandas # upgrade pandas $ pip install swifter In case of ```terminal:conda $ conda update pandas # upgrade pandas $ conda install -c conda-forge swifter</description>
    </item>
    
    <item>
      <title>Best practices for data manipulation with pandas</title>
      <link>https://japan2018.github.io/best-practices-for-data-manipulation-with-pandas-f7ed4/</link>
      <pubDate>Mon, 04 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://japan2018.github.io/best-practices-for-data-manipulation-with-pandas-f7ed4/</guid>
      <description>After preprocessing the data with machine learning, with a hypothesis,  Play with data? Play with? I think there are phases, At that time, how to control pandas freely is I think it will be important.
I myself have a little programming experience and database knowledge,
***pandas DataFrame [] ← This is too complicated! ! ***
Especially, it is difficult to narrow down by conditions.
train[train[&amp;#34;company_id&amp;#34;] == 1088][&amp;#34;meter_reading&amp;#34;] It&amp;rsquo;s confusing at this point, but if this is train_weather_df, it will be ruined</description>
    </item>
    
  </channel>
</rss>