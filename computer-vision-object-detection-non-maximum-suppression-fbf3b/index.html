<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  <meta name="generator" content="Hugo 0.72.0" />

  
  <meta name="description" content="Some description">
  

  
  <link rel="apple-touch-icon" sizes="180x180" href="https://japan2018.github.io/apple-touch-icon.png">

  
  <link rel="icon" type="image/png" sizes="32x32" href="https://japan2018.github.io/favicon-32x32.png">

  
  <link rel="icon" type="image/png" sizes="16x16" href="https://japan2018.github.io/favicon-16x16.png">

  
  <link rel="manifest" href="https://japan2018.github.io/site.webmanifest">

  
  <link rel="mask-icon" href="https://japan2018.github.io/safari-pinned-tab.svg" color="#5bbad5">

  <meta name="msapplication-TileColor" content="#da532c">

  <meta name="theme-color" content="#ffffff">

  
  <link rel="stylesheet" href="https://japan2018.github.io/css/bootstrap.min.css" />

  
  <title>Computer Vision : Object Detection - Non Maximum Suppression | Some Title</title>
  

  <style>
body {
  min-width: 300px;
}

.custom-navbar {
  margin-bottom: 1em;
  height: 60px;
}

.custom-navbar a {
  display: inline-block; 
  padding: 18px 0;
  margin-right: 1em; 
  font-weight: bold; 
}

.custom-navbar a:hover,
.custom-navbar a:focus {
  text-decoration: none; 
}

@media print {
  .custom-navbar {
    display: none;
  }
}

article {
  padding-bottom: 1em;
}

img {
  max-width: 100%;
}


body {
  background-color: #fff;
}



body {
  color: #212529;
}



a {
  color: #007bff;
}



a:hover,
a:focus {
  color: #0056b3;
}



.custom-navbar {
  background-color: #212529;
}



.custom-navbar a {
  color: rgba(255, 255, 255, 0.75);
}



.custom-navbar a:hover,
.custom-navbar a:focus {
  color: rgba(255, 255, 255, 1);
}



.container {
  max-width: 800px;
}



pre {
  display: block;
  padding: 9.5px;
  word-break: break-all;
  word-wrap: break-word;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre code {
  padding: 0;
  font-size: inherit;
  color: inherit; 
  white-space: pre-wrap;
  background-color: transparent;
  border: none;
  border-radius: 0;
}

code {
  padding: 2px 4px;
  color: inherit; 
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
  font-size: .9em;
}



blockquote,
.blockquote {
  padding: 10px 20px;
  margin: 0 0 20px;
  font-size: 1em;
  border-left: 5px solid #6c757d;
}

</style>
</head>

<body>
  <nav class="custom-navbar">
  <div class="container">
    
    <a href="/">Posts</a>
    
    <a href="/tags/">Tags</a>
    
    <a href="/about/">About</a>
    
    <a href="/index.xml">RSS</a>
    
  </div>
</nav>
  
  <div class="container">
    <article>
      <h1>Computer Vision : Object Detection - Non Maximum Suppression</h1>
<p>
  <small class="text-secondary">
  
  
  Jan 6, 2020
  </small>
  

<small><code><a href="https://japan2018.github.io/tags/python">Python</a></code></small>


<small><code><a href="https://japan2018.github.io/tags/opencv">OpenCV</a></code></small>


<small><code><a href="https://japan2018.github.io/tags/imageprocessing">ImageProcessing</a></code></small>


<small><code><a href="https://japan2018.github.io/tags/objectdetection">ObjectDetection</a></code></small>


<small><code><a href="https://japan2018.github.io/tags/nonmaximumsuppression">NonMaximumSuppression</a></code></small>

</p>
<pre><code>#Target
</code></pre>
<p>Implement Non Maximum Suppression used in object detection.</p>
<p>#Introduction
This section introduces Intersection over Union and Non Maximum Suppression used in <a href="https://qiita.com/sho_watari/items/c9bc5ad09a886508e154">Computer Vision: Object Detection Part2-Single Shot Multi Detector</a>.</p>
<p>##Non Maximum Suppression (NMS)
In object detection, multiple candidate regions that are presumed to exist may be obtained for one recognized object, as shown in the figure below.</p>
<p>The part surrounded by the colored rectangle indicates the candidate area, and the display at the upper left of each candidate area indicates the category and the certainty factor of the object existing in that candidate area.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/176315/365b339f-7a4e-dbf1-f7d0-434431784177.png" alt="bicycle-car-dog_bbox.png"></p>
<p>Non Maximum Suppression is the process that wants to retain only the candidate region with the highest certainty among the obtained candidate regions, that is, suppressing the non-maximum candidate region.</p>
<p>Now that we have decided the purpose of narrowing down the candidate areas, we will consider how to realize it.</p>
<h2 id="intersection-over-union-iou">Intersection over Union (IoU)</h2>
<p>In Non Maximum Suppression, the candidate area with the highest object certainty and other candidate areas are thresholded based on Intersection over Union (IoU), which is an index that quantifies the degree of overlap.</p>
<p>Considering two candidate areas as shown below, IoU can be calculated from the following equation.</p>
<pre><code class="language-math" data-lang="math">IoU = \frac{a \cap b}{a \cup b}
</code></pre><p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/176315/c557e2a0-a794-0a5b-12eb-36e8b034a033.png" alt="iou.png"></p>
<p>The symbols used in set theory, $a \cap b$ and $a \cup b$, represent the colored regions in the figure below, respectively. When mounting, calculate IoU by finding the area of each candidate area, common area and total area.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/176315/9c7affc3-57fb-52e6-73f1-acb5a60b69b3.png" alt="IoU_area.png"></p>
<p>IoU takes a value of [0, 1], and if the overlap is large, the value approaches 1, and if the overlap is small, the IoU value is also small. Therefore, a threshold is set in advance, and candidate areas with an IoU larger than the threshold are deleted. If the IoU value is smaller than the threshold value, it is considered that another object is detected and the candidate area is left.</p>
<p>#Implementation</p>
<h2 id="execution-environment">Execution environment</h2>
<p>###hardware
・CPU Intel(R) Core(TM) i7-6700 4.00GHz</p>
<p>###software
・Windows 10 Pro 1909
・Python 3.6.6
・Numpy 1.17.3
・Opencv-contrib-python 4.1.2.30</p>
<h2 id="program-to-execute">Program to execute</h2>
<p>The implemented program is published on <a href="https://github.com/sho-watari/ComputerVision/tree/master/SSMD">GitHub</a>.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-Python:non_maximum_suppression.py" data-lang="Python:non_maximum_suppression.py"></code></pre></div><p>#result
When the threshold was set to 0.1 and executed, each of the many candidate regions that were initially displayed was narrowed down to one.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/176315/246c2a6a-48a3-0dab-37fc-0a3891204419.png" alt="bicycle-car-dog_nms.png"></p>
<p>#reference
<a href="https://qiita.com/sho_watari/items/c9bc5ad09a886508e154">Computer Vision: Object Detection Part2-Single Shot Multi Detector</a></p>
<p>Tatsuya Harada. &ldquo;Machine Learning Professional Series Image Recognition&rdquo;, Kodansha, 2017.</p>

    </article>
  </div>

  
  
  
  <script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-123456789-1', 'auto');
  ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  

  
<link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.css" />
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#216942",
      "text": "#b2d192"
    },
    "button": {
      "background": "#afed71"
    }
  }
})});
</script>

</body>

</html>
