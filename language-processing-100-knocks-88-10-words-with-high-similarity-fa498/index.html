<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  <meta name="generator" content="Hugo 0.72.0" />

  
  <meta name="description" content="Some description">
  

  
  <link rel="apple-touch-icon" sizes="180x180" href="https://japan2018.github.io/apple-touch-icon.png">

  
  <link rel="icon" type="image/png" sizes="32x32" href="https://japan2018.github.io/favicon-32x32.png">

  
  <link rel="icon" type="image/png" sizes="16x16" href="https://japan2018.github.io/favicon-16x16.png">

  
  <link rel="manifest" href="https://japan2018.github.io/site.webmanifest">

  
  <link rel="mask-icon" href="https://japan2018.github.io/safari-pinned-tab.svg" color="#5bbad5">

  <meta name="msapplication-TileColor" content="#da532c">

  <meta name="theme-color" content="#ffffff">

  
  <link rel="stylesheet" href="https://japan2018.github.io/css/bootstrap.min.css" />

  
  <title>Language processing 100 knocks-88: 10 words with high similarity | Some Title</title>
  

  <style>
body {
  min-width: 300px;
}

.custom-navbar {
  margin-bottom: 1em;
  height: 60px;
}

.custom-navbar a {
  display: inline-block; 
  padding: 18px 0;
  margin-right: 1em; 
  font-weight: bold; 
}

.custom-navbar a:hover,
.custom-navbar a:focus {
  text-decoration: none; 
}

@media print {
  .custom-navbar {
    display: none;
  }
}

article {
  padding-bottom: 1em;
}

img {
  max-width: 100%;
}


body {
  background-color: #fff;
}



body {
  color: #212529;
}



a {
  color: #007bff;
}



a:hover,
a:focus {
  color: #0056b3;
}



.custom-navbar {
  background-color: #212529;
}



.custom-navbar a {
  color: rgba(255, 255, 255, 0.75);
}



.custom-navbar a:hover,
.custom-navbar a:focus {
  color: rgba(255, 255, 255, 1);
}



.container {
  max-width: 800px;
}



pre {
  display: block;
  padding: 9.5px;
  word-break: break-all;
  word-wrap: break-word;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre code {
  padding: 0;
  font-size: inherit;
  color: inherit; 
  white-space: pre-wrap;
  background-color: transparent;
  border: none;
  border-radius: 0;
}

code {
  padding: 2px 4px;
  color: inherit; 
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
  font-size: .9em;
}



blockquote,
.blockquote {
  padding: 10px 20px;
  margin: 0 0 20px;
  font-size: 1em;
  border-left: 5px solid #6c757d;
}

</style>
</head>

<body>
  <nav class="custom-navbar">
  <div class="container">
    
    <a href="/">Posts</a>
    
    <a href="/tags/">Tags</a>
    
    <a href="/about/">About</a>
    
    <a href="/index.xml">RSS</a>
    
  </div>
</nav>
  
  <div class="container">
    <article>
      <h1>Language processing 100 knocks-88: 10 words with high similarity</h1>
<p>
  <small class="text-secondary">
  
  
  Jan 16, 2020
  </small>
  

<small><code><a href="https://japan2018.github.io/tags/python">Python</a></code></small>


<small><code><a href="https://japan2018.github.io/tags/nlp"> NLP</a></code></small>


<small><code><a href="https://japan2018.github.io/tags/vector"> vector</a></code></small>


<small><code><a href="https://japan2018.github.io/tags/language-processing-100-knocks"> language processing 100 knocks</a></code></small>


<small><code><a href="https://japan2018.github.io/tags/cosine-similarity"> cosine similarity</a></code></small>

</p>
<pre><code>[Language Processing 100 Knock 2015](http://www.cl.ecei.tohoku.ac.jp/nlp100/) 88th record &quot;10 words with high similarity&quot; is recorded.
</code></pre>
<p>Extract similar words from all words. This is also the process I want to do from my mailbox and minutes.
Technically it is almost the same as the previous content.</p>
<h1 id="reference-link">Reference link</h1>
<table>
<thead>
<tr>
<th align="left">Links</th>
<th align="left">Remarks</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><a href="https://github.com/YoheiFukuhara/nlp100/blob/master/09.%E3%83%99%E3%82%AF%E3%83%88%E3%83%AB%E7%A9%BA%E9%96%93%E6%B3%95%20(I)/088.%E9%A1%9E%E4%BC%BC%E5%BA%A6%E3%81%AE%E9%AB%98%E3%81%84%E5%8D%98%E8%AA%9E10%E4%BB%B6.ipynb">088. 10 words with high similarity.ipynb</a></td>
<td align="left">Answer program GitHub link</td>
</tr>
<tr>
<td align="left"><a href="http://qiita.com/segavvy/items/26ec387217b030a15c21">Amateur language processing 100 knocks: 88</a></td>
<td align="left">I have always taken care of 100 language processing knocks</td>
</tr>
</tbody>
</table>
<p>#Environment</p>
<table>
<thead>
<tr>
<th align="left">Type</th>
<th align="left">Version</th>
<th align="left">Content</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">OS</td>
<td align="left">Ubuntu18.04.01 LTS</td>
<td align="left">Virtually running</td>
</tr>
<tr>
<td align="left">pyenv</td>
<td align="left">1.2.15</td>
<td align="left">I use pyenv because I sometimes use multiple Python environments.</td>
</tr>
<tr>
<td align="left">Python</td>
<td align="left">3.6.9</td>
<td align="left">I am using python3.6.9 on pyenv <br>There is no deep reason not to use 3.7 or 3.8 series<br>Packages are managed using venv</td>
</tr>
</tbody>
</table>
<p>The following additional Python packages are used in the above environment. Just install with normal pip.</p>
<table>
<thead>
<tr>
<th align="left">Kind</th>
<th align="left">Version</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">numpy</td>
<td align="left">1.17.4</td>
</tr>
<tr>
<td align="left">pandas</td>
<td align="left">0.25.3</td>
</tr>
</tbody>
</table>
<h1 id="task">Task</h1>
<h2 id="chapter-9-vector-space-method-ihttpwwwcleceitohokuacjpnlp100ch9"><a href="http://www.cl.ecei.tohoku.ac.jp/nlp100/#ch9">Chapter 9: Vector Space Method (I)</a></h2>
<blockquote>
<p><a href="http://www.cl.ecei.tohoku.ac.jp/nlp100/data/enwiki-20150112-400-r10-105752.txt.bz2">enwiki-20150112-400-r10-105752.txt.bz2</a>Isatextobtainedbycompressingthetextof105,752articlesrandomlysampled1/10outofthearticlesconsistingofabout400wordsormoreoutoftheWikipediaarticlesinEnglishasofJanuary12,2015inbzip2format.isthere.Iwanttolearnavector(distributedexpression)thatrepresentsthemeaningofaword,usingthistextasacorpus.InthefirsthalfofChapter9,weapplyprincipalcomponentanalysistoawordcontextco-occurrencematrixcreatedfromacorpusandimplementtheprocessoflearningawordvectorbydividingitintoseveralprocesses.InthelatterhalfofChapter9,thewordvector(300dimensions) obtained by learning is used to calculate word similarity and analogy.</p>
<p>Note that a straightforward implementation of Problem 83 requires a large amount (about 7GB) of main memory. If the memory is insufficient, devise the process or use a 1/100 sampling corpus <a href="http://www.cl.ecei.tohoku.ac.jpUse/nlp100/data/enwiki-20150112-400-r100-10576.txt.bz2">enwiki-20150112-400-r100-10576.txt.bz2</a>.</p>
</blockquote>
<p>This time * &ldquo;Corpus of 1/100 sampling <a href="http://www.cl.ecei.tohoku.ac.jp/nlp100/data/enwiki-20150112-400-r100-10576.txt.bz2">enwiki-20150112-400-r100-10576.txt.bz2</a>‚Äù*.</p>
<h3 id="88-10-words-with-high-similarity">88. 10 words with high similarity</h3>
<blockquote>
<p>Read the meaning vector of the word obtained in 85, and output the 10 words with a high cosine similarity to &ldquo;England&rdquo; and the similarity.</p>
</blockquote>
<h1 id="answer">Answer</h1>
<h2 id="answer-program-088-10-words-with-high-similarityipynbhttpsgithubcomyoheifukuharanlp100blobmaster09e38399e382afe38388e383abe7a9bae99693e6b39520i088e9a19ee4bcbce5baa6e381aee9ab98e38184e58d98e8aa9e10e4bbb6ipynb">Answer program [088. 10 words with high similarity.ipynb](<a href="https://github.com/YoheiFukuhara/nlp100/blob/master/09.%E3%83%99%E3%82%AF%E3%83%88%E3%83%AB%E7%A9%BA%E9%96%93%E6%B3%95%20(I)/088.%E9%A1%9E%E4%BC%BC%E5(%BA%A6%E3%81%AE%E9%AB%98%E3%81%84%E5%8D%98%E8%AA%9E10%E4%BB%B6.ipynb)">https://github.com/YoheiFukuhara/nlp100/blob/master/09.%E3%83%99%E3%82%AF%E3%83%88%E3%83%AB%E7%A9%BA%E9%96%93%E6%B3%95%20(I)/088.%E9%A1%9E%E4%BC%BC%E5(%BA%A6%E3%81%AE%E9%AB%98%E3%81%84%E5%8D%98%E8%AA%9E10%E4%BB%B6.ipynb)</a></h2>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">import</span> pandas <span style="color:#f92672">as</span> pd

<span style="color:#75715e"># Stored in&#39;arr_0&#39; because no argument was specified when saving</span>
matrix_x300 <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>load(<span style="color:#e6db74">&#39;085.matrix_x300.npz&#39;</span>)[<span style="color:#e6db74">&#39;arr_0&#39;</span>]

<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;matrix_x300 Shape:&#39;</span>, matrix_x300<span style="color:#f92672">.</span>shape)

<span style="color:#75715e">#&#39;England word vector is read and norm is calculated</span>
v1 <span style="color:#f92672">=</span> matrix_x300[group_t<span style="color:#f92672">.</span>index<span style="color:#f92672">.</span>get_loc(<span style="color:#e6db74">&#39;England&#39;</span>)]
v1_norm <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>linalg<span style="color:#f92672">.</span>norm(v1)


<span style="color:#75715e">#Cosine similarity calculation</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">get_cos_similarity</span>(v2):
    
    <span style="color:#75715e"># Returns -1 if the vector is all zero</span>
    <span style="color:#66d9ef">if</span> np<span style="color:#f92672">.</span>count_nonzero(v2) <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span>:
        <span style="color:#66d9ef">return</span> <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>
    <span style="color:#66d9ef">else</span>:
        <span style="color:#66d9ef">return</span> np<span style="color:#f92672">.</span>dot(v1, v2) <span style="color:#f92672">/</span> (v1_norm <span style="color:#f92672">*</span> np<span style="color:#f92672">.</span>linalg<span style="color:#f92672">.</span>norm(v2))

cos_sim <span style="color:#f92672">=</span> [get_cos_similarity(matrix_x300[i]) <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(len(group_t))]
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;Cosign Similarity result length:&#39;</span>, len(cos_sim))

<span style="color:#75715e"># Sort by leaving index</span>
cos_sim_sorted <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>argsort(cos_sim)

<span style="color:#75715e"># Output from the end of the array sorted in ascending order to -11(-12) one by one (top is England itself)</span>
<span style="color:#66d9ef">for</span> index <span style="color:#f92672">in</span> cos_sim_sorted[:<span style="color:#f92672">-</span><span style="color:#ae81ff">12</span>:<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>]:
    <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;{}</span><span style="color:#ae81ff">\t</span><span style="color:#e6db74">{}&#39;</span><span style="color:#f92672">.</span>format(group_t<span style="color:#f92672">.</span>index[index], cos_sim[index]))
</code></pre></div><h2 id="answer-commentary">Answer commentary</h2>
<p>Made the cosine similarity calculation part a function. If it is judged by the <code>count_nonzero</code> function and the vector is all zero, -1 is returned.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e">#Cosine similarity calculation</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">get_cos_similarity</span>(v2):
    
    <span style="color:#75715e"># Returns -1 if the vector is all zero</span>
    <span style="color:#66d9ef">if</span> np<span style="color:#f92672">.</span>count_nonzero(v2) <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span>:
        <span style="color:#66d9ef">return</span> <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>
    <span style="color:#66d9ef">else</span>:
        <span style="color:#66d9ef">return</span> np<span style="color:#f92672">.</span>dot(v1, v2) <span style="color:#f92672">/</span> (v1_norm <span style="color:#f92672">*</span> np<span style="color:#f92672">.</span>linalg<span style="color:#f92672">.</span>norm(v2))
</code></pre></div><p>Comprehensive inclusive notation is given to the array at once.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">cos_sim <span style="color:#f92672">=</span> [get_cos_similarity(matrix_x300[i]) <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(len(group_t))]
</code></pre></div><p>I thought it would be faster to use this <code>apply_along_axis</code> with numpy for the above calculation, but it was rather slow, so it is not adopted.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">cos_sim <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>apply_along_axis(get_cos_similarity, <span style="color:#ae81ff">1</span>, matrix_x300)
</code></pre></div><p>The final output result. Scotland and Italy are among the top.
It&rsquo;s surprising that Japan is also there. Is it because it is an island country?</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">England 1.0000000000000002
Scotland 0.6364961613062289
Italy 0.6033905306935802
Wales 0.5961887337227456
Australia 0.5953277272306978
Spain 0.5752511915429617
Japan 0.5611603300967408
France 0.5547284075334182
Germany 0.5539239745925412
United_Kingdom 0.5225684232409136
Cheshire 0.5125286144779688
</code></pre></div>
    </article>
  </div>

  
  
  
  <script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-123456789-1', 'auto');
  ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  

  
<link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.css" />
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#216942",
      "text": "#b2d192"
    },
    "button": {
      "background": "#afed71"
    }
  }
})});
</script>

</body>

</html>
