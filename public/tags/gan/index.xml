<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>GAN on Memo Tut</title>
    <link>https://memotut.com/tags/gan/</link>
    <description>Recent content in GAN on Memo Tut</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 24 May 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://memotut.com/tags/gan/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>[Python] AnimeGAN that converts live-action film into anime style (Windows10, Python3.6)</title>
      <link>https://memotut.com/448047e8a/</link>
      <pubDate>Sun, 24 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/448047e8a/</guid>
      <description>#Introduction  I tried AnimeGAN, which transforms live-action film into anime style.
System environment  Windows10 (RTX2080 Max-Q, i7-8750H, RAM16GB) Anaconda 2020.02 Python 3.6 CUDA 9.0  Introduction Clone AnimeGAN.
Create an environment for animegan.
$ conda create -n animegan python=3.6 $ conda activate animegan $ pip install tensorflow-gpu==1.8.0 $ pip install tqdm $ pip install scipy $ pip install opencv-python $ cd AnimeGAN-master Put dataset on AnimeGAN-master.
Copy and paste the contents of Haoyao-style to checkpoint\AnimeGAN_Hayao_lsgan_300_300_1_3_10</description>
    </item>
    
    <item>
      <title>[Python] Try running wav2pix, which creates a face image from audio (there is also an anime face generator)</title>
      <link>https://memotut.com/159ce81d0/</link>
      <pubDate>Wed, 13 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/159ce81d0/</guid>
      <description>#Introduction  The world of deep learning, especially Generative Adversarial Networks (GAN), has grown dramatically in recent years, and I think that research is progressing in various fields such as text-to-image, voice conversion, and sound source separation.
In this talk, I will loosely write about wav2pix, which generates face images from voice.
Paper: WAV2PIX: SPEECH-CONDITIONED FACE GENERATION USING GENERATIVEADVERSARIAL NETWORKS
#Overview https://imatge-upc.github.io/wav2pix/
The proposed model consists of the following three modules.</description>
    </item>
    
    <item>
      <title>[Python] Landscape transformation by AI † Different world transformation †</title>
      <link>https://memotut.com/93d2ca0eb/</link>
      <pubDate>Mon, 24 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/93d2ca0eb/</guid>
      <description># Introduction († horror transformation †)     Before conversion After conversion     !      Did you understand?
This uses GAN (Hostile Generation Network) to add &amp;ldquo;horror&amp;rdquo; features to photos and convert them.
Let&amp;rsquo;s leave the principle behind for now, and take a look at the possibilities of GAN!
Seasonal conversion, Aurora conversion, Fireworks conversion    Before conversion After conversion     !</description>
    </item>
    
    <item>
      <title>[Python] Story that made Mel icon generator</title>
      <link>https://memotut.com/cad3f6117/</link>
      <pubDate>Fri, 14 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/cad3f6117/</guid>
      <description>#Introduction  Do you know this icon? Yes, it is the icon of the famous Melville. It is known that there are many people who have Melville draw their favorite characters, etc. and use it as a thumbnail for twitter, and it has gained great support. The icon drawn by this person is often called &amp;ldquo;Mel icon&amp;rdquo; due to its unique style. Examples of typical Mel icons
  (Those of Yukatayu and Shun, respectively.</description>
    </item>
    
    <item>
      <title>[Python] I tried to make an Anpanman painter discrimination machine</title>
      <link>https://memotut.com/30a44256f/</link>
      <pubDate>Sun, 12 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/30a44256f/</guid>
      <description>## Introduction  I thought about learning AI and making a simple application with the technology I learned, I tried to make something like the following. The reason why I chose Anpanman was because it was a cartoon character that I could easily write. I wanted to handle GAN as a model, and that it is possible to detect abnormalities by learning only normal images I thought I would make it ANOGAN, but when I looked it up, it was called EfficientGAN in the high-speed version of ANOGAN.</description>
    </item>
    
    <item>
      <title>[Python] What ICCV2019 Best paper SinGAN cannot do [Practice]</title>
      <link>https://memotut.com/1f14148c9/</link>
      <pubDate>Wed, 18 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/1f14148c9/</guid>
      <description>#Introduction  This article is an entry of CyberAgent20 new graduate engineer Advent Calender 2019 on the 18th day. I am a graduate student doing computer vision research using deep learning. twitter → https://twitter.com/revi_matsu This time, it is SinGAN practice that won the best paper at ICCV2019 held the other day.
How to read this article [For those who want a rough overview] Read this article. [For those who want to know the specifications a little] This article →I briefly read &amp;ldquo;SinGAN&amp;rdquo; and summarized it [For those who want to know the details] This article → &amp;ldquo;SinGAN&amp;rdquo; I read it briefly and summarized it→Papers</description>
    </item>
    
  </channel>
</rss>