<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>TensorFlow2.0 on Memo Tut</title>
    <link>https://memotut.com/tags/tensorflow2.0/</link>
    <description>Recent content in TensorFlow2.0 on Memo Tut</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 28 May 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://memotut.com/tags/tensorflow2.0/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Generate physically robust shapes with GAN and print on a 3D printer</title>
      <link>https://memotut.com/generate-physically-robust-shapes-with-gan-and-print-on-a-3d-printer-9f17c/</link>
      <pubDate>Thu, 28 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/generate-physically-robust-shapes-with-gan-and-print-on-a-3d-printer-9f17c/</guid>
      <description># 0. What makes me happy about this article   You can see the flow of printing the data generated by deep learning on a 3D printer (10. In the experimental code, I have posted it to GitHub for all the codes **. The same thing can be done if you make an environment by git clone It should be easy.I wrote in herehowtocreatetheenvironment.) It becomes a study of material mechanics (I am writing while studying&amp;hellip;) Learn how TensorFlow 2.</description>
    </item>
    
    <item>
      <title>[TF2.0 Application] High-speed parallelization of general-purpose Data Augmentation with the strong dataset function of TF</title>
      <link>https://memotut.com/tf2.0-application-high-speed-parallelization-of-general-purpose-data-augmentation-with-the-strong-dataset-function-of-tf-52844/</link>
      <pubDate>Sun, 08 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/tf2.0-application-high-speed-parallelization-of-general-purpose-data-augmentation-with-the-strong-dataset-function-of-tf-52844/</guid>
      <description>#Introduction  This article is the previous article &amp;ldquo;The story that the dataset function that can be used in TensorFlow was strong&amp;quot;&amp;quot;[[TF2.0application]tf.data.&amp;ldquo;DataAugmentationisfasterthanDataAugmentation]&amp;quot;(https://qiita.com/Suguru_Toyohara/items/49c2914b21615b554afa)&amp;quot;, which is a slightly enhanced version of Data Augmentation.
While using tf.data.Dataset for speed enhancement and keras.preprocessing.image system ** We have succeeded in realizing code that can be processed in parallel. ** I will post the actual mechanism and how it came to this point after the code.</description>
    </item>
    
    <item>
      <title>Built environment for machine learning from 0 (windows10 &#43; Anaconda &#43; VSCode &#43; Tensorflow &#43; GPU version)</title>
      <link>https://memotut.com/built-environment-for-machine-learning-from-0-windows10-anaconda-vscode-tensorflow-gpu-version-08d3f/</link>
      <pubDate>Sat, 30 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/built-environment-for-machine-learning-from-0-windows10-anaconda-vscode-tensorflow-gpu-version-08d3f/</guid>
      <description>I opened the OS for a while and reinstalled the OS, so I rebuilt the environment.  It is a memorandum at that time.
Overview  Machine learning (reinforcement learning) environment built from almost 0 (GPU compatible) Environment  windows10 NVIDIA GeForce GTX 1060   Build environment  Anaconda VSCode Tensorflow GPU compatible settings Cooperation between Anaconda and VS Code ChainerRL    Preparation for using Tensorflow GPU version *Not required when using the CPU version.</description>
    </item>
    
    <item>
      <title>Beginners read Introduction to TensorFlow 2.0 for experts</title>
      <link>https://memotut.com/beginners-read-introduction-to-tensorflow-2.0-for-experts-a6ea8/</link>
      <pubDate>Thu, 14 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/beginners-read-introduction-to-tensorflow-2.0-for-experts-a6ea8/</guid>
      <description># Things to do: point_up:  Read the tensorflow 2.0 tutorial. I would like to investigate and supplement the things I did not understand well in the tutorial to make a memorandum. So you may want to read it along with the tutorial.
#Background I used to use chainer When I was about to learn tensorflow, the mainstream moved to 2.0 before I knew it. I don&amp;rsquo;t even know the tensorflow1 system, but if I do it now, it seems reasonable to start with the 2 system and start reading the tensorflow2 tutorial.</description>
    </item>
    
  </channel>
</rss>