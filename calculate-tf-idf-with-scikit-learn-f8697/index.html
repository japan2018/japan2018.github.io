<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  <meta name="generator" content="Hugo 0.72.0" />

  
  <meta name="description" content="Some description">
  

  
  <link rel="apple-touch-icon" sizes="180x180" href="https://memotut.com/apple-touch-icon.png">

  
  <link rel="icon" type="image/png" sizes="32x32" href="https://memotut.com/favicon-32x32.png">

  
  <link rel="icon" type="image/png" sizes="16x16" href="https://memotut.com/favicon-16x16.png">

  
  <link rel="manifest" href="https://memotut.com/site.webmanifest">

  
  <link rel="mask-icon" href="https://memotut.com/safari-pinned-tab.svg" color="#5bbad5">

  <meta name="msapplication-TileColor" content="#da532c">

  <meta name="theme-color" content="#ffffff">

  
  <link rel="stylesheet" href="https://memotut.com/css/bootstrap.min.css" />

  
  <title>[Python] Calculate tf-idf with scikit-learn | Memo Tut</title>
  

  <style>
body {
  min-width: 300px;
}

.custom-navbar {
  margin-bottom: 1em;
  height: 60px;
}

.custom-navbar a {
  display: inline-block; 
  padding: 18px 0;
  margin-right: 1em; 
  font-weight: bold; 
}

.custom-navbar a:hover,
.custom-navbar a:focus {
  text-decoration: none; 
}

@media print {
  .custom-navbar {
    display: none;
  }
}

article {
  padding-bottom: 1em;
}

img {
  max-width: 100%;
}


body {
  background-color: #fff;
}



body {
  color: #212529;
}



a {
  color: #007bff;
}



a:hover,
a:focus {
  color: #0056b3;
}



.custom-navbar {
  background-color: #212529;
}



.custom-navbar a {
  color: rgba(255, 255, 255, 0.75);
}



.custom-navbar a:hover,
.custom-navbar a:focus {
  color: rgba(255, 255, 255, 1);
}



.container {
  max-width: 800px;
}



pre {
  display: block;
  padding: 9.5px;
  word-break: break-all;
  word-wrap: break-word;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre code {
  padding: 0;
  font-size: inherit;
  color: inherit; 
  white-space: pre-wrap;
  background-color: transparent;
  border: none;
  border-radius: 0;
}

code {
  padding: 2px 4px;
  color: inherit; 
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
  font-size: .9em;
}



blockquote,
.blockquote {
  padding: 10px 20px;
  margin: 0 0 20px;
  font-size: 1em;
  border-left: 5px solid #6c757d;
}

</style>
</head>

<body>
  <nav class="custom-navbar">
  <div class="container">
    
    <a href="/">Posts</a>
    
    <a href="/tags/">Tags</a>
    
    <a href="/about/">About</a>
    
    <a href="/index.xml">RSS</a>
    
  </div>
</nav>
  
  <div class="container">
    <article>
      <h1>[Python] Calculate tf-idf with scikit-learn</h1>
<p>
  <small class="text-secondary">
  
  
  Dec 26, 2013
  </small>
  

<small><code><a href="https://memotut.com/tags/python">Python</a></code></small>


<small><code><a href="https://memotut.com/tags/machine-learning"> machine learning</a></code></small>


<small><code><a href="https://memotut.com/tags/machinelearning"> MachineLearning</a></code></small>


<small><code><a href="https://memotut.com/tags/scikit-learn">scikit-learn</a></code></small>


<small><code><a href="https://memotut.com/tags/tfidf">tfidf</a></code></small>

</p>
<pre><code>**This post is the fourth day article of [Reality Escape Advent Calendar 2013](http://katryo.hatenablog.com/entry/2013/12/19/001823). **
</code></pre>
<p><a href="http://qiita.com/katryo/items/62291ba328de9d12bd30">2nd day</a>usesthehtmlfetchedusingtheBingAPI,so[2ndday](<a href="http://qiita.com/katryo(/items/62291ba328de9d12bd30)">http://qiita.com/katryo(/items/62291ba328de9d12bd30)</a> is easier to understand if you read it first.</p>
<h2 id="put-this-article-in-3-lines">Put this article in 3 lines</h2>
<ul>
<li>I checked a Python library called <a href="http://scikit-learn.org/stable/index.html">scikit-learn</a></li>
<li><a href="http://qiita.com/katryo/items/62291ba328de9d12bd30">Day 2</a> Calculated tf-idf of word in html saved</li>
<li>Confirmed word to tfidf mapping</li>
</ul>
<h2 id="reference">Reference</h2>
<p><a href="http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction">scikit-learn formula, text feature extraction document</a></p>
<p><a href="http://blog.parosky.net/archives/2212">Calculating tfidf of words in Tweet using scikit-learn</a></p>
<h2 id="finished-product">finished product</h2>
<p><a href="https://github.com/katryo/tfidf_with_sklearn">https://github.com/katryo/tfidf_with_sklearn</a></p>
<p>Fork me!</p>
<h2 id="theory">Theory</h2>
<h3 id="tfidf-definition">tfidf definition</h3>
<ul>
<li>tf-idf is the value of <strong>tf * idf</strong>. It is attached to a word of a document in a document set. Words with high tf-idf can be considered important. It can be used for weighting words in information retrieval.</li>
<li>tf (Term Frequency) is the number of occurrences of the word (Term) in the document / total number of all words that occur in the document **. Words grow when they are used many times in the document.</li>
<li>idf (Inverse Document Frequency) is the reciprocal of df. However, in practice, logarithm is used to make the calculation easier. So it becomes <strong>log(1/df)</strong>. The base of log is usually 2, but it can be either e or 10. Should be.</li>
<li>df (Document Frequency) is ** number of documents in which the word appears / total number of documents **. It grows when the word is used on a wide topic. “Ha” and “o”, and in English, “is” and “that” are very large. A value assigned to a word in a document set.</li>
</ul>
<h2 id="feature-extraction-from-text-with-scikit-learn">Feature extraction from text with scikit-learn</h2>
<p>While partially translating the contents of <a href="http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction">scikit-learn formula, text feature extraction document</a> In addition, it demonstrates.</p>
<p>When extracting features from text with scikit-learn, three processes are required.</p>
<ul>
<li>tokenizing: Convert text into bag-of-words. In English, you can simply divide the white space and remove noise such as symbols, but if you use Japanese, use a morphological analyzer such as MeCab or KyTea. Since scikit-learn does not include a Japanese morphological analyzer, this process is required separately.</li>
<li>Counting: Count the frequency of each word in each document.</li>
<li>normalizing and weighting: normalizing and weighting. Calculate tf-idf by word frequency, number of words in document and number of documents, and convert it to a more convenient value.</li>
</ul>
<p>In scikit-learn, the above three steps are collectively called &ldquo;vectorization&rdquo;, that is, &ldquo;vectorization&rdquo;. The TfidfVectorizer, which will appear later, can do all three steps. If you have already completed the procedure halfway, you can do the calculation halfway or halfway.</p>
<p>By the way, scikit-learn can not only do bag-of-words, but also tfidf calculation in n-gram focusing on the continuation of two or more words, but this time I will not do it.</p>
<h3 id="countvectorizer">CountVectorizer</h3>
<p>CountVectorizer in sklearn.feature_extraction.text can tokenize and count. Counting results are expressed as vectors, so use Vectorizer.</p>
<p><a href="http://scikit-learn.org/stable/modules/feature_extraction.html#common-vectorizer-usage">This is explained in the official document here. </a></p>
<h3 id="tfidftransformer">TfidfTransformer</h3>
<p>Similarly, TfidfTransformer in sklearn.feature_extraction.text is responsible for normalizing. With the fit_transform method, tfidf is calculated based on just the &ldquo;word appearance frequency for each document&rdquo; and further normalization is performed. <a href="http://scikit-learn.org/stable/modules/feature_extraction.html#tfidf-term-weighting">Here in the official documentation. </a></p>
<h3 id="tfidfvectorizer">TfidfVectorizer</h3>
<p>An entity that combines the functions of CountVectorizer and TfidfTransformer. It&rsquo;s a Trinity form, a Trinity. It is convenient to use this when extracting features from raw text.</p>
<h2 id="i-actually-tried-using-it">I actually tried using it</h2>
<h3 id="see-high-words-in-tfidf">See high words in tfidf</h3>
<p>This is the main subject from here. 36934 words in 400 Web pages retrieved from 8 queries. From these, print &ldquo;Words with tfidf greater than 0.1 in the document that appeared&rdquo;.</p>
<p>First of all, tfidf calculation is quite expensive, so let&rsquo;s make tfledf and then pickle the result.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python:set_tfidf_with_sklearn_to_fetched_pages.py" data-lang="python:set_tfidf_with_sklearn_to_fetched_pages.py"><span style="color:#f92672">import</span> utils
<span style="color:#f92672">import</span> constants
<span style="color:#f92672">import</span> pickle
<span style="color:#f92672">import</span> os
<span style="color:#f92672">from</span> sklearn.feature_extraction.text <span style="color:#f92672">import</span> TfidfVectorizer


<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">is_bigger_than_min_tfidf</span>(term, terms, tfidfs):
    <span style="color:#e6db74">&#39;&#39;&#39;
</span><span style="color:#e6db74">    Used in [term for term in terms if is_bigger_than_min_tfidf(term, terms, tfidfs)]
</span><span style="color:#e6db74">    A function that applies in order from the values of tfidf of the words that are made into a list.
</span><span style="color:#e6db74">    Returns True if the value of tfidf is greater than MIN_TFIDF
</span><span style="color:#e6db74">    &#39;&#39;&#39;</span>
    <span style="color:#66d9ef">if</span> tfidfs[terms<span style="color:#f92672">.</span>index(term)]<span style="color:#f92672">&gt;</span> constants<span style="color:#f92672">.</span>MIN_TFIDF:
        <span style="color:#66d9ef">return</span> True
    <span style="color:#66d9ef">return</span> False


<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">tfidf</span>(pages):
    <span style="color:#75715e"># analyzer is a function that returns a list of strings when you enter a string</span>
    vectorizer <span style="color:#f92672">=</span> TfidfVectorizer(analyzer<span style="color:#f92672">=</span>utils<span style="color:#f92672">.</span>stems, min_df<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>, max_df<span style="color:#f92672">=</span><span style="color:#ae81ff">50</span>)
    corpus <span style="color:#f92672">=</span> [page<span style="color:#f92672">.</span>text <span style="color:#66d9ef">for</span> page <span style="color:#f92672">in</span> pages]

    x <span style="color:#f92672">=</span> vectorizer<span style="color:#f92672">.</span>fit_transform(corpus)

    <span style="color:#75715e"># From here on down has nothing to do with the returned value. I just wanted to see what a high word in tfidf looks like</span>
    terms <span style="color:#f92672">=</span> vectorizer<span style="color:#f92672">.</span>get_feature_names()
    tfidfs <span style="color:#f92672">=</span> x<span style="color:#f92672">.</span>toarray()[constants<span style="color:#f92672">.</span>DOC_NUM]
    <span style="color:#66d9ef">print</span>([term <span style="color:#66d9ef">for</span> term <span style="color:#f92672">in</span> terms <span style="color:#66d9ef">if</span> is_bigger_than_min_tfidf(term, terms, tfidfs)])

    <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;Total </span><span style="color:#e6db74">%i</span><span style="color:#e6db74"> type words found in page </span><span style="color:#e6db74">%i</span><span style="color:#e6db74">.&#39;</span> <span style="color:#f92672">%</span>(len(terms), len(pages)))

    <span style="color:#66d9ef">return</span> x, vectorizer <span style="color:#75715e"># x is received in main as tfidf_result</span>

<span style="color:#66d9ef">if</span> __name__ <span style="color:#f92672">==</span><span style="color:#e6db74">&#39;__main__&#39;</span>:
    utils<span style="color:#f92672">.</span>go_to_fetched_pages_dir()
    pages <span style="color:#f92672">=</span> utils<span style="color:#f92672">.</span>load_all_html_files() <span style="color:#75715e"># pages fetch html and set to text</span>
    tfidf_result, vectorizer <span style="color:#f92672">=</span> tfidf(pages) <span style="color:#75715e"># tfidf_result is the tfidf function x</span>

    pkl_tfidf_result_path <span style="color:#f92672">=</span> os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>join(<span style="color:#e6db74">&#39;..&#39;</span>, constants<span style="color:#f92672">.</span>TFIDF_RESULT_PKL_FILENAME)
    pkl_tfidf_vectorizer_path <span style="color:#f92672">=</span> os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>join(<span style="color:#e6db74">&#39;..&#39;</span>, constants<span style="color:#f92672">.</span>TFIDF_VECTORIZER_PKL_FILENAME)

    <span style="color:#66d9ef">with</span> open(pkl_tfidf_result_path,<span style="color:#e6db74">&#39;wb&#39;</span>) <span style="color:#66d9ef">as</span> f:
        pickle<span style="color:#f92672">.</span>dump(tfidf_result, f)
    <span style="color:#66d9ef">with</span> open(pkl_tfidf_vectorizer_path,<span style="color:#e6db74">&#39;wb&#39;</span>) <span style="color:#66d9ef">as</span> f:
        pickle<span style="color:#f92672">.</span>dump(vectorizer, f)
</code></pre></div><p>in the tfidf function</p>
<pre><code>vectorizer = TfidfVectorizer(analyzer=utils.stems, min_df=1, max_df=50)
</code></pre><p>I am trying. The analyzer puts in a function that returns a list of strings when it puts in a string. By default, it is divided by white space and only one character is removed, but when doing it in Japanese, it is necessary to create and set the function using the morphological analyzer by yourself. The utils.stems function is a function that performs morphological analysis with MeCab, converts it into a stem, and returns it as a list, which was written in utils.py described later.</p>
<p>What is printed in the tfidf function is a word that can be found in one of the result pages searched by &ldquo;stomach reliance&rdquo;, and the value of tfidf is 0.1 or more. The result of this will be described later.</p>
<p>The utils that appear in the code are as follows, and are a collection of useful functions used in various situations.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python:utils.py" data-lang="python:utils.py"><span style="color:#f92672">import</span> MeCab
<span style="color:#f92672">import</span> constants
<span style="color:#f92672">import</span> os
<span style="color:#f92672">import</span> pdb
<span style="color:#f92672">from</span> web_page <span style="color:#f92672">import</span> WebPage

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">_split_to_words</span>(text, to_stem<span style="color:#f92672">=</span>False):
    <span style="color:#e6db74">&#34;&#34;&#34;
</span><span style="color:#e6db74">    Input:&#39;All towards me&#39;Output: tuple([&#39;all&#39;,&#39;self&#39;,&#39;no&#39;,&#39;ho&#39;,&#39;to&#39;])
</span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
    tagger <span style="color:#f92672">=</span> MeCab<span style="color:#f92672">.</span>Tagger(<span style="color:#e6db74">&#39;mecabrc&#39;</span>) <span style="color:#75715e"># You can use another Tagger</span>
    mecab_result <span style="color:#f92672">=</span> tagger<span style="color:#f92672">.</span>parse(text)
    info_of_words <span style="color:#f92672">=</span> mecab_result<span style="color:#f92672">.</span>split(<span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span>)
    words <span style="color:#f92672">=</span> []
    <span style="color:#66d9ef">for</span> info <span style="color:#f92672">in</span> info_of_words:
        When divided by <span style="color:#75715e"># macab, ‘’ comes at the end of the sentence, and “EOS” comes before it.</span>
        <span style="color:#66d9ef">if</span> info <span style="color:#f92672">==</span><span style="color:#e6db74">&#39;EOS&#39;</span> <span style="color:#f92672">or</span> info <span style="color:#f92672">==</span> <span style="color:#e6db74">``</span>:
            <span style="color:#66d9ef">break</span>
            <span style="color:#75715e"># info =&gt;&#39;na\t particle, final particle, *,*,*,*, na, na, na&#39;</span>
        info_elems <span style="color:#f92672">=</span> info<span style="color:#f92672">.</span>split(<span style="color:#e6db74">&#39;,&#39;</span>)
        <span style="color:#75715e">#6 is a non-use word. If the 6th is&#39;*&#39;, insert the 0th</span>
        <span style="color:#66d9ef">if</span> info_elems[<span style="color:#ae81ff">6</span>] <span style="color:#f92672">==</span><span style="color:#e6db74">&#39;*&#39;</span>:
            <span style="color:#75715e"># info_elems[0] =&gt;&#39;Van Rossum\t noun&#39;</span>
            words<span style="color:#f92672">.</span>append(info_elems[<span style="color:#ae81ff">0</span>][:<span style="color:#f92672">-</span><span style="color:#ae81ff">3</span>])
            <span style="color:#66d9ef">continue</span>
        <span style="color:#66d9ef">if</span> to_stem:
            <span style="color:#75715e"># Convert to stem</span>
            words<span style="color:#f92672">.</span>append(info_elems[<span style="color:#ae81ff">6</span>])
            <span style="color:#66d9ef">continue</span>
        <span style="color:#75715e"># Keep the word</span>
        words<span style="color:#f92672">.</span>append(info_elems[<span style="color:#ae81ff">0</span>][:<span style="color:#f92672">-</span><span style="color:#ae81ff">3</span>])
    <span style="color:#66d9ef">return</span> words


<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">words</span>(text):
    words <span style="color:#f92672">=</span> _split_to_words(text<span style="color:#f92672">=</span>text, to_stem<span style="color:#f92672">=</span>False)
    <span style="color:#66d9ef">return</span> words


<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">stems</span>(text):
    stems <span style="color:#f92672">=</span> _split_to_words(text<span style="color:#f92672">=</span>text, to_stem<span style="color:#f92672">=</span>True)
    <span style="color:#66d9ef">return</span> stems


<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">load_all_html_files</span>():
    pages <span style="color:#f92672">=</span> []
    <span style="color:#66d9ef">for</span> query <span style="color:#f92672">in</span> constants<span style="color:#f92672">.</span>QUERIES:
        pages<span style="color:#f92672">.</span>extend(load_html_files_with_query(query))
    <span style="color:#66d9ef">return</span> pages


<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">load_html_files_with_query</span>(query):
    pages <span style="color:#f92672">=</span> []
    <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(constants<span style="color:#f92672">.</span>NUM_OF_FETCHED_PAGES):
        <span style="color:#66d9ef">with</span> open(<span style="color:#e6db74">&#39;</span><span style="color:#e6db74">%s</span><span style="color:#e6db74">_</span><span style="color:#e6db74">%s</span><span style="color:#e6db74">.html&#39;</span> <span style="color:#f92672">%</span>(query, str(i)),<span style="color:#e6db74">&#39;r&#39;</span>) <span style="color:#66d9ef">as</span> f:
            page <span style="color:#f92672">=</span> WebPage()
            page<span style="color:#f92672">.</span>html_body <span style="color:#f92672">=</span> f<span style="color:#f92672">.</span>read()
        page<span style="color:#f92672">.</span>remove_html_tags()
        pages<span style="color:#f92672">.</span>append(page)
    <span style="color:#66d9ef">return</span> pages

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">load_html_files</span>():
    <span style="color:#e6db74">&#34;&#34;&#34;
</span><span style="color:#e6db74">    Used assuming that you are in the directory containing the HTML file
</span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
    pages <span style="color:#f92672">=</span> load_html_files_with_query(constants<span style="color:#f92672">.</span>QUERY)
    <span style="color:#66d9ef">return</span> pages


<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">go_to_fetched_pages_dir</span>():
    <span style="color:#66d9ef">if</span> <span style="color:#f92672">not</span> os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>exists(constants<span style="color:#f92672">.</span>FETCHED_PAGES_DIR_NAME):
        os<span style="color:#f92672">.</span>mkdir(constants<span style="color:#f92672">.</span>FETCHED_PAGES_DIR_NAME)
    os<span style="color:#f92672">.</span>chdir(constants<span style="color:#f92672">.</span>FETCHED_PAGES_DIR_NAME)

</code></pre></div><p>And the constants are as follows.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python:constants.py" data-lang="python:constants.py">FETCHED_PAGES_DIR_NAME <span style="color:#f92672">=</span><span style="color:#e6db74">&#39;fetched_pages&#39;</span>
QUERIES <span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Stomach relief, caries, hay fever, depression, mechanical fractures, stiff shoulders&#39;</span><span style="color:#f92672">.</span>split(<span style="color:#e6db74">&#39;&#39;</span>)
NUM_OF_FETCHED_PAGES <span style="color:#f92672">=</span> <span style="color:#ae81ff">50</span>
NB_PKL_FILENAME <span style="color:#f92672">=</span><span style="color:#e6db74">&#39;naive_bayes_classifier.pkl&#39;</span>
DOC_NUM <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
MIN_TFIDF <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.1</span>
TFIDF_RESULT_PKL_FILENAME <span style="color:#f92672">=</span><span style="color:#e6db74">&#39;tfidf_result.pkl&#39;</span>
TFIDF_VECTORIZER_PKL_FILENAME <span style="color:#f92672">=</span><span style="color:#e6db74">&#39;tfidf_vectorizer.pkl&#39;</span>
</code></pre></div><p>If you look at the order of QUERIES, you&rsquo;ll see that the “stomach up” category comes first. The DOC_NUM constant was created for this experiment, and was used to specify the 0th file in the &ldquo;stomach lean&rdquo; category, that is, the file named &ldquo;stomach lean_0.html&rdquo;.</p>
<p>Now. Let&rsquo;s run this code.</p>
<pre><code>$ python set_tfidf_with_sklearn_to_fetched_pages.py
</code></pre><p>Even if scikit-learn is used, it takes time to calculate tfidf. It took 25.81 seconds in my environment. result.</p>
<pre><code>['gaJsHost','https','Sagging','Yake','Air swallowing','Hyperacidemia','Breast','Cooking','Ingredients','Esophageal hiatal hernia']
A total of 36934 words were found on 400 pages.
</code></pre><p>It&rsquo;s a stomach-like word. It was found that tfidf exceeded 0.1 among the words in the stomach upset_0.html for the above 10 kinds of words.</p>
<p>gaJsHost and https seem to be part of the JavaScript code. Unu. I want to remove all this noise, but I can&rsquo;t think of a good way. Better yet, it might be better to eliminate words that are only in the alphabet.</p>
<p>By the way, words like &ldquo;esophageal hiatus hernia&rdquo; are not included in MeCab&rsquo;s IPADIC (see <a href="http://parame.mwj.jp/blog/0209">this article</a>fortheoriginofIPADIC)), so Wikipedia It is necessary to strengthen it by putting words of the Hatena keyword in a dictionary. Please google how to do it.</p>
<h3 id="check-the-mapping-of-words-to-tfidf-values">check the mapping of words to tfidf values</h3>
<p>I read the official page, but the result of calculating tfidf is output in the scipy type csr_matrix. This is a sparse (mostly zero) matrix that represents the tf-idf of a word in each document as a decimal number from 0 to 1.</p>
<pre><code>(Pdb) type(x)
&lt;class'scipy.sparse.csr.csr_matrix'&gt;
</code></pre><p>I didn&rsquo;t know what the mapping of the tfidf values to the words was (I found out later), so I tried a simple experiment using pdb.set_trace().</p>
<p>TfidfVectorizer has the method to use</p>
<ul>
<li>get_feature_names</li>
<li>inverse_transform</li>
</ul>
<p>And scipy.sparse.csr_matrix has</p>
<ul>
<li>toarray</li>
</ul>
<p>Is.</p>
<p>First, when I checked the WebPage of document number 0, it was a page called <a href="http://atdesk.jp/">Stomach leaning.com</a>. Find out how the words that appear on this page are represented.</p>
<p>The following code was executed after pickling the calculation result of tfidf.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python:play_with_tfidf.py" data-lang="python:play_with_tfidf.py"><span style="color:#75715e"># -*- coding: utf-8 -*-</span>
<span style="color:#f92672">import</span> pickle
<span style="color:#f92672">import</span> constants
<span style="color:#f92672">import</span> pdb

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">is_bigger_than_min_tfidf</span>(term, terms, tfidfs):
    <span style="color:#e6db74">&#39;&#39;&#39;
</span><span style="color:#e6db74">    Used in [term for term in terms if is_bigger_than_min_tfidf(term, terms, tfidfs)]
</span><span style="color:#e6db74">    A function that applies in order from the values of tfidf of the words that are made into a list.
</span><span style="color:#e6db74">    Returns True if the value of tfidf is greater than MIN_TFIDF
</span><span style="color:#e6db74">    &#39;&#39;&#39;</span>
    <span style="color:#66d9ef">if</span> tfidfs[terms<span style="color:#f92672">.</span>index(term)]<span style="color:#f92672">&gt;</span> constants<span style="color:#f92672">.</span>MIN_TFIDF:
        <span style="color:#66d9ef">return</span> True
    <span style="color:#66d9ef">return</span> False

<span style="color:#66d9ef">if</span> __name__ <span style="color:#f92672">==</span><span style="color:#e6db74">&#39;__main__&#39;</span>:
    <span style="color:#66d9ef">with</span> open(constants<span style="color:#f92672">.</span>TFIDF_VECTORIZER_PKL_FILENAME,<span style="color:#e6db74">&#39;rb&#39;</span>) <span style="color:#66d9ef">as</span> f:
        vectorizer <span style="color:#f92672">=</span> pickle<span style="color:#f92672">.</span>load(f)
    <span style="color:#66d9ef">with</span> open(constants<span style="color:#f92672">.</span>TFIDF_RESULT_PKL_FILENAME,<span style="color:#e6db74">&#39;rb&#39;</span>) <span style="color:#66d9ef">as</span> f:
        x <span style="color:#f92672">=</span> pickle<span style="color:#f92672">.</span>load(f)

    pdb<span style="color:#f92672">.</span>set_trace()

    terms <span style="color:#f92672">=</span> vectorizer<span style="color:#f92672">.</span>get_feature_names()
    <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">3</span>):
        tfidfs <span style="color:#f92672">=</span> x<span style="color:#f92672">.</span>toarray()[i]
        <span style="color:#66d9ef">print</span>([term <span style="color:#66d9ef">for</span> term <span style="color:#f92672">in</span> terms <span style="color:#66d9ef">if</span> is_bigger_than_min_tfidf(term, terms, tfidfs)])
</code></pre></div><p>It becomes a breakpoint by pdb.set_trace, and the value can be output in the interactive environment from there, so you can check various things.</p>
<pre><code>(Pdb) vectorizer.inverse_transform(x)[0]
&gt; array(['esophageal hiatus hernia','ingredients','diet','administration','reflux esophagitis','cooking','chest','hyperacidity','stomachache',
       'Gastric ulcer','gastric ptosis','gastric cancer','air swallowing','herbal medicine','structure','chronic gastritis','duodenal ulcer','medical insurance',
       'Disclaimer','Corporate Information','Polyp','Point','Care','American Family Life Insurance Company','Aflac','Yuku',
       'Burn','about',' lean','unescape','try','ssl','protocol',
       'javascript','inquiry','https','gaJsHost','ga','err',
       'comCopyright','analytics','Inc','Cscript','CROSSFINITY',
       '=\'&quot;', &quot;='&quot;,':&quot;','.&quot;)','.&quot;',')\u3000','((&quot;','(&quot;%', &quot;'%&quot; ,
       '&quot;))'],
      dtype='&lt;U26')
</code></pre><p>The term &ldquo;esophageal hiatal hernia&rdquo; is unusual and unlikely to appear on other pages, so I decided to use it as a marker.</p>
<pre><code>(Pdb) vectorizer.get_feature_names().index('esophageal hiatus hernia')36097
</code></pre><p>It turned out to be the 36097th word. So what is the value of tfidf for the 36097th word in the 0th document (ie Stomach.com)?</p>
<pre><code>(Pdb) x.toarray()[0][36097]
0.10163697033184078
</code></pre><p>Quite expensive. In document number 0, the word with word number 36097 was found to have tfidf of 0.10163697033184078. It&rsquo;s unlikely that a value of tfidf that&rsquo;s so high (first of all, not 0) happens to occur in word number 36097. x.toarray() is a very sparse matrix and most of its elements should be 0. Therefore, you can think that the order of the word list that can be taken by vectorizer.get_feature_names() is the same as the order of the words that have tfidf set by x.toarray().</p>
<p>In this way, it was confirmed that the word list maintained the same order. I think somewhere in the official documentation says, &ldquo;Word order is preserved.&rdquo;</p>
<p>After this, I deleted pdb.set_trace() and ran play_with_tfidf.py again.</p>
<pre><code>['gaJsHost','https','Sagging','Yake','Air swallowing','Hyperacidemia','Breast','Cooking','Ingredients','Esophageal hiatal hernia']
['Dripping','Musuki','Burning','Stomachache','Breast','Too much']
['TVCM','Gusuru','Leap','Nomu','Let's lean','Yake','Yake','Ri','Action','Science','Sacron','Cerbere ',' triple',' veil',' hangover',' weaken',' condition',' mucus',' stomachache',' stomach medicine',' chest',' fullness']
</code></pre><p>These words have a high tfidf (which seems to be very high), and are considered useful as features in calculating the similarity between a document and the stomach category.</p>
<h2 id="summary">Summary</h2>
<p>scikit-learn Convenient.</p>
<p>I uploaded the code to Github.</p>
<p><a href="https://github.com/katryo/tfidf_with_sklearn">https://github.com/katryo/tfidf_with_sklearn</a></p>
<h2 id="next-time-preview">Next time preview</h2>
<p>I want to implement the calculation function of tfidf and compare it with scikit-learn.</p>

    </article>
  </div>

  
  
  
  <script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-169005401-1', 'auto');
  ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  

  
<link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.css" />
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#216942",
      "text": "#b2d192"
    },
    "button": {
      "background": "#afed71"
    }
  }
})});
</script>

</body>

</html>
