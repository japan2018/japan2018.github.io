<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>pandas on Memo Tut</title>
    <link>https://memotut.com/tags/pandas/</link>
    <description>Recent content in pandas on Memo Tut</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 20 May 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://memotut.com/tags/pandas/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Simultaneous visualization of data and understanding of correlation</title>
      <link>https://memotut.com/simultaneous-visualization-of-data-and-understanding-of-correlation-649cf/</link>
      <pubDate>Wed, 20 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/simultaneous-visualization-of-data-and-understanding-of-correlation-649cf/</guid>
      <description>#Introduction  When analyzing data, I think you will visualize the data using graphs. At that time, it would be convenient if the statistics showing the correlation between two variables could be displayed at the same time. Therefore, we made it possible to display the appropriate statistics on the appropriate graph according to the content of the variable (category or numerical value).
Review so far I will summarize the appropriate graphing methods by content of variables and the statistics that show the correlation, which have been described so far.</description>
    </item>
    
    <item>
      <title>Extract only Python for preprocessing</title>
      <link>https://memotut.com/extract-only-python-for-preprocessing-dad2f/</link>
      <pubDate>Sat, 09 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/extract-only-python-for-preprocessing-dad2f/</guid>
      <description>I&#39;ve been wandering around the code on the author&#39;s github each time, so I&#39;ll put it together for immediate use.  Original story Pre-processing Daizen [SQL/R/Python practice technique for data analysis]
https://github.com/ghmagazine/awesomebook
Extract the Python part from github below. See the book for detailed explanation.
Also, these source codes are licensed under the BSD 3 terms.
 BSD 3-Clause License
Copyright (c) 2018, Tomomitsu Motohashi All rights reserved.
 Data read # Read from library from preprocess.</description>
    </item>
    
    <item>
      <title>Visualize railway line data and solve shortest route problems (Python&#43;Pandas&#43;NetworkX)</title>
      <link>https://memotut.com/visualize-railway-line-data-and-solve-shortest-route-problems-python-pandas-networkx-d7737/</link>
      <pubDate>Sat, 02 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/visualize-railway-line-data-and-solve-shortest-route-problems-python-pandas-networkx-d7737/</guid>
      <description>## Introduction  The route map and the graph network are compatible, and we will touch on the shortest path problem that anyone can think of when trying to think about something on the route map.
Convert the railway route map into a simple graph problem, and use the Dijkstra method to find the shortest route. The Python library NetworkX has a built-in Dijkstra method, so this time we will use it.</description>
    </item>
    
    <item>
      <title>Read table data in PDF file with Python</title>
      <link>https://memotut.com/read-table-data-in-pdf-file-with-python-5e474/</link>
      <pubDate>Fri, 03 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/read-table-data-in-pdf-file-with-python-5e474/</guid>
      <description>## PDF data  People in the world seem to love PDF, and even if they say they hate it, they have to deal with it. However, it is common for people to think that spending hours on it is a bit&amp;hellip; In some cases, there is only PDF table data, but in such a case there was a very convenient library called tabula-py. Make a note.
https://github.com/chezou/tabula-py
Regarding tabula tabula is a Java library for extracting PDF tables.</description>
    </item>
    
    <item>
      <title>Parse Apache access logs with Pandas and Matplotlib</title>
      <link>https://memotut.com/parse-apache-access-logs-with-pandas-and-matplotlib-79cd4/</link>
      <pubDate>Tue, 24 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/parse-apache-access-logs-with-pandas-and-matplotlib-79cd4/</guid>
      <description>## Overview  Even if you try to analyze the access log of Apache, Tomcat, etc., it is not a surprisingly good tool. I would like to have a tool that supports various output formats and that can filter only the necessary information and visualize it easily, but I can not find it easily.
So, I tried using Pandas and Matplotlib, which are standard in the world of data analysis, to analyze and visualize Apache access logs on Jupyter Notebook.</description>
    </item>
    
    <item>
      <title>Visualize coronavirus infection status with Plotly [For beginners]</title>
      <link>https://memotut.com/visualize-coronavirus-infection-status-with-plotly-for-beginners-507cf/</link>
      <pubDate>Tue, 17 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/visualize-coronavirus-infection-status-with-plotly-for-beginners-507cf/</guid>
      <description>Next time https://qiita.com/Naoya_Study/items/851f4032fb6e2a5cd5ed  With the spread of coronavirus infection, various organizations have released cool dashboards that visualize the infection status.
Example 1 WHO Novel Coronavirus (COVID-19) Situation Example 2 Ministry of Health, Labor and Welfare new coronavirus infection domestic case Example 3 Toyo Keizai ONLINE New Coronavirus Domestic Infection Status It is cool! I want to be able to make this myself. The goal is to create a dashboard like the one above using Python&amp;rsquo;s visualization-specific data frame Dash.</description>
    </item>
    
    <item>
      <title>Performance verification of data preprocessing for machine learning (numerical data edition) (1)</title>
      <link>https://memotut.com/performance-verification-of-data-preprocessing-for-machine-learning-numerical-data-edition-1-cf176/</link>
      <pubDate>Tue, 10 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/performance-verification-of-data-preprocessing-for-machine-learning-numerical-data-edition-1-cf176/</guid>
      <description>First Edition: March 10, 2020 &amp;lt;br&amp;gt;  Author: Soichi Takashige, Masahiro Ito, Hitachi, Ltd.
#Introduction In this post, I will introduce the design know-how of data preprocessing and the results of performance verification of data preprocessing when designing a system incorporating a machine learning model.
The second article introduces know-how for performance improvement and verification results in data preprocessing using Python.
Post list:
 Data preprocessing for systems that use machine learning Performance Verification of Data Preprocessing for Machine Learning (Numerical Data) (Part 1) (Posted) Performance Verification of Data Preprocessing for Machine Learning (Numerical Data) (Part 2)  #About the benchmark (BigBench) referenced in the performance verification Before introducing design know-how and performance verification results, we will introduce the benchmarks that were referenced as references in verification.</description>
    </item>
    
    <item>
      <title>Data preprocessing for systems using machine learning</title>
      <link>https://memotut.com/data-preprocessing-for-systems-using-machine-learning-48825/</link>
      <pubDate>Tue, 03 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/data-preprocessing-for-systems-using-machine-learning-48825/</guid>
      <description>First Edition: March 3, 2020 &amp;lt;br&amp;gt;  Author: Soichi Takashige, Masahiro Ito, Hitachi, Ltd.
#Introduction In this post, I will introduce the design know-how of data preprocessing and the performance verification results of numerical data preprocessing when designing a system incorporating a machine learning model.
The first article introduces the data preprocessing of machine learning system and its design.
Post list:
 Data preprocessing for systems that use machine learning (this post) Performance verification of data preprocessing for machine learning (numerical data) (1) Performance Verification of Data Preprocessing for Machine Learning (Numerical Data) (Part 2)  #Outline and flow of AI projects Data analysis utilizing AI technology such as machine learning is drawing attention, and the number of projects utilizing AI is increasing.</description>
    </item>
    
    <item>
      <title>Qiita, early Pythonâ™ª</title>
      <link>https://memotut.com/qiita-early-python-be75f/</link>
      <pubDate>Sat, 29 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/qiita-early-python-be75f/</guid>
      <description>&amp;quot;I want to start Python programming, but what should I do?&amp;quot;  I often get the question, so I tried to put together a Qiita page for beginners. Initially
 Python syntax How to use Numpy How to use Pandas How to use matplotlib  I think it is good to take a look at all four.
Python syntax  Python warming up Python Basic Summary Python basic learning  How to use #Numpy</description>
    </item>
    
    <item>
      <title>A little scrutiny of pandas 1.0 and dask</title>
      <link>https://memotut.com/a-little-scrutiny-of-pandas-1.0-and-dask-58675/</link>
      <pubDate>Fri, 14 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/a-little-scrutiny-of-pandas-1.0-and-dask-58675/</guid>
      <description>#Background  Pandas 1.0.0 has been released on January 29, 2020! Crackling As of February 14, 2020, it is 1.0.1.
Personally, I think the following changes are important points.
 pandas original NA Enhanced support for String type (Experimental)  So.
I often use the following libraries and pandas together during analysis.
 dask intake  In particular, I think I should sort out the status of dask&amp;rsquo;s pandas 1.0 support and other detailed behaviors.</description>
    </item>
    
    <item>
      <title>Introductory Pandas to learn while suffering [Part1]</title>
      <link>https://memotut.com/introductory-pandas-to-learn-while-suffering-part1-c0bd3/</link>
      <pubDate>Sat, 01 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/introductory-pandas-to-learn-while-suffering-part1-c0bd3/</guid>
      <description>## Introduction  Pandas is an inevitable library for data analysis in Python. However, this Pandas has a high hurdle for beginners&amp;hellip; I also had a hard time, so I&amp;rsquo;ll try to put it all together from the basics. I am not an advanced Pandas person, so I would appreciate any comments or advice. Also, this article will be divided into three parts. (Since it is a plan, it is very likely to change&amp;hellip;)</description>
    </item>
    
    <item>
      <title>Japanese text preprocessing without for statement in pandas</title>
      <link>https://memotut.com/japanese-text-preprocessing-without-for-statement-in-pandas-15750/</link>
      <pubDate>Mon, 27 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/japanese-text-preprocessing-without-for-statement-in-pandas-15750/</guid>
      <description>A memorandum for pandas, when you process text, you will not be asked &amp;quot;Do you use a for statement because you are not sure?&amp;quot;  Information is compiled for the purpose of preprocessing Japanese text.
I would appreciate if you could tell me if there is a better processing method.
Execution environment
 macOS Catalina Python 3.7.4   pandas 0.25.3
 TL;DR  Simple processing is implemented in the method of df[&amp;quot;column name&amp;quot;].</description>
    </item>
    
    <item>
      <title>Pandas Learning with Chemoinformatics</title>
      <link>https://memotut.com/pandas-learning-with-chemoinformatics-49511/</link>
      <pubDate>Sun, 19 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/pandas-learning-with-chemoinformatics-49511/</guid>
      <description>#Introduction  Following NumPy with chemoinformatics (https://qiita.com/yukiya285/items/ce8677ac6ac0f4842a02), one of Python&amp;rsquo;s representative libraries, &amp;ldquo;Pandas,&amp;rdquo; using lipidomics (a comprehensive analysis of lipids) I will explain about. Since we will focus on chemoinformatics practical examples, if you want to check the basics, please read this article after reading the following articles.
Pharmaceutical company researchers summarized Pandas
Series and DataFrame creation Pandas makes it easy to do spreadsheets.
To use the library, first import it with import.</description>
    </item>
    
    <item>
      <title>How to count the number of occurrences of each element included in the list with weight in Python</title>
      <link>https://memotut.com/how-to-count-the-number-of-occurrences-of-each-element-included-in-the-list-with-weight-in-python-cc3f1/</link>
      <pubDate>Fri, 17 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/how-to-count-the-number-of-occurrences-of-each-element-included-in-the-list-with-weight-in-python-cc3f1/</guid>
      <description># Thing you want to do  Given the following two lists, we want to count the number of occurrences of each element included in a by weighting it with the value of b. Python is 3.7.5.
a = [&amp;#34;A&amp;#34;, &amp;#34;B&amp;#34;, &amp;#34;C&amp;#34;, &amp;#34;A&amp;#34;] b = [1 ,1 ,2 ,2] c = hoge(a, b) print(c) {&amp;quot;A&amp;quot;: 3, &amp;quot;B&amp;quot;: 1, &amp;quot;C&amp;quot;: 2} # I want this output # key and value can be different # ([&amp;quot;A&amp;quot;, &amp;quot;B&amp;quot;, &amp;quot;C&amp;quot;], [3, 1, 2]) *Addition: Comment introduced a simple implementation for the above issue.</description>
    </item>
    
    <item>
      <title>[BigQuery] How to use BigQuery&#39;s API for Python -Table creation-</title>
      <link>https://memotut.com/bigquery-how-to-use-bigquerys-api-for-python-table-creation-0e00f/</link>
      <pubDate>Mon, 13 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/bigquery-how-to-use-bigquerys-api-for-python-table-creation-0e00f/</guid>
      <description># In line 5   Data scientists usually analyze with Jupyter Therefore, there is a desire to process DB as well on Jupyter Therefore it is more convenient to use BigQuery on Jupyter via library instead of WebUI or REST API. I decided to investigate the function of the official library google.cloud.bigquery to achieve the above Below is a summary of how to create tables in BigQuery  #Preparation</description>
    </item>
    
    <item>
      <title>Features of pd.NA in pandas 1.0.0 (rc0)</title>
      <link>https://memotut.com/features-of-pd.na-in-pandas-1.0.0-rc0-52195/</link>
      <pubDate>Mon, 13 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/features-of-pd.na-in-pandas-1.0.0-rc0-52195/</guid>
      <description>update1 2020-01-25: Added that bug-like behavior was bug  As of 2020-01-13, pandas 1.0.0rc0 has been released, but one of the major features is that pd.NA is introduced as a missing value. Summarize this property and usage.
Disclaimer: pandas 1.0.0 It is a confirmed operation with rc0, and there is a good possibility of change in the future.
Verification environment is the last.
wrap up  pd.NA appears as the meaning of missing value.</description>
    </item>
    
    <item>
      <title>Beginning with Python, a quick and easy analysis of the weather data of the last 10 years was started.</title>
      <link>https://memotut.com/beginning-with-python-a-quick-and-easy-analysis-of-the-weather-data-of-the-last-10-years-was-started.-ee6a3/</link>
      <pubDate>Fri, 13 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/beginning-with-python-a-quick-and-easy-analysis-of-the-weather-data-of-the-last-10-years-was-started.-ee6a3/</guid>
      <description>#Introduction  I recently started studying Python. Since I&amp;rsquo;m sorry, I&amp;rsquo;d like to make a post that will be useful for those who are new to Python like me. Since I have never written Python, this time I would like to do a simple data analysis while understanding the syntax of python and what kind of library it has.
Reference book: [Immediately usable! Can be practiced in work! How to create AI/machine learning/deep learning apps with Python](https://www.</description>
    </item>
    
    <item>
      <title>I know? Things that you want to use when you want to analyze data using Python or numpy</title>
      <link>https://memotut.com/i-know-things-that-you-want-to-use-when-you-want-to-analyze-data-using-python-or-numpy-4153d/</link>
      <pubDate>Tue, 03 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/i-know-things-that-you-want-to-use-when-you-want-to-analyze-data-using-python-or-numpy-4153d/</guid>
      <description>Codes that I want to reach when I want it mainly in Pandas  I tried to make it like Advent Calender, but I couldn&amp;rsquo;t make it in time
Will be added soon
Hereafter, add an alias as follows
import pandas as pd import numpy as np import matplotlib.pyplot as plt Do not omit columns and rows when displaying pd.set_option(&amp;#39;display.max_columns&amp;#39;, 100) pd.set_option(&amp;#39;display.max_rows&amp;#39;, 500) #describe() is also used for lines other than numbers</description>
    </item>
    
    <item>
      <title>Implement Data Visualization Design #2 with matplotlib</title>
      <link>https://memotut.com/implement-data-visualization-design-#2-with-matplotlib-ee27a/</link>
      <pubDate>Tue, 03 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/implement-data-visualization-design-#2-with-matplotlib-ee27a/</guid>
      <description># What is the design of data visualization?  Go Ando of THE GUILD, which is famous for its services that focus on UX and UI, has published a note on the points of data visualization.
https://note.mu/goando/n/n4a2735c3d69d
#1?  See below for #1  https://qiita.com/skotaro/items/cdb0732ad1ad2a4b6236
Notes  Regarding fonts, it works on mac, but probably not on other OS, so specify a different font.  plt.rcParams[&amp;#39;font.family&amp;#39;] =&amp;#39;Hiragino Sans&amp;#39; Is the part.</description>
    </item>
    
    <item>
      <title>I tried Pandas&#39; Sql Upsert</title>
      <link>https://memotut.com/i-tried-pandas-sql-upsert-b329c/</link>
      <pubDate>Sat, 30 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/i-tried-pandas-sql-upsert-b329c/</guid>
      <description>## Introduction  This is Miyano (@estie_mynfire) of estie CTO.
Since estie builds real estate data from various resources, pandas is used for data shaping. for that reason Data created with pandas -&amp;gt; DataBase It is important to carry out this flow smoothly.
Since there was only replace and append as it was, I had to do my best on the pandas side and then update it. (This is very troublesome)</description>
    </item>
    
    <item>
      <title>Pandas User Guide merge, join and concatenate (official document in Japanese)</title>
      <link>https://memotut.com/pandas-user-guide-merge-join-and-concatenate-official-document-in-japanese-aea83/</link>
      <pubDate>Tue, 26 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/pandas-user-guide-merge-join-and-concatenate-official-document-in-japanese-aea83/</guid>
      <description>This article is a machine translation of [User Guide-Merge, join, and concatenate](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html) of Pandas official document. It is a rework of an unnatural sentence in a section.  If you have any suggestions for mistranslation, alternative translations, questions, etc., please use the comments or edit request.
merge, join and concatenate pandas provides various kinds of set operations and various functions of index and relational algebra function in join/merge type operations to easily join Series or DataFrame.</description>
    </item>
    
    <item>
      <title>How to use jpxlab, a processing/analysis tool for TSE stock high frequency data (FLEX historical)</title>
      <link>https://memotut.com/how-to-use-jpxlab-a-processing-analysis-tool-for-tse-stock-high-frequency-data-flex-historical-23a9e/</link>
      <pubDate>Wed, 20 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/how-to-use-jpxlab-a-processing-analysis-tool-for-tse-stock-high-frequency-data-flex-historical-23a9e/</guid>
      <description>Alpaca Japan (hereafter Alpaca) is a processing/analysis tool for TSE stock high-frequency data (FLEX historical), which is a data service provided by the Tokyo Stock Exchange, &amp;quot;[jpxlab](https://github.com/AlpacaDB/jpxlab)&amp;quot;. Is now available. FLEX historical collects market information distributed by TSE in real time in one file and provides it as historical information, and this project was realized by collaboration between Alpaca and the Tokyo Stock Exchange.   Prerequisites A contract with the Tokyo Stock Exchange is required to access FLEX Historical.</description>
    </item>
    
    <item>
      <title>How to speed up Pandas apply method with just one sentence (with verification calculation)</title>
      <link>https://memotut.com/how-to-speed-up-pandas-apply-method-with-just-one-sentence-with-verification-calculation-fc4d2/</link>
      <pubDate>Thu, 14 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/how-to-speed-up-pandas-apply-method-with-just-one-sentence-with-verification-calculation-fc4d2/</guid>
      <description>#Conclusion  Just add swifter method before Pandas apply method
Concrete example import pandas as pd import numpy as np import swifter # Create a suitable DataFrame df = pd.DataFrame({&amp;#39;col&amp;#39;: np.random.normal(size=10000000)}) # Add swifter method before apply method. %time df[&amp;#39;col2&amp;#39;] = df[&amp;#39;col&amp;#39;].swifter.apply(lambda x: x**2) # Wall time: 50 ms # For comparison (normal pandas apply method) %time df[&amp;#39;col2&amp;#39;] = df[&amp;#39;col&amp;#39;].apply(lambda x: x**2) # Wall time: 3.48 s How to install $ pip install -U pandas # upgrade pandas $ pip install swifter In case of ```terminal:conda $ conda update pandas # upgrade pandas $ conda install -c conda-forge swifter</description>
    </item>
    
    <item>
      <title>I tried to summarize how to use pandas in python</title>
      <link>https://memotut.com/i-tried-to-summarize-how-to-use-pandas-in-python-ae607/</link>
      <pubDate>Mon, 11 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/i-tried-to-summarize-how-to-use-pandas-in-python-ae607/</guid>
      <description>#Introduction  This time I will summarize how to use pandas.
Many people have summarized how to use pandas, so it may not be new, but I would appreciate it if you could associate.
Check back if you&amp;rsquo;d like since I have summarized how to use numpy in the previous article.
I tried to summarize python&amp;rsquo;s numpy
#Series generation You can generate a Series by doing the following. Series has a form in which an index is attached to the array.</description>
    </item>
    
    <item>
      <title>Introducing Bitcoin Systre on the weekend</title>
      <link>https://memotut.com/introducing-bitcoin-systre-on-the-weekend-97937/</link>
      <pubDate>Mon, 11 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/introducing-bitcoin-systre-on-the-weekend-97937/</guid>
      <description>#Background    If you were surfing the internet, you found a very helpful site about Systre -Even in the literature! How to start Bitcoin BOT automatic trading -It was explained very clearly -I feel like I can do it even if I have no experience with Systre
  Because I was interested, I decided to write the code on the weekend and check the feeling -GithubThisisthecodeIwrotethistime.(notebookformat)
  By the way, I tried Cryptocurrency prediction with LSTM and it didn&amp;rsquo;t work very well.</description>
    </item>
    
    <item>
      <title>Visualize quickly with Pandas</title>
      <link>https://memotut.com/visualize-quickly-with-pandas-16c20/</link>
      <pubDate>Mon, 11 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/visualize-quickly-with-pandas-16c20/</guid>
      <description>There are several libraries that visualize data in Python, but Pandas alone is quite good.  Visualization using Pandas can be completed in the method chain, which can prevent random scattering of temporary variables. In this article, I will introduce visualization recipes, focusing on the ones I often use in practice.
#Preparation
Environment  Python 3.6.8 jupyter==1.0.0 pandas==0.25.3  data I borrow the following two data this time.
 Titanic: Machine Learning from Disaster | Kaggle Crimes in Boston | Kaggle  Create a DataFrame called titanic and crime respectively.</description>
    </item>
    
    <item>
      <title>Matching application I tried to take statistics of strong people &amp; created a machine learning model</title>
      <link>https://memotut.com/matching-application-i-tried-to-take-statistics-of-strong-people-created-a-machine-learning-model-54bab/</link>
      <pubDate>Fri, 08 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/matching-application-i-tried-to-take-statistics-of-strong-people-created-a-machine-learning-model-54bab/</guid>
      <description>#Introduction  Hello everyone.
Do you use a matching app? ! I feel good as one of those who have recently matched with a matching app.
By the way, the matching app I was using was able to refer to the data of other popular members. (Probably people who have received more than 100 like are displayed.)
When I saw it, I was disappointed.
&amp;ldquo;Like, I didn&amp;rsquo;t get 100&amp;hellip;&amp;rdquo; ** &amp;ldquo;I want to be a man who exceeds 100&amp;rdquo; **</description>
    </item>
    
  </channel>
</rss>