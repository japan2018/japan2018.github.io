<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  <meta name="generator" content="Hugo 0.72.0" />

  
  <meta name="description" content="Some description">
  

  
  <link rel="apple-touch-icon" sizes="180x180" href="https://memotut.com/apple-touch-icon.png">

  
  <link rel="icon" type="image/png" sizes="32x32" href="https://memotut.com/favicon-32x32.png">

  
  <link rel="icon" type="image/png" sizes="16x16" href="https://memotut.com/favicon-16x16.png">

  
  <link rel="manifest" href="https://memotut.com/site.webmanifest">

  
  <link rel="mask-icon" href="https://memotut.com/safari-pinned-tab.svg" color="#5bbad5">

  <meta name="msapplication-TileColor" content="#da532c">

  <meta name="theme-color" content="#ffffff">

  
  <link rel="stylesheet" href="https://memotut.com/css/bootstrap.min.css" />

  
  <title>[Python] College students who don&#39;t want to read English papers (python) | Memo Tut</title>
  

  <style>
body {
  min-width: 300px;
}

.custom-navbar {
  margin-bottom: 1em;
  height: 60px;
}

.custom-navbar a {
  display: inline-block; 
  padding: 18px 0;
  margin-right: 1em; 
  font-weight: bold; 
}

.custom-navbar a:hover,
.custom-navbar a:focus {
  text-decoration: none; 
}

@media print {
  .custom-navbar {
    display: none;
  }
}

article {
  padding-bottom: 1em;
}

img {
  max-width: 100%;
}


body {
  background-color: #fff;
}



body {
  color: #212529;
}



a {
  color: #007bff;
}



a:hover,
a:focus {
  color: #0056b3;
}



.custom-navbar {
  background-color: #212529;
}



.custom-navbar a {
  color: rgba(255, 255, 255, 0.75);
}



.custom-navbar a:hover,
.custom-navbar a:focus {
  color: rgba(255, 255, 255, 1);
}



.container {
  max-width: 800px;
}



pre {
  display: block;
  padding: 9.5px;
  word-break: break-all;
  word-wrap: break-word;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre code {
  padding: 0;
  font-size: inherit;
  color: inherit; 
  white-space: pre-wrap;
  background-color: transparent;
  border: none;
  border-radius: 0;
}

code {
  padding: 2px 4px;
  color: inherit; 
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
  font-size: .9em;
}



blockquote,
.blockquote {
  padding: 10px 20px;
  margin: 0 0 20px;
  font-size: 1em;
  border-left: 5px solid #6c757d;
}

</style>
</head>

<body>
  <nav class="custom-navbar">
  <div class="container">
    
    <a href="/">Posts</a>
    
    <a href="/tags/">Tags</a>
    
    <a href="/about/">About</a>
    
    <a href="/index.xml">RSS</a>
    
  </div>
</nav>
  
  <div class="container">
    <article>
      <h1>[Python] College students who don&rsquo;t want to read English papers (python)</h1>
<p>
  <small class="text-secondary">
  
  
  Jan 21, 2020
  </small>
  

<small><code><a href="https://memotut.com/tags/python">Python</a></code></small>


<small><code><a href="https://memotut.com/tags/lstm"> LSTM</a></code></small>


<small><code><a href="https://memotut.com/tags/lexrank"> LexRank</a></code></small>


<small><code><a href="https://memotut.com/tags/article-generation"> article generation</a></code></small>


<small><code><a href="https://memotut.com/tags/colaboratory"> colaboratory</a></code></small>

</p>
<pre><code># I want to read English papers easily! !! !!
</code></pre>
<p>Since I am not good at English and I can&rsquo;t go on to learn more, I thought there would be a way to have fun.
The idea I came up with would be something like a summary and translate that English sentence&hellip;</p>
<h3 id="operation-confirmation-environment">Operation confirmation environment</h3>
<ul>
<li>Windows10</li>
<li>Powershell (even cmd is OK)</li>
<li>Google Colaboratory</li>
<li>Python 3.7.3</li>
</ul>
<h2 id="what-is-colaboratoryhttpscolabresearchgooglecomnotebookswelcomeipynbhlja">What is <a href="https://colab.research.google.com/notebooks/welcome.ipynb?hl=ja">Colaboratory</a></h2>
<p><a href="https://colab.research.google.com/">Colaboratory</a> is a Jupyter notebook environment that runs entirely in the cloud. No settings required and can be used free of charge.
With <a href="https://colab.research.google.com/">Colaboratory</a>, you can write and run code, save and share analyzes, access powerful computing resources, all from your browser for free. Can.
<a href="http://www.youtube.com/watch?v=inN8seMm7UI"><img src="http://img.youtube.com/vi/inN8seMm7UI/0.jpg" alt="Sorry, the video cannot be played. "></a></p>
<h2 id="procedure">Procedure</h2>
<ol>
<li>Extract only the text from the paper (remove titles, chapter names, figures, and references)</li>
<li>Apply LexRank to the text of each chapter and extract the key text</li>
<li>Combine the key sentences of each chapter to create a sentence close to the summary using the language model</li>
</ol>
<p>*We use a method that does not require correct sentences in order to generate more detailed sentences than abstract and conclusion of the paper.</p>
<h2 id="about-lexrankhttpswwwaaaiorgpapersjairvol22jair-2214pdf">About <a href="https://www.aaai.org/Papers/JAIR/Vol22/JAIR-2214.pdf">LexRank</a></h2>
<p>Text summaries are broadly classified into extractive and generative.
<a href="https://www.aaai.org/Papers/JAIR/Vol22/JAIR-2214.pdf">LexRank</a> is a summarization algorithm classified as extraction type.
By creating a graph structure from a document and ranking important sentences, a sentence that can be called a summary is output.
Proposed by Gunes Erkan, Dragomir R. Radev in 2004.</p>
<blockquote>
<p>LexRank, a new approach for calculating sentence importance based on the concept of eigenvector centrality in the graphical representation of sentences is examined. In this model, the connectivity matrix based on cosine similarity within a sentence is used as the adjacency matrix for the graphical representation of the sentence.</p>
<blockquote>
<p>We consider a new approach, LexRank, for computing sentence importance based on the concept of eigenvector centrality in a graph representation of sentences.In this model, a connectivity matrix based on intra-sentence cosine similarity is used as the adjacency matrix of the graph representation of sentences.</p>
</blockquote>
</blockquote>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/266405/f1141010-e32a-6fd1-46ea-23b2e01e0a59.png" alt="20181117143216.png"></p>
<p><a href="https://ohke.hateblo.jp/entry/2018/11/17/230000">Ohke&rsquo;s article</a> explained in detail.</p>
<blockquote>
<p>LexRank has two key points, and is a derivative of TextRank (PDF of the proposed paper) inspired by PageRank. Create a non-directional graph with sentences as nodes and similarity between sentences as edges. In the proposed paper, TF-IDF is used to calculate the cosine similarity (modern words such as word2vec can also be used). The transition probability matrix (M) obtained from the above graph and the probability vector (P) are calculated up to a stable state (MP=P), and the sentence with the larger final probability vector value is selected as the summary sentence.
In the above figure that visualizes the above theory (extracted from Figure 2 of the proposed paper), there are many edges (= similar to many sentences) and thick edges (= high similarity) such as d5s1 and d4s1. It is a candidate for a summary sentence.</p>
</blockquote>
<h2 id="implementation">Implementation</h2>
<p>The library import is as follows. It uses the libraries needed to implement LexRank, to separate words, and to build LSTM language models.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> __future__ <span style="color:#f92672">import</span> absolute_import
<span style="color:#f92672">from</span> __future__ <span style="color:#f92672">import</span> division, print_function, unicode_literals
<span style="color:#f92672">from</span> sumy.parsers.html <span style="color:#f92672">import</span> HtmlParser
<span style="color:#f92672">from</span> sumy.parsers.plaintext <span style="color:#f92672">import</span> PlaintextParser
<span style="color:#f92672">from</span> sumy.nlp.tokenizers <span style="color:#f92672">import</span> Tokenizer
<span style="color:#f92672">from</span> sumy.summarizers.lsa <span style="color:#f92672">import</span> LsaSummarizer <span style="color:#66d9ef">as</span> Summarizer
<span style="color:#f92672">from</span> sumy.nlp.stemmers <span style="color:#f92672">import</span> Stemmer
<span style="color:#f92672">from</span> sumy.utils <span style="color:#f92672">import</span> get_stop_words
<span style="color:#f92672">from</span> keras.callbacks <span style="color:#f92672">import</span> LambdaCallback
<span style="color:#f92672">from</span> keras.models <span style="color:#f92672">import</span> Sequential
<span style="color:#f92672">from</span> keras.layers <span style="color:#f92672">import</span> Dense
<span style="color:#f92672">from</span> keras.layers <span style="color:#f92672">import</span> LSTM
<span style="color:#f92672">from</span> keras.optimizers <span style="color:#f92672">import</span> RMSprop
<span style="color:#f92672">from</span> keras.utils.data_utils <span style="color:#f92672">import</span> get_file
<span style="color:#f92672">from</span> googletrans <span style="color:#f92672">import</span> Translator
<span style="color:#f92672">import</span> nltk
<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">import</span> random
<span style="color:#f92672">import</span> sys
<span style="color:#f92672">import</span> io
<span style="color:#f92672">import</span> os
<span style="color:#f92672">import</span> glob
</code></pre></div><p><b>Supplement: When using nltk, it seems that you can use it by updating every punkt package. <b></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#960050;background-color:#1e0010">!</span>python <span style="color:#f92672">-</span>c <span style="color:#e6db74">&#34;import nltk; nltk.download(&#39;punkt&#39;)&#34;</span>
</code></pre></div><h3 id="lexrank-part-implementation-using-sumyhttpsgithubcommiso-belicasumy">LexRank part (Implementation using <a href="https://github.com/miso-belica/sumy">sumy</a>)</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">sectionLex</span>():
  <span style="color:#75715e"># Language set to English</span>
  LANG <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;english&#34;</span>
  Select all <span style="color:#75715e">#.txt files (text data of each section)</span>
  file <span style="color:#f92672">=</span> glob<span style="color:#f92672">.</span>glob(<span style="color:#e6db74">&#39;*.txt&#39;</span>)
  ex <span style="color:#f92672">=</span> []
  <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(len(file)):
    parser <span style="color:#f92672">=</span> PlaintextParser<span style="color:#f92672">.</span>from_file(file[i], Tokenizer(LANG))
    stemmer <span style="color:#f92672">=</span> Stemmer(LANG)
    summarizer <span style="color:#f92672">=</span> Summarizer(stemmer)
    summarizer<span style="color:#f92672">.</span>stop_words <span style="color:#f92672">=</span> get_stop_words(LANG)
    <span style="color:#66d9ef">for</span> sentence <span style="color:#f92672">in</span> summarizer(parser<span style="color:#f92672">.</span>document, [what sentence to output]):
      ex<span style="color:#f92672">.</span>append(str(sentence) <span style="color:#f92672">+</span><span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span>)
    Output <span style="color:#66d9ef">with</span> <span style="color:#75715e">#utf-8 encoding</span>
    <span style="color:#66d9ef">with</span> open(<span style="color:#e6db74">&#39;output.txt&#39;</span>, mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;w&#39;</span>, encoding<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;utf-8&#39;</span>) <span style="color:#66d9ef">as</span> f:
      f<span style="color:#f92672">.</span>writelines(ex)
</code></pre></div><p>Declaration of variables used for dictionary</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Ordered dictionary list</span>
chr_index <span style="color:#f92672">=</span> {}
<span style="color:#75715e">#Reverse dictionary list</span>
rvs_index <span style="color:#f92672">=</span> {}
<span style="color:#75715e">#Sentence list</span>
sentences <span style="color:#f92672">=</span> []
<span style="color:#75715e">#Next word</span>
next_word <span style="color:#f92672">=</span> []
</code></pre></div><h3 id="separating">separating</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">Read <span style="color:#f92672">in</span> <span style="color:#75715e">#utf-8 encoding and store in text</span>
<span style="color:#66d9ef">with</span> io<span style="color:#f92672">.</span>open(<span style="color:#e6db74">&#39;output.txt&#39;</span>, encoding<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;utf-8&#39;</span>) <span style="color:#66d9ef">as</span> f:
    text <span style="color:#f92672">=</span> f<span style="color:#f92672">.</span>read()<span style="color:#f92672">.</span>lower()

<span style="color:#75715e"># Divide into words (separate)</span>
text <span style="color:#f92672">=</span> nltk<span style="color:#f92672">.</span>word_tokenize(text)
chars <span style="color:#f92672">=</span> text
</code></pre></div><h3 id="creating-a-dictionary">Creating a dictionary</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">
<span style="color:#75715e">#Create normal order list</span>
count <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
<span style="color:#66d9ef">for</span> c <span style="color:#f92672">in</span> chars:
    <span style="color:#66d9ef">if</span> <span style="color:#f92672">not</span> c <span style="color:#f92672">in</span> chr_index:
        chr_index[c] <span style="color:#f92672">=</span> count
        count <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>
        <span style="color:#66d9ef">print</span>(count, c)
<span style="color:#75715e"># Create list in reverse order</span>
rvs_index <span style="color:#f92672">=</span> dict([(value, key) <span style="color:#66d9ef">for</span> (key, value) <span style="color:#f92672">in</span> chr_index<span style="color:#f92672">.</span>items()])
</code></pre></div><h3 id="create-substring">Create substring</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">0</span>, len(text)<span style="color:#f92672">-</span>maxlen, step):
    Store <span style="color:#75715e">#maxlen words as substring (1 sentence)</span>
    sentences<span style="color:#f92672">.</span>append(text[i: i <span style="color:#f92672">+</span> maxlen])
    <span style="color:#75715e"># Store the next word of the stored substring</span>
    next_word<span style="color:#f92672">.</span>append(text[i <span style="color:#f92672">+</span> maxlen])
</code></pre></div><h3 id="vectorization-of-words">Vectorization of words</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e">#np.bool type three-dimensional array: (number of substrings, maximum length of substring, number of words)</span>
x <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>zeros((len(sentences), maxlen, len(chars)), dtype<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>bool)
Two<span style="color:#f92672">-</span>dimensional array of type <span style="color:#75715e">#np.bool: (number of substrings, number of words)</span>
y <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>zeros((len(sentences), len(chars)), dtype<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>bool)
<span style="color:#75715e"># Vectorize each substring</span>
<span style="color:#66d9ef">for</span> i, sentence <span style="color:#f92672">in</span> enumerate(sentences):
    <span style="color:#66d9ef">for</span> t, ch <span style="color:#f92672">in</span> enumerate(sentence):
        x[i, t, chr_index[ch]] <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
    y[i, chr_index[next_word[i]]] <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
</code></pre></div><h3 id="creating-a-model">Creating a model</h3>
<p>This time, <a href="https://keras.io/ja/getting-started/sequential-model-guide/">Sequential model</a> is used.
Regarding <a href="https://qiita.com/rtok/items/b1affc619d826eea61fd">softmax</a>,@rtok&rsquo;s<a href="https://qiita.com/rtok/items/b1affc619d826eea61fd">Article</a> was easy to understand.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Make a simple modelmodel = Sequential()</span>
Use <span style="color:#75715e">#LSTM. Batch size is 128</span>
model<span style="color:#f92672">.</span>add(LSTM(<span style="color:#ae81ff">128</span>, input_shape<span style="color:#f92672">=</span>(maxlen, len(chars))))
<span style="color:#75715e"># Make a probability with softmax for each word</span>
model<span style="color:#f92672">.</span>add(Dense(len(chars), activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;softmax&#39;</span>))
</code></pre></div><p><a href="https://keras.io/ja/optimizers/">RMSprop</a>wasusedfor<a href="https://www.pynote.info/entry/math-gradient-method">gradientmethod</a>.
As for RMSprop, @tokkuman&rsquo;s <a href="https://qiita.com/tokkuman/items/1944c00415d129ca0ee9#rmsprop">Article</a> was easy to understand.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">optimizer <span style="color:#f92672">=</span> RMSprop(learning_rate<span style="color:#f92672">=</span><span style="color:#ae81ff">0.01</span>)
model<span style="color:#f92672">.</span>compile(loss<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;categorical_crossentropy&#39;</span>, optimizer<span style="color:#f92672">=</span>optimizer)
</code></pre></div><h3 id="calculate-the-appearance-rate-of-each-word-and-select-the-word-to-output">Calculate the appearance rate of each word and select the word to output</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e">#preds: Output from the model. float32 type.</span>
<span style="color:#75715e"># temperature: versatility. The lower the value, the more likely it is that the appearance rate will be high.</span>
Since the output <span style="color:#f92672">from</span> the <span style="color:#75715e"># model is a multinomial distribution, the sum is 1.0</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">selectWD</span>(preds, temperature<span style="color:#f92672">=</span><span style="color:#ae81ff">1.0</span>):
    Convert to <span style="color:#75715e">#float64 type</span>
    preds <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>asarray(preds)<span style="color:#f92672">.</span>astype(<span style="color:#e6db74">&#39;float64&#39;</span>)
    <span style="color:#75715e"># Divide the natural logarithm by the degree of diversity so that words with a low probability are easily selected</span>
    preds <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>log(preds) <span style="color:#f92672">/</span> temperature
    <span style="color:#75715e">#Reverse the natural logarithm of the probability (make it a natural exponential function)</span>
    exp_preds <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>exp(preds)
    <span style="color:#75715e"># Divide all values by the sum so that the sum is 1.</span>
    preds <span style="color:#f92672">=</span> exp_preds <span style="color:#f92672">/</span> np<span style="color:#f92672">.</span>sum(exp_preds)
    <span style="color:#75715e"># Choose randomly according to multinomial distribution</span>
    probas <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>multinomial(<span style="color:#ae81ff">1</span>, preds, <span style="color:#ae81ff">1</span>)
    <span style="color:#66d9ef">return</span> np<span style="color:#f92672">.</span>argmax(probas)
</code></pre></div><h3 id="processing-for-each-epoch">Processing for each epoch</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">on_epoch_end</span>(epoch, _):
    <span style="color:#66d9ef">print</span>()
    <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;----- Generating text after Epoch: </span><span style="color:#e6db74">%d</span><span style="color:#e6db74">&#39;</span> <span style="color:#f92672">%</span>epoch)
    <span style="color:#75715e"># Make the first 4 words the beginning of the input string</span>
    start_index <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
    <span style="color:#75715e">#diversity: Diversity. Same as selectWD temperature. The higher the value, the less likely the character will be selected.</span>
    <span style="color:#66d9ef">for</span> diversity <span style="color:#f92672">in</span> [<span style="color:#ae81ff">0.2</span>, <span style="color:#ae81ff">0.5</span>, <span style="color:#ae81ff">0.8</span>, <span style="color:#ae81ff">1.0</span>]:
        <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;----- diversity:&#39;</span>, diversity)
        <span style="color:#75715e">#For output</span>
        generated <span style="color:#f92672">=</span><span style="color:#e6db74">&#39;&#39;</span>
        sentence <span style="color:#f92672">=</span> text[start_index: start_index <span style="color:#f92672">+</span> maxlen]
        generated <span style="color:#f92672">+=</span> <span style="color:#e6db74">&#34;&#34;</span><span style="color:#f92672">.</span>join(sentence)
        <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34; &#34;</span><span style="color:#f92672">.</span>join(sentence))

        <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;----- Generating with seed: &#34;&#39;</span><span style="color:#f92672">+</span> <span style="color:#e6db74">&#34;&#34;</span><span style="color:#f92672">.</span>join(sentence)<span style="color:#f92672">+</span><span style="color:#e6db74">&#39;&#34;&#39;</span>)
        sys<span style="color:#f92672">.</span>stdout<span style="color:#f92672">.</span>write(generated)
        
        Outputs <span style="color:#75715e">#OUTSEN sentences or ends with 1000 words output</span>
        flag <span style="color:#f92672">=</span> OUTSEN
        <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">1000</span>):
            <span style="color:#75715e">#What word is in which position in the current sentence</span>
            x_pred <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>zeros((<span style="color:#ae81ff">1</span>, maxlen, len(chars)))
            <span style="color:#66d9ef">for</span> t, ch <span style="color:#f92672">in</span> enumerate(sentence):
                x_pred[<span style="color:#ae81ff">0</span>, t, chr_index[ch]] <span style="color:#f92672">=</span> <span style="color:#ae81ff">1.</span>
            <span style="color:#75715e">#Predict next word</span>
            preds <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>predict(x_pred, verbose<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)[<span style="color:#ae81ff">0</span>]
            next_index <span style="color:#f92672">=</span> selectWD(preds, diversity)
            next_char <span style="color:#f92672">=</span> rvs_index[next_index]
            <span style="color:#75715e">#Scrap the first word and add the predicted word after</span>
            sentence <span style="color:#f92672">=</span> sentence[<span style="color:#ae81ff">1</span>:]
            sentence<span style="color:#f92672">.</span>append(next_char)
            <span style="color:#75715e"># Output organization</span>
            <span style="color:#66d9ef">if</span> next_char <span style="color:#f92672">==</span><span style="color:#e6db74">&#39;.&#39;</span>:
                flag <span style="color:#f92672">-=</span> <span style="color:#ae81ff">1</span>
                generated <span style="color:#f92672">+=</span> next_char <span style="color:#f92672">+</span> <span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>
                sys<span style="color:#f92672">.</span>stdout<span style="color:#f92672">.</span>write(next_char<span style="color:#f92672">+</span><span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>)
            <span style="color:#66d9ef">elif</span> next_char <span style="color:#f92672">==</span><span style="color:#e6db74">&#39;,&#39;</span>:
                generated <span style="color:#f92672">+=</span> next_char
                sys<span style="color:#f92672">.</span>stdout<span style="color:#f92672">.</span>write(next_char)
            <span style="color:#66d9ef">else</span>:
                generated <span style="color:#f92672">+=</span> <span style="color:#e6db74">&#34;&#34;</span> <span style="color:#f92672">+</span> next_char
                sys<span style="color:#f92672">.</span>stdout<span style="color:#f92672">.</span>write(<span style="color:#e6db74">&#34; &#34;</span><span style="color:#f92672">+</span>next_char)
            sys<span style="color:#f92672">.</span>stdout<span style="color:#f92672">.</span>flush()
            <span style="color:#66d9ef">if</span> flag <span style="color:#f92672">&lt;=</span> <span style="color:#ae81ff">0</span>:
                <span style="color:#66d9ef">break</span>
        sys<span style="color:#f92672">.</span>stdout<span style="color:#f92672">.</span>flush()
        <span style="color:#66d9ef">print</span>()
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e">#Set to call the above process at each epoch</span>
print_callback <span style="color:#f92672">=</span> LambdaCallback(on_epoch_end<span style="color:#f92672">=</span>on_epoch_end)
</code></pre></div><h3 id="fitting-process">Fitting process</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e">#Batch size 128, 100 epochs, call the function described above</span>
model<span style="color:#f92672">.</span>fit(x, y, batch_size<span style="color:#f92672">=</span><span style="color:#ae81ff">128</span>, epochs<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span>, callbacks<span style="color:#f92672">=</span>[print_callback])
</code></pre></div><h2 id="result">result</h2>
<p>It is the result when data of <a href="https://www.sciencedirect.com/science/article/pii/S0167739X15003015">Integration of Cloud computing and Internet of Things: A survey</a>(2016) by Botta et al.</p>
<blockquote>
<p>&mdash;&ndash; Generating text after Epoch: 99</p>
</blockquote>
<ul>
<li>&mdash;- diversity: 0.2
in general ,iot</li>
<li>&mdash;- Generating with seed: &ldquo;in general ,iot&rdquo;
in general ,iot can benefit from the virtually unlimited capabilities and resources of cloud to compensate its technological constraints (e.g., storage, processing, communication ).
being iot characterized by a very high heterogeneity of devices, technologies, and protocols, it lacks different important properties such as scalability, interoperability, flexibility, reliability, efficiency, availability, and security.
as a consequence, analyzes of unprecedented complexity are possible, and data-driven decision making and prediction algorithms can be employed at low cost, providing means for increasing revenues and reduced risks.
the availability of high speed networks enables effective monitoring and control of remote things, their coordination, their communications, and real-time access to the produced data.
this represents another important cloudiot driver: iot processing needs can be properly satisfied for performing real-time data analysis (on-the-fly ), for implementing scalable, real-time, collaborative, sensor-centric applications, for managing complex events, and for supporting task offloading for energy saving.</li>
</ul>
<p>It outputs 5 sentences, but it looks like this when translated into Japanese with google translation.</p>
<blockquote>
<p>In general, iot can benefit from the virtually unlimited capabilities and resources of the cloud to supplement technical constraints (storage, processing, communications, etc.).
It is characterized by a very high degree of device, technology, and protocol heterogeneity, and lacks various important properties such as scalability, interoperability, flexibility, reliability, efficiency, availability, and security.
The result is unprecedented complexity analysis and low-cost adoption of data-driven decision-making and forecasting algorithms that help increase revenue and reduce risk.
High-speed network availability allows effective monitoring and control of remote things, their coordination, communication, and real-time access to the data generated.
This represents another important cloudiot driver: performing real-time data analytics (on-the-fly), implementing scalable, real-time, collaboration-centric, sensor-centric applications, managing complex events, and offloading tasks to save energy. Support</p>
</blockquote>
<p>It feels like it&rsquo;s organized!The entire source code is available on <a href="https://github.com/7vvXi/writeEnglish">github</a>.
There are some things that are strange in Japanese, so I will improve it&hellip;</p>

    </article>
  </div>

  
  
  
  <script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-169005401-1', 'auto');
  ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  

  
<link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.css" />
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#216942",
      "text": "#b2d192"
    },
    "button": {
      "background": "#afed71"
    }
  }
})});
</script>

</body>

</html>
