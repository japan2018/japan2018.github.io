<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  <meta name="generator" content="Hugo 0.72.0" />

  
  <meta name="description" content="Some description">
  

  
  <link rel="apple-touch-icon" sizes="180x180" href="https://memotut.com/apple-touch-icon.png">

  
  <link rel="icon" type="image/png" sizes="32x32" href="https://memotut.com/favicon-32x32.png">

  
  <link rel="icon" type="image/png" sizes="16x16" href="https://memotut.com/favicon-16x16.png">

  
  <link rel="manifest" href="https://memotut.com/site.webmanifest">

  
  <link rel="mask-icon" href="https://memotut.com/safari-pinned-tab.svg" color="#5bbad5">

  <meta name="msapplication-TileColor" content="#da532c">

  <meta name="theme-color" content="#ffffff">

  
  <link rel="stylesheet" href="https://memotut.com/css/bootstrap.min.css" />

  
  <title>[Python] Google Cloud Speech API vs. Amazon Transcribe | Memo Tut</title>
  

  <style>
body {
  min-width: 300px;
}

.custom-navbar {
  margin-bottom: 1em;
  height: 60px;
}

.custom-navbar a {
  display: inline-block; 
  padding: 18px 0;
  margin-right: 1em; 
  font-weight: bold; 
}

.custom-navbar a:hover,
.custom-navbar a:focus {
  text-decoration: none; 
}

@media print {
  .custom-navbar {
    display: none;
  }
}

article {
  padding-bottom: 1em;
}

img {
  max-width: 100%;
}


body {
  background-color: #fff;
}



body {
  color: #212529;
}



a {
  color: #007bff;
}



a:hover,
a:focus {
  color: #0056b3;
}



.custom-navbar {
  background-color: #212529;
}



.custom-navbar a {
  color: rgba(255, 255, 255, 0.75);
}



.custom-navbar a:hover,
.custom-navbar a:focus {
  color: rgba(255, 255, 255, 1);
}



.container {
  max-width: 800px;
}



pre {
  display: block;
  padding: 9.5px;
  word-break: break-all;
  word-wrap: break-word;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre code {
  padding: 0;
  font-size: inherit;
  color: inherit; 
  white-space: pre-wrap;
  background-color: transparent;
  border: none;
  border-radius: 0;
}

code {
  padding: 2px 4px;
  color: inherit; 
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
  font-size: .9em;
}



blockquote,
.blockquote {
  padding: 10px 20px;
  margin: 0 0 20px;
  font-size: 1em;
  border-left: 5px solid #6c757d;
}

</style>
</head>

<body>
  <nav class="custom-navbar">
  <div class="container">
    
    <a href="/">Posts</a>
    
    <a href="/tags/">Tags</a>
    
    <a href="/about/">About</a>
    
    <a href="/index.xml">RSS</a>
    
  </div>
</nav>
  
  <div class="container">
    <article>
      <h1>[Python] Google Cloud Speech API vs. Amazon Transcribe</h1>
<p>
  <small class="text-secondary">
  
  
  Jan 11, 2020
  </small>
  

<small><code><a href="https://memotut.com/tags/python">Python</a></code></small>


<small><code><a href="https://memotut.com/tags/googlecloudplatform"> GoogleCloudPlatform</a></code></small>


<small><code><a href="https://memotut.com/tags/voice-recognition"> voice recognition</a></code></small>


<small><code><a href="https://memotut.com/tags/googlespeechapi"> GoogleSpeechAPI</a></code></small>


<small><code><a href="https://memotut.com/tags/amazontranscribe"> AmazonTranscribe</a></code></small>

</p>
<pre><code>## Transcription API Gachinko Battle
</code></pre>
<img width="904" alt="Screenshot 2020-01-10 23.02.46.png" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/100780/ea7cde61-007d-94c7-fc53-96caf86a22ed.png">
<p>In the range of &ldquo;Transcription API comparison&rdquo; that is easy to see in Gugu, there are many articles that say good/bad by performing very short transcription at the level of several lines (or minutes). Or, there are many things we do for &ldquo;too clear sound sources&rdquo; such as news videos. The <a href="https://note.com/sangmin/n/nf404e9945f48">Blog that buzzed about Amazon Transcribe</a> also tells highly accurate transcriptions in English. It is well known that English is highly accurate in the field of natural language processing, but I am worried about how it is Japanese.</p>
<p>I want to know</p>
<ul>
<li>Japanese sound source</li>
<li>Sound sources such as podcasts that are recorded by amateurs and contain some noise</li>
<li>Long sound source of about 1h</li>
<li>Sound source where multiple people are cross-talking
Since we were wondering how much we could fight with the API alone (whether we could transcribe it) for voice data with such characteristics, we have conducted various verifications.</li>
</ul>
<p>In the first article, I summarized how to use the Google Cloud Speech API and made a hypothesis that the transcription accuracy is low.</p>
<ul>
<li><a href="https://qiita.com/ysdyt/items/bc22eb04d90eb074cf9d">Speech transcription procedure using Python and Google Cloud Speech API</a></li>
</ul>
<p>In the second article, we experimented with preprocessing methods to improve transcription accuracy with the Google Cloud Speech API.</p>
<ul>
<li><a href="https://qiita.com/ysdyt/items/cfbfaba5e0bc5dce54ee">Research on relationship between voice preprocessing and transcription accuracy in Google Cloud Speech API</a></li>
</ul>
<p>〆This time, I will transcribe the best-accuracy Google Speech API transcription obtained last time vs. Amazon Transcribe, which has become a hot topic recently, and I would like to summarize the <strong>limit points</strong> of the transcription API. I think.</p>
<p>If you want to know only the result, please read only the &ldquo;Google Cloud Speech API vs. Amazon Transcribe result summary&rdquo; item at the bottom.</p>
<p>** * Note: The conclusions obtained this time are the results of the audio data used this time and the preprocessing performed. Please understand that this result does not conclude the performance of the API. **</p>
<h2 id="transcription-with-amazon-transcribe">Transcription with Amazon Transcribe</h2>
<p>Amazon&rsquo;s automatic transcription API <a href="https://aws.amazon.com/jp/transcribe/">Amazon Transcribe</a> is a service that has existed for a long time, but it also supports Japanese at the end of November 2019.</p>
<p>It is very easy to use compared to the Google Speech API, so I will omit it here. <a href="https://aws.amazon.com/jp/getting-started/tutorials/create-audio-transcript-transcribe/">Official tutorial</a>and<a href="https://dev.classmethod.jpPleasereferto/cloud/aws/amazontranscribe-japanese/">Classmethod&rsquo;sblog</a> etc.</p>
<p>Not only transcription, but also Japanese.</p>
<p>The file formats that Amazon Tanscribe can process are mp3, mp4, wav, flac. Google Speech API is a nice point because we could not specify general file formats such as mp3 and wav.
Since the audio sampling rate is also recognized automatically, it seems that it is not necessary to specify it manually like Google does. Convenient.</p>
<p>By the way, Amazon Transcribe allows you to specify your own parameters as optional in addition to the required parameters.
<img width="836" alt="Screenshot 2020-01-04 18.09.39.png" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/100780/afc95050-e566-44b6-f202-d53cdeeb6dc8.png"></p>
<p>In summary,</p>
<ul>
<li>Audio identification
-<a href="https://docs.aws.amazon.com/transcribe/latest/dg/how-channel-id.html">Channel identification</a>&hellip; Set this to True if the sound source is divided into multiple channels. It makes sense. For example, in the sound source of telephone customer support, the channel is 2 when the answerer and the questioner are different sound sources. Amazon Transcribe seems to output both the transcribed version of each channel and the transcribed version of the merged sound source when this parameter is set to true.
-Speaker identification・・・The number of speakers in the sound source can be specified arbitrarily. The maximum is 10 people. Two people by default. (So it might be better to set this to 1 if the sound source is just one person talking.)</li>
<li>Alternative results・・・Classmethod&rsquo;s <a href="https://dev.classmethod.jp/cloud/aws/transcribe-alternatrive-results/">blog reference</a></li>
<li>Vocabualry filtering: A function that automatically masks and transcribes specified words such as inappropriate words. Classmethod&rsquo;s <a href="https://dev.classmethod.jp/cloud/aws/amazon-transcribe-supports-vocabulary-filtering/">blog reference</a></li>
<li>Custom vocabulary: To improve recognition accuracy by giving hints such as technical terms in a specific domain or proper nouns that amazon transcribe cannot recognize</li>
</ul>
<p>Since there are two speakers in the sound source used this time, &ldquo;Speaker identification&rdquo; is 2. However, since it seems to be 2 by default, I did not specify it in particular, and executed it by default (all are not specified).</p>
<p>The processing time was about 10 minutes with a 1h sound source. Google Speech API took a little over 15 minutes, so Amazon transcribe has faster processing time.</p>
<h2 id="verification-data-set-and-evaluation-method">Verification data set and evaluation method</h2>
<p>Same as <a href="https://qiita.com/ysdyt/items/cfbfaba5e0bc5dce54ee">Last time</a>,No1toNo8soundsources(flacfiles)createdbycombiningvariouspreprocessingparametersareused.Thesoundsourcedatais<a href="https://drive.google.com/drive/folders/1e6mZH7G9Oa7zOdIMUKq9n9QUA93gXKqB?usp=sharing">here</a> so please use it if you want.</p>
<p>The same file is targeted, and Amazon Transcribe side executes it by default without specifying any optional parameter, so it should be possible to compare it with the result of Google speech API on the same level.</p>
<p>The transcription output result of Amazon Transcribe will be json. The number of characters and the number of words were counted in the same way as <a href="https://qiita.com/ysdyt/items/cfbfaba5e0bc5dce54ee">Last time</a>.(Clickherefortheactualprocessingcode)</p>
<p>For horizontal comparison, the evaluation method is the same as <a href="https://qiita.com/ysdyt/items/cfbfaba5e0bc5dce54ee">Last time</a>.</p>
<h2 id="result">result</h2>
<h3 id="quantitative-result">Quantitative result</h3>
<p>| No. | File name | Noise reduction processing | Volume control | sample rate hertz | ** Number of transcription characters ** | ** Total number of duplicated words ** | ** Number of duplicated noun words ** | ** Total number of unique words ** | ** Number of unique noun words ** |
| &mdash;- | &mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash; | - &mdash;&mdash;&mdash;&mdash; | &mdash;&mdash;&ndash; | &mdash;&mdash;&mdash;&mdash;&mdash;&ndash; | &mdash;&mdash;&mdash;- &mdash;&mdash;&mdash;- | &mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;- | &mdash;&mdash;&mdash;&mdash;&mdash;- &mdash;&mdash;&ndash; | &mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;- | &mdash;&mdash;&mdash;&mdash;&mdash;&mdash; &mdash;&mdash; |
1 | 01_001_NoiRed-true_lev-true_samp16k.flac | True | True | 16k | 19320 | 10469 | 3150 | 1702 | 1057 |
2 | 02_001_NoiRed-true_lev-true_samp44k.flac | True | True | 44k | 19317 | 10463 | 3152 | 1708 | 1060 |
3 | 03_001_NoiRed-true_lev-false_samp16k.flac | True | False | 16k | 19278 | 10429 | 3166 | 1706 | 1059 |
4 | 04_001_NoiRed-true_lev-false_samp44k.flac | True | False | 44k | 19322 | 10453 | 3170 | 1706 | 1058 |5 | 05_001_NiRed-false_lev-true_samp16k.flac | False | True | 16k | 19660 | 10664 | 3209 | 1713 | 1054 |
6 | 06_001_NiRed-false_lev-true_samp44k.flac | False | True | 44k | 19653 | 10676 | 3211 | 1701 | 1052 |
7 | 07_001_NiRed-false_lev-false_samp16k.flac | False | False | 16k | 19639 | 10653 | 3209 | 1702 | 1052 |
8 | 08_001_NiRed-false_lev-false_samp44k.flac | False | False | 44k | 19620 | 10638 | 3213 | 1702 | 1047 |</p>
<p>The one shown in the figure is as follows.</p>
<img width="592" alt="Screenshot 2020-01-10 23.07.02.png" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/100780/5f08f8bd-bf41-6e8c-205e-dabca5348e93.png">
<img width="710" alt="Screenshot 2020-01-10 23.07.30.png" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/100780/796355fc-cf5d-b083-f2b3-ad03164ac025.png">
<img width="692" alt="Screenshot 2020-01-10 23.07.40.png" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/100780/dbf6a601-14f9-257d-7de9-657fb5616ec4.png">
<p>Almost all the results were the same between the samples. From the whole result,</p>
<ul>
<li>In Amazon Transcribe, unlike the result of Google Speech API, <strong>Pre-processing of voice is not affected</strong> (* The pre-processing performed here is noise reduction processing by Audacity and volume adjustment processing by Levelator. The result may be different under other conditions.)</li>
</ul>
<p>Here, the result of No. 2 which has the highest &ldquo;number of noun words without duplication **&rdquo; (almost at the error level) is set as the representative value as the best result in Amazon transcribe.</p>
<p>Since it may not be affected by the presence or absence of pre-processing, I tried Amazon transcribe even with a raw wav file (No. 0) ** recorded and shot out as a trial.</p>
<p>The only difference between this wav file that has not been pre-processed and the No. 2 file is <strong>stereo or monaural</strong>. In No. 2, when converting from wav to flac file, the conversion from stereo to monaural is performed at the same time. This was necessary because the Google speech API only accepts monaural files.</p>
<p>| No. | File name | Noise reduction processing | Volume control | sample rate hertz | ** Number of transcription characters ** | ** Total number of duplicated words ** | ** Number of duplicated noun words ** | ** Total number of unique words ** | ** Number of unique noun words ** |
| &mdash;- | &mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;- | &mdash; &mdash;&mdash;&mdash;&ndash; | &mdash;&mdash;&ndash; | &mdash;&mdash;&mdash;&mdash;&mdash;&ndash; | &mdash;&mdash;&mdash;&ndash; &mdash;&mdash;&mdash; | &mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;- | &mdash;&mdash;&mdash;&mdash;&mdash;&ndash; &mdash;&mdash;- | &mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;- | &mdash;&mdash;&mdash;&mdash;&mdash;&mdash;- &mdash;&ndash; |
0 | 001.wav | False | False | 44k | 19620 | 10637 | 3212 | 1701 | 1046 |
2 | 02_001_NoiRed-true_lev-true_samp44k.flac | True | True | 44k | 19317 | 10463 | 3152 | 1708 | 1060 |</p>
<p>Strictly speaking, “No. of duplicate words” and “No. of duplicate noun words” are higher in No. 2, but there is not much difference. If you can get almost the same accuracy without pre-processing &amp; stereo ⇔ monaural conversion, it is best to &ldquo;push a raw wav file&rdquo; that does not require pre-processing.</p>
<p>With Amazon Transcribe, the results were almost the same from No. 1 to No. 8, so without comparing the qualitative results between No. 1 to No. 8, <code>Best results of Google Cloud Speech API'' and </code>Best of Amazon Transcribe&rsquo;&rsquo; I would like to compare the results.</p>
<h2 id="google-cloud-speech-api-vs-amazon-transcribe">Google Cloud Speech API vs. Amazon Transcribe</h2>
<p>The values of the previously confirmed Google Cloud Speech API (best result No.8) and Amazon Transcribe (best result No.2) confirmed this time are compared. The result on Google is taken from <a href="https://qiita.com/ysdyt/items/cfbfaba5e0bc5dce54ee">Last result</a>.</p>
<h3 id="quantitative-result-comparison">Quantitative result comparison</h3>
<h4 id="transcribed-character-count-comparison">Transcribed character count comparison</h4>
<img width="592" alt="Screenshot 2020-01-10 23.13.45.png" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/100780/b0c0d6d3-08c0-c5e5-de9c-4e4feb1e4a02.png">
It seems that Amazon Transcribe had many simple transcriptions for the 1h sound source.
<h4 id="word-count-comparison">Word count comparison</h4>
<img width="649" alt="Screenshot 2020-01-10 23.13.55.png" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/100780/3d058f99-d99c-3d08-66cf-2531c9ef831c.png">
Perhaps because of the large number of transcriptions, Amazon Transcribe also had a large number of duplicated total words and nouns.
<p>On the other hand, the number of all words and the number of nouns without duplicates were almost the same. As I planned&hellip;</p>
<h3 id="qualitative-result-comparison">Qualitative result comparison</h3>
<p>I will roughly compare what the content of the text was like, but I will compare it in the same way as <a href="https://qiita.com/ysdyt/items/cfbfaba5e0bc5dce54ee">previous</a>.</p>
<h4 id="transcription-result">Transcription result</h4>
<p>I arranged the images on the left and right to make it easier to compare the beginning of the transcription. Google is on the left and Amazon is on the right.
<img width="920" alt="Screenshot 2020-01-10 23.15.54.png" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/100780/6c85c9ee-7bb0-77ab-99d9-5658857ee5e3.png">
It&rsquo;s difficult to judge, but I feel that Google&rsquo;s transcription is still better. Compared to the acorns.
(* Line breaks are included here only in Google results, but both Google and Amazon originally transcribe with line breaks. The accuracy is subtle. going.)</p>
<h4 id="frequent-nouns">Frequent nouns</h4>
<p>Let&rsquo;s compare &ldquo;noun words without duplication&rdquo; and &ldquo;the number of counts&rdquo; on Google and Amazon respectively. Let&rsquo;s try displaying the words that appeared 11 times or more.
<img width="752" alt="Screenshot 2020-01-10 23.16.05.png" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/100780/30d79b4e-fb3f-d1f2-5427-55f77c61e47c.png"></p>
<p>Amazon seems to have more words that can be recognized. However, since most words are duplicated between Google and Amazon, it also shows that the transcription performance of both is not significantly different. According to Amazon&rsquo;s results, our company name &ldquo;Brain Pad&rdquo; has been removed, so it&rsquo;s fine.</p>
<p>If you want to recognize more words, Amazon seems to be better (in this voice data). (Please check if it is a meaningful word)</p>
<h4 id="word-cloud">word cloud</h4>
<p>Noun word cloud in the flow. The visualization above. Google is on the left and Amazon is on the right.<img width="900" alt="Screenshot 2020-01-10 23.16.15.png" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/100780/3096fc1a-7809-2c14-7b1b-76fd62fae948.png"></p>
<h2 id="google-cloud-speech-api-vs-amazon-transcribe-result-summary">Google Cloud Speech API vs. Amazon Transcribe result summary</h2>
<p>As a result of Google Cloud Speech API vs. Amazon Transcribe,</p>
<ul>
<li>Both Google and Amazon can transcribe Japanese characters (* Just using the API with a simple pre-processing of the voice data this time) ** Practical transcription seems impossible **</li>
<li>I was able to transcribe <strong>Comparing the number of words, the result is almost the same</strong></li>
<li>Amazon Transcribe got the same accuracy as Google without pre-processing, so Amazon Transcribe wins for convenience **</li>
<li>When operating the console on the browser and transcribing with the GUI instead of installing the SDK and hitting the API with the CLI (almost all non-engineers should use this method) ** Difficulty of use Needless to say, Amazon Transcribe won**. Rather, the Google API is too difficult for non-engineers. (* By the way, among non-engineers, recently <a href="https://www.cg-method.com/entry/google-document-convert-voice-to-text/">Transcription by voice input of Google Doc</a> is popular. It seems that</li>
<li>** Processing time is a little faster than Amazon transcribe **. Google takes a little over 15 minutes for a 1h file, while Amazon takes about 10 minutes.</li>
</ul>
<p>personally,</p>
<p>As for Japanese transcription, both are far from being practically accurate, ** so the transcription API can be used only for word extraction **. (And even if you can extract only words, it is almost useless&hellip;)</p>
<p>And if it is used only for word extraction, it is a personal conclusion that <strong>Amazon Transcribe is good</strong> in that it can be used without pre-processing, it can be used easily with GUI, and processing time is fast.</p>
<p>Although I have not abandoned &ldquo;the possibility of improving the accuracy of transcribing if you can take clear sound using more recording equipment (increasing the voice quality to input)&rdquo;, but my own recording environment (around 16000 yen) It is difficult for general users to prepare more than the above (using an external microphone as much as possible), so &ldquo;low-priced crisp and high-precision Japanese transcription&rdquo; is not possible with current technology anyway. I think it is. It seems that Japanese transcription cannot be done overnight.</p>
<p>It&rsquo;s kind of awkward, so if anyone knows the tip, &ldquo;If you do this, the transcription will be recognized,&rdquo; I would love to hear your comment!</p>

    </article>
  </div>

  
  
  
  <script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-169005401-1', 'auto');
  ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  

  
<link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.css" />
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#216942",
      "text": "#b2d192"
    },
    "button": {
      "background": "#afed71"
    }
  }
})});
</script>

</body>

</html>
