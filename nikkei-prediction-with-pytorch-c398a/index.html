<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  <meta name="generator" content="Hugo 0.72.0" />

  
  <meta name="description" content="Some description">
  

  
  <link rel="apple-touch-icon" sizes="180x180" href="https://memotut.com/apple-touch-icon.png">

  
  <link rel="icon" type="image/png" sizes="32x32" href="https://memotut.com/favicon-32x32.png">

  
  <link rel="icon" type="image/png" sizes="16x16" href="https://memotut.com/favicon-16x16.png">

  
  <link rel="manifest" href="https://memotut.com/site.webmanifest">

  
  <link rel="mask-icon" href="https://memotut.com/safari-pinned-tab.svg" color="#5bbad5">

  <meta name="msapplication-TileColor" content="#da532c">

  <meta name="theme-color" content="#ffffff">

  
  <link rel="stylesheet" href="https://memotut.com/css/bootstrap.min.css" />

  
  <title>[Python] Nikkei Prediction with Pytorch | Memo Tut</title>
  

  <style>
body {
  min-width: 300px;
}

.custom-navbar {
  margin-bottom: 1em;
  height: 60px;
}

.custom-navbar a {
  display: inline-block; 
  padding: 18px 0;
  margin-right: 1em; 
  font-weight: bold; 
}

.custom-navbar a:hover,
.custom-navbar a:focus {
  text-decoration: none; 
}

@media print {
  .custom-navbar {
    display: none;
  }
}

article {
  padding-bottom: 1em;
}

img {
  max-width: 100%;
}


body {
  background-color: #fff;
}



body {
  color: #212529;
}



a {
  color: #007bff;
}



a:hover,
a:focus {
  color: #0056b3;
}



.custom-navbar {
  background-color: #212529;
}



.custom-navbar a {
  color: rgba(255, 255, 255, 0.75);
}



.custom-navbar a:hover,
.custom-navbar a:focus {
  color: rgba(255, 255, 255, 1);
}



.container {
  max-width: 800px;
}



pre {
  display: block;
  padding: 9.5px;
  word-break: break-all;
  word-wrap: break-word;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre code {
  padding: 0;
  font-size: inherit;
  color: inherit; 
  white-space: pre-wrap;
  background-color: transparent;
  border: none;
  border-radius: 0;
}

code {
  padding: 2px 4px;
  color: inherit; 
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
  font-size: .9em;
}



blockquote,
.blockquote {
  padding: 10px 20px;
  margin: 0 0 20px;
  font-size: 1em;
  border-left: 5px solid #6c757d;
}

</style>
</head>

<body>
  <nav class="custom-navbar">
  <div class="container">
    
    <a href="/">Posts</a>
    
    <a href="/tags/">Tags</a>
    
    <a href="/about/">About</a>
    
    <a href="/index.xml">RSS</a>
    
  </div>
</nav>
  
  <div class="container">
    <article>
      <h1>[Python] Nikkei Prediction with Pytorch</h1>
<p>
  <small class="text-secondary">
  
  
  Jan 30, 2020
  </small>
  

<small><code><a href="https://memotut.com/tags/python">Python</a></code></small>


<small><code><a href="https://memotut.com/tags/python3"> Python3</a></code></small>


<small><code><a href="https://memotut.com/tags/lstm"> LSTM</a></code></small>


<small><code><a href="https://memotut.com/tags/stock-price-forecast"> stock price forecast</a></code></small>

</p>
<pre><code>I am a graduate student studying Pytorch recently.
</code></pre>
<p>I started studying neural networks by dreaming about stock price forecasts and horse racing forecasts.</p>
<p>At last, it is in shape, so I will write it as a memorandum.
I hope it will be helpful for a beginner like me.</p>
<h1 id="references-cited-articles-and-books">References, cited articles and books</h1>
<p><a href="https://qiita.com/KojiOhki/items/89cd7b69a8a6239d67ca">Overview of LSTM network</a>
This is an article about the network structure and mechanism of LSTM.</p>
<p><a href="http://hilinker.hatenablog.com/entry/2018/06/23/204910">I want to start LSTM with pytorch&hellip; don&rsquo;t you want to? </a>
This is mainly about how to implement LSTM.</p>
<p><a href="https://qiita.com/THERE2/items/3c13164c1c82c1dcf4b7">FX prediction: Time series data prediction with LSTM of PyTorch</a>
Since I wrote in detail how to collect data, molding, back testing, and actual learning, it was very helpful.</p>
<p><a href="https://qiita.com/shiroino11111/items/f812938fbbba7123fbcc">67% accuracy deep learning stock price forecast model_1</a>
This is not a Forex, I was forecasting the stock price and it matched the forecast of the next day I wanted to do so I used it as a reference. This is implemented with keras, but I will implement it with pytorch.</p>
<p><a href="https://www.amazon.co.jp/%E3%81%BF%E3%82%93%E3%81%AA%E3%81%AEPython-%E7%AC%AC4%E7%89%88-%E6%9F%B4%E7%94%B0-%E6%B7%B3/dp/479738946X/ref=sr_1_1?__mk_ja_JP=%E3%82%AB%E3%82%BF%E3%82%AB%E3%83%8A&amp;keywords=%E3%81%BF%E3%82%93%E3%81%AA%E3%81%AEpython&amp;qid=1580280858&amp;sr=8-1">Minna no python 4th edition</a>
This book was used to find out the basic usage of python.</p>
<h1 id="data-collection">Data collection</h1>
<p>Data was collected using HYPER SBI which can be downloaded from SBI SECURITIES.
<a href="https://qiita.com/shiroino11111/items/f812938fbbba7123fbcc">67% accuracy deep learning stock price prediction model_1</a> learned the stock price of 20 years of 423 listed companies.
So, first of all, I learned whether the Nikkei average alone would increase next day. The data is for 20 years.</p>
<p>#Overview
I collected data for 20 years and trained them separately for train and test.
The accuracy for ~~test was 62.5%. However, there are problems such as loss not converging, and the value of f1 calculated from the mixing matrix becomes 0 during learning. ~~</p>
<p>Eventually I settled on Accuracy 60.5%.</p>
<p>#Constant definition</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python:main.py" data-lang="python:main.py"><span style="color:#f92672">import</span> glob
<span style="color:#f92672">import</span> pandas <span style="color:#f92672">as</span> pd
<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">import</span> torch
<span style="color:#f92672">import</span> torch.nn <span style="color:#f92672">as</span> nn
<span style="color:#f92672">from</span> sklearn.metrics <span style="color:#f92672">import</span> accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
<span style="color:#f92672">import</span> torch.nn.functional <span style="color:#f92672">as</span> F
<span style="color:#f92672">import</span> torch.optim <span style="color:#f92672">as</span> optim

device <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>device(<span style="color:#e6db74">&#34;cuda&#34;</span> <span style="color:#66d9ef">if</span> torch<span style="color:#f92672">.</span>cuda<span style="color:#f92672">.</span>is_available() <span style="color:#66d9ef">else</span> <span style="color:#e6db74">&#34;cpu&#34;</span>)
torch<span style="color:#f92672">.</span>manual_seed(<span style="color:#ae81ff">1</span>)

future_num <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span> <span style="color:#75715e"># how many days to predict</span>
feature_num <span style="color:#f92672">=</span> <span style="color:#ae81ff">7</span> <span style="color:#75715e"># 7 items:&#39;Open price&#39;,&#39;High price&#39;,&#39;Low price&#39;,&#39;Close price&#39;,&#39;5 day average&#39;,&#39;25 day average&#39;,&#39;75 day average&#39;</span>
batch_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">128</span>

time_steps <span style="color:#f92672">=</span> <span style="color:#ae81ff">30</span> <span style="color:#75715e">#lstm timesteps</span>
moving_average_num <span style="color:#f92672">=</span> <span style="color:#ae81ff">30</span> <span style="color:#75715e"># number of days to take moving average</span>
n_epocs <span style="color:#f92672">=</span> <span style="color:#ae81ff">50</span>

lstm_hidden_dim <span style="color:#f92672">=</span> <span style="color:#ae81ff">16</span>
target_dim <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
</code></pre></div><p>#Read data
The way to collect the data was on <a href="https://faq.sbisec.co.jp/faq_detail.html?id=16128">SBI Official Website: Frequently Asked Questions Q&amp;A</a>. Here, I selected the index and downloaded the Nikkei average data for 20 years.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python:main.py" data-lang="python:main.py">path <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;./data/nikkei_heikin.csv&#34;</span>

model_name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;./models/nikkei.mdl&#34;</span>

<span style="color:#75715e">#data load</span>
flist <span style="color:#f92672">=</span> glob<span style="color:#f92672">.</span>glob(path)
<span style="color:#66d9ef">for</span> file <span style="color:#f92672">in</span> flist:
    df <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>read_csv(file, header<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>, encoding<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;cp932&#39;</span>)
    dt <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>read_csv(file, header<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>, encoding<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;cp932&#39;</span>)


Index that divides the data into train <span style="color:#f92672">and</span> test
val_idx_from <span style="color:#f92672">=</span> <span style="color:#ae81ff">3500</span>
test_idx_from <span style="color:#f92672">=</span> <span style="color:#ae81ff">4000</span>

future_price <span style="color:#f92672">=</span> df<span style="color:#f92672">.</span>iloc[future_num:][<span style="color:#e6db74">&#39;close price&#39;</span>]<span style="color:#f92672">.</span>values
curr_price <span style="color:#f92672">=</span> df<span style="color:#f92672">.</span>iloc[:<span style="color:#f92672">-</span>future_num][<span style="color:#e6db74">&#39;close price&#39;</span>]<span style="color:#f92672">.</span>values

<span style="color:#75715e">#future_num Treat the price compared with the day after as the correct label</span>
y_data_tmp <span style="color:#f92672">=</span> future_price <span style="color:#f92672">/</span> curr_price
<span style="color:#75715e"># Prepare list for correct label</span>
y_data <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>zeros_like(y_data_tmp)

<span style="color:#75715e"># Predict future_num Correct if it is more than the previous day</span>

<span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(len(y_data_tmp)):
    <span style="color:#66d9ef">if</span> y_data_tmp[i]<span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">1.0</span>:
        y_data[i] <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>

<span style="color:#75715e"># When you normalize the price, there is blank data for moving_average_num, so delete that part.</span>
y_data <span style="color:#f92672">=</span> y_data[moving_average_num:]

<span style="color:#75715e">#Price normalization</span>
<span style="color:#75715e">#Get column name</span>
cols <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;Open price&#39;</span>,<span style="color:#e6db74">&#39;High price&#39;</span>,<span style="color:#e6db74">&#39;Low price&#39;</span>,<span style="color:#e6db74">&#39;Close price&#39;</span>,<span style="color:#e6db74">&#39;5 day average&#39;</span>,<span style="color:#e6db74">&#39;25 day average&#39;</span>,<span style="color:#e6db74">&#39;75 day average&#39;</span>]
<span style="color:#75715e">#Pulled out because there was a defect in the volume data</span>

<span style="color:#66d9ef">for</span> col <span style="color:#f92672">in</span> cols:
    dt[col] <span style="color:#f92672">=</span> df[col]<span style="color:#f92672">.</span>rolling(window<span style="color:#f92672">=</span><span style="color:#ae81ff">25</span>, min_periods<span style="color:#f92672">=</span><span style="color:#ae81ff">25</span>)<span style="color:#f92672">.</span>mean()
    df[col] <span style="color:#f92672">=</span> df[col] <span style="color:#f92672">/</span> dt[col]<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>
    

X_data <span style="color:#f92672">=</span> df<span style="color:#f92672">.</span>iloc[moving_average_num:<span style="color:#f92672">-</span>future_num][cols]<span style="color:#f92672">.</span>values

<span style="color:#75715e"># Split data, convert to Torch Tensor</span>
<span style="color:#75715e">#Learning data</span>
X_train <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>tensor(X_data[:val_idx_from], dtype<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>float, device<span style="color:#f92672">=</span>device)
y_train <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>tensor(y_data[:val_idx_from], dtype<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>float, device<span style="color:#f92672">=</span>device)
<span style="color:#75715e">#Evaluation data</span>
X_val <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>tensor(X_data[val_idx_from:test_idx_from], dtype<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>float, device<span style="color:#f92672">=</span>device)
y_val <span style="color:#f92672">=</span> y_data[val_idx_from:test_idx_from]
<span style="color:#75715e">#Test data</span>
X_test <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>tensor(X_data[test_idx_from:], dtype<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>float, device<span style="color:#f92672">=</span>device)
y_test <span style="color:#f92672">=</span> y_data[test_idx_from:]
</code></pre></div><p>The original number of data was about 4,500. The training data number is 3500, validation is 500 and the rest is test data.</p>
<h1 id="model-definition">Model definition</h1>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python:main.py" data-lang="python:main.py"><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">LSTMClassifier</span>(nn<span style="color:#f92672">.</span>Module):
    <span style="color:#66d9ef">def</span> __init__(self, lstm_input_dim, lstm_hidden_dim, target_dim):
        super(LSTMClassifier, self)<span style="color:#f92672">.</span>__init__()
        self<span style="color:#f92672">.</span>input_dim <span style="color:#f92672">=</span> lstm_input_dim
        self<span style="color:#f92672">.</span>hidden_dim <span style="color:#f92672">=</span> lstm_hidden_dim
        self<span style="color:#f92672">.</span>lstm <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>LSTM(input_size<span style="color:#f92672">=</span>lstm_input_dim,
                            hidden_size<span style="color:#f92672">=</span>lstm_hidden_dim,
                            num_layers<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>, <span style="color:#75715e">#default</span>
                            <span style="color:#75715e">#dropout=0.2,</span>
                            batch_first<span style="color:#f92672">=</span>True
                            )
        self<span style="color:#f92672">.</span>dense <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Linear(lstm_hidden_dim, target_dim)

    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, X_input):
        _, lstm_out <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>lstm(X_input)
        Use only the final output of <span style="color:#75715e">#LSTM.</span>
        linear_out <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>dense(lstm_out[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>view(X_input<span style="color:#f92672">.</span>size(<span style="color:#ae81ff">0</span>), <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>))
        <span style="color:#66d9ef">return</span> torch<span style="color:#f92672">.</span>sigmoid(linear_out)
</code></pre></div><p>The model definition. I pulled LSTM from the Pytorch library.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python:main.py" data-lang="python:main.py"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">prepare_data</span>(batch_idx, time_steps, X_data, feature_num, device):
    feats <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>zeros((len(batch_idx), time_steps, feature_num), dtype<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>float, device<span style="color:#f92672">=</span>device)
    <span style="color:#66d9ef">for</span> b_i, b_idx <span style="color:#f92672">in</span> enumerate(batch_idx):
        <span style="color:#75715e"># Store the past 30 days as time step data.</span>
        b_slc <span style="color:#f92672">=</span> slice(b_idx <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span><span style="color:#f92672">-</span>time_steps ,b_idx <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>)
        feats[b_i, :, :] <span style="color:#f92672">=</span> X_data[b_slc, :]

    <span style="color:#66d9ef">return</span> feats
</code></pre></div><p>The function prepare_data plays a role in collecting the data input to LSTM for 30 days.</p>
<h1 id="learning-and-evaluation">Learning and evaluation</h1>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python:main.py" data-lang="python:main.py"><span style="color:#75715e">#Learningmodel = LSTMClassifier(feature_num, lstm_hidden_dim, target_dim).to(device)</span>
loss_function <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>BCELoss()
optimizer<span style="color:#f92672">=</span> optim<span style="color:#f92672">.</span>Adam(model<span style="color:#f92672">.</span>parameters(), lr<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-4</span>)


train_size <span style="color:#f92672">=</span> X_train<span style="color:#f92672">.</span>size(<span style="color:#ae81ff">0</span>)
best_acc_score <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>

<span style="color:#66d9ef">for</span> epoch <span style="color:#f92672">in</span> range(n_epocs):
    <span style="color:#75715e"># Replace the index of train data at random. Do not use the first time_steps.</span>
    perm_idx <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>permutation(np<span style="color:#f92672">.</span>arange(time_steps, train_size))
    <span style="color:#66d9ef">for</span> t_i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">0</span>, len(perm_idx), batch_size):
        batch_idx <span style="color:#f92672">=</span> perm_idx[t_i:(t_i <span style="color:#f92672">+</span> batch_size)]
        <span style="color:#75715e">#Preparing time series data for LSTM input</span>
        feats <span style="color:#f92672">=</span> prepare_data(batch_idx, time_steps, X_train, feature_num, device)
        y_target <span style="color:#f92672">=</span> y_train[batch_idx]
        model<span style="color:#f92672">.</span>zero_grad()
        train_scores <span style="color:#f92672">=</span> model(feats) <span style="color:#75715e"># batch size x time steps x feature_num</span>
        loss <span style="color:#f92672">=</span> loss_function(train_scores, y_target<span style="color:#f92672">.</span>view(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
        loss<span style="color:#f92672">.</span>backward()
        optimizer<span style="color:#f92672">.</span>step()

    <span style="color:#75715e"># validation data evaluation</span>
    <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;EPOCH:&#39;</span>, str(epoch),<span style="color:#e6db74">&#39;loss :&#39;</span>, loss<span style="color:#f92672">.</span>item())
    <span style="color:#66d9ef">with</span> torch<span style="color:#f92672">.</span>no_grad():
        feats_val <span style="color:#f92672">=</span> prepare_data(np<span style="color:#f92672">.</span>arange(time_steps, X_val<span style="color:#f92672">.</span>size(<span style="color:#ae81ff">0</span>)), time_steps, X_val, feature_num, device)
        val_scores <span style="color:#f92672">=</span> model(feats_val)
        tmp_scores <span style="color:#f92672">=</span> val_scores<span style="color:#f92672">.</span>view(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>)<span style="color:#f92672">.</span>to(<span style="color:#e6db74">&#39;cpu&#39;</span>)<span style="color:#f92672">.</span>numpy()
        bi_scores <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>round(tmp_scores)
        acc_score <span style="color:#f92672">=</span> accuracy_score(y_val[time_steps:], bi_scores)
        roc_score <span style="color:#f92672">=</span> roc_auc_score(y_val[time_steps:], tmp_scores)
        f1_scores <span style="color:#f92672">=</span> f1_score(y_val[time_steps:], bi_scores)
        <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;Val ACC Score :&#39;</span>, acc_score,<span style="color:#e6db74">&#39;ROC AUC Score :&#39;</span>, roc_score,<span style="color:#e6db74">&#39;f1 Score :&#39;</span>, f1_scores)

    Save model <span style="color:#66d9ef">if</span> <span style="color:#75715e"># validation is good</span>
    <span style="color:#66d9ef">if</span> acc_score<span style="color:#f92672">&gt;</span> best_acc_score:
        best_acc_score <span style="color:#f92672">=</span> acc_score
        torch<span style="color:#f92672">.</span>save(model<span style="color:#f92672">.</span>state_dict(),model_name)
        <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;best score updated, Pytorch model was saved!!&#39;</span>,)

Predict <span style="color:#66d9ef">with</span> the <span style="color:#75715e"># best model.</span>
model<span style="color:#f92672">.</span>load_state_dict(torch<span style="color:#f92672">.</span>load(model_name))

<span style="color:#66d9ef">with</span> torch<span style="color:#f92672">.</span>no_grad():
    feats_test <span style="color:#f92672">=</span> prepare_data(np<span style="color:#f92672">.</span>arange(time_steps, X_test<span style="color:#f92672">.</span>size(<span style="color:#ae81ff">0</span>)), time_steps, X_test, feature_num, device)
    val_scores <span style="color:#f92672">=</span> model(feats_test)
    tmp_scores <span style="color:#f92672">=</span> val_scores<span style="color:#f92672">.</span>view(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>)<span style="color:#f92672">.</span>to(<span style="color:#e6db74">&#39;cpu&#39;</span>)<span style="color:#f92672">.</span>numpy()
    bi_scores <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>round(tmp_scores)
    acc_score <span style="color:#f92672">=</span> accuracy_score(y_test[time_steps:], bi_scores)
    roc_score <span style="color:#f92672">=</span> roc_auc_score(y_test[time_steps:], tmp_scores)
    f1_scores <span style="color:#f92672">=</span> f1_score(y_test[time_steps:], bi_scores)
    <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;Test ACC Score :&#39;</span>, acc_score,<span style="color:#e6db74">&#39;ROC AUC Score :&#39;</span>, roc_score,<span style="color:#e6db74">&#39;f1 Score :&#39;</span>, f1_scores)
</code></pre></div><p>In learning, Accuracy, ROC Score, f1 Score are output. Weights are saved when the highest accuracy is updated.</p>
<p>#result</p>
<pre><code>EPOCH: 0 loss: 0.7389694452285767
Val ACC Score: 0.4851063829787234 ROC AUC Score: 0.5448111497752646 f1 Score: 0.653295128939828
best score updated, Pytorch model was saved!!
EPOCH: 1 loss: 0.6844338178634644
Val ACC Score: 0.4851063829787234 ROC AUC Score: 0.5550601710888793 f1 Score: 0.653295128939828
EPOCH: 2 loss: 0.7206816673278809
Val ACC Score: 0.4851063829787234 ROC AUC Score: 0.5678012179208352 f1 Score: 0.653295128939828
EPOCH: 3 loss: 0.7066923975944519
Val ACC Score: 0.4851063829787234 ROC AUC Score: 0.5815934464259822 f1 Score: 0.653295128939828
EPOCH: 4 loss: 0.7148252129554749
Val ACC Score: 0.4851063829787234 ROC AUC Score: 0.6025717703349283 f1 Score: 0.653295128939828
EPOCH: 5 loss: 0.6946689486503601
Val ACC Score: 0.4851063829787234 ROC AUC Score: 0.6224264172828766 f1 Score: 0.653295128939828
EPOCH: 6 loss: 0.7018400430679321
Val ACC Score: 0.4851063829787234 ROC AUC Score: 0.639100333478324 f1 Score: 0.653295128939828
EPOCH: 7 loss: 0.7006129026412964
.
.
.
.
EPOCH: 43 loss: 0.7038401961326599
Val ACC Score: 0.5148936170212766 ROC AUC Score: 0.6018921270117442 f1 Score: 0.0
EPOCH: 44 loss: 0.6951379179954529
Val ACC Score: 0.5148936170212766 ROC AUC Score: 0.6018921270117443 f1 Score: 0.0
EPOCH: 45 loss: 0.6788191795349121
Val ACC Score: 0.5148936170212766 ROC AUC Score: 0.6018921270117443 f1 Score: 0.0
EPOCH: 46 loss: 0.6547065377235413
Val ACC Score: 0.5148936170212766 ROC AUC Score: 0.6018558793678411 f1 Score: 0.0
EPOCH: 47 loss: 0.6936472654342651
Val ACC Score: 0.5148936170212766 ROC AUC Score: 0.6016746411483254 f1 Score: 0.0
EPOCH: 48 loss: 0.719009280204773
Val ACC Score: 0.5148936170212766 ROC AUC Score: 0.6016202696824707 f1 Score: 0.0
EPOCH: 49 loss: 0.6854437589645386
Val ACC Score: 0.5148936170212766 ROC AUC Score: 0.6014934029288096 f1 Score: 0.0
Test ACC Score: 0.6252100840336134 ROC AUC Score: 0.6860275646683414 f1 Score: 0.6915629322268327
</code></pre><h1 id="addition">Addition</h1>
<p>When I change the number of epochs from 50 to 500, the loss also becomes a decent number, so I will list it.</p>
<pre><code>EPOCH: 0 loss: 0.7389694452285767
Val ACC Score: 0.4851063829787234 ROC AUC Score: 0.5448111497752646 f1 Score: 0.653295128939828
best score updated, Pytorch model was saved!!
EPOCH: 1 loss: 0.6844338178634644
Val ACC Score: 0.4851063829787234 ROC AUC Score: 0.5550601710888793 f1 Score: 0.653295128939828
EPOCH: 2 loss: 0.7206816673278809
Val ACC Score: 0.4851063829787234 ROC AUC Score: 0.5678012179208352 f1 Score: 0.653295128939828
EPOCH: 3 loss: 0.7066923975944519Val ACC Score : 0.4851063829787234  ROC AUC Score : 0.5815934464259822 f1 Score : 0.653295128939828
EPOCH:  4  loss : 0.7148252129554749
Val ACC Score : 0.4851063829787234  ROC AUC Score : 0.6025717703349283 f1 Score : 0.653295128939828
EPOCH:  5  loss : 0.6946689486503601
Val ACC Score : 0.4851063829787234  ROC AUC Score : 0.6224264172828766 f1 Score : 0.653295128939828
EPOCH:  6  loss : 0.7018400430679321
Val ACC Score : 0.4851063829787234  ROC AUC Score : 0.639100333478324 f1 Score : 0.653295128939828
EPOCH:  7  loss : 0.7006129026412964
.
.
.
.
EPOCH:  493  loss : 0.694491982460022
Val ACC Score : 0.6042553191489362  ROC AUC Score : 0.638157894736842 f1 Score : 0.5079365079365079
EPOCH:  494  loss : 0.6935185194015503
Val ACC Score : 0.6063829787234043  ROC AUC Score : 0.638157894736842 f1 Score : 0.5144356955380578
EPOCH:  495  loss : 0.6262539029121399
Val ACC Score : 0.5957446808510638  ROC AUC Score : 0.6370704654197477 f1 Score : 0.48087431693989063
EPOCH:  496  loss : 0.5570085644721985
Val ACC Score : 0.6085106382978723  ROC AUC Score : 0.6387559808612441 f1 Score : 0.5422885572139303
EPOCH:  497  loss : 0.6102970838546753
Val ACC Score : 0.6  ROC AUC Score : 0.6374691895026823 f1 Score : 0.4973262032085562
EPOCH:  498  loss : 0.6443783640861511
Val ACC Score : 0.6042553191489362  ROC AUC Score : 0.6395534290271132 f1 Score : 0.5633802816901409
EPOCH:  499  loss : 0.663628876209259
Val ACC Score : 0.6085106382978723  ROC AUC Score : 0.6380310279831811 f1 Score : 0.518324607329843
Test ACC Score : 0.6050420168067226  ROC AUC Score : 0.644737139882771 f1 Score : 0.660894660894661
</code></pre><p>#結果の考察
<del>学習途中を見ればAccuracyが更新されていない時が多々あります。そしてf1 Scoreが0になっています。
Lossが収束していないなど問題が多いように思えます。しかしながらtestデータの結果を見ればAccuracy62.5%を記録しています。</del></p>
<p>エポック数を増加させることによってROC Scoreやf1 Scoreがまともな数値になっています。ただAccuracy自体は60.5％になってしまいました。</p>
<p>データ数や特徴量を増やしたり、自分でLSTMを実装したりすることで精度を上げていきたいと思います。</p>
<p>次回は<a href="https://qiita.com/shiroino11111/items/f812938fbbba7123fbcc">精度６７％のディープラーニング株価予測モデル_1</a>で行われていたように3%増加する銘柄を予想していきます。</p>

    </article>
  </div>

  
  
  
  <script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-169005401-1', 'auto');
  ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  

  
<link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.css" />
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#216942",
      "text": "#b2d192"
    },
    "button": {
      "background": "#afed71"
    }
  }
})});
</script>

</body>

</html>
