<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Scrapy on Memo Tut</title>
    <link>https://memotut.com/tags/scrapy/</link>
    <description>Recent content in Scrapy on Memo Tut</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 21 Jan 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://memotut.com/tags/scrapy/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>[Starter Kit No.1] Build an automatic data collection bot system with Scrapy&amp;MariaDB&amp;Django&amp;Docker</title>
      <link>https://memotut.com/starter-kit-no.1-build-an-automatic-data-collection-bot-system-with-scrapymariadbdjangodocker-dfde3/</link>
      <pubDate>Tue, 21 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/starter-kit-no.1-build-an-automatic-data-collection-bot-system-with-scrapymariadbdjangodocker-dfde3/</guid>
      <description>![screencapture-192-168-99-102-admin-nutrition-item-2019-03-04-15_04_19-1024x686.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/514619/8e65d631-de2a-b0f4-18a4-b427fb78e439.png)  #Background
You can easily create a Web service with your needs by automatically synchronizing the database of Web services in the world and adding added value that the original family does not have.
For example, scrape the data of the EC site and keep it as a database yourself, provide a search method that does not exist in the original home, attach a link, and have a lightweight business model like earning by affiliate at the level of individual business Is possible.</description>
    </item>
    
    <item>
      <title>Regular serverless scraping with AWS lambda&#43;scrapy Part 1</title>
      <link>https://memotut.com/regular-serverless-scraping-with-aws-lambda-scrapy-part-1-a0102/</link>
      <pubDate>Sun, 01 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/regular-serverless-scraping-with-aws-lambda-scrapy-part-1-a0102/</guid>
      <description>First post!  Actually, I wanted to include serverless in one article, but I couldn&amp;rsquo;t make it in time. So this time it will be scraping.
Thing you want to do I want to automatically scrape web pages where information is updated regularly!
Target Obtain Yahoo! Weather (Tokyo) data every 6 hours.
Method Is it possible to go around Python + Scrapy + AWSlambda + CroudWatchEvents&amp;hellip;?
Try it for now First from scraping Follow the steps below to create crawling and scraping parts.</description>
    </item>
    
  </channel>
</rss>