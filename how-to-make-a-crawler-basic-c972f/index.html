<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  <meta name="generator" content="Hugo 0.72.0" />

  
  <meta name="description" content="Some description">
  

  
  <link rel="apple-touch-icon" sizes="180x180" href="https://memotut.com/apple-touch-icon.png">

  
  <link rel="icon" type="image/png" sizes="32x32" href="https://memotut.com/favicon-32x32.png">

  
  <link rel="icon" type="image/png" sizes="16x16" href="https://memotut.com/favicon-16x16.png">

  
  <link rel="manifest" href="https://memotut.com/site.webmanifest">

  
  <link rel="mask-icon" href="https://memotut.com/safari-pinned-tab.svg" color="#5bbad5">

  <meta name="msapplication-TileColor" content="#da532c">

  <meta name="theme-color" content="#ffffff">

  
  <link rel="stylesheet" href="https://memotut.com/css/bootstrap.min.css" />

  
  <title>How to make a crawler-Basic | Memo Tut</title>
  

  <style>
body {
  min-width: 300px;
}

.custom-navbar {
  margin-bottom: 1em;
  height: 60px;
}

.custom-navbar a {
  display: inline-block; 
  padding: 18px 0;
  margin-right: 1em; 
  font-weight: bold; 
}

.custom-navbar a:hover,
.custom-navbar a:focus {
  text-decoration: none; 
}

@media print {
  .custom-navbar {
    display: none;
  }
}

article {
  padding-bottom: 1em;
}

img {
  max-width: 100%;
}


body {
  background-color: #fff;
}



body {
  color: #212529;
}



a {
  color: #007bff;
}



a:hover,
a:focus {
  color: #0056b3;
}



.custom-navbar {
  background-color: #212529;
}



.custom-navbar a {
  color: rgba(255, 255, 255, 0.75);
}



.custom-navbar a:hover,
.custom-navbar a:focus {
  color: rgba(255, 255, 255, 1);
}



.container {
  max-width: 800px;
}



pre {
  display: block;
  padding: 9.5px;
  word-break: break-all;
  word-wrap: break-word;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre code {
  padding: 0;
  font-size: inherit;
  color: inherit; 
  white-space: pre-wrap;
  background-color: transparent;
  border: none;
  border-radius: 0;
}

code {
  padding: 2px 4px;
  color: inherit; 
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
  font-size: .9em;
}



blockquote,
.blockquote {
  padding: 10px 20px;
  margin: 0 0 20px;
  font-size: 1em;
  border-left: 5px solid #6c757d;
}

</style>
</head>

<body>
  <nav class="custom-navbar">
  <div class="container">
    
    <a href="/">Posts</a>
    
    <a href="/tags/">Tags</a>
    
    <a href="/about/">About</a>
    
    <a href="/index.xml">RSS</a>
    
  </div>
</nav>
  
  <div class="container">
    <article>
      <h1>How to make a crawler-Basic</h1>
<p>
  <small class="text-secondary">
  
  
  Mar 10, 2020
  </small>
  

<small><code><a href="https://memotut.com/tags/python">Python</a></code></small>


<small><code><a href="https://memotut.com/tags/beautifulsoup">BeautifulSoup</a></code></small>


<small><code><a href="https://memotut.com/tags/crawler">crawler</a></code></small>


<small><code><a href="https://memotut.com/tags/crawler">crawler</a></code></small>


<small><code><a href="https://memotut.com/tags/lapras-output-relay">LAPRAS output relay</a></code></small>

</p>
<pre><code>This is the first day of LAPRAS Output Relay!
</code></pre>
<p>Hello! This is <a href="https://lapras.com/public/RPA67MF">@Chanmoro</a>, a LAPRAS crawler engineer!
This time, LAPRAS members will output articles daily by the end of March, entitled <a href="https://daily.lapras.blog/">LAPRAS Output Relay</a>!
Study sessions and conferences have been canceled due to the recent corona shock, but I hope that this LAPRAS output relay will be useful for engineers&rsquo; motivation to input and output as much as possible.</p>
<h1 id="content-of-this-article">Content of this article</h1>
<p>By the way, I usually work as a crawler developer, but I would like to write about the flow of development when developing a new crawler this time.</p>
<p>Here, as a sample, the information of articles published in <a href="https://note.lapras.com/">LAPRAS NOTE</a>, the company&rsquo;s own medium operated by LAPRAS, is acquired and output to a JSON format file. I would like to introduce a crawler implementation example.
*LAPRAS NOTE is a site that sends news and interview articles related to LAPRAS to engineers.</p>
<p>#Crawler development procedure
When implementing a crawler, roughly follow the steps below to investigate, design, and implement.</p>
<ol>
<li>Examine the link structure of the site and the leads on each page</li>
<li>Examine the HTML structure of the crawling page</li>
<li>Implement the crawler</li>
</ol>
<p>I will explain each in detail.</p>
<h1 id="1-investigate-site-link-structure-and-leads-on-each-page">1. Investigate site link structure and leads on each page</h1>
<p>A quick look at the LAPRAS NOTE page shows that the list of articles is displayed on the top page, and the links to the articles in the list lead to the page of each article.</p>
<p>You can see that it is roughly composed of two types of pages.</p>
<ul>
<li>Article list page</li>
<li>Article details page</li>
</ul>
<p>Let&rsquo;s take a closer look at creating these pages.</p>
<h2 id="check-the-article-list-page">Check the article list page</h2>
<p>On the article list page, you can see that the article title, category, publication date, digest information of the text, and links to the detail pages of each article are posted in this way.
<img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/43699/a8c3edf4-1d56-9e5d-215f-cda2af4d01db.png" alt="image.png"></p>
<p>You can also see that the paging link to the next page is displayed at the bottom of the page.
<img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/43699/bc287ff4-3e18-39e7-af89-33034d36a0a2.png" alt="image.png"></p>
<p>If you go to page 2, which is the last page at the moment, you can see that there is no link to the next page here.
<img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/43699/cf01aeea-5469-4250-aca9-8935de9a3cd9.png" alt="image.png"></p>
<p>So, if there is a link to the next page, move to the next page, and if there is no link, it may be judged that it is the final page.</p>
<h2 id="check-article-details-page">Check article details page</h2>
<p>Next, let&rsquo;s look at the contents of the article detail page.
From this page, you can see that you can get the article title, publication date, category, and article body.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/43699/b437d077-1ad9-b12d-d3b1-f3276c1e7491.png" alt="image.png"></p>
<p>For the purpose of fetching all articles, moving from the article detail page to other pages does not seem to be particularly important.</p>
<h2 id="put-together-the-structure-of-the-data-to-be-extracted">Put together the structure of the data to be extracted</h2>
<p>From the survey on the site, I found that these data could be extracted.</p>
<ul>
<li>Article
-Title
<ul>
<li>release date
-Category</li>
<li>Article Text</li>
</ul>
</li>
</ul>
<p>Also, I found that to extract the above data for all articles in LAPRAS NOTE, follow the site with the following flow.</p>
<ol>
<li>Access the list page of published articles and get the URL to the article details
1. If there is a link to the next page, move to the next page and get the URL to the article details as in (1).</li>
<li>Access the article details page to get article information</li>
</ol>
<h1 id="2-examine-the-html-structure-of-the-crawling-page">2. Examine the HTML structure of the crawling page</h1>
<p>Next, let&rsquo;s investigate how to extract the target data by looking at the HTML structure of the crawled page.
Here, we will use the developer tools of the web browser.</p>
<h2 id="list-page-of-published-articles">List page of published articles</h2>
<p>I want to extract the following from the article list page.</p>
<ul>
<li>Article detail page link URL</li>
<li>Link URL to the next page</li>
</ul>
<h3 id="get-the-link-url-of-the-article-detail-page">Get the link URL of the article detail page</h3>
<p>First, find the element that corresponds to one article in order to find the link to the article detail page.</p>
<p>Looking at the HTML structure of the page, we can see that the <code>div</code> element with the <code>post-item</code> class set corresponds to the scope of an article.
Also, if you look at the elements in the corresponding <code>div.post-item</code>, you can see that the URL of the article detail page is set in the <code>a</code> tag immediately below the <code>h2</code> tag.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/43699/9ebeb4b1-597c-64e0-5681-d36aebe49f00.png" alt="image.png"></p>
<p>The CSS path for specifying the a tag you want to get is <code>div.post-item h2 &gt;a</code>.</p>
<p>The current expectation is that you should be able to get <strong>10 elements that match this CSS path on the first page of the article list</strong>, but I would like to check if a URL that is not related to anything else is obtained.
For example, you can run the following JavaScript code from the browser console to see how many matches the CSS selector has.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-javascript" data-lang="javascript">document.<span style="color:#a6e22e">querySelectorAll</span>(<span style="color:#e6db74">&#34;#main div.post-item h2 &gt;a&#34;</span>).<span style="color:#a6e22e">length</span>
</code></pre></div><p>Actually, if you execute the following from the console of the browser with the first page of the article list page displayed, you can get the result of <code>10</code>, so I confirmed that the CSS path seems to be okay.
<img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/43699/426e625b-99bc-7ffd-e4b1-264fd2409c91.png" alt="image.png"></p>
<h3 id="get-the-link-url-to-the-next-page">Get the link URL to the next page</h3>
<p>Next, find the link URL to the next page of the article list page.</p>
<p>If you look at the element of <code>nav.navagation.pagination</code>, you can see that this is the area displaying links to each page and links to the next page.
You can see that the link URL to the next page is set in the <code>a</code> tag which has the class of <code>next</code> and <code>page-numbers</code> in this element.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/43699/ac59ab73-6c53-1b2b-19a1-bba9d450e264.png" alt="image.png"></p>
<p>The CSS path to get this is <code>nav.navigation.pagination a.next.page-numbers</code>.
Again, I will check the number that can actually be obtained from the browser console.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-javascript" data-lang="javascript">document.<span style="color:#a6e22e">querySelectorAll</span>(<span style="color:#e6db74">&#34;nav.navigation.pagination a.next.page-numbers&#34;</span>).<span style="color:#a6e22e">length</span>
</code></pre></div><p>When you execute it, the result is <code>1</code>, so it seems that you can get the target link URL.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/43699/ec4c0cef-3057-2ebd-9ed7-deec00d2f6d2.png" alt="image.png"></p>
<p>Also, you can see that the element of the link to the next page is not displayed on the second page which is the final page.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/43699/1f2d5425-98ad-b588-c1d4-96e43cd43a6b.png" alt="image.png"></p>
<p>Just in case I searched the element of the link to the next page from the console, I got the result of <code>0</code>.
<img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/43699/4416285c-c8e8-5ddc-e7da-36ac7a3680e1.png" alt="image.png"></p>
<h2 id="article-details-page">Article details page</h2>
<p>I want to extract the following from the article detail page.</p>
<ul>
<li>Title</li>
<li>release date</li>
<li>Category</li>
<li>Article Text</li>
</ul>
<p>As before, look at the HTML structure and look at the CSS path to the desired element.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/43699/b437d077-1ad9-b12d-d3b1-f3276c1e7491.png" alt="image.png"></p>
<p>The steps are the same as above, so I will omit them, but I found that the data should be extracted from the following elements.</p>
<ul>
<li>Title
-<code>h1</code></li>
<li>release date
-<code>article header div.entry-meta</code></li>
<li>Category
-<code>article header div.entry-meta a</code></li>
<li>Article Text
-<code>article div.entry-content</code></li>
</ul>
<h1 id="3-implement-the-crawler">3. Implement the crawler</h1>
<p>Since the contents of the investigation so far reveal almost the logic for crawling, I will implement it in code.
In most cases, it doesn&rsquo;t matter what language you implement, but I&rsquo;d like to write an example implementation in Python.</p>
<h2 id="organize-things-to-do">Organize things to do</h2>
<p>First of all, I will enumerate what I do.</p>
<pre><code># TODO: Access https://note.lapras.com/# TODO: Get URL of article details from response HTML
    # TODO: Get the link on the next page if there is one

# TODO: Access article details page

# TODO: Get article information from response HTML
    # TODO: URL
    # TODO: Title
    # TODO: Release date
    # TODO: Category
    # TODO: Article text

# Save the retrieved data in a file in JSON format
</code></pre><h2 id="notes-on-crawler-mounting">Notes on crawler mounting</h2>
<p>As a precaution at the time of implementation, adjust the interval for accessing by inserting sleep as appropriate so that the crawl destination service is not overloaded.
In most cases, it is a good idea to keep at most 1 request per second as a guide, but if you crawl the service down, it will be a problem, so it will be a problem. Always check the response for errors.</p>
<h2 id="solid-implementation-in-python">Solid implementation in Python</h2>
<p>For Python, we often write crawler by combining requests and Beautiful Soup.
For how to use the library, please refer to <a href="https://qiita.com/Chanmoro/items/db51658b073acddea4ac">Beautiful Soup in 10 minutes</a>.</p>
<p>There are frameworks that implement crawlers such as <a href="https://qiita.com/Chanmoro/items/f4df85eb73b18d902739">Scrapy</a>, but in order to understand the whole picture of crawlers, first without using the framework. We recommend that you implement it.</p>
<p>Once you think about the process you want to write in solid code without thinking deeply about the design, it will look like this.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> json
<span style="color:#f92672">import</span> time

<span style="color:#f92672">import</span> requests
<span style="color:#f92672">from</span> bs4 <span style="color:#f92672">import</span> BeautifulSoup


<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">parse_article_list_page</span>(html):
    <span style="color:#e6db74">&#34;&#34;&#34;
</span><span style="color:#e6db74">    Parsing the article list page and extracting data
</span><span style="color:#e6db74">    :param html:
</span><span style="color:#e6db74">    :return:
</span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
    soup <span style="color:#f92672">=</span> BeautifulSoup(html,<span style="color:#e6db74">&#39;html.parser&#39;</span>)
    next_page_link <span style="color:#f92672">=</span> soup<span style="color:#f92672">.</span>select_one(<span style="color:#e6db74">&#34;nav.navigation.pagination a.next.page-numbers&#34;</span>)

    <span style="color:#66d9ef">return</span> {
        <span style="color:#e6db74">&#34;article_url_list&#34;</span>: [a[<span style="color:#e6db74">&#34;href&#34;</span>] <span style="color:#66d9ef">for</span> a <span style="color:#f92672">in</span> soup<span style="color:#f92672">.</span>select(<span style="color:#e6db74">&#34;#main div.post-item h2 &gt;a&#34;</span>)],
        <span style="color:#e6db74">&#34;next_page_link&#34;</span>: next_page_link[<span style="color:#e6db74">&#34;href&#34;</span>] <span style="color:#66d9ef">if</span> next_page_link <span style="color:#66d9ef">else</span> None
    }


<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">crawl_article_list_page</span>(start_url):
    <span style="color:#e6db74">&#34;&#34;&#34;
</span><span style="color:#e6db74">    Crawl the article list page to get all URLs of article details
</span><span style="color:#e6db74">    :return:
</span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
    <span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#34;Accessing to {start_url}...&#34;</span>)
    <span style="color:#75715e"># Visit https://note.lapras.com/</span>
    response <span style="color:#f92672">=</span> requests<span style="color:#f92672">.</span>get(start_url)
    response<span style="color:#f92672">.</span>raise_for_status()
    time<span style="color:#f92672">.</span>sleep(<span style="color:#ae81ff">10</span>)

    <span style="color:#75715e"># Get the article details URL from the response HTML</span>
    page_data <span style="color:#f92672">=</span> parse_article_list_page(response<span style="color:#f92672">.</span>text)
    article_url_list <span style="color:#f92672">=</span> page_data[<span style="color:#e6db74">&#34;article_url_list&#34;</span>]

    <span style="color:#75715e">#Get the link on the next page if there is one</span>
    <span style="color:#66d9ef">while</span> page_data[<span style="color:#e6db74">&#34;next_page_link&#34;</span>]:
        <span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#39;Accessing to {page_data[&#34;next_page_link&#34;]}...&#39;</span>)
        response <span style="color:#f92672">=</span> requests<span style="color:#f92672">.</span>get(page_data[<span style="color:#e6db74">&#34;next_page_link&#34;</span>])
        time<span style="color:#f92672">.</span>sleep(<span style="color:#ae81ff">10</span>)
        page_data <span style="color:#f92672">=</span> parse_article_list_page(response<span style="color:#f92672">.</span>text)
        article_url_list <span style="color:#f92672">+=</span> page_data[<span style="color:#e6db74">&#34;article_url_list&#34;</span>]

    <span style="color:#66d9ef">return</span> article_url_list


<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">parse_article_detail</span>(html):
    <span style="color:#e6db74">&#34;&#34;&#34;
</span><span style="color:#e6db74">    Parsing the article detail page and extracting the data
</span><span style="color:#e6db74">    :param html:
</span><span style="color:#e6db74">    :return:
</span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
    soup <span style="color:#f92672">=</span> BeautifulSoup(html,<span style="color:#e6db74">&#39;html.parser&#39;</span>)
    <span style="color:#66d9ef">return</span> {
        <span style="color:#e6db74">&#34;title&#34;</span>: soup<span style="color:#f92672">.</span>select_one(<span style="color:#e6db74">&#34;h1&#34;</span>)<span style="color:#f92672">.</span>get_text(),
        <span style="color:#e6db74">&#34;publish_date&#34;</span>: soup<span style="color:#f92672">.</span>select_one(<span style="color:#e6db74">&#34;article header div.entry-meta&#34;</span>)<span style="color:#f92672">.</span>find(text<span style="color:#f92672">=</span>True, recursive<span style="color:#f92672">=</span>False)<span style="color:#f92672">.</span>replace(<span style="color:#e6db74">&#34;｜&#34;</span>, <span style="color:#e6db74">&#34;&#34;</span>),
        <span style="color:#e6db74">&#34;category&#34;</span>: soup<span style="color:#f92672">.</span>select_one(<span style="color:#e6db74">&#34;article header div.entry-meta a&#34;</span>)<span style="color:#f92672">.</span>get_text(),
        <span style="color:#e6db74">&#34;content&#34;</span>: soup<span style="color:#f92672">.</span>select_one(<span style="color:#e6db74">&#34;article div.entry-content&#34;</span>)<span style="color:#f92672">.</span>get_text(strip<span style="color:#f92672">=</span>True)
    }


<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">crawl_article_detail_page</span>(url):
    <span style="color:#e6db74">&#34;&#34;&#34;
</span><span style="color:#e6db74">    Crawl the article detail page to get article data
</span><span style="color:#e6db74">    :param url:
</span><span style="color:#e6db74">    :return:
</span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
    <span style="color:#75715e"># Access article details</span>
    <span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#34;Accessing to {url}...&#34;</span>)
    response <span style="color:#f92672">=</span> requests<span style="color:#f92672">.</span>get(url)
    response<span style="color:#f92672">.</span>raise_for_status()

    time<span style="color:#f92672">.</span>sleep(<span style="color:#ae81ff">10</span>)
    <span style="color:#75715e"># Get article information from response HTML</span>
    <span style="color:#66d9ef">return</span> parse_article_detail(response<span style="color:#f92672">.</span>text)


<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">crawl_lapras_note_articles</span>(start_url):
    <span style="color:#e6db74">&#34;&#34;&#34;
</span><span style="color:#e6db74">    Crawl LAPRAS NOTE to get all article data
</span><span style="color:#e6db74">    :return:
</span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
    article_url_list <span style="color:#f92672">=</span> crawl_article_list_page(start_url)
    article_list <span style="color:#f92672">=</span> []
    <span style="color:#66d9ef">for</span> article_url <span style="color:#f92672">in</span> article_url_list:
        article_data <span style="color:#f92672">=</span> crawl_article_detail_page(article_url)
        article_list<span style="color:#f92672">.</span>append(article_data)
    <span style="color:#66d9ef">return</span> article_list


<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">collect_lapras_note_articles</span>():
    <span style="color:#e6db74">&#34;&#34;&#34;
</span><span style="color:#e6db74">    Acquire all the data of LAPRAS NOTE articles and save them in a file
</span><span style="color:#e6db74">    :return:
</span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
    <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Start crawl LAPRAS NOTE.&#34;</span>)
    article_list <span style="color:#f92672">=</span> crawl_lapras_note_articles(<span style="color:#e6db74">&#34;https://note.lapras.com/&#34;</span>)

    output_json_path <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;./articles.json&#34;</span>
    <span style="color:#66d9ef">with</span> open(output_json_path, mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;w&#34;</span>) <span style="color:#66d9ef">as</span> f:
        <span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#34;Start output to file. path: {output_json_path}&#34;</span>)
        json<span style="color:#f92672">.</span>dump(article_list, f)
        <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Done output.&#34;</span>)

    <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Done crawl LAPRAS NOTE.&#34;</span>)


<span style="color:#66d9ef">if</span> __name__ <span style="color:#f92672">==</span><span style="color:#e6db74">&#39;__main__&#39;</span>:
    collect_lapras_note_articles()
</code></pre></div><p>The implemented code is published in this repository.
<a href="https://github.com/Chanmoro/lapras-note-crawler">https://github.com/Chanmoro/lapras-note-crawler</a></p>
<p>There is a feeling that it is a disposable code, but for the Basic edition, I would like to finish the explanation so far.</p>
<p>#Summary
By the way, this time, &ldquo;How to make crawlers-Basic&rdquo;, the theme of the crawler implementation of <a href="https://note.lapras.com/">LAPRAS NOTE</a> is the theme of a series of flows when developing crawlers. I introduced the basics.</p>
<p>When I develop a crawler, I&rsquo;m proceeding with the procedure like this one.
The code given in the implementation example is often still insufficient when viewed as a crawler that continues maintenance for a long time, but if it is sufficient to acquire a set of data at one time instead of continuously updating the data I think this code is enough for simple usage.
Personally, if it&rsquo;s enough to be run a few times, a crawler for investigation may be easily implemented only by a shell script without using Python.</p>
<p>In my real work, I spend much more time developing data modeling, crawl flow design, error handling, etc. to keep my data unbroken during repeated crawls.
I plan to write some articles during the LAPRAS output relay period, but in my next article I will write &ldquo;How to make crawlers-Advanced edition&rdquo;, so based on the contents of this article, long-term maintenance What should be carefully designed from here to develop a crawler that continues? I would like to introduce you, so please look forward to it!</p>
<p><a href="https://lapras.com/public/QFGM5QX">@Nasum</a> will write on the second day of tomorrow&rsquo;s LAPRAS Output Relay! Stay tuned!</p>

    </article>
  </div>

  
  
  
  <script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-169005401-1', 'auto');
  ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  

  
<link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.css" />
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#216942",
      "text": "#b2d192"
    },
    "button": {
      "background": "#afed71"
    }
  }
})});
</script>

</body>

</html>
