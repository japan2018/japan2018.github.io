<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title> CloudDataflow on Memo Tut</title>
    <link>https://memotut.com/tags/clouddataflow/</link>
    <description>Recent content in  CloudDataflow on Memo Tut</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 23 Dec 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://memotut.com/tags/clouddataflow/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Use Cloud Dataflow to dynamically change the destination depending on the data value and save it in GCS</title>
      <link>https://memotut.com/use-cloud-dataflow-to-dynamically-change-the-destination-depending-on-the-data-value-and-save-it-in-gcs-a0f30/</link>
      <pubDate>Mon, 23 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/use-cloud-dataflow-to-dynamically-change-the-destination-depending-on-the-data-value-and-save-it-in-gcs-a0f30/</guid>
      <description>#Introduction  This article is the 23rd day article of Classi Advent Calendar 2019.
Hello, this is @tomoyanamekawa of data AI part of Classi. Usually, I mainly build a data analysis platform on GCP.
Recently, there was something like &amp;ldquo;I want to divide the data in BigQuery into files according to the value inside and save it in GCS&amp;rdquo;, and at that time I was indebted to Cloud Dataflow. There seems to be demand for other people, and there are few implementation examples in Python, so I will summarize.</description>
    </item>
    
  </channel>
</rss>