<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  <meta name="generator" content="Hugo 0.72.0" />

  
  <meta name="description" content="Some description">
  

  
  <link rel="apple-touch-icon" sizes="180x180" href="https://japan2018.github.io/apple-touch-icon.png">

  
  <link rel="icon" type="image/png" sizes="32x32" href="https://japan2018.github.io/favicon-32x32.png">

  
  <link rel="icon" type="image/png" sizes="16x16" href="https://japan2018.github.io/favicon-16x16.png">

  
  <link rel="manifest" href="https://japan2018.github.io/site.webmanifest">

  
  <link rel="mask-icon" href="https://japan2018.github.io/safari-pinned-tab.svg" color="#5bbad5">

  <meta name="msapplication-TileColor" content="#da532c">

  <meta name="theme-color" content="#ffffff">

  
  <link rel="stylesheet" href="https://japan2018.github.io/css/bootstrap.min.css" />

  
  <title>Approach explanation for beginners who are in the top 1.5% (0.83732) in Kaggle Titanic_2 | Some Title</title>
  

  <style>
body {
  min-width: 300px;
}

.custom-navbar {
  margin-bottom: 1em;
  height: 60px;
}

.custom-navbar a {
  display: inline-block; 
  padding: 18px 0;
  margin-right: 1em; 
  font-weight: bold; 
}

.custom-navbar a:hover,
.custom-navbar a:focus {
  text-decoration: none; 
}

@media print {
  .custom-navbar {
    display: none;
  }
}

article {
  padding-bottom: 1em;
}

img {
  max-width: 100%;
}


body {
  background-color: #fff;
}



body {
  color: #212529;
}



a {
  color: #007bff;
}



a:hover,
a:focus {
  color: #0056b3;
}



.custom-navbar {
  background-color: #212529;
}



.custom-navbar a {
  color: rgba(255, 255, 255, 0.75);
}



.custom-navbar a:hover,
.custom-navbar a:focus {
  color: rgba(255, 255, 255, 1);
}



.container {
  max-width: 800px;
}



pre {
  display: block;
  padding: 9.5px;
  word-break: break-all;
  word-wrap: break-word;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre code {
  padding: 0;
  font-size: inherit;
  color: inherit; 
  white-space: pre-wrap;
  background-color: transparent;
  border: none;
  border-radius: 0;
}

code {
  padding: 2px 4px;
  color: inherit; 
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
  font-size: .9em;
}



blockquote,
.blockquote {
  padding: 10px 20px;
  margin: 0 0 20px;
  font-size: 1em;
  border-left: 5px solid #6c757d;
}

</style>
</head>

<body>
  <nav class="custom-navbar">
  <div class="container">
    
    <a href="/">Posts</a>
    
    <a href="/tags/">Tags</a>
    
    <a href="/about/">About</a>
    
    <a href="/index.xml">RSS</a>
    
  </div>
</nav>
  
  <div class="container">
    <article>
      <h1>Approach explanation for beginners who are in the top 1.5% (0.83732) in Kaggle Titanic_2</h1>
<p>
  <small class="text-secondary">
  
  
  Jan 10, 2020
  </small>
  

<small><code><a href="https://japan2018.github.io/tags/python">Python</a></code></small>


<small><code><a href="https://japan2018.github.io/tags/beginner">Beginner</a></code></small>


<small><code><a href="https://japan2018.github.io/tags/kaggle">Kaggle</a></code></small>


<small><code><a href="https://japan2018.github.io/tags/randomforest">randomForest</a></code></small>


<small><code><a href="https://japan2018.github.io/tags/titanic">titanic</a></code></small>

</p>
<pre><code>[Last time](https://qiita.com/shiroino11111/items/bc3889fa38ff32d46c13),followedby[KaggleTitanic](https://www.kaggle.com/c/titanic/submissions)totop1.5%(0.83732) I will explain the approach of.
</code></pre>
<p>The code used is titanic(0.83732)_2 from <a href="https://github.com/shiroino11111/taitanic-0.83732-">Github</a>.
This time, we will extend the submission score to 0.81339 and prepare for the next time it will be 0.83732.
Also, before forecasting, we will visualize the data used in <a href="https://qiita.com/shiroino11111/items/bc3889fa38ff32d46c13">Last time</a> and analyze the data.</p>
<p>###1. Import the required library and read the CSV.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#f92672">import</span> pandas <span style="color:#f92672">as</span> pd
<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#f92672">as</span> plt
<span style="color:#f92672">import</span> seaborn <span style="color:#f92672">as</span> sns
<span style="color:#f92672">from</span> sklearn.ensemble <span style="color:#f92672">import</span> RandomForestRegressor
<span style="color:#f92672">from</span> sklearn.pipeline <span style="color:#f92672">import</span> Pipeline,make_pipeline
<span style="color:#f92672">from</span> sklearn.ensemble <span style="color:#f92672">import</span> RandomForestClassifier
<span style="color:#f92672">from</span> sklearn.feature_selection <span style="color:#f92672">import</span> SelectKBest
<span style="color:#f92672">from</span> sklearn <span style="color:#f92672">import</span> model_selection
<span style="color:#f92672">from</span> sklearn.model_selection <span style="color:#f92672">import</span> GridSearchCV
<span style="color:#f92672">import</span> warnings
warnings<span style="color:#f92672">.</span>filterwarnings(<span style="color:#e6db74">&#39;ignore&#39;</span>)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#75715e"># Read CSV</span>
train<span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>read_csv(<span style="color:#e6db74">&#34;train.csv&#34;</span>)
test<span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>read_csv(<span style="color:#e6db74">&#34;test.csv&#34;</span>)

<span style="color:#75715e"># Data integration</span>
dataset <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>concat([train, test], ignore_index <span style="color:#f92672">=</span> True)

<span style="color:#75715e"># For submission</span>
PassengerId <span style="color:#f92672">=</span> test[<span style="color:#e6db74">&#39;PassengerId&#39;</span>]
</code></pre></div><p>Let&rsquo;s look at the relationship of each data.
###2. Confirm the relationship between age and survival rate</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#75715e"># Age and Survival Belt Chart</span>
sns<span style="color:#f92672">.</span>barplot(x<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Sex&#34;</span>, y<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Survived&#34;</span>, data<span style="color:#f92672">=</span>train, palette<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Set3&#39;</span>)

<span style="color:#75715e"># Survival rate by gender</span>
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;females: </span><span style="color:#e6db74">%.2f</span><span style="color:#e6db74">&#34;</span> <span style="color:#f92672">%</span>(train[<span style="color:#e6db74">&#39;Survived&#39;</span>][train[<span style="color:#e6db74">&#39;Sex&#39;</span>] <span style="color:#f92672">==</span><span style="color:#e6db74">&#39;female&#39;</span>]<span style="color:#f92672">.</span>value_counts(normalize <span style="color:#f92672">=</span> True)[<span style="color:#ae81ff">1</span>]))
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;males: </span><span style="color:#e6db74">%.2f</span><span style="color:#e6db74">&#34;</span> <span style="color:#f92672">%</span>(train[<span style="color:#e6db74">&#39;Survived&#39;</span>][train[<span style="color:#e6db74">&#39;Sex&#39;</span>] <span style="color:#f92672">==</span><span style="color:#e6db74">&#39;male&#39;</span>]<span style="color:#f92672">.</span>value_counts(normalize <span style="color:#f92672">=</span> True)[<span style="color:#ae81ff">1</span>]))
</code></pre></div><p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/479337/95fdb6eb-bdc9-2ce8-0540-f913514fce47.png" alt="image.png">
females: 0.74
males: 0.19
You can see that women are much more helpful.
What is the survival rate for each ticket class?
###3. Confirm the survival rate relationship for each ticket class</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#75715e">#Ticket Class and Survival Belt Graph</span>
sns<span style="color:#f92672">.</span>barplot(x<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Pclass&#39;</span>, y<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Survived&#39;</span>, data<span style="color:#f92672">=</span>train, palette<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Set3&#39;</span>)

<span style="color:#75715e"># Survival rate by ticket class</span>
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Pclass = 1 :</span><span style="color:#e6db74">%.2f</span><span style="color:#e6db74">&#34;</span> <span style="color:#f92672">%</span>(train[<span style="color:#e6db74">&#39;Survived&#39;</span>][train[<span style="color:#e6db74">&#39;Pclass&#39;</span>]<span style="color:#f92672">==</span><span style="color:#ae81ff">1</span>]<span style="color:#f92672">.</span>value_counts(normalize <span style="color:#f92672">=</span> True)[<span style="color:#ae81ff">1</span>]))
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Pclass = 2 :</span><span style="color:#e6db74">%.2f</span><span style="color:#e6db74">&#34;</span> <span style="color:#f92672">%</span>(train[<span style="color:#e6db74">&#39;Survived&#39;</span>][train[<span style="color:#e6db74">&#39;Pclass&#39;</span>]<span style="color:#f92672">==</span><span style="color:#ae81ff">2</span>]<span style="color:#f92672">.</span>value_counts(normalize <span style="color:#f92672">=</span> True)[<span style="color:#ae81ff">1</span>]))
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Pclass = 3 :</span><span style="color:#e6db74">%.2f</span><span style="color:#e6db74">&#34;</span> <span style="color:#f92672">%</span>(train[<span style="color:#e6db74">&#39;Survived&#39;</span>][train[<span style="color:#e6db74">&#39;Pclass&#39;</span>]<span style="color:#f92672">==</span><span style="color:#ae81ff">3</span>]<span style="color:#f92672">.</span>value_counts(normalize <span style="color:#f92672">=</span> True)[<span style="color:#ae81ff">1</span>]))
</code></pre></div><p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/479337/36731410-ddce-1273-0d2a-6928efad923b.png" alt="image.png">
Pclass = 1: 0.63
Pclass = 2: 0.47
Pclass = 3: 0.24
The higher the ticket purchaser, the higher the survival rate.
How about the price?
###4. Confirm the relationship of the survival rate by the fee</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#75715e"># Survival rate comparison</span>
fare <span style="color:#f92672">=</span> sns<span style="color:#f92672">.</span>FacetGrid(train, hue<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Survived&#34;</span>, aspect<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>)
fare<span style="color:#f92672">.</span>map(sns<span style="color:#f92672">.</span>kdeplot,<span style="color:#e6db74">&#39;Fare&#39;</span>,shade<span style="color:#f92672">=</span> True)
fare<span style="color:#f92672">.</span>set(xlim<span style="color:#f92672">=</span>(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">200</span>))
fare<span style="color:#f92672">.</span>add_legend()
</code></pre></div><p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/479337/df8570fc-f8ba-129f-88ad-e0c1d8aa2daa.png" alt="image.png">
As you can see, people with low ticket prices have low survival rates.
###5. Confirm the relationship between age and survival rate</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#75715e"># Survival rate comparison by age</span>
age <span style="color:#f92672">=</span> sns<span style="color:#f92672">.</span>FacetGrid(train, hue<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Survived&#34;</span>, aspect<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>)
age<span style="color:#f92672">.</span>map(sns<span style="color:#f92672">.</span>kdeplot,<span style="color:#e6db74">&#39;Age&#39;</span>,shade<span style="color:#f92672">=</span> True)
age<span style="color:#f92672">.</span>set(xlim<span style="color:#f92672">=</span>(<span style="color:#ae81ff">0</span>, train[<span style="color:#e6db74">&#39;Age&#39;</span>]<span style="color:#f92672">.</span>max()))
age<span style="color:#f92672">.</span>add_legend()
</code></pre></div><p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/479337/eaf8fd73-d91d-668a-f96c-77dc95296114.png" alt="image.png">
Did the child get priority help?
You can see that the survival rate is 10 years or younger.</p>
<p>###6. Confirm the relationship between guest room and survival rate
From here, <a href="https://qiita.com/shiroino11111/items/bc3889fa38ff32d46c13">Last time</a> I will check the data that was not used.
First is room information.
Cabin (room number) seems to have a different hierarchy of rooms depending on the initials.
<img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/479337/f6dfddd6-ab91-1c45-ef01-a382a119d2be.png" alt="image.png"></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#75715e"># Survival rate comparison by guest room level</span>
dataset[<span style="color:#e6db74">&#39;Cabin&#39;</span>] <span style="color:#f92672">=</span> dataset[<span style="color:#e6db74">&#39;Cabin&#39;</span>]<span style="color:#f92672">.</span>fillna(<span style="color:#e6db74">&#39;Unknown&#39;</span>) <span style="color:#75715e"># assign Unknown if room data is missing</span>
dataset[<span style="color:#e6db74">&#39;Deck&#39;</span>] <span style="color:#f92672">=</span> dataset[<span style="color:#e6db74">&#39;Cabin&#39;</span>]<span style="color:#f92672">.</span>str<span style="color:#f92672">.</span>get(<span style="color:#ae81ff">0</span>) Get the first letter (<span style="color:#ae81ff">0</span>th character) of <span style="color:#75715e">#Cabin (room number)</span>
sns<span style="color:#f92672">.</span>barplot(x<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Deck&#34;</span>, y<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Survived&#34;</span>, data<span style="color:#f92672">=</span>dataset, palette<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Set3&#39;</span>)
</code></pre></div><p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/479337/d799cc60-66ac-6eaf-c4ba-4ab3c7c870fe.png" alt="image.png">
There are some variations.
<a href="https://qiita.com/shiroino11111/items/bc3889fa38ff32d46c13">Last time</a>Similarly,ifyouconfirmthatthereisnomissingvaluebysubstitutingthemedianforthemissingvalue,checkthe&rsquo;Deck&rsquo;(roomlevel) information created this time. Add and make predictions.
###6.1 Add room information and make a prediction in the same way as <a href="https://qiita.com/shiroino11111/items/bc3889fa38ff32d46c13">Last time</a></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">Substitute the median of <span style="color:#75715e"># Age and Fare (charge), and substitute S (Southampton) for Embarked (port of departure)</span>
dataset[<span style="color:#e6db74">&#34;Age&#34;</span>]<span style="color:#f92672">.</span>fillna(dataset<span style="color:#f92672">.</span>Age<span style="color:#f92672">.</span>mean(), inplace<span style="color:#f92672">=</span>True)
dataset[<span style="color:#e6db74">&#34;Fare&#34;</span>]<span style="color:#f92672">.</span>fillna(dataset<span style="color:#f92672">.</span>Fare<span style="color:#f92672">.</span>mean(), inplace<span style="color:#f92672">=</span>True)
dataset[<span style="color:#e6db74">&#34;Embarked&#34;</span>]<span style="color:#f92672">.</span>fillna(<span style="color:#e6db74">&#34;S&#34;</span>, inplace<span style="color:#f92672">=</span>True)

<span style="color:#75715e"># Check the number of missing data in the whole</span>
dataset_null <span style="color:#f92672">=</span> dataset<span style="color:#f92672">.</span>fillna(np<span style="color:#f92672">.</span>nan)
dataset_null<span style="color:#f92672">.</span>isnull()<span style="color:#f92672">.</span>sum()
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Extract variables to use</span>
dataset3 <span style="color:#f92672">=</span> dataset[[<span style="color:#e6db74">&#39;Survived&#39;</span>,<span style="color:#e6db74">&#39;Pclass&#39;</span>,<span style="color:#e6db74">&#39;Sex&#39;</span>,<span style="color:#e6db74">&#39;Age&#39;</span>,<span style="color:#e6db74">&#39;Fare&#39;</span>,<span style="color:#e6db74">&#39;Embarked&#39;</span>,<span style="color:#e6db74">&#39;Deck&#39;</span>]]

<span style="color:#75715e"># Create a dummy variable</span>
dataset_dummies <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>get_dummies(dataset3)
dataset_dummies<span style="color:#f92672">.</span>head(<span style="color:#ae81ff">3</span>)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#75715e"># Decompose data into train and test</span>
<span style="color:#75715e"># (Train exists when&#39;Survived&#39; exists, test does not exist)</span>
train_set <span style="color:#f92672">=</span> dataset_dummies[dataset_dummies[<span style="color:#e6db74">&#39;Survived&#39;</span>]<span style="color:#f92672">.</span>notnull()]
test_set <span style="color:#f92672">=</span> dataset_dummies[dataset_dummies[<span style="color:#e6db74">&#39;Survived&#39;</span>]<span style="color:#f92672">.</span>isnull()]
<span style="color:#66d9ef">del</span> test_set[<span style="color:#e6db74">&#34;Survived&#34;</span>]

Separate <span style="color:#75715e">#train data into variables and correct answers</span>
X <span style="color:#f92672">=</span> train_set<span style="color:#f92672">.</span>as_matrix()[:, <span style="color:#ae81ff">1</span>:] <span style="color:#75715e"># variables after Pclass</span>
y <span style="color:#f92672">=</span> train_set<span style="color:#f92672">.</span>as_matrix()[:, <span style="color:#ae81ff">0</span>] <span style="color:#75715e"># Correct data</span>

<span style="color:#75715e">#Create predictive model</span>
clf <span style="color:#f92672">=</span> RandomForestClassifier(random_state <span style="color:#f92672">=</span> <span style="color:#ae81ff">10</span>, max_features<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;sqrt&#39;</span>)
pipe <span style="color:#f92672">=</span> Pipeline([(<span style="color:#e6db74">&#39;classify&#39;</span>, clf)])
param_test <span style="color:#f92672">=</span> {<span style="color:#e6db74">&#39;classify__n_estimators&#39;</span>:list(range(<span style="color:#ae81ff">20</span>, <span style="color:#ae81ff">30</span>, <span style="color:#ae81ff">1</span>)), <span style="color:#75715e">#20 to 30 are tried one by one</span>
              <span style="color:#e6db74">&#39;classify__max_depth&#39;</span>:list(range(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">1</span>))} Try <span style="color:#75715e">#3 to 10 step by stepgrid = GridSearchCV(estimator = pipe, param_grid = param_test, scoring=&#39;accuracy&#39;, cv=10)</span>
grid<span style="color:#f92672">.</span>fit(X, y)
<span style="color:#66d9ef">print</span>(grid<span style="color:#f92672">.</span>best_params_, grid<span style="color:#f92672">.</span>best_score_)

<span style="color:#75715e"># test data prediction</span>
pred <span style="color:#f92672">=</span> grid<span style="color:#f92672">.</span>predict(test_set)

<span style="color:#75715e"># Create a csv file for Kaggle submission</span>
submission <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame({<span style="color:#e6db74">&#34;PassengerId&#34;</span>: PassengerId, <span style="color:#e6db74">&#34;Survived&#34;</span>: pred<span style="color:#f92672">.</span>astype(np<span style="color:#f92672">.</span>int32)})
submission<span style="color:#f92672">.</span>to_csv(<span style="color:#e6db74">&#34;submission3.csv&#34;</span>, index<span style="color:#f92672">=</span>False)
</code></pre></div><p>{&lsquo;classify__max_depth&rsquo;: 8,&lsquo;classify__n_estimators&rsquo;: 22}
0.8327721661054994
The submitted score was 0.78947. By including the information on the guest room level, we have improved from the previous time.
###7. Check the relationship between ticket and survival rate
Next, try the ticket information.
But how do you divide into groups?
Although it may be divided into the number of characters and whether to include the initials and alphabetic characters of the numbers, if too many are used, the accuracy will be reduced.
Let&rsquo;s check the number of characters in the ticket once.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#75715e"># Survival rate comparison based on the number of characters in the ticket</span>
Ticket_Count <span style="color:#f92672">=</span> dict(dataset[<span style="color:#e6db74">&#39;Ticket&#39;</span>]<span style="color:#f92672">.</span>value_counts()) <span style="color:#75715e"># Group by number of ticket characters</span>
dataset[<span style="color:#e6db74">&#39;TicketGroup&#39;</span>] <span style="color:#f92672">=</span> dataset[<span style="color:#e6db74">&#39;Ticket&#39;</span>]<span style="color:#f92672">.</span>apply(<span style="color:#66d9ef">lambda</span> x:Ticket_Count[x]) <span style="color:#75715e"># Group distribution</span>
sns<span style="color:#f92672">.</span>barplot(x<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;TicketGroup&#39;</span>, y<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Survived&#39;</span>, data<span style="color:#f92672">=</span>dataset, palette<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Set3&#39;</span>)
</code></pre></div><p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/479337/054dc78f-6b25-441f-cdf3-e9401460059a.png" alt="image.png">
There is a difference from the previous Cabin (room level) division.
###7.1 Predict by adding the initial information of the ticket</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#75715e"># Extract variables to use</span>
dataset4 <span style="color:#f92672">=</span> dataset[[<span style="color:#e6db74">&#39;Survived&#39;</span>,<span style="color:#e6db74">&#39;Pclass&#39;</span>,<span style="color:#e6db74">&#39;Sex&#39;</span>,<span style="color:#e6db74">&#39;Age&#39;</span>,<span style="color:#e6db74">&#39;Fare&#39;</span>,<span style="color:#e6db74">&#39;Embarked&#39;</span>,<span style="color:#e6db74">&#39;Deck&#39;</span>,<span style="color:#e6db74">&#39;TicketGroup&#39;</span>]]

<span style="color:#75715e"># Create a dummy variable</span>
dataset_dummies <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>get_dummies(dataset4)
dataset_dummies<span style="color:#f92672">.</span>head(<span style="color:#ae81ff">4</span>)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#75715e"># Decompose data into train and test</span>
<span style="color:#75715e"># (Train exists when&#39;Survived&#39; exists, test does not exist)</span>
train_set <span style="color:#f92672">=</span> dataset_dummies[dataset_dummies[<span style="color:#e6db74">&#39;Survived&#39;</span>]<span style="color:#f92672">.</span>notnull()]
test_set <span style="color:#f92672">=</span> dataset_dummies[dataset_dummies[<span style="color:#e6db74">&#39;Survived&#39;</span>]<span style="color:#f92672">.</span>isnull()]
<span style="color:#66d9ef">del</span> test_set[<span style="color:#e6db74">&#34;Survived&#34;</span>]

Separate <span style="color:#75715e">#train data into variables and correct answers</span>
X <span style="color:#f92672">=</span> train_set<span style="color:#f92672">.</span>as_matrix()[:, <span style="color:#ae81ff">1</span>:] <span style="color:#75715e"># variables after Pclass</span>
y <span style="color:#f92672">=</span> train_set<span style="color:#f92672">.</span>as_matrix()[:, <span style="color:#ae81ff">0</span>] <span style="color:#75715e"># Correct data</span>

<span style="color:#75715e">#Create predictive model</span>
clf <span style="color:#f92672">=</span> RandomForestClassifier(random_state <span style="color:#f92672">=</span> <span style="color:#ae81ff">10</span>, max_features<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;sqrt&#39;</span>)
pipe <span style="color:#f92672">=</span> Pipeline([(<span style="color:#e6db74">&#39;classify&#39;</span>, clf)])
param_test <span style="color:#f92672">=</span> {<span style="color:#e6db74">&#39;classify__n_estimators&#39;</span>:list(range(<span style="color:#ae81ff">20</span>, <span style="color:#ae81ff">30</span>, <span style="color:#ae81ff">1</span>)), <span style="color:#75715e">#20 to 30 are tried one by one</span>
              <span style="color:#e6db74">&#39;classify__max_depth&#39;</span>:list(range(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">1</span>))} Try <span style="color:#75715e">#3 to 10 step by step</span>
grid <span style="color:#f92672">=</span> GridSearchCV(estimator <span style="color:#f92672">=</span> pipe, param_grid <span style="color:#f92672">=</span> param_test, scoring<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;accuracy&#39;</span>, cv<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>)
grid<span style="color:#f92672">.</span>fit(X, y)
<span style="color:#66d9ef">print</span>(grid<span style="color:#f92672">.</span>best_params_, grid<span style="color:#f92672">.</span>best_score_, sep<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>)

<span style="color:#75715e"># test data prediction</span>
pred <span style="color:#f92672">=</span> grid<span style="color:#f92672">.</span>predict(test_set)

<span style="color:#75715e"># Create a csv file for Kaggle submission</span>
submission <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame({<span style="color:#e6db74">&#34;PassengerId&#34;</span>: PassengerId, <span style="color:#e6db74">&#34;Survived&#34;</span>: pred<span style="color:#f92672">.</span>astype(np<span style="color:#f92672">.</span>int32)})
submission<span style="color:#f92672">.</span>to_csv(<span style="color:#e6db74">&#34;submission4.csv&#34;</span>, index<span style="color:#f92672">=</span>False)
</code></pre></div><p>{&lsquo;classify__max_depth&rsquo;: 8,&lsquo;classify__n_estimators&rsquo;: 23}
0.8406285072951739
Although my training score increased, my submission score to Kaggle dropped to 0.77990.
In the first place, realistically, it seems that the correlation between the number of characters on the ticket and the survival rate is weak.
However, since it is a feature that has come out at all, I will try learning by suppressing the items into two groups, a high group and a low group.
###7.2 Predict by grouping ticket initial information</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#75715e"># Divide into two groups, one with high survival rate based on the number of characters in the ticket and one with low survival rate.</span>
<span style="color:#75715e"># Substitute 2 if high and 1 if low</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">Ticket_Label</span>(s):
    <span style="color:#66d9ef">if</span> (s <span style="color:#f92672">&gt;=</span> <span style="color:#ae81ff">2</span>) <span style="color:#f92672">&amp;</span> (s <span style="color:#f92672">&lt;=</span> <span style="color:#ae81ff">4</span>): <span style="color:#75715e"># group with high survival rate in number of characters</span>
        <span style="color:#66d9ef">return</span> <span style="color:#ae81ff">2</span>
    <span style="color:#66d9ef">elif</span> ((s<span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">4</span>) <span style="color:#f92672">&amp;</span> (s <span style="color:#f92672">&lt;=</span> <span style="color:#ae81ff">8</span>)) <span style="color:#f92672">|</span> (s <span style="color:#f92672">==</span> <span style="color:#ae81ff">1</span>): <span style="color:#75715e"># groups with low survival in # characters</span>
        <span style="color:#66d9ef">return</span> <span style="color:#ae81ff">1</span>
    <span style="color:#66d9ef">elif</span> (s<span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">8</span>):
        <span style="color:#66d9ef">return</span> <span style="color:#ae81ff">0</span>

dataset[<span style="color:#e6db74">&#39;TicketGroup&#39;</span>] <span style="color:#f92672">=</span> dataset[<span style="color:#e6db74">&#39;TicketGroup&#39;</span>]<span style="color:#f92672">.</span>apply(Ticket_Label)
sns<span style="color:#f92672">.</span>barplot(x<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;TicketGroup&#39;</span>, y<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Survived&#39;</span>, data<span style="color:#f92672">=</span>dataset, palette<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Set3&#39;</span>)
</code></pre></div><p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/479337/84924721-a136-fb33-8715-3a01e9142165.png" alt="image.png">
It looks like a clean division.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#75715e"># Decompose data into train and test</span>
<span style="color:#75715e"># (Train exists when&#39;Survived&#39; exists, test does not exist)</span>
train_set <span style="color:#f92672">=</span> dataset_dummies[dataset_dummies[<span style="color:#e6db74">&#39;Survived&#39;</span>]<span style="color:#f92672">.</span>notnull()]
test_set <span style="color:#f92672">=</span> dataset_dummies[dataset_dummies[<span style="color:#e6db74">&#39;Survived&#39;</span>]<span style="color:#f92672">.</span>isnull()]
<span style="color:#66d9ef">del</span> test_set[<span style="color:#e6db74">&#34;Survived&#34;</span>]

Separate <span style="color:#75715e">#train data into variables and correct answers</span>
X <span style="color:#f92672">=</span> train_set<span style="color:#f92672">.</span>as_matrix()[:, <span style="color:#ae81ff">1</span>:] <span style="color:#75715e"># variables after Pclass</span>
y <span style="color:#f92672">=</span> train_set<span style="color:#f92672">.</span>as_matrix()[:, <span style="color:#ae81ff">0</span>] <span style="color:#75715e"># Correct data</span>

<span style="color:#75715e">#Create predictive model</span>
clf <span style="color:#f92672">=</span> RandomForestClassifier(random_state <span style="color:#f92672">=</span> <span style="color:#ae81ff">10</span>, max_features<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;sqrt&#39;</span>)
pipe <span style="color:#f92672">=</span> Pipeline([(<span style="color:#e6db74">&#39;classify&#39;</span>, clf)])
param_test <span style="color:#f92672">=</span> {<span style="color:#e6db74">&#39;classify__n_estimators&#39;</span>:list(range(<span style="color:#ae81ff">20</span>, <span style="color:#ae81ff">30</span>, <span style="color:#ae81ff">1</span>)), <span style="color:#75715e">#20 to 30 are tried one by one</span>
              <span style="color:#e6db74">&#39;classify__max_depth&#39;</span>:list(range(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">1</span>))} Try <span style="color:#75715e">#3 to 10 step by step</span>
grid <span style="color:#f92672">=</span> GridSearchCV(estimator <span style="color:#f92672">=</span> pipe, param_grid <span style="color:#f92672">=</span> param_test, scoring<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;accuracy&#39;</span>, cv<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>)
grid<span style="color:#f92672">.</span>fit(X, y)
<span style="color:#66d9ef">print</span>(grid<span style="color:#f92672">.</span>best_params_, grid<span style="color:#f92672">.</span>best_score_, sep<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>)

<span style="color:#75715e"># test data prediction</span>
pred <span style="color:#f92672">=</span> grid<span style="color:#f92672">.</span>predict(test_set)

<span style="color:#75715e"># Create a csv file for Kaggle submission</span>
submission <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame({<span style="color:#e6db74">&#34;PassengerId&#34;</span>: PassengerId, <span style="color:#e6db74">&#34;Survived&#34;</span>: pred<span style="color:#f92672">.</span>astype(np<span style="color:#f92672">.</span>int32)})
submission<span style="color:#f92672">.</span>to_csv(<span style="color:#e6db74">&#34;submission5.csv&#34;</span>, index<span style="color:#f92672">=</span>False)
</code></pre></div><p>{&lsquo;classify__max_depth&rsquo;: 7,&lsquo;classify__n_estimators&rsquo;: 23}
0.8417508417508418
The submission score to Kaggle has improved significantly to 0.81339.</p>
<p>###8. Summary
This time, by adding new information on the guest room hierarchy and information on two groups, a group with high survival rate and a group with low survival rate based on the initial letters of the ticket, <a href="https://qiita.com/shiroino11111/items/bc3889fa38ff32d46c13">previous</a> submission score was improved from 0.78468 to 0.81339.
<a href="https://qiita.com/shiroino11111/items/21bf1303587eeae0fc30">Next time</a> Finally, I will explain the approach to the submission score of 0.83732, which is equivalent to the top 1.5%.</p>

    </article>
  </div>

  
  
  
  <script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-123456789-1', 'auto');
  ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  

  
<link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.css" />
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#216942",
      "text": "#b2d192"
    },
    "button": {
      "background": "#afed71"
    }
  }
})});
</script>

</body>

</html>
