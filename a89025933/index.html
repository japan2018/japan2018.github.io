<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  <meta name="generator" content="Hugo 0.72.0" />

  
  <meta name="description" content="Some description">
  

  
  <link rel="apple-touch-icon" sizes="180x180" href="https://memotut.com/apple-touch-icon.png">

  
  <link rel="icon" type="image/png" sizes="32x32" href="https://memotut.com/favicon-32x32.png">

  
  <link rel="icon" type="image/png" sizes="16x16" href="https://memotut.com/favicon-16x16.png">

  
  <link rel="manifest" href="https://memotut.com/site.webmanifest">

  
  <link rel="mask-icon" href="https://memotut.com/safari-pinned-tab.svg" color="#5bbad5">

  <meta name="msapplication-TileColor" content="#da532c">

  <meta name="theme-color" content="#ffffff">

  
  <link rel="stylesheet" href="https://memotut.com/css/bootstrap.min.css" />

  
  <title>[Python] First image classifier | Memo Tut</title>
  

  <style>
body {
  min-width: 300px;
}

.custom-navbar {
  margin-bottom: 1em;
  height: 60px;
}

.custom-navbar a {
  display: inline-block; 
  padding: 18px 0;
  margin-right: 1em; 
  font-weight: bold; 
}

.custom-navbar a:hover,
.custom-navbar a:focus {
  text-decoration: none; 
}

@media print {
  .custom-navbar {
    display: none;
  }
}

article {
  padding-bottom: 1em;
}

img {
  max-width: 100%;
}


body {
  background-color: #fff;
}



body {
  color: #212529;
}



a {
  color: #007bff;
}



a:hover,
a:focus {
  color: #0056b3;
}



.custom-navbar {
  background-color: #212529;
}



.custom-navbar a {
  color: rgba(255, 255, 255, 0.75);
}



.custom-navbar a:hover,
.custom-navbar a:focus {
  color: rgba(255, 255, 255, 1);
}



.container {
  max-width: 800px;
}



pre {
  display: block;
  padding: 9.5px;
  word-break: break-all;
  word-wrap: break-word;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre code {
  padding: 0;
  font-size: inherit;
  color: inherit; 
  white-space: pre-wrap;
  background-color: transparent;
  border: none;
  border-radius: 0;
}

code {
  padding: 2px 4px;
  color: inherit; 
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
  font-size: .9em;
}



blockquote,
.blockquote {
  padding: 10px 20px;
  margin: 0 0 20px;
  font-size: 1em;
  border-left: 5px solid #6c757d;
}

</style>
</head>

<body>
  <nav class="custom-navbar">
  <div class="container">
    
    <a href="/">Posts</a>
    
    <a href="/tags/">Tags</a>
    
    <a href="/about/">About</a>
    
    <a href="/index.xml">RSS</a>
    
  </div>
</nav>
  
  <div class="container">
    <article>
      <h1>[Python] First image classifier</h1>
<p>
  <small class="text-secondary">
  
  
  Dec 2, 2019
  </small>
  

<small><code><a href="https://memotut.com/tags/python">Python</a></code></small>


<small><code><a href="https://memotut.com/tags/machinelearning">MachineLearning</a></code></small>


<small><code><a href="https://memotut.com/tags/keras">Keras</a></code></small>


<small><code><a href="https://memotut.com/tags/tensorflow">TensorFlow</a></code></small>


<small><code><a href="https://memotut.com/tags/colaboratory">colaboratory</a></code></small>

</p>
<pre><code>Hello. In my work, I'm far from engineering and I can't write much by doing what I've done,
</code></pre>
<p>I have a little time, so I&rsquo;ll summarize what I learned a little.
Advent calendar I&rsquo;m not afraid! You can write an article that you just did a tutorial! That means one&hellip;</p>
<h1 id="assumed-readers">Assumed readers</h1>
<p>I&rsquo;ve heard a lot about machine learning, but I haven&rsquo;t touched on implementation so much so I will touch on it.
Therefore, the intended readers are people who have never touched on machine learning but are interested and would like to take a look at the implementation of machine learning.
Experienced people have warm eyes and it is helpful if you can point out the mistaken part :smile_cat:</p>
<h1 id="theme">Theme</h1>
<p>If you don&rsquo;t have a theme that is easy to catch up with, you won&rsquo;t know the goal to aim for and you&rsquo;ll be lost.
So this time when you give an image, you classify what is in the image,
Create an image classifier.</p>
<p>Anything is fine, but let&rsquo;s first decide which classifier to use.
I&rsquo;ve been addicted to curry these days, so I&rsquo;ll try to make an image classifier for spices.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1979/97493458-4ffa-7d55-e7a1-652bf72b042d.jpeg" alt="IMG_2034.jpg"></p>
<p><a href="https://sugaret.hatenablog.com/entry/2019/11/28/234511">Our blog</a></p>
<h1 id="prerequisite-knowledge">Prerequisite knowledge</h1>
<p>Since the image classifier is a catchy theme, there are many tutorial articles, but I recommend you to read the whole article in a quick manner with the following articles rather than start reading without any prerequisite knowledge.</p>
<p><a href="https://jp.techcrunch.com/2017/04/15/20170413neural-networks-made-easy/">Introduction to neural networks from scratch that does not require mathematical knowledge</a>
<a href="https://www.imagazine.co.jp/%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF%E3%82%92%E7%90%86%E8%A7%A3%E3%81%99%E3%82%8B%E3%80%80%EF%BD%9E%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97/">Understanding the &ldquo;Basics&rdquo; of Neural Networks-Introduction to Deep Learning | Part 1</a></p>
<p>Also, please refer to the reference links for words that look like technical terms.</p>
<h1 id="do-a-tutorial">Do a tutorial</h1>
<p>Tensorflow (*2) Transfer learning (*2) tutorial.
<a href="https://www.tensorflow.org/tutorials/images/transfer_learning_with_hub">Transfer learning with TensorFlow Hub</a>.</p>
<p>I wrote it according to the items of the version of 2019/12, but I hope that you will read it nicely if there are changes.
The code in each section is reproduced, but the results are not included except for some parts, so please read while executing it yourself.</p>
<p>(*1) tensorflow is one of the machine learning libraries, created by google. <a href="https://en.wikipedia.org/wiki/TensorFlow">wiki</a>
(*2) Transfer learning is a method that diverts a model learned in another task to another task.
In this case, the accuracy cannot be improved without preparing a large amount of data.
It seems that it can be solved with a fairly small number.
It seems that if you master one programming language, you will learn the second quickly. <a href="https://jinbeizame.hateblo.jp/entry/kelpnet_transfer">Reference</a></p>
<h2 id="setup">Setup</h2>
<p>As a premise, this tutorial uses Google Colaboratory (Colab *3), so let&rsquo;s click &ldquo;Run in Google Colab&rdquo; at the top to enable it.
When the Colab screen opens, let&rsquo;s execute it in order from the top. Place the cursor near [] in the upper left of the code, and the execute button should appear.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> __future__ <span style="color:#f92672">import</span> absolute_import, division, print_function, unicode_literals

<span style="color:#f92672">import</span> matplotlib.pylab <span style="color:#f92672">as</span> plt

<span style="color:#f92672">import</span> tensorflow <span style="color:#f92672">as</span> tf
</code></pre></div><p>You are importing various libraries around here.
The description of <code>__future__ ..</code> is for keeping compatibility with python2-3.
<code>import matplotlib.pylab as plt</code> is a library for plotting to be used later.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#960050;background-color:#1e0010">!</span>pip install <span style="color:#f92672">-</span>q <span style="color:#f92672">-</span>U tf<span style="color:#f92672">-</span>hub<span style="color:#f92672">-</span>nightly
<span style="color:#f92672">import</span> tensorflow_hub <span style="color:#f92672">as</span> hub

<span style="color:#f92672">from</span> tensorflow.keras <span style="color:#f92672">import</span> layers
</code></pre></div><p>The description of <code>!pip install -q -U tf-hub-nightly</code> installs the python library.
<code>tensorflow_hub</code> is a library for using a platform (tensorflow hub) that can easily use pretrained models.
<code>tensorflow.keras</code> is a machine learning library that seems to have been created by a google engineer but can be used from other than tensorflow.</p>
<p>It&rsquo;s amazing that it&rsquo;s so easy to run on a virtual machine just by clicking and writing text.</p>
<p>(*3)Colaboratory is a Jupyter notebook environment that runs entirely in the cloud. You can use it free of charge without any settings.
With Colaboratory, you can write and run code, save and share analyzes, access powerful computing resources, and more, all from your browser.
<a href="https://colab.research.google.com/notebooks/welcome.ipynb?hl=ja">Welcome to Colaboratory</a></p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1979/027de34b-cac9-b15f-d5e2-15387899b96a.png" alt="image.png">
By the way, if you get this kind of error, press the [RESTART RUNTIME] button according to your support, and then press the play button.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1979/aae8384c-26fb-28ae-a38f-a56f40d292be.png" alt="curry_ko.png"></p>
<h2 id="an-imagenet-classifier">An ImageNet classifier</h2>
<p>Let&rsquo;s try image classification using a trained model.</p>
<h3 id="download-the-classifier">Download the classifier</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">classifier_url <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/2&#34;</span> <span style="color:#75715e">#@param {type:&#34;string&#34;}</span>
</code></pre></div><p>The URL of the learned classifier. As written in the tutorial, it is said that <a href="https://tfhub.dev/s?module-type=image-classification&amp;q=tf2">it&rsquo;s here</a> is all right.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">IMAGE_SHAPE <span style="color:#f92672">=</span> (<span style="color:#ae81ff">224</span>, <span style="color:#ae81ff">224</span>)

classifier <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>Sequential((
    hub<span style="color:#f92672">.</span>KerasLayer(classifier_url, input_shape<span style="color:#f92672">=</span>IMAGE_SHAPE<span style="color:#f92672">+</span>(<span style="color:#ae81ff">3</span>,))
])
</code></pre></div><p>Push the trained model as a layer in the neural network.
It seems that it is necessary to tell the format of the image given, so give it with (width, height, channel).
I added channel 3 (the number of colors) later. Does it have a deep meaning?</p>
<h3 id="run-it-on-a-single-image">Run it on a single image</h3>
<p>When you are ready, let&rsquo;s discriminate with an appropriate image.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">import</span> PIL.Image <span style="color:#f92672">as</span> Image

grace_hopper <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>utils<span style="color:#f92672">.</span>get_file(<span style="color:#e6db74">&#39;image.jpg&#39;</span>,<span style="color:#e6db74">&#39;https://storage.googleapis.com/download.tensorflow.org/example_images/grace_hopper.jpg&#39;</span>)
grace_hopper <span style="color:#f92672">=</span> Image<span style="color:#f92672">.</span>open(grace_hopper)<span style="color:#f92672">.</span>resize(IMAGE_SHAPE)
grace_hopper
</code></pre></div><p><a href="https://en.wikipedia.org/wiki/%E3%82%B0%E3%83%AC%E3%83%BC%E3%82%B9%E3%83%BB%E3%83%9B%E3%83%83%E3%83%91%E3%83%BC">Mr. grace_hopper</a> images have been acquired.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">grace_hopper <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(grace_hopper)<span style="color:#f92672">/</span><span style="color:#ae81ff">255.0</span>
grace_hopper<span style="color:#f92672">.</span>shape
</code></pre></div><p>It seems that type conversion is being performed.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">result <span style="color:#f92672">=</span> classifier<span style="color:#f92672">.</span>predict(grace_hopper[np<span style="color:#f92672">.</span>newaxis, <span style="color:#f92672">...</span>])
result<span style="color:#f92672">.</span>shape
</code></pre></div><p>If you add one dimension to the image data and run the prediction, an array of 1001 element vectors (exactly ndarray) will be returned.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">predicted_class <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>argmax(result[<span style="color:#ae81ff">0</span>], axis<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>)
predicted_class
</code></pre></div><p>These 1001 elements represent the probability of each class (in this case, the analogy element), so let&rsquo;s take the one with the highest probability.
The value of 653 is returned. This represents the thing that this classifier has analogized.</p>
<h3 id="decode-the-predictions">Decode the predictions</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">labels_path <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>utils<span style="color:#f92672">.</span>get_file(<span style="color:#e6db74">&#39;ImageNetLabels.txt&#39;</span>,<span style="color:#e6db74">&#39;https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt&#39;</span>)
imagenet_labels <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(open(labels_path)<span style="color:#f92672">.</span>read()<span style="color:#f92672">.</span>splitlines())
<span style="color:#e6db74">``</span><span style="color:#960050;background-color:#1e0010">`</span>Download the labels <span style="color:#f92672">and</span> pack them into an array to find out what the results above show<span style="color:#f92672">.</span>
As you can see immediately by accessing the URL directly, it corresponds to the <span style="color:#ae81ff">1001</span> items mentioned earlier<span style="color:#f92672">.</span>

<span style="color:#e6db74">``</span><span style="color:#960050;background-color:#1e0010">`</span>python
plt<span style="color:#f92672">.</span>imshow(grace_hopper)
plt<span style="color:#f92672">.</span>axis(<span style="color:#e6db74">&#39;off&#39;</span>)
predicted_class_name <span style="color:#f92672">=</span> imagenet_labels[predicted_class]
_ <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#34;Prediction: &#34;</span><span style="color:#f92672">+</span> predicted_class_name<span style="color:#f92672">.</span>title())
</code></pre></div><p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1979/401eb898-f0a7-7657-ca25-d455d7e60416.png" alt="output_uzziRK3Z2VQo_0.png"></p>
<p>We will use the image display library to output what the 653th image was.
The result was Military Uniform. Happy New Year.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1979/755efb03-e947-cd0d-e0a1-99906decbada.png" alt="nut_hakkaku.png"></p>
<h2 id="simple-transfer-learning">Simple transfer learning</h2>
<p>The production starts from here. I used to say &ldquo;I can use a learned classifier like this ~&rdquo;,
Next is &ldquo;I will make a classifier from the images I have collected ~&rdquo;.</p>
<h3 id="dataset">Dataset</h3>
<p>In this tutorial, we will use a flower image. Finally, swap this data set appropriately to create another classifier.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">data_root <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>utils<span style="color:#f92672">.</span>get_file(
  <span style="color:#e6db74">&#39;flower_photos&#39;</span>,<span style="color:#e6db74">&#39;https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz&#39;</span>,
   untar<span style="color:#f92672">=</span>True)
</code></pre></div><p>Download dataset</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">image_generator <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>preprocessing<span style="color:#f92672">.</span>image<span style="color:#f92672">.</span>ImageDataGenerator(rescale<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span><span style="color:#f92672">/</span><span style="color:#ae81ff">255</span>)
image_data <span style="color:#f92672">=</span> image_generator<span style="color:#f92672">.</span>flow_from_directory(str(data_root), target_size<span style="color:#f92672">=</span>IMAGE_SHAPE)
</code></pre></div><p>I&rsquo;m going to plunge into the ImageDataGenarator to process the images well.
By the way, you can see the image classification by downloading the image group from the above URL,
It feels like collecting specific images for each directory.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">for</span> image_batch, label_batch <span style="color:#f92672">in</span> image_data:
  <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Image batch shape: &#34;</span>, image_batch<span style="color:#f92672">.</span>shape)
  <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Label batch shape: &#34;</span>, label_batch<span style="color:#f92672">.</span>shape)
  <span style="color:#66d9ef">break</span>
</code></pre></div><p>Iterate on image_data to create an array of image_batch and label_batch.</p>
<h3 id="run-the-classifier-on-a-batch-of-images">Run the classifier on a batch of images</h3>
<p>In order to compare it with the state after learning, let&rsquo;s classify it in the unlearned state.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">result_batch <span style="color:#f92672">=</span> classifier<span style="color:#f92672">.</span>predict(image_batch)
result_batch<span style="color:#f92672">.</span>shape
</code></pre></div><p>Let&rsquo;s predict the same as before.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">predicted_class_names <span style="color:#f92672">=</span> imagenet_labels[np<span style="color:#f92672">.</span>argmax(result_batch, axis<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>)]
predicted_class_names
</code></pre></div><p>32 classification results were obtained. Check it against the image.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">10</span>,<span style="color:#ae81ff">9</span>))
plt<span style="color:#f92672">.</span>subplots_adjust(hspace<span style="color:#f92672">=</span><span style="color:#ae81ff">0.5</span>)
<span style="color:#66d9ef">for</span> n <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">30</span>):
  plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">6</span>,<span style="color:#ae81ff">5</span>,n<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>)
  plt<span style="color:#f92672">.</span>imshow(image_batch[n])
  plt<span style="color:#f92672">.</span>title(predicted_class_names[n])
  plt<span style="color:#f92672">.</span>axis(<span style="color:#e6db74">&#39;off&#39;</span>)
_ <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>suptitle(<span style="color:#e6db74">&#34;ImageNet predictions&#34;</span>)
</code></pre></div><p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1979/cd610f49-c0e9-58a5-7957-47e44cbfe9b2.png" alt="output_IXTB22SpxDLP_0.png"></p>
<p>Looking at the results, they are quite different.
It&rsquo;s possible that you&rsquo;re choosing from 1001 objects, but I haven&rsquo;t got the answer right at all.</p>
<h3 id="download-the-headless-model">Download the headless model</h3>
<p>So let&rsquo;s make our own classifier.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">
feature_extractor_url <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/2&#34;</span> <span style="color:#75715e">#@param {type:&#34;string&#34;}</span>
</code></pre></div><p>As usual, we will download the trained model from tensorflow hub. The extractor is like an extractor.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">
feature_extractor_layer <span style="color:#f92672">=</span> hub<span style="color:#f92672">.</span>KerasLayer(feature_extractor_url,
                                         input_shape<span style="color:#f92672">=</span>(<span style="color:#ae81ff">224</span>,<span style="color:#ae81ff">224</span>,<span style="color:#ae81ff">3</span>))
</code></pre></div><p>Create a layer to plunge into the model.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">
feature_batch <span style="color:#f92672">=</span> feature_extractor_layer(image_batch)
<span style="color:#66d9ef">print</span>(feature_batch<span style="color:#f92672">.</span>shape)
</code></pre></div><p>This guy will return 1280 vectors for each image.
You try to classify images from various elements.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">
feature_extractor_layer<span style="color:#f92672">.</span>trainable <span style="color:#f92672">=</span> False
</code></pre></div><p>This time, we will not tune the extractor part, so specify it so that it will not be learned.</p>
<h3 id="attach-a-classification-head">Attach a classification head</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">
model <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>Sequential((
  feature_extractor_layer,
  layers<span style="color:#f92672">.</span>Dense(image_data<span style="color:#f92672">.</span>num_classes, activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;softmax&#39;</span>)
])

model<span style="color:#f92672">.</span>summary()
</code></pre></div><p>I am pushing the instance of the extractor I made earlier into the classifier.
You also display a summary of the model you made.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">
predictions <span style="color:#f92672">=</span> model(image_batch)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">predictions<span style="color:#f92672">.</span>shape
</code></pre></div><p>Checking the shape of the tensor.</p>
<h3 id="train-the-model">Train the model</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">
model<span style="color:#f92672">.</span>compile(
  optimizer<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>optimizers<span style="color:#f92672">.</span>Adam(),
  loss<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;categorical_crossentropy&#39;</span>,
  metrics<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;acc&#39;</span>])
</code></pre></div><p>Compile the model.
optimizer: There seems to be various kinds. <a href="https://keras.io/ja/optimizers/">Reference</a>
loss: A function used for learning to adjust the loss to be as small as possible. There seems to be a lot of this too. <a href="https://keras.io/ja/losses/">Reference</a>
metrics (evaluation function): values used to evaluate the performance of the model, but not used for learning, such as the loss function. There seems to be various kinds of this as well. <a href="https://keras.io/ja/metrics/">Reference</a></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">CollectBatchStats</span>(tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>callbacks<span style="color:#f92672">.</span>Callback):
  <span style="color:#66d9ef">def</span> __init__(self):
    self<span style="color:#f92672">.</span>batch_losses <span style="color:#f92672">=</span> []
    self<span style="color:#f92672">.</span>batch_acc <span style="color:#f92672">=</span> []

  <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">on_train_batch_end</span>(self, batch, logs<span style="color:#f92672">=</span>None):
    self<span style="color:#f92672">.</span>batch_losses<span style="color:#f92672">.</span>append(logs[<span style="color:#e6db74">&#39;loss&#39;</span>])
    self<span style="color:#f92672">.</span>batch_acc<span style="color:#f92672">.</span>append(logs[<span style="color:#e6db74">&#39;acc&#39;</span>])
    self<span style="color:#f92672">.</span>model<span style="color:#f92672">.</span>reset_metrics()
</code></pre></div><p>This is a function definition for observing the values of the loss function and evaluation function.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">steps_per_epoch <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>ceil(image_data<span style="color:#f92672">.</span>samples<span style="color:#f92672">/</span>image_data<span style="color:#f92672">.</span>batch_size)

batch_stats_callback <span style="color:#f92672">=</span> CollectBatchStats()

history <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>fit_generator(image_data, epochs<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>,
                              steps_per_epoch<span style="color:#f92672">=</span>steps_per_epoch,
                              callbacks <span style="color:#f92672">=</span> [batch_stats_callback])
</code></pre></div><p>Start learning with fit_generator.
You have specified the number of times of learning etc. <a href="https://keras.io/ja/models/sequential/">Reference</a>
Learning will take some time.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">plt<span style="color:#f92672">.</span>figure()
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;Loss&#34;</span>)
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;Training Steps&#34;</span>)
plt<span style="color:#f92672">.</span>ylim([<span style="color:#ae81ff">0</span>,<span style="color:#ae81ff">2</span>])
plt<span style="color:#f92672">.</span>plot(batch_stats_callback<span style="color:#f92672">.</span>batch_losses)
</code></pre></div><p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1979/7e2c626e-ce1f-62a7-0c1c-aaadf78cf09d.png" alt="output_A5RfS1QIIP-P_1.png"></p>
<p>This is the transition of the loss function. It’s good that it’s gradually falling.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">plt<span style="color:#f92672">.</span>figure()
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;Accuracy&#34;</span>)
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;Training Steps&#34;</span>)
plt<span style="color:#f92672">.</span>ylim([<span style="color:#ae81ff">0</span>,<span style="color:#ae81ff">1</span>])
plt<span style="color:#f92672">.</span>plot(batch_stats_callback<span style="color:#f92672">.</span>batch_acc)
</code></pre></div><p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1979/8ee11add-566e-876d-1a50-59c0ebeb6716.png" alt="output_3uvX11avTiDg_1.png">This is the transition of the evaluation function. This is going up so it feels good.</p>
<h3 id="check-the-predictions">Check the predictions</h3>
<p>Let&rsquo;s finally classify.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">class_names <span style="color:#f92672">=</span> sorted(image_data<span style="color:#f92672">.</span>class_indices<span style="color:#f92672">.</span>items(), key<span style="color:#f92672">=</span><span style="color:#66d9ef">lambda</span> pair:pair[<span style="color:#ae81ff">1</span>])
class_names <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array([key<span style="color:#f92672">.</span>title() <span style="color:#66d9ef">for</span> key, value <span style="color:#f92672">in</span> class_names])
class_names
</code></pre></div><p>Let&rsquo;s take a look at the classes that actually exist. There are only five types.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">predicted_batch <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>predict(image_batch)
predicted_id <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>argmax(predicted_batch, axis<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>)
predicted_label_batch <span style="color:#f92672">=</span> class_names[predicted_id]
</code></pre></div><p>Predict as you did earlier, get the maximum value and label it.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">label_id <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>argmax(label_batch, axis<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>)
</code></pre></div><p>Keep a label for the correct answer</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">10</span>,<span style="color:#ae81ff">9</span>))
plt<span style="color:#f92672">.</span>subplots_adjust(hspace<span style="color:#f92672">=</span><span style="color:#ae81ff">0.5</span>)
<span style="color:#66d9ef">for</span> n <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">30</span>):
  plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">6</span>,<span style="color:#ae81ff">5</span>,n<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>)
  plt<span style="color:#f92672">.</span>imshow(image_batch[n])
  color <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;green&#34;</span> <span style="color:#66d9ef">if</span> predicted_id[n] <span style="color:#f92672">==</span> label_id[n] <span style="color:#66d9ef">else</span> <span style="color:#e6db74">&#34;red&#34;</span>
  plt<span style="color:#f92672">.</span>title(predicted_label_batch[n]<span style="color:#f92672">.</span>title(), color<span style="color:#f92672">=</span>color)
  plt<span style="color:#f92672">.</span>axis(<span style="color:#e6db74">&#39;off&#39;</span>)
_ <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>suptitle(<span style="color:#e6db74">&#34;Model predictions (green: correct, red: incorrect)&#34;</span>)
</code></pre></div><p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1979/23a7818b-7e87-049e-3c6d-411091fbdb21.png" alt="output_wC_AYRJU9NQe_0.png"></p>
<p>It outputs green when the answer is correct and red when it fails.
Isn&rsquo;t it correct? Yosage.</p>
<p>After this, the tutorial continues for a little while the export of the learned model etc. is written, but this is the only time to use it, so I will omit it from this point on.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1979/b8644d26-1985-173b-62b1-fa3f01d905ed.png" alt="cooking_cumin_seed.png"></p>
<h1 id="make-your-own-classifier">Make your own classifier</h1>
<p>Now, let&rsquo;s create your own classifier using the code given in the tutorial. This time, I will make a goal by moving up to Colab.</p>
<h2 id="image-collection">Image collection</h2>
<p>Image collection is essential for image classification.</p>
<h3 id="download-image">Download image</h3>
<p><a href="https://github.com/hardikvasa/google-images-download">google-images-download</a>isconvenient.(Becarefulaboutthelicenseofthedownloadedimage)</p>
<p>Since it can be installed via pip, I think it can be used as follows on mac.</p>
<pre><code>pip install google_images_download
googleimagesdownload --keywords &quot;images you want to find&quot;
</code></pre><h3 id="image-selection">Image selection</h3>
<p>If you try to use the downloaded images as they are, you will not be able to use them because there is too much dust.
So, let&rsquo;s remove the strange images while looking at each image one by one.
This task was the most difficult..</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1979/2bc5db1b-35e9-5df7-9d2f-5a9b537bb6b5.png" alt="image.png">
In the end, let&rsquo;s create a state in which specific images that are clean in each directory are collected like this.</p>
<h3 id="package-and-upload">Package and upload</h3>
<p>For the time being, let&rsquo;s upload the tar-compressed file somewhere so that it can be downloaded from Colab. I turned it up to Google Drive.
In the case of Google Drive, after uploading tar.gz, get a sharable link and replace its ID part with the following link.
<code>https://drive.google.com/uc?export=download&amp;id=XXXXXXXXXXXXXXXXXXXXX</code></p>
<h2 id="reflected-in-colab-code">Reflected in Colab code</h2>
<p>I have prepared a Colab file that extracts only the part that makes the classifier, so please replace xxxx.
<a href="https://colab.research.google.com/gist/NaoyaTabakomori/089f66284d583ff9c908e819c11727bc/.ipynb#forceEdit=true&amp;sandboxMode=true&amp;scrollTo=IwBLpCtK-s8f"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a></p>
<p>Did it work well?</p>
<p>This is what I have.
<img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1979/e059416c-75c9-1c82-c022-2772b04701d7.png" alt="image (85).png"></p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1979/d49988c6-83af-d88c-6c80-817f9a26eeda.png" alt="spice_clove.png"></p>
<h1 id="in-conclusion">in conclusion</h1>
<p>Although I was able to experience the upper side of machine learning, I think that it is an image of a classifier that I want the photos taken by myself to be classified.
I&rsquo;d like to build an environment at hand and try to create something more casual. I will hang on.</p>

    </article>
  </div>

  
  
  
  <script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-169005401-1', 'auto');
  ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  

  
<link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.css" />
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#216942",
      "text": "#b2d192"
    },
    "button": {
      "background": "#afed71"
    }
  }
})});
</script>

</body>

</html>
