<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  <meta name="generator" content="Hugo 0.72.0" />

  
  <meta name="description" content="Some description">
  

  
  <link rel="apple-touch-icon" sizes="180x180" href="https://memotut.com/apple-touch-icon.png">

  
  <link rel="icon" type="image/png" sizes="32x32" href="https://memotut.com/favicon-32x32.png">

  
  <link rel="icon" type="image/png" sizes="16x16" href="https://memotut.com/favicon-16x16.png">

  
  <link rel="manifest" href="https://memotut.com/site.webmanifest">

  
  <link rel="mask-icon" href="https://memotut.com/safari-pinned-tab.svg" color="#5bbad5">

  <meta name="msapplication-TileColor" content="#da532c">

  <meta name="theme-color" content="#ffffff">

  
  <link rel="stylesheet" href="https://memotut.com/css/bootstrap.min.css" />

  
  <title>I want to understand (engineering) UMAP, which is stronger than t-SNE | Memo Tut</title>
  

  <style>
body {
  min-width: 300px;
}

.custom-navbar {
  margin-bottom: 1em;
  height: 60px;
}

.custom-navbar a {
  display: inline-block; 
  padding: 18px 0;
  margin-right: 1em; 
  font-weight: bold; 
}

.custom-navbar a:hover,
.custom-navbar a:focus {
  text-decoration: none; 
}

@media print {
  .custom-navbar {
    display: none;
  }
}

article {
  padding-bottom: 1em;
}

img {
  max-width: 100%;
}


body {
  background-color: #fff;
}



body {
  color: #212529;
}



a {
  color: #007bff;
}



a:hover,
a:focus {
  color: #0056b3;
}



.custom-navbar {
  background-color: #212529;
}



.custom-navbar a {
  color: rgba(255, 255, 255, 0.75);
}



.custom-navbar a:hover,
.custom-navbar a:focus {
  color: rgba(255, 255, 255, 1);
}



.container {
  max-width: 800px;
}



pre {
  display: block;
  padding: 9.5px;
  word-break: break-all;
  word-wrap: break-word;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre code {
  padding: 0;
  font-size: inherit;
  color: inherit; 
  white-space: pre-wrap;
  background-color: transparent;
  border: none;
  border-radius: 0;
}

code {
  padding: 2px 4px;
  color: inherit; 
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
  font-size: .9em;
}



blockquote,
.blockquote {
  padding: 10px 20px;
  margin: 0 0 20px;
  font-size: 1em;
  border-left: 5px solid #6c757d;
}

</style>
</head>

<body>
  <nav class="custom-navbar">
  <div class="container">
    
    <a href="/">Posts</a>
    
    <a href="/tags/">Tags</a>
    
    <a href="/about/">About</a>
    
    <a href="/index.xml">RSS</a>
    
  </div>
</nav>
  
  <div class="container">
    <article>
      <h1>I want to understand (engineering) UMAP, which is stronger than t-SNE</h1>
<p>
  <small class="text-secondary">
  
  
  Feb 18, 2020
  </small>
  

<small><code><a href="https://memotut.com/tags/python">Python</a></code></small>


<small><code><a href="https://memotut.com/tags/algorithm"> Algorithm</a></code></small>


<small><code><a href="https://memotut.com/tags/machine-learning"> Machine Learning</a></code></small>


<small><code><a href="https://memotut.com/tags/kaggle"> Kaggle</a></code></small>

</p>
<pre><code>Do you know UMAP?
</code></pre>
<p>I know</p>
<p>If you&rsquo;ve heard it but don&rsquo;t know it, this article will help you understand it.</p>
<p>#What is UMAP</p>
<p><strong>It is a method to reduce and visualize dimensions faster and with higher performance than t-SNE</strong>. Compare with the commonly used t-SNE. The following figure is a visualization of Fashion MNIST.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/305855/6b2abc15-4354-6449-24c5-4a3623d35985.jpeg" alt="umap_vs_tsne.jpg">
(From <a href="https://pair-code.github.io/understanding-umap/">Understanding UMAP</a>)</p>
<p>Compared to t-SNE, UMAP seems to have distinct clusters. Similar categories are placed near each other and dissimilar categories are placed far away. (There are many visualization examples in <a href="https://pair-code.github.io/understanding-umap/">Understanding UMAP</a> explanations, so please see there for more details. You can go around the 3D diagram above to see them.)
<br></p>
<p><strong>UMAP has almost constant execution time</strong> regardless of the embedded dimension. Since the execution time does not increase exponentially even if the embedded dimension increases like t-SNE, it can be used not only for visualization but also for dimension reduction. Also, UMAP written in Python is faster than the fast implementation of t-SNE called FIt-SNE in C++.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/305855/b3d42839-db70-6458-6849-6ea9f65b246c.jpeg" alt="umap_fig5-1581396556877.jpg"></p>
<p>And ** support for embedding new samples **. In the case of t-SNE, it was difficult to add new data to the low-dimensional space, and the whole process had to be performed again. On the other hand, in UMAP, it is only necessary to calculate the difference and it can be embedded naturally.</p>
<p>**It&rsquo;s very easy if you just want to use it as a tool. ** (code from [official document] <a href="https://umap-learn.readthedocs.io/en/latest/basic_usage.html">howToUseUMAP</a>)</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#960050;background-color:#1e0010">!</span>pip install umap<span style="color:#f92672">-</span>learn

<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">from</span> sklearn.datasets <span style="color:#f92672">import</span> load_digits
<span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#f92672">as</span> plt
<span style="color:#f92672">import</span> umap

Try <span style="color:#66d9ef">with</span> <span style="color:#75715e"># Digits</span>
digits <span style="color:#f92672">=</span> load_digits()

Reduced to <span style="color:#ae81ff">2</span>D <span style="color:#66d9ef">with</span> <span style="color:#75715e"># umap</span>
reducer <span style="color:#f92672">=</span> umap<span style="color:#f92672">.</span>UMAP(random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">42</span>)
reducer<span style="color:#f92672">.</span>fit(digits<span style="color:#f92672">.</span>data)
embedding <span style="color:#f92672">=</span> reducer<span style="color:#f92672">.</span>transform(digits<span style="color:#f92672">.</span>data)

<span style="color:#75715e"># plot</span>
plt<span style="color:#f92672">.</span>scatter(embedding[:, <span style="color:#ae81ff">0</span>], embedding[:, <span style="color:#ae81ff">1</span>], c<span style="color:#f92672">=</span>digits<span style="color:#f92672">.</span>target, cmap<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Spectral&#39;</span>, s<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>)
plt<span style="color:#f92672">.</span>gca()<span style="color:#f92672">.</span>set_aspect(<span style="color:#e6db74">&#39;equal&#39;</span>,<span style="color:#e6db74">&#39;datalim&#39;</span>)
plt<span style="color:#f92672">.</span>colorbar(boundaries<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>arange(<span style="color:#ae81ff">11</span>)<span style="color:#f92672">-</span><span style="color:#ae81ff">0.5</span>)<span style="color:#f92672">.</span>set_ticks(np<span style="color:#f92672">.</span>arange(<span style="color:#ae81ff">10</span>))
plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#39;UMAP projection of the Digits dataset&#39;</span>, fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">24</span>);
</code></pre></div><p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/305855/4782b062-10a8-ae5a-7b1e-3d2d1eecb103.png" alt="umap4digits.png">
<br></p>
<p>In addition, it can be executed in a realistic time even for a very large amount of data. The figure below is a visualization of a binary vector obtained by factorizing 30 million integers as input. (I don&rsquo;t know if it makes sense but it&rsquo;s cool)</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/305855/dbbe946b-a1cf-686d-a4c1-0532b2deea93.jpeg" alt="umap_fig9.jpg"></p>
<p>If you are satisfied with this, this is the end. Please use it conveniently as a tool.</p>
<p>#Existing method</p>
<p>Before getting into the explanation of UMAP, <strong>check the existing methods</strong>.</p>
<p>Many dimension reduction methods have been proposed so far. It is required to be able to retain the global structure and local structure of data. And recently, some calculation speed is also required.</p>
<h2 id="linear-method-pca-etc">Linear method (PCA, etc.)</h2>
<p>Works well for artificial data, but poor performance for high-dimensional real data. Swiss-roll doesn&rsquo;t work.</p>
<h2 id="non-linear-method">Non-linear method</h2>
<p>UMAP belongs here.</p>
<ul>
<li>Isomap</li>
<li>LLE</li>
<li>Laplacian Eignmap</li>
<li>t-SNE</li>
<li>LargeVis</li>
</ul>
<p>Among them, **t-SNE is often used as a method ** that can maintain both global and local structures. However, there was a problem in execution time, and LargeVis etc. were proposed to solve it. In this article, I&rsquo;ll try to explain the engineering of UMAP, but if you know Isomap and t-SNE to some extent, it will be easier to understand. The papers listed in the existing methods are summarized in <a href="#References">References</a>.</p>
<p>Definition of # character</p>
<p>I will define some for the future.</p>
<ul>
<li>Number of data $N$</li>
<li>$n$ dimension high-dimensional data set $X$
-$X = \{x_1, x_2, &hellip;, x_N\}, ; x_i \in \mathbb{R}^n$</li>
<li>$m$ dimension low-dimensional data set $Y$ ($m &laquo; n$)
-$Y = \{y_1, y_2, &hellip;, y_N\}, ; y_i \in \mathbb{R}^m$</li>
</ul>
<p>Hereinafter, these characters will be used without special notice.</p>
<h1 id="umap-engineering-understanding">UMAP engineering understanding</h1>
<p>First, let&rsquo;s reconfirm the purpose of UMAP.</p>
<p>** Convert high-dimensional data $X$ to low-dimensional data $Y$. However, the local structure and global structure of $X$ are converted and retained. **</p>
<p>UMAP papers cannot be truly understood without knowledge of mathematics. However, the thesis has instructions for people who do not have knowledge of mathematics. UMAP is based on advanced mathematics, but in reality <strong>UMAP can be regarded as graph creation and graph operation</strong>. This is because UMAP is based on a concept very similar to Isomap, t-SNE and LargeVis.</p>
<p>The flow of the method is the following two steps.</p>
<ol>
<li>Create a weighted k-nearest neighbor graph</li>
<li>Arrange the graph in low dimensions</li>
</ol>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/305855/3a3d1c8d-4ce3-b5ba-d753-98207c501cd1.jpeg" alt="typicalPipeline_largeVis.jpg">
The figure is from <a href="https://arxiv.org/abs/1602.00370">LargeVis paper</a> <a href="https://arxiv.org/abs/1602.00370">LargeVis paper</a></p>
<p>Step 1 focuses on the local structure of the data. Then, in step 2, the graph constructed based on the local structure is arranged so as to represent the global structure. Since the measurement point distance can be locally regarded as the Euclidean distance in the manifold, the neighborhood bluff can also be an image using the Euclidean distance. (Actually, you can use not only distance but also dissimilarity.)</p>
<p>Let&rsquo;s look at them in order.</p>
<h2 id="1-create-a-weighted-k-neighborhood-graph">1. Create a weighted k-neighborhood graph</h2>
<h3 id="k-create-a-neighborhood-graph">①k Create a neighborhood graph</h3>
<p>First, let&rsquo;s create a neighborhood graph without weighting. Distance (metrics) $d$ is defined to find the neighborhood (Imagine Euclidean distance etc.).</p>
<p>Then, we write k neighborhoods in the metric $d$ of $x_i$ as follows.
$\{x_{i_1}, &hellip;, x_{i_k}\}$</p>
<p>The neighborhood search may use the usual k-nearest neighbor method, but UMAP uses an approximate method. It costs $O(N^2)$ in the usual k-nearest neighbor method, but it becomes faster to $O(N^{1.14})$ in the approximation method. For details, see Reference [Forefront of approximate nearest neighbor search] <a href="https://speakerdeck.com/matsui_528/jin-si-zui-jin-bang-tan-suo-falsezui-qian-xian">approximation knn</a>.</p>
<p>After the neighborhood search is completed, the neighborhoods are separated by edges to create a k-neighborhood graph. That is, the edge set $E$ and the vertex set $V$ are defined as follows.</p>
<p>$E = \{(x_i, x_{i_j}) ; | ; 0\leq i \leq N, , 0\leq j \leq k \}$
$V$ corresponds to each point in the data.</p>
<p>In this way, we have a directed k-neighborhood graph $G_1$ with no weight. $G_1=(V, E)$</p>
<p>To summarize,
** In “(1) Create a k-nearest neighbor graph”, we searched k neighbors for each $x_i$ of the high-dimensional data $X$ and created a weighted directed k-nearest neighbor graph $G_1$. **</p>
<h3 id="-create-a-weighted-k-neighborhood-graph">➁ Create a weighted k-neighborhood graph</h3>
<p>To add weight, we first define the weight function $w$. The right side is normalized by $\rho_i$ and $\sigma_i$.</p>
<p>$w((x_i, x_{i_j})) = \exp(\dfrac{-\max(0, , d(x_i, x_{i_j})-\rho_i)}{\sigma_i})$</p>
<p>Where $\rho_i$ is the distance from the nearest neighbor.
$\rho_i = \min\{d(x_i, x_{i_j}) ; |; 1\leq j \leq k \}$</p>
<p>In addition, $\sigma_i$ is obtained by a two-part search so as to satisfy the following formula.
$\Sigma_j w((x_i, x_{i_j})) = \log_2 (k)$
The $\log_2(k)$ on the right side is empirically obtained.</p>
<p>(This $log_2{k}$ isn&rsquo;t good, but I think it&rsquo;s the meaning of t-SNE&rsquo;s perplexity because the variance is sought by a two-part search.)</p>
<p>Create a directed weighted graph $G_2$ using the weighting function.
$G_2 = (V, E, w)$</p>
<p>However, I do not use this $G_2$ as it is. Create an undirected graph $G$ by the following transformations.
$A$: Adjacency matrix of $G_2$
$B = A+A^T-A\circ A^T, \circ: Hadamard product $</p>
<p>If you look at the element of $B$, you can see that it is targeting.
$B_{i,l} = w((x_i, x_l)) + w((x_l, x_i))-w((x_i, x_l))*w((x_l, x_i)) \ = B_{l. i}$</p>
<p>(I think this is the same as t-SNE symmetrizing the conditional probability of SNE. The cost function becomes easy to handle.)</p>
<p>Create a graph $G$ using the thus created $B$ as an adjacency matrix. This graph $G$ is arranged in low dimensions in step ➂.</p>
<p>To summarize,
** In &ldquo;➁ Creating a weighted k-nearest neighbor graph&rdquo;, we created a weighted and undirected k-nearest neighbor graph $G$**.</p>
<h2 id="2-place-in-low-dimension">2. Place in low dimension</h2>
<p>Now that we have the adjacency matrix, we want to place it in the low-dimensional space. However, the method of drawing a graph from an adjacency matrix is not unique. Look at the two figures below.<img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/305855/0c94c7c3-4924-0757-05da-fca87ed03022.jpeg" alt="dirty_vs_nice.jpg"></p>
<p>Both are visualizations of the same graph (images are [here] [mechanical model description]). Use <strong>dynamic model</strong> for clean placement. Since the explanation becomes long, the explanation of the dynamic model was written in [Qiita separate article (back side of graph drawing algorithm and Networkx)] [Qiita dynamic model]. In the dynamic model, the vertices are arranged in a good feeling by the following algorithm.</p>
<ol>
<li>Calculate the attractive/repulsive force acting between each vertex</li>
<li>Move the vertex based on the force calculated in 1. The amount of displacement to move is less than the temperature parameter $t$</li>
<li>Lower the temperature parameter</li>
<li>Repeat steps 1 to 3 a certain number of times</li>
</ol>
<p>Since it is necessary to define the attractive force and the repulsive force in the dynamic model, define it as follows. I&rsquo;ll explain why this expression is a little later, so I&rsquo;ll accept it and move on.</p>
<p>$f_a(y_i, y_j) = \dfrac{-2ab|y_i-y_j|^{2(b-1)}} {1+|y_i-y_j|^2} w((x_i, x_j) )(y_i-y_j)$</p>
<p>$f_r(y_i, y_j) = \dfrac{b} {(\epsilon + |y_i-y_j|^2)(1 + |y_i-y_j|^2)} (1-w((x_i, x_j))) (y_i-y_j)$</p>
<p>$a, b$: Hyper parameter
$\epsilon$: small value to avoid division by zero</p>
<p>However, UMAP streamlines the calculation of repulsive force. Considering a vertex $x_i$,</p>
<ul>
<li>The attractive force acts on the k neighbors</li>
<li>Repulsive force works on N-k other than near</li>
</ul>
<p>Generally $k&laquo;N$, so the calculation of repulsive force becomes a bottleneck. UMAP uses <strong>negative sampling</strong> to reduce the amount of calculation. Vertices that are not connected by edges are considered to be connected by negative edges.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/305855/7c2e56d2-cd0c-6851-8d34-fb0544619db1.jpeg" alt="negativeSampling.jpg"></p>
<p>Then, this negative edge is sampled with a good feeling and updated tentatively. UMAP uses the following vertex sampling distribution $P$. This can be approximated as a uniform distribution in a sufficiently large data set. (I don&rsquo;t know about this, so I would like you to tell me.)</p>
<p>$P(x_i) = \dfrac{ \sum_{{a \in A | d_0(a) = x_i}}{1-\mu(a)} }{ \sum_{{b\in A | d_0 (b) \neq x_i }}{1-\mu(b)} }$</p>
<p>$\mu$: Membership function ($\mu:A\rightarrow [0, 1]$, degree of belonging to $A$)
$A$: Fuzzy topological expression</p>
<p>Instead of using all negative edges when updating the constellation, some sampling and updating are performed. In other words, the algorithm is as follows.</p>
<ol>
<li>Calculate the attractive force acting between each vertex. <strong>Repulsive force is calculated by sampling with distribution $P$</strong>.</li>
<li>Move the vertex based on the force calculated in 1. The amount of displacement to move is less than the temperature parameter $t$</li>
<li>Lower the temperature parameter</li>
<li>Repeat steps 1 to 3 a certain number of times</li>
</ol>
<p>I don&rsquo;t know if the convergence is guaranteed, but empirically it seems to converge properly.</p>
<h1 id="is-this-understanding-completely-different-from-the-original-flow-">Is this understanding completely different from the original flow? ?</h1>
<p>&ldquo;UMAP&rsquo;s papers are insanely mathematical, but do you have an explanation for them now?&rdquo;</p>
<p>&ldquo;How do you relate to Fuzzy topology and Riemannian manifolds?&rdquo;</p>
<p>For those who think, write the relationship with the original flow. To do so, we first need to know the original mathematical flow&hellip;</p>
<h1 id="original-umap-flow">Original UMAP flow</h1>
<p>Those who have knowledge of mathematics should understand this process.</p>
<ol>
<li>Formulation</li>
<li>Derivation of cost function</li>
<li>Minimize the cost function and embed it in the lower dimension</li>
</ol>
<p>Let&rsquo;s take a quick look at each.</p>
<h2 id="1-formulation">1. Formulation</h2>
<p>To get an overview, I will cite a part from <a href="https://qiita.com/cympfh/items/e8c2669c646a73205ea9">Qiita reading UMAP paper</a> <a href="https://qiita.com/cympfh/items/e8c2669c646a73205ea9">Qiita reading UMAP paper</a>.</p>
<p>The following concepts are introduced in UMAP. (Hey)</p>
<blockquote>
<ol>
<li>fuzzy set
-Fuzzy set</li>
<li>simplicial set
-Refers to a complex</li>
<li>fuzzy simplicial set
-A combination of 1 and 2</li>
<li>FinReal
-Convert simplex to EPMet</li>
<li>FinSing
-Convert EPMet to fuzzy simplicial set</li>
</ol>
</blockquote>
<p>And define the operation to transform the sequence of points into a fuzzy topological expression.</p>
<blockquote>
<p>First, in Chapter 1, we described a method for estimating Riemannian manifolds from a sequence of data points.
However, we did not really estimate the shape of the manifold itself, but rather the distance over a finite space (FinEPMet).</p>
<p>In Section 3, we defined a fuzzy simplicial set that is a fuzzy complex, and defined operations for converting FinSing FinEPMet to fuzzy simplicial set.</p>
</blockquote>
<p>I&rsquo;m not sure if I just quote it, but I think it&rsquo;s probably because the mathematician says it (abandon understanding). For those who want to know this area, the following articles will be helpful. If you are comfortable with English, it is accurate to read the paper.</p>
<ul>
<li><a href="https://qiita.com/cympfh/items/e8c2669c646a73205ea9">Qiita reading UMAP paper</a> <a href="https://qiita.com/cympfh/items/e8c2669c646a73205ea9">Qiita reading UMAP paper</a></li>
<li>[UMAP commentary article] <a href="http://cympfh.cc/paper/UMAP.html">Article following UMAP formula</a></li>
</ul>
<h2 id="2-derivation-of-cost-function">2. Derivation of cost function</h2>
<p>The cross entropy of two Fuzzy topological expressions is defined as follows.</p>
<p>$C((A, \mu), (A, \nu)) \rightarrow \sum_{a \in A}{( \mu(a)\log(\nu(a)) + (1-\mu( a)) \log(1-\nu(a)) )}$</p>
<p>$\mu, \nu$: Membership function ($\mu:A\rightarrow [0, 1]$, degree of belonging to $A$)
$A$: Fuzzy topological expression</p>
<p>The equal sign is not used because the right side is an expression after omitting the part that is not related to the minimization. (See the paper for details.)</p>
<h2 id="3-minimize-the-cost-function-and-embed-it-in-the-lower-dimension">3. Minimize the cost function and embed it in the lower dimension</h2>
<ul>
<li>Convert high-dimensional data to fuzzy topological expression $X$</li>
<li>Convert low-dimensional data (embedding destination) to fuzzy topological expression $Y$ as well</li>
</ul>
<p>The low-dimensional data $Y$ is changed according to the gradient method so that the cross entropy between the fuzzy topological expressions is minimized. The resulting $Y$ is the visualization result or dimension reduction result.</p>
<p>To summarize roughly here,</p>
<p>**There is a cost function derived by a mathematician. **
**If this is minimized, low-dimensional embedding based on mathematics is possible. **</p>
<h1 id="connection-with-engineering-understanding-up-to-now">Connection with engineering understanding up to now</h1>
<p>&ldquo;What was the explanation about the k-neighborhood graph and the dynamic model just before?!&rdquo;
Thank you for waiting. <strong>The definition of attractive/repulsive force in the dynamic model is connected to the cost function</strong>.</p>
<p>The cost function can be written as</p>
<p>$C((A, \mu), (A, \nu)) \rightarrow \sum_{a \in A}{( \mu(a)\log(\nu(a)) + (1-\mu( a)) \log(1-\nu(a)) )}$</p>
<p>$\mu, \nu$: Membership function ($\mu:A\rightarrow [0, 1]$, degree of belonging to $A$)
$A$: Fuzzy topological expression</p>
<p>If you look closely at the equation, you can see the relationship with the dynamic model. Since $\mu$ is a membership function for higher-dimensional data, $\mu(a)$ belongs to $A$ and $(1-\mu(a))$ belongs to $A$. Not a degree. In other words, the first term of $\sum$ can be regarded as a term that acts on the neighborhood, and the second term can be regarded as a term that acts on other than the neighborhood.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/305855/8e1c6c62-6636-6d99-cac6-223f3cda69e9.jpeg" alt="costFunction.jpg"></p>
<p><strong>The attractive force and the repulsive force are calculated back from the cost function</strong>-like (not specified in the paper, but after deriving the cost function in the existing method, LargeVis, the term corresponding to the repulsive force is efficiently evaluated by negative sampling. Is calculated).</p>
<p>After all, mathematical knowledge is needed to approach the truth of the definition of attraction/repulsion. However, it seems that understanding &ldquo;making a graph and embedding it according to power&rdquo; is one step more advanced than understanding &ldquo;minimizing unknown cost functions&rdquo;.</p>
<h1 id="finally">Finally</h1>
<p>It&rsquo;s interesting that a mathematically difficult UMAP can be formulated with a simple (albeit slightly technical) mechanical model. This is the maximum understanding for those who have no background in mathematics (I). Since there is a part that I do not understand whether it has been explained, it would be helpful if you could point out the mistake by hitting the article without swallowing this article.</p>
<h1 id="references">References</h1>
<dl>
<dt>[UMAP:UniformManifold ApproximationandProjectionfor DimensionReduction,arXiv] [UMAP Papers]</dt>
<dd>Everything here</dd>
</dl>
<ul>
<li><a href="https://qiita.com/cympfh/items/e8c2669c646a73205ea9">Qiita reading UMAP paper</a> <a href="https://qiita.com/cympfh/items/e8c2669c646a73205ea9">Qiita reading UMAP paper</a></li>
<li>[UMAP commentary article] <a href="http://cympfh.cc/paper/UMAP.html">Article following UMAP formula</a>
: These two are articles trying to understand mathematical formulas</li>
</ul>
<dl>
<dt><a href="https://pair-code.github.io/understanding-umap/">Understanding UMAP</a></dt>
<dd>Easy to understand with abundant diagrams. It&rsquo;s interesting just to look at it, so please see it.</dd>
</dl>
<ul>
<li><a href="https://umap-learn.readthedocs.io/en/latest/">UMAP document</a> <a href="https://umap-learn.readthedocs.io/en/latest/">UMAP document</a></li>
<li><a href="https://umap-learn.readthedocs.io/en/latest/basic_usage.html">HowToUseUMAP</a>
: Look here if you want to use it as a tool</li>
</ul>
<dl>
<dt>[Dimensionality reduction with t-SNE(Rtsne) and UMAP(uwot) using R packages.] [From tSNE to UMAP (I tried it)]</dt>
<dd>Get an overview of t-SNE and UMAP. Practical&gt; Theory</dd>
<dt>[Backside of graph drawing algorithm and Networkx] [Qiita dynamic model]</dt>
<dd>Explanation of a typical dynamic model algorithm. (My article)</dd>
<dt>[Forefront of approximate nearest neighbor search] <a href="https://speakerdeck.com/matsui_528/jin-si-zui-jin-bang-tan-suo-falsezui-qian-xian">Approximation knn</a></dt>
<dd>Spatial division by tree, hash, and hypothesis that &ldquo;neighborhood is also neighbor&rdquo; is interesting.</dd>
</dl>
<p>Also, reading the following papers will deepen your understanding.</p>
<ul>
<li>[Barns-Hut-SNE] <a href="https://arxiv.org/abs/1301.3342">Barns-Hut-SNE Paper</a></li>
<li><a href="http://www.jmlr.org/papers/v9/vandermaaten08a.html">(t-SNE)Visualizing Data using t-SNE</a>-[(LargeVis) Visualizing Large-scale and High-dimensional Data] <a href="https://arxiv.org/abs/1602.00370">LargeVis paper</a></li>
<li><a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/spe.4380211102">(fruchterman-reingold algorithm) Graph drawing by force‐directed placement</a></li>
</ul>

    </article>
  </div>

  
  
  
  <script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-169005401-1', 'auto');
  ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  

  
<link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.css" />
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#216942",
      "text": "#b2d192"
    },
    "button": {
      "background": "#afed71"
    }
  }
})});
</script>

</body>

</html>
