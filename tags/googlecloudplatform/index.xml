<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>GoogleCloudPlatform on Memo Tut</title>
    <link>https://memotut.com/tags/googlecloudplatform/</link>
    <description>Recent content in GoogleCloudPlatform on Memo Tut</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 13 Jan 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://memotut.com/tags/googlecloudplatform/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>[BigQuery] How to use BigQuery&#39;s API for Python -Table creation-</title>
      <link>https://memotut.com/bigquery-how-to-use-bigquerys-api-for-python-table-creation-0e00f/</link>
      <pubDate>Mon, 13 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/bigquery-how-to-use-bigquerys-api-for-python-table-creation-0e00f/</guid>
      <description># In line 5   Data scientists usually analyze with Jupyter Therefore, there is a desire to process DB as well on Jupyter Therefore it is more convenient to use BigQuery on Jupyter via library instead of WebUI or REST API. I decided to investigate the function of the official library google.cloud.bigquery to achieve the above Below is a summary of how to create tables in BigQuery  #Preparation</description>
    </item>
    
    <item>
      <title>Google Cloud Speech API vs. Amazon Transcribe</title>
      <link>https://memotut.com/google-cloud-speech-api-vs.-amazon-transcribe-03729/</link>
      <pubDate>Sat, 11 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/google-cloud-speech-api-vs.-amazon-transcribe-03729/</guid>
      <description>## Transcription API Gachinko Battle  In the range of &amp;ldquo;Transcription API comparison&amp;rdquo; that is easy to see in Gugu, there are many articles that say good/bad by performing very short transcription at the level of several lines (or minutes). Or, there are many things we do for &amp;ldquo;too clear sound sources&amp;rdquo; such as news videos. The Blog that buzzed about Amazon Transcribe also tells highly accurate transcriptions in English. It is well known that English is highly accurate in the field of natural language processing, but I am worried about how it is Japanese.</description>
    </item>
    
    <item>
      <title>Investigation of relationship between voice preprocessing and transcription accuracy in Google Cloud Speech API</title>
      <link>https://memotut.com/investigation-of-relationship-between-voice-preprocessing-and-transcription-accuracy-in-google-cloud-speech-api-cfbfa/</link>
      <pubDate>Thu, 02 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/investigation-of-relationship-between-voice-preprocessing-and-transcription-accuracy-in-google-cloud-speech-api-cfbfa/</guid>
      <description>## Transcription accuracy is lower than expected  As I mentioned at the end of the previous article that summarized How to use Google Speech API, I encountered a problem that the character recognition accuracy is lower than I expected. It was.
It seems that about 80% can be transcribed in rebuild.fm, but in my case not even half recognized by experience It&amp;rsquo;s an impression. Even though it wasn&amp;rsquo;t perfect, I was hoping that reading the transcribed text would give me a sense of what the conversation was about, but it was pretty devastating.</description>
    </item>
    
    <item>
      <title>Speech transcription procedure using Python and Google Cloud Speech API</title>
      <link>https://memotut.com/speech-transcription-procedure-using-python-and-google-cloud-speech-api-bc22e/</link>
      <pubDate>Sun, 15 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/speech-transcription-procedure-using-python-and-google-cloud-speech-api-bc22e/</guid>
      <description>![Screenshot 2019-12-15 16.20.07.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/100780/160e795f-1baf-4446-2331-(eb4d0e37dbeb.png)  I have a podcast called Platinum Mining Industry.FM, so I tried Google Cloud Speech API this time to transcribe the voice data. (*Google&amp;rsquo;s transcription API is officially shaking with the names &amp;ldquo;Google Cloud Speech API&amp;rdquo; and &amp;ldquo;Cloud Speech-to-Text. Maybe they are together. Mystery.&amp;quot;)
Please refer to here for the procedure to create recording and audio data.
 [Fiscal 2019 version] Introduction to Podcast distribution for those who aim for the minimum beautiful sound quality with the minimum effort-Qiita  The following blogs are the most detailed on how to use the Google Cloud Speech API.</description>
    </item>
    
    <item>
      <title>Judging food photos using Google Cloud Vision API</title>
      <link>https://memotut.com/judging-food-photos-using-google-cloud-vision-api-a679e/</link>
      <pubDate>Thu, 12 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/judging-food-photos-using-google-cloud-vision-api-a679e/</guid>
      <description>This article is the 12th day article of [Fujitsu Systems Web Technology Advent Calendar](https://qiita.com/advent-calendar/2019/fsweb).  (Promise) The content of this article is my own opinion, not representative of the organization to which it belongs.
#Introduction This article summarizes the minimum procedure for using Google&amp;rsquo;s image recognition API &amp;ldquo;Cloud Vision API&amp;rdquo;. Lastly, I am trying to judge food photos.
Aside My personal hobby is Mesitello 1, and I post food photos on the LINE timeline to make me think &amp;ldquo;I&amp;rsquo;m hungry&amp;rdquo;.</description>
    </item>
    
    <item>
      <title>Automatically access the flow in enebular and pull the trigger</title>
      <link>https://memotut.com/automatically-access-the-flow-in-enebular-and-pull-the-trigger-99d65/</link>
      <pubDate>Tue, 26 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/automatically-access-the-flow-in-enebular-and-pull-the-trigger-99d65/</guid>
      <description>My name is Nyamugi and I am in charge of the second day of [enebular Advent Calendar 2019](https://qiita.com/advent-calendar/2019/enebular).  This time I would like to introduce how to automatically access http://enebular.com/app and pull the trigger of the flow.
Way Scraping
Trigger The Node-RED flow created with enebular is finally deployed to some device or service. There is a flow on enebular, but it&amp;rsquo;s a waste to not use it&amp;hellip; So, if the flow can be automatically opened and executed, can it be used?</description>
    </item>
    
  </channel>
</rss>