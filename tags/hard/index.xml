<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title> Hard on Memo Tut</title>
    <link>https://memotut.com/tags/hard/</link>
    <description>Recent content in  Hard on Memo Tut</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 23 May 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://memotut.com/tags/hard/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>How to easily draw the structure of neural network on Google Colaboratory using convnet-drawer</title>
      <link>https://memotut.com/how-to-easily-draw-the-structure-of-neural-network-on-google-colaboratory-using-convnet-drawer-d2b6d/</link>
      <pubDate>Sat, 23 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/how-to-easily-draw-the-structure-of-neural-network-on-google-colaboratory-using-convnet-drawer-d2b6d/</guid>
      <description>&amp;lt;img width=&amp;quot;498&amp;quot; alt=&amp;quot;nn-draw.png&amp;quot; src=&amp;quot;https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/81919/087786b6-8954-4811-b377-f781f3fe7881.png&amp;quot;&amp;gt;  What is &amp;ldquo;convnet-drawer&amp;rdquo;? It is a software that visualizes the structure of the neural network created by @yu4u. I knew it existed before, but I hadn&amp;rsquo;t tried it yet, so I tried it. It felt good to run on Google Colaboratory (Google Colab), so I also created a notebook that you can try easily.
Please refer to the following blog article for explanations about Google Colab.</description>
    </item>
    
    <item>
      <title>Japanese preprocessing for machine learning</title>
      <link>https://memotut.com/japanese-preprocessing-for-machine-learning-0daf9/</link>
      <pubDate>Wed, 29 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/japanese-preprocessing-for-machine-learning-0daf9/</guid>
      <description>#Introduction  A memorandum when creating a simple neural network with text as training data in order to understand the mechanism of a chatbot using machine learning.
#Purpose Apply the rule-based chatbot created in English text to Japanese text to operate. Preprocess the Japanese text and make sure it can be passed through the neural network. As training data, Web scraping of support pages related to Niantic&amp;rsquo;s &amp;ldquo;Pokemon GO&amp;rdquo; was used.</description>
    </item>
    
    <item>
      <title>I want to use activation function Mish</title>
      <link>https://memotut.com/i-want-to-use-activation-function-mish-e6e29/</link>
      <pubDate>Sun, 23 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/i-want-to-use-activation-function-mish-e6e29/</guid>
      <description>## New activation function Mish   Below, GitHub where Mish writer&amp;rsquo;s implementation is written  GitHub-digantamisra98/Mish: Mish: A Self Regularized Non-Monotonic Neural Activation Function
This seems to be an implementation of Tensorflow-Keras Mish/mish.py at master ·digantamisra98/Mish ·GitHub
I don&amp;rsquo;t know what&amp;rsquo;s difficult  Run on google cola boratory keras/mnist_cnn.py at master · keras-team/keras · GitHub Run with the above CNN code Replaced ReLU with Mish Copy and paste the Tensorflow-Keras Implementation of Mish class  There was a detailed implementation of pytorch and Keras written here&amp;hellip;  I did my best to copy and paste, but see below https://towardsdatascience.</description>
    </item>
    
    <item>
      <title>A science university student started studying deep learning in his spare time</title>
      <link>https://memotut.com/a-science-university-student-started-studying-deep-learning-in-his-spare-time-30329/</link>
      <pubDate>Fri, 21 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/a-science-university-student-started-studying-deep-learning-in-his-spare-time-30329/</guid>
      <description>#Introduction  My specs I gave the title &amp;ldquo;Science University Student&amp;rdquo;, but I think there is a punch like &amp;ldquo;I&amp;rsquo;m actually an information student&amp;rdquo; only in these articles. If so, it will be an article that hopeless for university students who are not information systems, so I will clarify my features first. I am in the second year of university, belonging to the Department of Physics, Faculty of Science. I&amp;rsquo;m in the manufacturing circle, so programming (Python) is a bit of a bit of skill, but I&amp;rsquo;m just a beginner in deep learning**.</description>
    </item>
    
    <item>
      <title>Grad-CAMとdilated convolution</title>
      <link>https://memotut.com/grad-cam%E3%81%A8dilated-convolution-e9dfa/</link>
      <pubDate>Thu, 14 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/grad-cam%E3%81%A8dilated-convolution-e9dfa/</guid>
      <description>#Introduction  Grad-CAM is a good way to visualize where the model looks and discriminates. However, as a personal complaint, Grad-CAM has a low resolution of (14,14) for the image size (224,224). The reason why the resolution of Grad-CAM is low is that pooling is included 4 times in VGG16 model. However, except for the pooling layer, only the short-distance features of the image can be extracted, and the long-distance features cannot be extracted.</description>
    </item>
    
  </channel>
</rss>