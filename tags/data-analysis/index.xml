<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title> data analysis on Memo Tut</title>
    <link>https://memotut.com/tags/data-analysis/</link>
    <description>Recent content in  data analysis on Memo Tut</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 26 May 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://memotut.com/tags/data-analysis/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>[Python] Prediction of horse racing: If I thought that the collection rate exceeded 100% in machine learning (Light GBM), I did it</title>
      <link>https://memotut.com/prediction-of-horse-racing-if-i-thought-that-the-collection-rate-exceeded-100-in-machine-learning-light-gbm-i-did-it-3e099/</link>
      <pubDate>Tue, 26 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/prediction-of-horse-racing-if-i-thought-that-the-collection-rate-exceeded-100-in-machine-learning-light-gbm-i-did-it-3e099/</guid>
      <description>#Thank you  Note!!! This article is completely disguised
I&amp;rsquo;m sorry for the person who stocked it.
Thanks to @hal27 for pointing it out, thank you.
・What I did I made a fatal mistake from the scraping stage. I was going to get the data for the previous 3 races from the time of the race, but in fact I was getting the information for the latest 3 races from the scraping execution time.</description>
    </item>
    
    <item>
      <title>[Python] Simultaneous visualization of data and understanding of correlation</title>
      <link>https://memotut.com/simultaneous-visualization-of-data-and-understanding-of-correlation-649cf/</link>
      <pubDate>Wed, 20 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/simultaneous-visualization-of-data-and-understanding-of-correlation-649cf/</guid>
      <description>#Introduction  When analyzing data, I think you will visualize the data using graphs. At that time, it would be convenient if the statistics showing the correlation between two variables could be displayed at the same time. Therefore, we made it possible to display the appropriate statistics on the appropriate graph according to the content of the variable (category or numerical value).
Review so far I will summarize the appropriate graphing methods by content of variables and the statistics that show the correlation, which have been described so far.</description>
    </item>
    
    <item>
      <title>[Python] Causal reasoning using machine learning (arrangement of causal reasoning methods)</title>
      <link>https://memotut.com/causal-reasoning-using-machine-learning-arrangement-of-causal-reasoning-methods-fa213/</link>
      <pubDate>Sat, 16 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/causal-reasoning-using-machine-learning-arrangement-of-causal-reasoning-methods-fa213/</guid>
      <description># Causal reasoning using machine learning   A rough understanding and notes of when to use causal reasoning using machine learning methods that have been actively used in recent years (Memorandum) Basically, the current causal reasoning method is summarized as a flow chart.
 Introduction Causal reasoning is a series of statistical methods aimed at answering the cause of an outcome. Generally, statistical approaches such as regression analysis focus on quantifying how changes in X are related to changes in Y.</description>
    </item>
    
    <item>
      <title>[Python] Extract only Python for preprocessing</title>
      <link>https://memotut.com/extract-only-python-for-preprocessing-dad2f/</link>
      <pubDate>Sat, 09 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/extract-only-python-for-preprocessing-dad2f/</guid>
      <description>I&#39;ve been wandering around the code on the author&#39;s github each time, so I&#39;ll put it together for immediate use.  Original story Pre-processing Daizen [SQL/R/Python practice technique for data analysis]
https://github.com/ghmagazine/awesomebook
Extract the Python part from github below. See the book for detailed explanation.
Also, these source codes are licensed under the BSD 3 terms.
 BSD 3-Clause License
Copyright (c) 2018, Tomomitsu Motohashi All rights reserved.
 Data read # Read from library from preprocess.</description>
    </item>
    
    <item>
      <title>[Python] 5 Data Science Masterpieces You Can Learn for Free [Japanese books are not scared if you can speak English even if they are expensive]</title>
      <link>https://memotut.com/5-data-science-masterpieces-you-can-learn-for-free-japanese-books-are-not-scared-if-you-can-speak-english-even-if-they-are-expensive-5e5a7/</link>
      <pubDate>Thu, 07 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/5-data-science-masterpieces-you-can-learn-for-free-japanese-books-are-not-scared-if-you-can-speak-english-even-if-they-are-expensive-5e5a7/</guid>
      <description>#Let&#39;s study by this time  There are many generous organizations overseas, or there are many specialized books that can be read for free.
There are other summary articles of this series, I would like to display translated Japanese books and original books side by side. Especially introduced only in the field of data science.
Maybe that expensive original book is actually free?
(As of May 2020)
#1
Japanese: Basics of statistical learning (15,000 yen) It&amp;rsquo;s commonly called a &amp;ldquo;castella book.</description>
    </item>
    
    <item>
      <title>[Python] [Understand the shortest] Python basics for data analysis</title>
      <link>https://memotut.com/understand-the-shortest-python-basics-for-data-analysis-7d8f5/</link>
      <pubDate>Tue, 05 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/understand-the-shortest-python-basics-for-data-analysis-7d8f5/</guid>
      <description>#Introduction  For those who want to analyze data using Python &amp;hellip; or those who have decided to use Python for seminars and research but have never done programming &amp;hellip; Once you know this, the basics are okay for now (Maybe). I think it can be used as a review of knowledge. First, we will cover the basics of general-purpose Python syntax to a minimum, and then describe the basic tools and techniques used for data analysis.</description>
    </item>
    
    <item>
      <title>[Python] I have read 10 books related to time series data, so I write a book review.</title>
      <link>https://memotut.com/i-have-read-10-books-related-to-time-series-data-so-i-write-a-book-review.-58c3e/</link>
      <pubDate>Mon, 27 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/i-have-read-10-books-related-to-time-series-data-so-i-write-a-book-review.-58c3e/</guid>
      <description>#About the standing position of each book  I&amp;rsquo;m worried about what kind of axis to explain the standing position, but this time I tried to position it as &amp;ldquo;arbitrary and prejudiced&amp;rdquo; on the two axes of &amp;ldquo;target reader level&amp;rdquo; and &amp;ldquo;relationship with time series&amp;rdquo;.
#Introduction At work, I use various methods for various data regarding data analysis, but when I analyze it, there are surprisingly many time series data.</description>
    </item>
    
    <item>
      <title>[Python] I tried to predict Titanic survival on PyCaret</title>
      <link>https://memotut.com/i-tried-to-predict-titanic-survival-on-pycaret-a377f/</link>
      <pubDate>Sat, 25 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/i-tried-to-predict-titanic-survival-on-pycaret-a377f/</guid>
      <description>#Introduction  The other day, I tried using the machine learning library PyCaret that was released. Data feature analysis and performance comparison work with multiple models will be automated, and the work time of data scientists up to now will be considerably reduced.
This time, I will apply PyCaret to the Titanic survival prediction problem, submit the prediction result to Kaggle, and see the result.
**This is a follow-up article to I tried to classify wine quality with PyCaret, which I posted last time.</description>
    </item>
    
    <item>
      <title>[Python] I tried to classify the quality of wine with PyCaret</title>
      <link>https://memotut.com/i-tried-to-classify-the-quality-of-wine-with-pycaret-c8fa7/</link>
      <pubDate>Fri, 24 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/i-tried-to-classify-the-quality-of-wine-with-pycaret-c8fa7/</guid>
      <description>#Introduction  The other day, I tried using the machine learning library PyCaret that was released. Data feature analysis and performance comparison work with multiple models will be automated, and the work time of data scientists up to now will be considerably reduced.
#1. Install PyCaret
Run the following code to install. I use Anaconda, but I launched and installed a virtual environment dedicated to PyCaret. An error may occur in a virtual environment managed by an existing Conda.</description>
    </item>
    
    <item>
      <title>[Python] If Tokyo citizens become severely ill with the new coronavirus, they may be taken to a hospital in Kagoshima prefecture.</title>
      <link>https://memotut.com/if-tokyo-citizens-become-severely-ill-with-the-new-coronavirus-they-may-be-taken-to-a-hospital-in-kagoshima-prefecture.-b6391/</link>
      <pubDate>Fri, 24 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/if-tokyo-citizens-become-severely-ill-with-the-new-coronavirus-they-may-be-taken-to-a-hospital-in-kagoshima-prefecture.-b6391/</guid>
      <description>#table of contents  Introduction Current status of medical collapse risk Whether or not to secure beds for severely ill persons Severely ill transport model Delivery destination of severely ill Conclusion
#Introduction
 Background Infectious disease designated medical institutions are tight, and it is extremely difficult to secure sufficient beds to accommodate severely ill persons. In various places, measures have been taken to treat patients with mild illness at hotels, homes, etc.</description>
    </item>
    
    <item>
      <title>[Python] [The strongest English word book bomb ww] Automatically generate the English word book required by engineers in Python-Part 1</title>
      <link>https://memotut.com/the-strongest-english-word-book-bomb-ww-automatically-generate-the-english-word-book-required-by-engineers-in-python-part-1-5bf18/</link>
      <pubDate>Wed, 22 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/the-strongest-english-word-book-bomb-ww-automatically-generate-the-english-word-book-required-by-engineers-in-python-part-1-5bf18/</guid>
      <description>#Introduction  I think that everyone has bought once If you automatically create an English word book in Python,
 You don&#39;t need to buy an English word book anymore?  I will verify the hypothesis.   **If LGTM exceeds 10,** We will make more practical ones in the second part (or the second part), so please LGTM if you find it interesting~! About the author Biography After graduating from the Department of Electrical and Information Engineering at the age of 20, at a technical trading company, translating specifications etc.</description>
    </item>
    
    <item>
      <title>[Python] Free version of DataRobot! ? Introduction to library PyCaret that automates machine learning</title>
      <link>https://memotut.com/free-version-of-datarobot-introduction-to-library-pycaret-that-automates-machine-learning-62151/</link>
      <pubDate>Tue, 21 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/free-version-of-datarobot-introduction-to-library-pycaret-that-automates-machine-learning-62151/</guid>
      <description>What is #PyCaret  I recently saw an article called Announcing PyCaret 1.0.0 .. It was an interesting library, so in this article I will explain how to use PyCaret. **PyCaret is a Python library that enables data pre-processing, visualization, and model development with a few lines of code in machine learning model development. **
PyCaret is a Python wrapper for some of the major machine learning libraries (scikit-learn, XGBoost, LightGBM, etc.</description>
    </item>
    
    <item>
      <title>[Python] I tried to visualize the model with the low-code machine learning library PyCaret</title>
      <link>https://memotut.com/i-tried-to-visualize-the-model-with-the-low-code-machine-learning-library-pycaret-bdd48/</link>
      <pubDate>Tue, 21 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/i-tried-to-visualize-the-model-with-the-low-code-machine-learning-library-pycaret-bdd48/</guid>
      <description># Overview   PyCaret, a library for machine learning with low-code, has finally become v1.0. Visualization of machine learning model is convenient, so let&amp;rsquo;s focus on Visualization of model and summarize.  If you check Source,youcanseeYellowbrick@HP(Yellowbrick@qiita). *In addition, it is taken up by Qiita in PyCaret tags below.  I tried using PyCaret at the fastest speed Introduction to the library &amp;ldquo;PyCaret&amp;rdquo; that automates machine learning    things to do The enumeration is as follows, but it can be executed in a few lines by automation of pycaret.</description>
    </item>
    
    <item>
      <title>[Python] I tried using PyCaret at the fastest speed</title>
      <link>https://memotut.com/i-tried-using-pycaret-at-the-fastest-speed-5dd40/</link>
      <pubDate>Mon, 20 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/i-tried-using-pycaret-at-the-fastest-speed-5dd40/</guid>
      <description>#Introduction  Immediately, I tried using the machine learning library PyCaret released the other day. I realized that anyone can easily model. It was really easy! You can tune and predict from preprocessing without writing 10 lines of code! Although there are many parts that I have not understood yet such as arguments, I decided to write the article of PyCaret first. If you have any notes, please comment.
0. Environment and version  PyCaret 1.</description>
    </item>
    
    <item>
      <title>[Python] 18 beautiful Python terms you want to read aloud. R18 with example sentence</title>
      <link>https://memotut.com/18-beautiful-python-terms-you-want-to-read-aloud.-r18-with-example-sentence-519b2/</link>
      <pubDate>Wed, 04 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/18-beautiful-python-terms-you-want-to-read-aloud.-r18-with-example-sentence-519b2/</guid>
      <description>#Background  Python, which is known as a frozen tuna script language, It is also famous for its many beautifully named packages.
 PyPy pypan pypants  Reference: 7 Python terms to read aloud http://doloopwhile.hatenablog.com/entry/20120120/1327062714
Enchanted by these beautifully named packages, How beautifully named packages exist **I really decided to investigate. **
The reference information is a little old from 2012, If you look again now, you will surely find a more beautiful name!</description>
    </item>
    
    <item>
      <title>[Python] Books on data science to read in 2020</title>
      <link>https://memotut.com/books-on-data-science-to-read-in-2020-fe474/</link>
      <pubDate>Mon, 13 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/books-on-data-science-to-read-in-2020-fe474/</guid>
      <description>&amp;gt;This article was published in November 2019 by [Przemek Chojecki](https://towardsdatascience.com/@pchojecki),[[DataScienceBooksyoushouldreadin2020](https://towardsdatascience.com/data-science-books-you-should-read-in-2020-358f70e1d9b2)”.  This article is published with the permission of the original author.
Data science is arguably one of the hottest markets right now. Almost all companies are looking for or considering a data science role.
So it&amp;rsquo;s a great time to become a data scientist. Or if you&amp;rsquo;re already a data scientist and want to promote to a senior position, it&amp;rsquo;s a great time to hone your skills.</description>
    </item>
    
    <item>
      <title>[Python] Process huge excel files with Python to improve productivity</title>
      <link>https://memotut.com/process-huge-excel-files-with-python-to-improve-productivity-33983/</link>
      <pubDate>Wed, 25 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/process-huge-excel-files-with-python-to-improve-productivity-33983/</guid>
      <description>&amp;gt;This article was published in November 2019 by [Benedikt Droste](https://towardsdatascience.com/@droste.benedikt),&amp;quot;[BoostyourefficiencyandprocessExcel-fileswithPython](https://towardsdatascience.com/boost-your-efficiency-and-process-excel-files-with-python-cae650c85d6c)”.  This article is published with the permission of the original author.
When you&amp;rsquo;re working with data, you inevitably come into contact with Excel. Even if you don&amp;rsquo;t use it for yourself, it will be needed by clients and colleagues. Excel excels in spreadsheets with small datasets.
But I always lamented when I saw an Excel sheet with tens of thousands of rows and hundreds of columns.</description>
    </item>
    
    <item>
      <title>[Python] Data analysis Appropriate use of data analysis tools for beginners</title>
      <link>https://memotut.com/data-analysis-appropriate-use-of-data-analysis-tools-for-beginners-74218/</link>
      <pubDate>Tue, 24 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/data-analysis-appropriate-use-of-data-analysis-tools-for-beginners-74218/</guid>
      <description># Purpose of this article and target audience  There are many tools for data analysis. Here, data analysis tools include Excel, programming, dashboard tools, BI tools, etc.
In this article, for those who are new to data analysis and those who are going to do data analysis, we will explain what kind of analysis tool should be used for what kind of situation.
The most important reason to decide what kind of analysis tool to use in what situation is that the right tool can make data analysis efficient.</description>
    </item>
    
    <item>
      <title>[Python] I analyzed the data of the soccer FIFA World Cup Russia tournament with soccer action</title>
      <link>https://memotut.com/i-analyzed-the-data-of-the-soccer-fifa-world-cup-russia-tournament-with-soccer-action-7a5c9/</link>
      <pubDate>Wed, 18 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/i-analyzed-the-data-of-the-soccer-fifa-world-cup-russia-tournament-with-soccer-action-7a5c9/</guid>
      <description>**This is the 18th day article of ADVENT CALENDER of NTT DOCOMO Service Innovation Department. **  Hello! This is Osugi from NTT DoCoMo.
I spent soccer and futsal when I was a student, and now I am doing marketing related data analysis.
Today, I&amp;rsquo;d like to introduce socceraction, a python package for soccer, by analyzing the game data from the 2018 FIFA World Cup Russia tournament.
#Introduction socceraction is featured in the KDD2019 Appried Data Sciense Track Best Paper Award ”Actions Speak Louder than Goals: Valuing Player Actions in Soccer” [^1].</description>
    </item>
    
    <item>
      <title>[Python] Get Youtube data in Python using Youtube Data API</title>
      <link>https://memotut.com/get-youtube-data-in-python-using-youtube-data-api-7c98e/</link>
      <pubDate>Mon, 16 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/get-youtube-data-in-python-using-youtube-data-api-7c98e/</guid>
      <description>#Introduction  Recently, I am investigating whether various data can be acquired using API. Since I investigated and practiced how to get information such as the number of video views and likes using the Youtube Data API, I wrote a memorandum. #reference I have referred to the following when using the Youtube Data API.
 Youtube video search with Python Outline of YouTube Data API Youtube Data API Reference  #Preparing to use API ##Youtube Data API registration You need a Google account to get Youtube Data API.</description>
    </item>
    
    <item>
      <title>[Python] How to deal with imbalanced data</title>
      <link>https://memotut.com/how-to-deal-with-imbalanced-data-5eaad/</link>
      <pubDate>Fri, 06 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/how-to-deal-with-imbalanced-data-5eaad/</guid>
      <description>This is the article on the 10th day of the Advent Calendar of the DOCOMO Advanced Technology Research Institute.  My name is Kaneda from DoCoMo. In this article, I will explain the basics of evaluation methods and model building methods for imbalanced data that are often encountered in actual data analysis. Also, in the second half of the article, we are experimenting to better understand imbalanced data. I think there are many points that cannot be reached, but I would appreciate your favor.</description>
    </item>
    
    <item>
      <title>[Python] Knowledge and study methods required for future data analysts</title>
      <link>https://memotut.com/knowledge-and-study-methods-required-for-future-data-analysts-34359/</link>
      <pubDate>Tue, 03 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/knowledge-and-study-methods-required-for-future-data-analysts-34359/</guid>
      <description># Target audience and content  The target audience of this article is those who are going to analyze user behavior and sales data of companies, researchers who have to do a little tedious data analysis to do with Excel, and so on.
Background of the demand for &amp;ldquo;dick&amp;rdquo; data analysts In recent years, it has become very important for IT companies to analyze data and to make detailed improvements in UI and UX and implement growth hack measures.</description>
    </item>
    
    <item>
      <title>[Python] Understand and implement ridge regression (L2 regularization)</title>
      <link>https://memotut.com/understand-and-implement-ridge-regression-l2-regularization-d3124/</link>
      <pubDate>Sat, 30 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/understand-and-implement-ridge-regression-l2-regularization-d3124/</guid>
      <description>#Introduction  I studied regularization as a development of multiple regression analysis. This time I have summarized Ridge regression (L2 regularization).
##reference In understanding Ridge regression (L2 regularization), I have referred to the following.
 Essence of machine learningKoichiKato(Author) Publisher; SB Creative Co., Ltd. Type and purpose of regularization L1 regularization About L2 regularization Carefully the theory and implementation of Ridge regression and Lasso regression from the beginning  #Ridge regression (L2 regularization) overview</description>
    </item>
    
    <item>
      <title>[Python] [Verification] There is no easy way to exceed 100% recovery rate for horse racing just because it is deep-planned.</title>
      <link>https://memotut.com/verification-there-is-no-easy-way-to-exceed-100-recovery-rate-for-horse-racing-just-because-it-is-deep-planned.-3f215/</link>
      <pubDate>Sat, 16 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/verification-there-is-no-easy-way-to-exceed-100-recovery-rate-for-horse-racing-just-because-it-is-deep-planned.-3f215/</guid>
      <description># Now, the beginning of the mystery solving  Original article: With a deep learning, the recovery rate can exceed 100% in horse racing
First try to move I will purchase the program and try it. As described in the explanation, basically it worked with copy and paste, but the following two places did not work as they are, so I fixed it here.
 Parsing date data Column names of features used for learning and inference  It doesn&amp;rsquo;t look exactly the same because it contains random elements, but the graphs also moved in roughly the same way, so it seems to have been reproduced.</description>
    </item>
    
    <item>
      <title>[Python] How to speed up Pandas apply method with just one sentence (with verification calculation)</title>
      <link>https://memotut.com/how-to-speed-up-pandas-apply-method-with-just-one-sentence-with-verification-calculation-fc4d2/</link>
      <pubDate>Thu, 14 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/how-to-speed-up-pandas-apply-method-with-just-one-sentence-with-verification-calculation-fc4d2/</guid>
      <description>#Conclusion  Just add swifter method before Pandas apply method
Concrete example import pandas as pd import numpy as np import swifter # Create a suitable DataFrame df = pd.DataFrame({&amp;#39;col&amp;#39;: np.random.normal(size=10000000)}) # Add swifter method before apply method. %time df[&amp;#39;col2&amp;#39;] = df[&amp;#39;col&amp;#39;].swifter.apply(lambda x: x**2) # Wall time: 50 ms # For comparison (normal pandas apply method) %time df[&amp;#39;col2&amp;#39;] = df[&amp;#39;col&amp;#39;].apply(lambda x: x**2) # Wall time: 3.48 s How to install $ pip install -U pandas # upgrade pandas $ pip install swifter In case of ```terminal:conda $ conda update pandas # upgrade pandas $ conda install -c conda-forge swifter</description>
    </item>
    
    <item>
      <title>[Python] With deep learning, you can exceed 100% recovery rate in horse racing</title>
      <link>https://memotut.com/with-deep-learning-you-can-exceed-100-recovery-rate-in-horse-racing-334a8/</link>
      <pubDate>Sat, 09 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/with-deep-learning-you-can-exceed-100-recovery-rate-in-horse-racing-334a8/</guid>
      <description>![4370674310_b118d0f62a_c.jpg](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/280076/a136d9bb-956d-2b10-6418-85302ddbbc07.jpeg)  pohotos by Ronnie Macdonald
It&amp;rsquo;s been a while since I was told that &amp;ldquo;AI takes away human work&amp;rdquo; **, but now some people say that &amp;ldquo;I&amp;rsquo;m in a period of disillusionment&amp;rdquo; **. Thanks to that, I was not robbed of my work, and I am swayed by a crowded train every day. The scams that rob you are also a good thing.
While the development of such AI seems to take a little longer, it is now easy to obtain an environment for learning.</description>
    </item>
    
    <item>
      <title>[Python] Smoother pipeline processing in Luigi! Introducing gokart</title>
      <link>https://memotut.com/smoother-pipeline-processing-in-luigi-introducing-gokart-8cf0e/</link>
      <pubDate>Tue, 05 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/smoother-pipeline-processing-in-luigi-introducing-gokart-8cf0e/</guid>
      <description># what is this?  This is a summary article about gokart, a wrapper library for Luigi.
The motivation for development and basic usage are summarized in M3&amp;rsquo;s blog very carefully, and the basic usage is It&amp;rsquo;s a story that I should read this, but I wanted to summarize it as a reverse lookup reference, so I made an article.
The functions of Luigi itself are not explained so much.</description>
    </item>
    
    <item>
      <title>[Python] Understanding the k-means method</title>
      <link>https://memotut.com/understanding-the-k-means-method-0d5d2/</link>
      <pubDate>Sat, 02 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/understanding-the-k-means-method-0d5d2/</guid>
      <description>#Introduction  Here is a summary of what I learned about the k-means method. The most basic clustering algorithm.
##reference In understanding the k-means method, I have referred to the following.
 Introduction to machine learning for language processing (natural language processing series)DaiyaTakamura(Author),ManabuOkumura(supervision) Publisher; Corona Essence of machine learningKoichiKato(Author) Publisher; SB Creative Co., Ltd.  #k-means method overview
What is k-means method The k-means method is an algorithm that first divides the data into appropriate clusters, and then adjusts the data so that the data can be divided in a good manner using the average of the clusters.</description>
    </item>
    
  </channel>
</rss>