<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  <meta name="generator" content="Hugo 0.72.0" />

  
  <meta name="description" content="Some description">
  

  
  <link rel="apple-touch-icon" sizes="180x180" href="https://memotut.com/apple-touch-icon.png">

  
  <link rel="icon" type="image/png" sizes="32x32" href="https://memotut.com/favicon-32x32.png">

  
  <link rel="icon" type="image/png" sizes="16x16" href="https://memotut.com/favicon-16x16.png">

  
  <link rel="manifest" href="https://memotut.com/site.webmanifest">

  
  <link rel="mask-icon" href="https://memotut.com/safari-pinned-tab.svg" color="#5bbad5">

  <meta name="msapplication-TileColor" content="#da532c">

  <meta name="theme-color" content="#ffffff">

  
  <link rel="stylesheet" href="https://memotut.com/css/bootstrap.min.css" />

  
  <title>[Python] [Machine learning] Understand logistic regression from both scikit-learn and mathematics | Memo Tut</title>
  

  <style>
body {
  min-width: 300px;
}

.custom-navbar {
  margin-bottom: 1em;
  height: 60px;
}

.custom-navbar a {
  display: inline-block; 
  padding: 18px 0;
  margin-right: 1em; 
  font-weight: bold; 
}

.custom-navbar a:hover,
.custom-navbar a:focus {
  text-decoration: none; 
}

@media print {
  .custom-navbar {
    display: none;
  }
}

article {
  padding-bottom: 1em;
}

img {
  max-width: 100%;
}


body {
  background-color: #fff;
}



body {
  color: #212529;
}



a {
  color: #007bff;
}



a:hover,
a:focus {
  color: #0056b3;
}



.custom-navbar {
  background-color: #212529;
}



.custom-navbar a {
  color: rgba(255, 255, 255, 0.75);
}



.custom-navbar a:hover,
.custom-navbar a:focus {
  color: rgba(255, 255, 255, 1);
}



.container {
  max-width: 800px;
}



pre {
  display: block;
  padding: 9.5px;
  word-break: break-all;
  word-wrap: break-word;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre code {
  padding: 0;
  font-size: inherit;
  color: inherit; 
  white-space: pre-wrap;
  background-color: transparent;
  border: none;
  border-radius: 0;
}

code {
  padding: 2px 4px;
  color: inherit; 
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
  font-size: .9em;
}



blockquote,
.blockquote {
  padding: 10px 20px;
  margin: 0 0 20px;
  font-size: 1em;
  border-left: 5px solid #6c757d;
}

</style>
</head>

<body>
  <nav class="custom-navbar">
  <div class="container">
    
    <a href="/">Posts</a>
    
    <a href="/tags/">Tags</a>
    
    <a href="/about/">About</a>
    
    <a href="/index.xml">RSS</a>
    
  </div>
</nav>
  
  <div class="container">
    <article>
      <h1>[Python] [Machine learning] Understand logistic regression from both scikit-learn and mathematics</h1>
<p>
  <small class="text-secondary">
  
  
  Feb 5, 2020
  </small>
  

<small><code><a href="https://memotut.com/tags/python">Python</a></code></small>


<small><code><a href="https://memotut.com/tags/machine-learning"> machine learning</a></code></small>


<small><code><a href="https://memotut.com/tags/scikit-learn"> scikit-learn</a></code></small>


<small><code><a href="https://memotut.com/tags/mathematics"> mathematics</a></code></small>


<small><code><a href="https://memotut.com/tags/logistic-regression"> logistic regression</a></code></small>

</p>
<pre><code>#1. Purpose
</code></pre>
<p>If you want to do machine learning, anyone can use scikit-learn etc. to implement it relatively easily.
However, in order to achieve results at work or to improve your level,
The explanation &ldquo;I don&rsquo;t really understand the background, but I got this result&rdquo; is clearly weak.</p>
<p>In this article, the two aims are to &ldquo;use the scikit-learn first because the theory is good&rdquo; and to &ldquo;understand the background from mathematics&rdquo; from the fourth and later.</p>
<p>*Since I am a liberal arts graduate, I am not good at mathematics. I tried to explain it to people who are not good at mathematics so that it is easy to understand.</p>
<ul>
<li>A similar article has been posted in Linear Single Regression Ver, so I hope you can read it together.
<a href="https://qiita.com/Hawaii/items/150897d4f807e5597f18">[Machine learning] Understanding linear simple regression from both scikit-learn and mathematics</a></li>
</ul>
<p>#2. What is Logistic Regression?
Logistic regression is a type of statistical regression model for Bernoulli-distributed variables.
Source: <a href="https://ja.wikipedia.org/wiki/Logisticregression">Wikipedia</a></p>
<p>It is used to &ldquo;predict the probability that an event will occur&rdquo; or &ldquo;classify based on that probability&rdquo;**, since it is unclear.
Therefore, logistic regression is used when you want to classify using machine learning or when you want to predict its probability.</p>
<p>(I was very surprised to be able to &ldquo;predict probability&rdquo; while studying machine learning.)</p>
<p>##◆ About sigmoid function (logistic function)
So, how does this logistic regression predict classification and probability?
I will omit the detailed explanation because I will turn it to the chapter of mathematics, but &ldquo;predicting the probability of a certain event&rdquo; means that if you enter the necessary information in the &ldquo;sigmoid function&rdquo; below, that event (let&rsquo;s call it A) It means that the probability of occurrence is calculated.
Then, if the probability is 50% or more, it is classified as A, and if the probability is less than 50%, it is classified as not A.</p>
<p>*Therefore, you should not think about &ldquo;probability prediction&rdquo; and &ldquo;classification&rdquo; separately, but first calculate the probability that the event will occur, and if you think that you classify by A or not A with 50% as the boundary, it is OK. ..</p>
<p>[Sigmoid function]
<img width="377" alt="Capture6.PNG" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/465870/eca0d4ad-1138-93a8-d150-0be92ebc2dfa.png"></p>
<p>By the way, the sigmoid function is defined as follows.
*It will come up again in the mathematics chapter, so you can skip it.</p>
<pre><code class="language-math" data-lang="math">y = \frac{1}{1 + e^{-(a_1x_1 + a_2x_2 + ... + b)}}

</code></pre><p>As a result of this calculation, the generated $y$ represents the probability that the event will occur, and logistic regression calculates this probability.</p>
<p>For example, if a red dot is added to the sigmoid function above, the probability of occurrence is predicted to be 40%, and since it is less than 50%, event A will not be classified.</p>
<p>##◆ What is classification?
Although it is the &ldquo;classification&rdquo; described above, &ldquo;regression (to predict a numerical value)&rdquo; or &ldquo;classification&rdquo; is mainly performed in machine learning.
As the name implies, classification is used when you want to classify &ldquo;A or B&rdquo;.
*For example, &ldquo;is the stock price going up or going down tomorrow?&rdquo; I think that classification is a very effective method, depending on how you set your objectives.</p>
<p>##◆ Specific example
*This concrete example is not very practical. In my case, I would like you to read it with your thoughts such that the score of the national language is ●● data.</p>
<p>Assume that you have data on the overall average of the middle and high school languages and mathematics of 15 students and whether they are going on to the humanities or sciences thereafter.
<img width="149" alt="Capture1.PNG" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/465870/6e68b077-bc44-dff1-0fa9-bfad188c227c.png"></p>
<p>Based on this data, I would like to use other students&rsquo; language and mathematics data in the future to predict whether they will study in the humanities or sciences in the future.</p>
<p>The distribution of the national averages of the 15 students&rsquo; national language and mathematics is as follows.
<img width="315" alt="capture2.PNG" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/465870/3db3b813-9208-400c-94f6-09e767ff0256.png"></p>
<p>Somehow, there seems to be a boundary between the blue dot (literary science) and the orange dot (science).</p>
<p>Next, let&rsquo;s do a logistic regression analysis using scikit-learn and create a model that classifies by humanities and sciences.</p>
<p>#3.scikit-learn logistic regression
##(1) Import required libraries
Import the following items required for logistic regression.</p>
<pre><code>from sklearn.linear_model import SGDClassifier
from sklearn.metrics import log_loss, accuracy_score, confusion_matrix
</code></pre><p>##(2) Data preparation
Set the score of national language and mathematics, and literary science (literature is True, science is False) as data as shown below.</p>
<ul>
<li>For example, the first student had an average junior high to high school score of 45 in Japanese and 75 in mathematics and eventually entered science.</li>
</ul>
<pre><code>data = pd.DataFrame({
        &quot;bunri&quot;:[False,True,False,True,True,False,True,False,True,False,False,True,False,False,False],
        &quot;Japanese_score&quot;:[45, 60, 52, 70, 85, 31, 90, 55, 75, 30, 42, 65, 38, 55, 60],
        &quot;Math_score&quot;:[75, 50, 80, 35, 40, 65, 42, 90, 35, 90, 80, 35, 88, 80, 90],
    })
</code></pre><p>##(3) Try to illustrate (important)
I will try to illustrate the scores and literacy of national language and mathematics. Instead of using scikit-learn suddenly to grasp the characteristics, try to map any data.</p>
<pre><code>y = data[&quot;bunri&quot;].values
x1, x2 = data[&quot;Japanese_score&quot;].values, data[&quot;Math_score&quot;].values
# Plot the data
plt.grid(which='major',color='black',linestyle=':')
plt.grid(which='minor',color='black',linestyle=':')
plt.plot(x1[y], x2[y],'o', color='C0', label='bunkei')# Blue point: y is True (= literary)
plt.plot(x1[~y], x2[~y],'^', color='C1', label='rikei')# Orange point: y is False (= science)
plt.xlabel(&quot;Japanese_score&quot;)
plt.ylabel(&quot;Math_score&quot;)
plt.legend(loc='best')
plt.show()
</code></pre><img width="217" alt="Capture3.PNG" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/465870/861d0557-3608-80d4-95ba-f27be4b5ec0e.png">
<p>It seems that you can make a clear distinction between blue (humanities) and orange (science).
(In the real world, there are few things that seem to be so clearly separated)
Let&rsquo;s build a logistic regression model.</p>
<p>##(4) Model construction
###(I) Data shaping
First of all, the shape of the data is adjusted to build the model.</p>
<pre><code>y = data[&quot;bunri&quot;].values# It's the same as the previous figure, so you can omit it.
X = data[[&quot;Japanese_score&quot;, &quot;Math_score&quot;]].values
</code></pre><p>This article is not a python grammar article, so I won&rsquo;t go into details, but I&rsquo;ll arrange x and y into a form for logistic regression with scikit-learn.
*I think that this is a code that I can not write unless I understand it to some extent, so I would like to put it somewhere.</p>
<p>###(Ii) model building
Finally, the code for model building.</p>
<pre><code>clf = SGDClassifier(loss='log', penalty='none', max_iter=10000, fit_intercept=True, random_state=1234, tol=1e-3)
clf.fit(X, y)
</code></pre><p>If it is a simple model, this is the end.
We will create a logistic regression model for a variable called clf! It is an image of doing something like the declaration and then fitting (= learning) the prepared X and y to that clf in the next line.</p>
<p>###(Iii) Try to issue the parameter</p>
<ul>
<li>Skip (iii) as it is unnecessary in the sense that it is the minimum if it is difficult.</li>
</ul>
<p>Suddenly the word parameter came out, but this is $y = \frac{1}{1 + e^{-(a_1x_1 + a_2x_2 + &hellip; + b)}}$ described in the sigmoid function at the beginning. Refers to $a$ and $b$.
In this example, there are two explanatory variables, national score and mathematical score, so we can define $y = \frac{1}{1 + e^{-(a_1x_1 + a_2x_2 + b)}}$ $ And $b$ can be calculated with scikit-learn as below.</p>
<pre><code># Get weight and display
b = clf.intercept_[0]
a1 = clf.coef_[0, 0]
a2 = clf.coef_[0, 1]
</code></pre><p>Then I think that it will be displayed as b = 4.950, a1 = 446.180, a2 = -400.540, so $y = \frac{1}{1 + e^{-(446.180x_1 + (-400.540)x_2 + 4.950)} You can see that it is a sigmoid function called }$.</p>
<p>##(5) Try to illustrate the built model
Now, let&rsquo;s illustrate this boundary in the scatter plot above.
*This code is a little difficult, so you can just copy and paste it without understanding. It is all right that scikit-learn calculates such a boundary line from learning, and recognizes that it is judged as a humanities system at the lower right and a science system at the upper left.</p>
<pre><code>y = data[&quot;bunri&quot;].valuesx1, x2 = data[&quot;Japanese_score&quot;].values, data[&quot;Math_score&quot;].values
# Plot the data
plt.grid(which='major',color='black',linestyle=':')
plt.grid(which='minor',color='black',linestyle=':')
plt.plot(x1[y], x2[y],'o', color='C0', label='bunkei')# Blue point: y is True (= literary)
plt.plot(x1[~y], x2[~y],'^', color='C1', label='rikei')# Orange point: y is False (= science)
plt.xlabel(&quot;Japanese_score&quot;)
plt.ylabel(&quot;Math_score&quot;)
plt.legend(loc='best')

# Plot and display borders
# Purple: border
line_x = np.arange(np.min(x1)-1, np.max(x1) + 1)
line_y =-line_x * w1 / w2-w0 / w2
plt.plot(line_x, line_y, linestyle='-.', linewidth=3, color='purple', label='kyoukai')
plt.ylim([np.min(x2)-1, np.max(x2) + 1])
plt.legend(loc='best')
plt.show()
</code></pre><img width="215" alt="Capture 4.PNG" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/465870/0afa0e7b-89d0-5849-aabb-79acfa525626.png">
<p>Like this, let&rsquo;s be aware of what we are doing with scikit-learn and what it is connected to.</p>
<p>##(6) In the real world&hellip;
After making a model, it doesn&rsquo;t make sense. In the real world, it is necessary to use this predictive model to predict the literacy of another student.
You got the information for another five and wrote down the data.
Store it in a variable called z as shown below.</p>
<pre><code>z = pd.DataFrame({
        &quot;Japanese_score&quot;:[80, 50, 65, 40, 75],
        &quot;Math_score&quot;:[50, 70, 55, 50, 40],
    })
z2 = z[[&quot;Japanese_score&quot;, &quot;Math_score&quot;]].values
</code></pre><p>What I want to do is to apply the data of another student above to the logistic regression model obtained by scikit-learn and predict the textual theory.</p>
<pre><code>y_est = clf.predict(z2)
</code></pre><p>This way, y_est will display the result as &ldquo;([True, False, True, False, True])&rdquo;.
In other words, the first person is predicted to be a liberal arts because Japanese is 80 points and mathematics is 50 points.</p>
<p>Your goals will be achieved as you will be able to predict your literary science from your national language and math scores.</p>
<p>In addition, let&rsquo;s display the &ldquo;probability of being a librarian&rdquo; mentioned at the beginning.</p>
<pre><code>clf.predict_proba(z2)
</code></pre><p>When written in this way, the probability that it is a literary style and the probability that it is not a literary style will be displayed in two columns.
However, since this example is so easy to understand, the result is displayed as follows and the probability is clearly divided into 0% and 100%.
*The right side is the probability of being a humanities.</p>
<p>[0., 1.],
[Ten.],
[0., 1.],
[Ten.],
[0., 1.]</p>
<p>#4. Understanding Logistic Regression from Mathematics
By the way, up to 3, I tried to implement the flow of constructing a logistic regression model using scikit-learn → drawing → predicting the textual science of another 5 students.
Here, I would like to clarify how the logistic regression model of this flow is calculated mathematically.
*If you don&rsquo;t need this knowledge at present, you can skip this step.</p>
<p>##(1) Prerequisite knowledge
Use the following for the logarithm of the product.
$log_aMN = log_aM + log_aN$</p>
<p>##(2) What is sigmoid function?
Although it was described a little in &ldquo;◆ Sigmoid function (sigmoid function)&rdquo; of 2., the sigmoid function is a function for expressing a certain event by probability, and has the following form.
*The maximum value of the $y$ axis is 1 (probability 100%) and the minimum value is 0 (probability 0%).</p>
<img width="209" alt="Capture5.PNG" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/465870/8dda471a-5f08-31fc-4f7b-64d9351adc8d.png">
<p>Also, this blue function is defined as:</p>
<pre><code class="language-math" data-lang="math">y = \frac{1}{1 + e^{-(a_1x_1 + a_2x_2 + ... + b)}}
</code></pre><p>The above $a_1$, $a_2$, and $b$ are so-called parameters, and their positions are the same as $a = and $b$ of the linear function $y = ax + b$.
And $x_1$ and $x_2$ are so-called explanatory variables. In this case, the national score is $x_1$ and the mathematical score is $x_2$.</p>
<p>If you decide $a_1$, $a_2$, and $b$ to <strong>a good number</strong>, then the newly acquired student&rsquo;s national language and math scores will be changed to $x_1$ and $x_2$. If you enter it, the probability of becoming a humanities (or the probability of becoming a science) can be calculated as $y$.</p>
<p>In other words ** Machine learning logistic regression calculates sigmoid function by calculating these parameters $a$ and $b$**.</p>
<p>I think that it is difficult to imagine the image only with sentences, so let&rsquo;s apply concrete numerical values from the next and calculate.</p>
<p>##(3) Mathematical understanding
####(Ⅰ) Apply sigmoid function to data one by one
&ldquo;Data&rdquo; set in &ldquo;Preparation of data&rdquo; is organized in a table format, and what happens when the sigmoid function is set to the far right is summarized.
This time, I&rsquo;m going to find the &ldquo;probability of being a liberal arts&rdquo;, so I leave the librarian as 1 and the science as 0 (on the contrary, if I want to obtain the probability of being a liberty, I set the lib as 1 and the lib as 0).</p>
<p>| Student | National score | Mathematical score | Bunri (0: Science 1: Literary) | Sigmoid function
|:&mdash;&mdash;|&mdash;&mdash;-:|:&mdash;&mdash;-:|:&mdash;&mdash;&mdash;&mdash;:|:&mdash;&mdash; &mdash;&mdash;:|
| First person | 45 | 75 | 0 | $\frac{1}{1 + e^{-(45a_1 + 75a_2 + b)}}$
Second person | 60 | 50 | 1 | $\frac{1}{1 + e^{-(60a_1 + 50a_2 + b)}}$
| ・・・| ・・・ | ・・・ |・・・ |
| 15th | 60 | 90 |0 | $\frac{1}{1 + e^{-(60a_1 + 90a_2 + b)}}$</p>
<h4 id="ii-find-the-maximum-likelihood-estimator">(ii) Find the maximum likelihood estimator</h4>
<p>Now, how do you find the parameters $a$ ($a_1$ and $a_2$ in this example) and $b$?
In conclusion, <strong>the probability of being a liberal arts is multiplied by the first to the fifteenth person, and the product of them can be maximized to find $a_1$, $a_2$ and $b$</strong>.</p>
<p>This is called the maximum likelihood estimator.</p>
<p>◆ What is the maximum likelihood estimator?
It is read as “saiyuusuiteiri” and means “most likely”.
→ It&rsquo;s complicated, but you can interpret it as &ldquo;the best numerical value&rdquo;.</p>
<p>◆Let&rsquo;s multiply
Multiplying the probability of being a human being from the first person to the fifteenth person is as follows (let&rsquo;s call it L).</p>
<pre><code class="language-math" data-lang="math">L = [1-\frac{1}{1 + e^{-(45a_1 + 75a_2 + b)}}] × [\frac{1}{1 + e^{-(60a_1 + 50a_2 + b)}} ] × ・・\\
× [1-\frac{1}{1 + e^{-(60a_1 + 90a_2 + b)}}]
</code></pre><ul>
<li>The 1st and 15th are subtracted from 1 because the 1st and 15th are science, so the value of the sigmoid function itself is a science, so subtracting from 1 will correct it to a probability of being a science. Because</li>
</ul>
<p>◆ Logarithm to find the maximum value of L
As you may imagine, L is multiplied by 15 people. This is very difficult to calculate when the data is for millions of people, so I will convert it to logarithmic.</p>
<pre><code class="language-math" data-lang="math">logL = log[1-\frac{1}{1 + e^{-(45a_1 + 75a_2 + b)}}] + log[\frac{1}{1 + e^{-(60a_1 + 50a_2 + b) }}] + ・・\\
log[1-\frac{1}{1 + e^{-(60a_1 + 90a_2 + b)}}]
</code></pre><p>◆ Find parameters
The parameters $a_1$, $a_2$, and $b$ that maximize $logL$ cannot be calculated analytically (=manual calculation).
scikit-learn calculates the optimal parameters using <strong>&ldquo;stochastic gradient method&rdquo;</strong>.</p>
<ul>
<li>Probabilistic gradient method is quite long to explain, so I will omit it here.</li>
</ul>
<p>So, while understanding that the underlying theory is doing this, it is OK if you use the one that scikit-learn gives for the actual calculation.</p>
<p>In ``I will issue the (iii) parameter&rsquo;&rsquo;, it says $b$ = 4.950, $a_1$ = 446.180, $a_2$ = -400.540, so I wanted to find this time $y = \frac{1 }{1 + e^{-(446.180x_1 + (-400.540)x_2 + 4.950)}}$ is a sigmoid function**.</p>
<h4 id="iii-summary-here">(iii) Summary here</h4>
<p>This sigmoid function ($y = \frac{1}{1 + e^{-(446.180x_1 + (-400.540)x_2 + 4.950)}}$) and the newly acquired national language score of the student ($x_1$) If you enter a mathematical score ($x_2$), the probability of the liberal arts will be calculated, and if the probability is greater than 0.5, it will be classified as a liberal arts, and if it is less than 0.5, it will be classified as a science.</p>
<h4 id="-some-development">(ⅳ) Some development</h4>
<p><strong>Why is it possible to obtain a &ldquo;good&rdquo; parameter by finding the maximum value of L</strong>
I&rsquo;ve put out parameters $a$ and $b$ that maximize $L$ and $logL$. Why is it possible to give optimal parameters when $L$ and $logL$ are maximized? ..</p>
<p>Please see below to grab the image.
You have only 3 data at hand, and let&rsquo;s make a rough blue graph of the overall normal distribution from those 3 data.
Which of the two blue graphs below is more likely to have a more general normal distribution?<img width="401" alt="Capture 7.PNG" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/465870/1269610c-1de0-2192-4395-787d964b88e8.png"></p>
<p>Obviously, the graph on the left is more likely. This is because the distribution on the right side is in the most frequently occurring mountain, and there is no data at hand.
This is an intuitive understanding, but mathematically, the graph on the left is more certain.</p>
<p>Below is the probability distribution added to the above normal distribution.
It&rsquo;s a rule of thumb, but I wrote the probability that if the red dot at hand is on this normal distribution, it will occur at this probability.</p>
<img width="463" alt="Capture 8.PNG" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/465870/8fdf0550-0564-626c-cfad-6ec0cf53095e.png">
<p>Multiplying the probabilities from the left distribution (which has the same meaning as $L$) gives 0.14 x 0.28 x 0.38 = 0.014896.
Similarly on the right side
0.01 x 0.03 x 0.09 = 0.000027.</p>
<p>In this way, the larger the value of the probability multiplication, the closer it is to the graph that properly represents the original distribution.</p>
<p>Therefore, it is necessary to find the parameters $a_1$, $a_2$, and $b$ such that the value of $L$, which is the multiplication of the probabilities of the liberal arts, and its logarithm, $logL$, are as large as possible.</p>
<p><strong>◆ Difference between sigmoid function and logistic function</strong>
You can understand that the special form of the logistic function is a sigmoid function.</p>
<p>Logistic function: ${N={\frac {K}{1+\exp {K(t_{0}-t)}}}}N={\frac {K}{1+\exp {K(t_{ 0}-t)}}}$
The sigmoid function refers to the function when $K=1$ and $t_0=0$ above.</p>
<p>Reference URL: Wikipedia
<a href="https://ja.wikipedia.org/wiki/%E3%82%B7%E3%82%B0%E3%83%A2%E3%82%A4%E3%83%89%E9%96%A2%E6">https://ja.wikipedia.org/wiki/%E3%82%B7%E3%82%B0%E3%83%A2%E3%82%A4%E3%83%89%E9%96%A2%E6</a> %95%B0</p>
<p><strong>◆Confusion matrix</strong>
I didn&rsquo;t use it because I gave a very easy-to-understand example this time, but in general, I use a confusion matrix as a method of checking accuracy.
If you are interested, please try learning as the reference URL is provided.
<Reference URL>
<a href="https://note.nkmk.me/python-sklearn-confusion-matrix-score/">https://note.nkmk.me/python-sklearn-confusion-matrix-score/</a></p>
<p>#5. Summary
What did you think.
Logistic regression is a part of which I myself have had a hard time understanding, so it may be difficult to understand it once I read it.
We hope that reading this a few times will help you to improve your understanding.</p>
<ul>
<li>In the future, I would like to make similar posts for other machine learning models.</li>
</ul>

    </article>
  </div>

  
  
  
  <script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-169005401-1', 'auto');
  ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  

  
<link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.css" />
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#216942",
      "text": "#b2d192"
    },
    "button": {
      "background": "#afed71"
    }
  }
})});
</script>

</body>

</html>
