<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  <meta name="generator" content="Hugo 0.72.0" />

  
  <meta name="description" content="Some description">
  

  
  <link rel="apple-touch-icon" sizes="180x180" href="https://memotut.com/apple-touch-icon.png">

  
  <link rel="icon" type="image/png" sizes="32x32" href="https://memotut.com/favicon-32x32.png">

  
  <link rel="icon" type="image/png" sizes="16x16" href="https://memotut.com/favicon-16x16.png">

  
  <link rel="manifest" href="https://memotut.com/site.webmanifest">

  
  <link rel="mask-icon" href="https://memotut.com/safari-pinned-tab.svg" color="#5bbad5">

  <meta name="msapplication-TileColor" content="#da532c">

  <meta name="theme-color" content="#ffffff">

  
  <link rel="stylesheet" href="https://memotut.com/css/bootstrap.min.css" />

  
  <title>[Python] I tried handwriting recognition of runes with scikit-learn | Memo Tut</title>
  

  <style>
body {
  min-width: 300px;
}

.custom-navbar {
  margin-bottom: 1em;
  height: 60px;
}

.custom-navbar a {
  display: inline-block; 
  padding: 18px 0;
  margin-right: 1em; 
  font-weight: bold; 
}

.custom-navbar a:hover,
.custom-navbar a:focus {
  text-decoration: none; 
}

@media print {
  .custom-navbar {
    display: none;
  }
}

article {
  padding-bottom: 1em;
}

img {
  max-width: 100%;
}


body {
  background-color: #fff;
}



body {
  color: #212529;
}



a {
  color: #007bff;
}



a:hover,
a:focus {
  color: #0056b3;
}



.custom-navbar {
  background-color: #212529;
}



.custom-navbar a {
  color: rgba(255, 255, 255, 0.75);
}



.custom-navbar a:hover,
.custom-navbar a:focus {
  color: rgba(255, 255, 255, 1);
}



.container {
  max-width: 800px;
}



pre {
  display: block;
  padding: 9.5px;
  word-break: break-all;
  word-wrap: break-word;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre code {
  padding: 0;
  font-size: inherit;
  color: inherit; 
  white-space: pre-wrap;
  background-color: transparent;
  border: none;
  border-radius: 0;
}

code {
  padding: 2px 4px;
  color: inherit; 
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
  font-size: .9em;
}



blockquote,
.blockquote {
  padding: 10px 20px;
  margin: 0 0 20px;
  font-size: 1em;
  border-left: 5px solid #6c757d;
}

</style>
</head>

<body>
  <nav class="custom-navbar">
  <div class="container">
    
    <a href="/">Posts</a>
    
    <a href="/tags/">Tags</a>
    
    <a href="/about/">About</a>
    
    <a href="/index.xml">RSS</a>
    
  </div>
</nav>
  
  <div class="container">
    <article>
      <h1>[Python] I tried handwriting recognition of runes with scikit-learn</h1>
<p>
  <small class="text-secondary">
  
  
  Dec 15, 2019
  </small>
  

<small><code><a href="https://memotut.com/tags/python">Python</a></code></small>


<small><code><a href="https://memotut.com/tags/scikit-learn">scikit-learn</a></code></small>

</p>
<pre><code>This article is from the 15th day of the Fujitsu Systems Web Technology Advent Calendar.
</code></pre>
<p>(Promise) The content of this article is my own opinion and does not represent the organization to which I belong.</p>
<h3 id="introduction">Introduction</h3>
<p>In this article, we use scikit-learn, a Python machine learning library.
I have summarized the procedure and the result when I tried handwriting recognition of runes **.
While the advent calendars of this Advent Calendar are putting in great features and know-how that are likely to be useful for actual work,
However, I made something that was just fun for me, and I cannot help being so enthusiastic. ..
I hope you can see it more easily.</p>
<p>Also, since the author of this article is a machine learning beginner, there may be more content now.
Also for people who will try python and scikit-learn from now on
I will do my best to provide reasonable information. Thank you.</p>
<h4 id="background">background</h4>
<p>Although I do not touch it at all in my daily work, I am interested in machine learning and would like to learn the basics of learning and movement.
I tried scikit-learn.
It would have been nice to try using the datasets that the library has,
I want to know &ldquo;What kind of data can I prepare and what can I do?&rdquo;
I decided to try it from the place where I prepared the data.</p>
<p><strong>(Aside)</strong>
The runes are kind of cool!</p>
<h3 id="used">Used</h3>
<ul>
<li>
<p>Anaconda: A package containing Python itself and commonly used libraries.</p>
</li>
<li>
<p>scikit-learn: A library that allows you to easily use neural networks in Python. It is open source. This time, I will use the model called &ldquo;Classification&rdquo; called MLPClassifier.</p>
</li>
<li>
<p>E-cutter: Free software for image segmentation. It was used to divide the handwritten image.</p>
</li>
</ul>
<h3 id="data-preparation">Data preparation</h3>
<p>This time, we will target the &ldquo;German common runes (24 characters)&rdquo; of the runes.
<img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/310568/dfae3b1f-d1d3-d40c-3c16-2a6d4544d703.png" alt="images.png"></p>
<p>Since there seems to be no convenient data such as &ldquo;Rune character data for machine learning&rdquo;, prepare your own image.
This time I created it by the following method.</p>
<p>① Create an image with handwritten characters arranged at equal intervals by handwriting.
(It will be convenient later to use a single character (eg &ldquo;ᚠ.png&rdquo;) that draws the image file name)
② Divide the image into equal parts with E-cutter (free software).
<img width="400" alt="01_Image acquisition Ecutter.PNG" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/310568/ce2a746b-466a-684c-f369-4f4be42b30b8.png">
The divided image was very convenient because it was saved in the specified folder with &ldquo;[original file name]_[branch number].png&rdquo;.
I once created 18 image data for each type of rune.</p>
<h3 id="load-image">Load image</h3>
<p>From here, we will process in Python. First, load the image.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#f92672">import</span> cv2 <span style="color:#75715e"># library for image conversion</span>
<span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#f92672">as</span> plt
<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">from</span> PIL <span style="color:#f92672">import</span> Image
<span style="color:#f92672">import</span> os<span style="color:#f92672">,</span> glob

<span style="color:#75715e"># An array that stores image data</span>
X <span style="color:#f92672">=</span> []
<span style="color:#75715e"># An array that stores the characters (answers) corresponding to the image data</span>
Y <span style="color:#f92672">=</span> []

<span style="color:#75715e"># Learning data directory/file</span>
dir <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;[Image data storage directory]&#34;</span>
files <span style="color:#f92672">=</span> glob<span style="color:#f92672">.</span>glob(dir <span style="color:#f92672">+</span> <span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\\</span><span style="color:#e6db74">*.png&#34;</span>)

<span style="color:#75715e"># Vertical and horizontal size of image (pixels)</span>
image_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">50</span>

<span style="color:#75715e"># Read files in directory and add to list of learning data</span>
<span style="color:#66d9ef">for</span> i, file <span style="color:#f92672">in</span> enumerate(files):
    image <span style="color:#f92672">=</span> Image<span style="color:#f92672">.</span>open(file)
    <span style="color:#75715e"># Convert to 8bit grayscale</span>
    image <span style="color:#f92672">=</span> image<span style="color:#f92672">.</span>convert(<span style="color:#e6db74">&#34;L&#34;</span>)
    image <span style="color:#f92672">=</span> image<span style="color:#f92672">.</span>resize((image_size, image_size))
    data <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>asarray(image)<span style="color:#f92672">.</span>flatten()
    X<span style="color:#f92672">.</span>append(data)
    moji <span style="color:#f92672">=</span> file<span style="color:#f92672">.</span>split(<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\\</span><span style="color:#e6db74">&#34;</span>)[<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>]<span style="color:#f92672">.</span>split(<span style="color:#e6db74">&#34;_&#34;</span>)[<span style="color:#ae81ff">0</span>]
    Y<span style="color:#f92672">.</span>append(moji)
 
X <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(X)
Y <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(Y)
</code></pre></div><p>Let&rsquo;s display the loaded image.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#75715e">#Visualize the first data</span>
showimage <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>reshape(X[<span style="color:#ae81ff">0</span>], (<span style="color:#ae81ff">50</span>,<span style="color:#ae81ff">50</span>)) <span style="color:#75715e">#reshape into a 50x50 double array</span>
plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">121</span>),plt<span style="color:#f92672">.</span>imshow(showimage),plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#39;Input&#39;</span>)
plt<span style="color:#f92672">.</span>show()
</code></pre></div><img width="148" alt="02_Load image .PNG" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/310568/5e560f4c-4cb1-49ab-14f6-9a3b2349e6e6.png">
<p>It is read as data of size 50*50.</p>
<h4 id="-lets-learn-and-classify">◆ Let&rsquo;s learn and classify</h4>
<p>The number of data is quite small, but I will let you learn and classify with this data (24 (characters) * 18 (sheets)) once!</p>
<h5 id="separate-data-for-learning-and-testing">・Separate data for learning and testing</h5>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#75715e"># Split data for training and testing</span>
x_train, x_test, y_train, y_test <span style="color:#f92672">=</span> model_selection<span style="color:#f92672">.</span>train_test_split(X, Y, test_size<span style="color:#f92672">=</span><span style="color:#ae81ff">0.1</span>, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)
</code></pre></div><h5 id="learn-and-judge">・Learn and judge</h5>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#75715e">#Learning</span>
clf <span style="color:#f92672">=</span> MLPClassifier(hidden_layer_sizes<span style="color:#f92672">=</span>(<span style="color:#ae81ff">200</span>,))
clf<span style="color:#f92672">.</span>fit(x_train, y_train)

<span style="color:#75715e"># Classify data for testing</span>
y_pred <span style="color:#f92672">=</span> clf<span style="color:#f92672">.</span>predict(x_test)

<span style="color:#75715e"># Show results</span>
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;--- expected answer ---&#34;</span>)
<span style="color:#66d9ef">print</span>(y_test)

<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;--- answer given by the model ---&#34;</span>)
<span style="color:#66d9ef">print</span>(y_pred)

<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;--- correct answer rate ---&#34;</span>)
accuracy_score(y_test, y_pred)
</code></pre></div><h4 id="result">・Result</h4>
<img width="800" alt="12120023_First result_No at all .PNG" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/310568/914112a1-6dd7-f62f-c614-410e4d7427e5.png">
<p><strong>The correct answer rate is very low&hellip;! ! (7.1%) orz</strong></p>
<p>Most of them are classified as &ldquo;ᚱ&rdquo;, and the other judged characters are also incorrect&hellip;
However, it seems that anything other than &ldquo;ᚱ&rdquo; is classified as a character with a similar shape among runes.
I&rsquo;m a bit happy to get a glimpse of the sprouting intelligence (though I&rsquo;m making a mistake after all).</p>
<p>After all, it seems that the learning data is insufficient, but it is troublesome to add more handwritten character data
Try Data Augmentation.</p>
<h3 id="data-augmentation">Data Augmentation</h3>
<p>[Character type] prepared *18 images are not enough for learning data, so
Convert the data to increase the amount of data.</p>
<p>The following article was very helpful for data augmentation.
<a href="https://products.sint.co.jp/aisia/blog/vol1-7#toc-3">https://products.sint.co.jp/aisia/blog/vol1-7#toc-3</a></p>
<p>It seems that there are methods such as &ldquo;increase noise&rdquo;, &ldquo;reverse&rdquo;, &ldquo;shift&rdquo;, &ldquo;transform&rdquo;, etc.
This time, &ldquo;transformation&rdquo; and &ldquo;rotation&rdquo; will be performed.</p>
<h4 id="transformation">Transformation</h4>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#75715e"># Transform image</span>
<span style="color:#66d9ef">for</span> i, file <span style="color:#f92672">in</span> enumerate(files):
    image <span style="color:#f92672">=</span> Image<span style="color:#f92672">.</span>open(file)
    image <span style="color:#f92672">=</span> image<span style="color:#f92672">.</span>resize((image_size, image_size))
    image <span style="color:#f92672">=</span> image<span style="color:#f92672">.</span>convert(<span style="color:#e6db74">&#34;L&#34;</span>)
    moji <span style="color:#f92672">=</span> file<span style="color:#f92672">.</span>split(<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\\</span><span style="color:#e6db74">&#34;</span>)[<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>]<span style="color:#f92672">.</span>split(<span style="color:#e6db74">&#34;_&#34;</span>)[<span style="color:#ae81ff">0</span>]
    
    <span style="color:#75715e"># Flip bits of data into array</span>
    image_array <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>bitwise_not(np<span style="color:#f92672">.</span>array(image))
    
    <span style="color:#75715e">## Deformation ①</span>
    <span style="color:#75715e"># Create image transformation map</span>
    pts1 <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>float32([[<span style="color:#ae81ff">0</span>,<span style="color:#ae81ff">0</span>],[<span style="color:#ae81ff">0</span>,<span style="color:#ae81ff">100</span>],[<span style="color:#ae81ff">100</span>,<span style="color:#ae81ff">100</span>],[<span style="color:#ae81ff">100</span>,<span style="color:#ae81ff">0</span>]])
    pts2 <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>float32([[<span style="color:#ae81ff">0</span>,<span style="color:#ae81ff">0</span>],[<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">98</span>],[<span style="color:#ae81ff">102</span>,<span style="color:#ae81ff">102</span>],[<span style="color:#ae81ff">100</span>,<span style="color:#ae81ff">0</span>]])
    <span style="color:#75715e"># Image transformation</span>
    M <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>getPerspectiveTransform(pts1,pts2)
    dst1 <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>warpPerspective(image_array,M,(<span style="color:#ae81ff">50</span>, <span style="color:#ae81ff">50</span>))
    
    X<span style="color:#f92672">.</span>append(dst1<span style="color:#f92672">.</span>flatten())
    Y<span style="color:#f92672">.</span>append(moji)
    
    <span style="color:#75715e">## Deformation ②</span>
    <span style="color:#75715e"># Create image transformation map</span>
    pts2 <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>float32([[<span style="color:#ae81ff">0</span>,<span style="color:#ae81ff">0</span>],[<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">102</span>],[<span style="color:#ae81ff">98</span>, <span style="color:#ae81ff">98</span>],[<span style="color:#ae81ff">100</span>,<span style="color:#ae81ff">0</span>]])
    <span style="color:#75715e"># Image transformation</span>
    M <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>getPerspectiveTransform(pts1,pts2)
    dst2 <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>warpPerspective(image_array,M,(<span style="color:#ae81ff">50</span>, <span style="color:#ae81ff">50</span>))
    X<span style="color:#f92672">.</span>append(dst2<span style="color:#f92672">.</span>flatten())
    Y<span style="color:#f92672">.</span>append(moji)

<span style="color:#75715e"># Display the data at the end</span>
showimage <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>reshape(image_array, (<span style="color:#ae81ff">50</span>,<span style="color:#ae81ff">50</span>)) <span style="color:#75715e">#reshape into a 50x50 double array</span>
plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">121</span>),plt<span style="color:#f92672">.</span>imshow(showimage),plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#39;Input&#39;</span>)
plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">122</span>),plt<span style="color:#f92672">.</span>imshow(dst),plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#39;Output&#39;</span>)
plt<span style="color:#f92672">.</span>show()
</code></pre></div><h5 id="display-of-transformed-image">Display of transformed image</h5>
<img width="293" alt="03_Image transformation.PNG" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/310568/a9d665ee-cdf7-6945-8553-c56f3e6520b7.png">
<p>I was able to generate an image that was slightly deformed compared to the original image.Two transformed images are generated for each original image and added to the training data.</p>
<h4 id="rotation">rotation</h4>
<p>In order to further increase the data, I will create an image that is the original image rotated by 15 degrees and add it.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#75715e"># Rotate image</span>
<span style="color:#66d9ef">for</span> i, file <span style="color:#f92672">in</span> enumerate(files):
    image <span style="color:#f92672">=</span> Image<span style="color:#f92672">.</span>open(file)
    image <span style="color:#f92672">=</span> image<span style="color:#f92672">.</span>resize((image_size, image_size))
    image <span style="color:#f92672">=</span> image<span style="color:#f92672">.</span>convert(<span style="color:#e6db74">&#34;L&#34;</span>)
    moji <span style="color:#f92672">=</span> file<span style="color:#f92672">.</span>split(<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\\</span><span style="color:#e6db74">&#34;</span>)[<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>]<span style="color:#f92672">.</span>split(<span style="color:#e6db74">&#34;_&#34;</span>)[<span style="color:#ae81ff">0</span>]
    
    <span style="color:#75715e"># Flip bits of data into array</span>
    image <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>bitwise_not(np<span style="color:#f92672">.</span>array(image))
    
    <span style="color:#75715e"># 1. Rotate 15 degrees clockwise</span>
    <span style="color:#75715e">#Specify rotation angle</span>
    angle <span style="color:#f92672">=</span> <span style="color:#f92672">-</span><span style="color:#ae81ff">15.0</span>
    <span style="color:#75715e"># Specify scale</span>
    scale <span style="color:#f92672">=</span> <span style="color:#ae81ff">1.0</span>
    Use the <span style="color:#75715e">#getRotationMatrix2D function</span>
    trans <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>getRotationMatrix2D((<span style="color:#ae81ff">24</span>, <span style="color:#ae81ff">24</span>), angle, scale)
    <span style="color:#75715e">#Affine transformation</span>
    image1 <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>warpAffine(image, trans, (<span style="color:#ae81ff">50</span>, <span style="color:#ae81ff">50</span>))
    X<span style="color:#f92672">.</span>append(image1<span style="color:#f92672">.</span>flatten())
    Y<span style="color:#f92672">.</span>append(moji)
    
    <span style="color:#75715e"># 2. Rotate 15 degrees counterclockwise</span>
    <span style="color:#75715e">#Specify rotation angle</span>
    angle <span style="color:#f92672">=</span> <span style="color:#ae81ff">15.0</span>
    <span style="color:#75715e"># Specify scale</span>
    scale <span style="color:#f92672">=</span> <span style="color:#ae81ff">1.0</span>
    Use <span style="color:#75715e">#getRotationMatrix2D function (argument: center position, rotation angle, scale)</span>
    trans <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>getRotationMatrix2D((<span style="color:#ae81ff">24</span>, <span style="color:#ae81ff">24</span>), angle, scale)
    <span style="color:#75715e">#Affine transformation</span>
    image2 <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>warpAffine(image, trans, (<span style="color:#ae81ff">50</span>, <span style="color:#ae81ff">50</span>))
    X<span style="color:#f92672">.</span>append(image2<span style="color:#f92672">.</span>flatten())
    Y<span style="color:#f92672">.</span>append(moji)

<span style="color:#75715e"># Display the data at the end</span>
showimage <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>reshape(image, (<span style="color:#ae81ff">50</span>,<span style="color:#ae81ff">50</span>)) <span style="color:#75715e"># reshape to a 50x50 double array</span>
plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">121</span>),plt<span style="color:#f92672">.</span>imshow(showimage),plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#39;Input&#39;</span>)
plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">122</span>),plt<span style="color:#f92672">.</span>imshow(image1),plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#39;Output&#39;</span>)
plt<span style="color:#f92672">.</span>show()

showimage <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>reshape(image, (<span style="color:#ae81ff">50</span>,<span style="color:#ae81ff">50</span>)) <span style="color:#75715e"># reshape to a 50x50 double array</span>
plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">121</span>),plt<span style="color:#f92672">.</span>imshow(showimage),plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#39;Input&#39;</span>)
plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">122</span>),plt<span style="color:#f92672">.</span>imshow(image2),plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#39;Output&#39;</span>)
plt<span style="color:#f92672">.</span>show()
</code></pre></div><h5 id="display-of-rotated-image">Display of rotated image</h5>
<img width="293" alt="03_Image rotation.PNG" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/310568/f0aae952-cea1-c2e2-a28c-dd9d9da899cd.png">
<p>We were able to generate images that were rotated 15 degrees to the left and right.
This image is also added to the training data.</p>
<p>Now, the number of data for learning is 5 times as much as the original (Original, transformation ①, transformation ②, right rotation, left rotation).</p>
<h3 id="learning-and-recognition-re">Learning and recognition [re]</h3>
<p>Let&rsquo;s recognize (classify) images for learning and testing again!</p>
<h4 id="result-1">・Result</h4>
<img width="800" alt="12152147_next result_ worked!.PNG" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/310568/7e2e703c-3e4a-e05b-5ac0-149d6573da27.png">
<p><strong>The accuracy has improved&hellip;! (86.9%)</strong></p>
<h3 id="looking-back">Looking back</h3>
<h5 id="which-data-was-valid-in-the-end">Which data was valid in the end</h5>
<p>I got the result that the analysis accuracy improved when I increased the data!
After all, I was wondering how effective each transformed image worked, so
Roughly, I tried to verify the correct answer rate by changing the breakdown of the data to be learned.
<img width="700" alt="Miscellaneous.PNG" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/310568/bc9984e0-e503-f4ad-e6d9-3c9e59228b25.png">
We were able to confirm that the more accurate the images were, the higher the percentage of correct answers.</p>
<h5 id="what-i-want-to-do-in-the-future">What I want to do in the future</h5>
<p>I would like to continue to verify whether other methods (“trimming”, “noise”, etc.) will improve the accuracy.
I also want to verify the pattern that changed the number of hidden layers in the neural network, which was fixed at 200 this time.</p>
<p>Thank you for reading above!</p>

    </article>
  </div>

  
  
  
  <script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-169005401-1', 'auto');
  ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  

  
<link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.css" />
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#216942",
      "text": "#b2d192"
    },
    "button": {
      "background": "#afed71"
    }
  }
})});
</script>

</body>

</html>
