<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  <meta name="generator" content="Hugo 0.72.0" />

  
  <meta name="description" content="Some description">
  

  
  <link rel="apple-touch-icon" sizes="180x180" href="https://memotut.com/apple-touch-icon.png">

  
  <link rel="icon" type="image/png" sizes="32x32" href="https://memotut.com/favicon-32x32.png">

  
  <link rel="icon" type="image/png" sizes="16x16" href="https://memotut.com/favicon-16x16.png">

  
  <link rel="manifest" href="https://memotut.com/site.webmanifest">

  
  <link rel="mask-icon" href="https://memotut.com/safari-pinned-tab.svg" color="#5bbad5">

  <meta name="msapplication-TileColor" content="#da532c">

  <meta name="theme-color" content="#ffffff">

  
  <link rel="stylesheet" href="https://memotut.com/css/bootstrap.min.css" />

  
  <title>[Python] What ICCV2019 Best paper SinGAN cannot do [Practice] | Memo Tut</title>
  

  <style>
body {
  min-width: 300px;
}

.custom-navbar {
  margin-bottom: 1em;
  height: 60px;
}

.custom-navbar a {
  display: inline-block; 
  padding: 18px 0;
  margin-right: 1em; 
  font-weight: bold; 
}

.custom-navbar a:hover,
.custom-navbar a:focus {
  text-decoration: none; 
}

@media print {
  .custom-navbar {
    display: none;
  }
}

article {
  padding-bottom: 1em;
}

img {
  max-width: 100%;
}


body {
  background-color: #fff;
}



body {
  color: #212529;
}



a {
  color: #007bff;
}



a:hover,
a:focus {
  color: #0056b3;
}



.custom-navbar {
  background-color: #212529;
}



.custom-navbar a {
  color: rgba(255, 255, 255, 0.75);
}



.custom-navbar a:hover,
.custom-navbar a:focus {
  color: rgba(255, 255, 255, 1);
}



.container {
  max-width: 800px;
}



pre {
  display: block;
  padding: 9.5px;
  word-break: break-all;
  word-wrap: break-word;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre code {
  padding: 0;
  font-size: inherit;
  color: inherit; 
  white-space: pre-wrap;
  background-color: transparent;
  border: none;
  border-radius: 0;
}

code {
  padding: 2px 4px;
  color: inherit; 
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
  font-size: .9em;
}



blockquote,
.blockquote {
  padding: 10px 20px;
  margin: 0 0 20px;
  font-size: 1em;
  border-left: 5px solid #6c757d;
}

</style>
</head>

<body>
  <nav class="custom-navbar">
  <div class="container">
    
    <a href="/">Posts</a>
    
    <a href="/tags/">Tags</a>
    
    <a href="/about/">About</a>
    
    <a href="/index.xml">RSS</a>
    
  </div>
</nav>
  
  <div class="container">
    <article>
      <h1>[Python] What ICCV2019 Best paper SinGAN cannot do [Practice]</h1>
<p>
  <small class="text-secondary">
  
  
  Dec 18, 2019
  </small>
  

<small><code><a href="https://memotut.com/tags/python">Python</a></code></small>


<small><code><a href="https://memotut.com/tags/deep-learning">Deep Learning</a></code></small>


<small><code><a href="https://memotut.com/tags/gan">GAN</a></code></small>


<small><code><a href="https://memotut.com/tags/few-shot">Few-Shot</a></code></small>


<small><code><a href="https://memotut.com/tags/iccv-2019">ICCV 2019</a></code></small>

</p>
<pre><code>#Introduction
</code></pre>
<p>This article is an entry of CyberAgent20 new graduate engineer <a href="https://adventar.org/calendars/3976">Advent Calender 2019</a> on the 18th day.
I am a graduate student doing computer vision research using deep learning.
twitter → <a href="https://twitter.com/revi_matsu">https://twitter.com/revi_matsu</a>
This time, it is <strong>SinGAN</strong> practice that won the best paper at ICCV2019 held the other day.</p>
<h1 id="how-to-read-this-article">How to read this article</h1>
<p>[For those who want a rough overview]
Read this article.
[For those who want to know the specifications a little]
This article →<a href="https://qiita.com/Vision_Matsu_Run/items/5f9a958cbaf93bc7b171">I briefly read &ldquo;SinGAN&rdquo; and summarized it</a>
[For those who want to know the details]
This article → <a href="https://qiita.com/Vision_Matsu_Run/items/5f9a958cbaf93bc7b171">&ldquo;SinGAN&rdquo; I read it briefly and summarized it</a>→<a href="https://arxiv.org/pdf/1905.01164.pdf">Papers</a></p>
<p>What is #SinGAN
Please refer to the following articles for the explanation of SinGAN. Here is a brief summary.
<a href="https://qiita.com/Vision_Matsu_Run/items/5f9a958cbaf93bc7b171">ICCV2019 Best Paper &ldquo;SinGAN&rdquo; I read it easily and summarized it</a></p>
<p>SinGAN is a GAN-based one-shot learning method.
What is amazing is that one learning image can be applied to various tasks**.
Usually, not only GAN but deep learning requires a lot of learning images. However, due to the difficulty of collecting data, etc., implementation with a small number of learning images is a subject of high demand, but of course it is not an easy problem.</p>
<p>With SinGAN, it is possible to learn even features that could not be extracted so far.
The following figure is an example of Random sampling (learning with one learning image and generating a similar sample image from noise).
With PSGAN and Deep Texture Synthesis of the conventional method, only the texture (atmosphere) ** of the learning image is retained and the image is generated, but it can be seen that the shape information of the building or building cannot be retained. On the other hand, it can be confirmed that SinGAN also reproduces things like buildings.</p>
<p>SinGAN can be applied to other tasks at a high level, and many experiments are described in the paper.
This time, in addition to actually conducting experiments from the author&rsquo;s <a href="https://github.com/tamarott/SinGAN">github</a>, the practice volume based on the case of applying to tasks not listed in the paper I would like to introduce you.
<img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/458845/7e222f8b-e428-c035-fa2c-106a01620d0c.png" alt="image.png"></p>
<p>#Practice
The code uses <a href="https://github.com/tamarott/SinGAN">here</a>. The code uses python3.6 and the framework uses pytorch.
This time I applied it to the following two tasks.
・Animation (Introduced in the paper)
・Semantic segmentation (not introduced in the paper)</p>
<p>##Animation
Here, gif is generated from one image.
The example of lightning was used in the paper, but this time I was writing an article with Sync in mind at Advent Calender the other day, so I want to ride it.
・<a href="https://qiita.com/Dai7Igarashi/items/84d75d7464b554a7dcf3">@Dai7Igarashi, Make Christmas-like things with FramerMotion! </a></p>
<ul>
<li><a href="https://qiita.com/airagu950/items/9042f22f7a517b6e165a">@Airagu950, Android animation implementation using Lottie</a></li>
</ul>
<p>So, <font color="Salmon">I will create a Christmas-like animation from a single learning image.</font>
<img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/458845/9bfc169a-abab-07d2-8ea0-2fdb3ef723fd.png" alt="snow4.png"></p>
<p>Learning image</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/458845/3b83baca-90ac-3f9f-1b4b-d249888a0218.gif" alt="alpha=0.100000_beta=0.900000.gif"></p>
<p>Generated animation</p>
<p>You can see how the snowy things are randomly generated while maintaining the style, so let&rsquo;s use a sample that can confirm whether the style is maintained or not.
<img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/458845/6792fe89-808c-8a9c-a59a-c833cefe70e8.png" alt="image.png">
Learning image
<img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/458845/535b3d8b-cbc3-2cb0-128a-4b130e1f689d.gif" alt="alpha=0.100000_beta=0.850000.gif">
Generated animation</p>
<p><strong>It can be confirmed that the snowman retains its shape</strong>. In this way, information with large features in the image is highly retained, and conversely, features with small features such as snow are stored. Something like is due to random noise of input when Random sampling
You can see that a small change occurs (I don&rsquo;t care if it is snowing or not.)
Don&rsquo;t you think this is really interesting? ?</p>
<p>##Semantic Segmentation
Semantic Segmentation is a task that has not been proposed in the paper, and it is considered very difficult to realize this task with One-shot.
The main reason for this is that Segmentation generally uses a method of assigning a label that is determined for each pixel, and that it does not learn the conversion of an image from a vehicle-mounted camera to a segmentation image.
**SinGAN is good at extracting features from the teacher image, and there is a high probability that this part of the image that will be the input during the test will be ○! Is not learning. **</p>
<p>However, this time I wanted to see how much feature extraction (I think the expression of feature retention seems more appropriate), so I applied original SinGAN to Semantic Segmentation. ．
To explain briefly, apply <strong>image to image</strong> directly. This time I tried to use in-vehicle camera data set and cell image data set.
<img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/458845/c2452eaa-1e7c-9aad-0c43-03e506571844.png" alt="image.png"></p>
<p>The actual segmentation result is shown below.
Most of the predictions were attached, but it seems difficult to apply segmentation directly to the task.
However, some parts of the cell image can be confirmed where the cell nucleus can be identified. Data such as cell images where the composition of the entire image does not change from image to image may indicate a possibility of segmentation.</p>
<p>In any case, this article simply drops the Segmentation into the existing SinGAN model.
I have high expectations for future development.
<img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/458845/37268f39-8d96-ee9a-5113-98521f8a0d93.png" alt="image.png"></p>
<h1 id="in-conclusion">in conclusion</h1>
<p>This article was SinGAN practice. Many of the tasks that can be done with the original SinGAN are all at a high level, and some of them cannot be considered one-shot learning. I am looking forward to application and development to other tasks as it will become one of the interesting research fields.</p>
<p>Also, this time, I am posting an article to CyberAgent20 new graduate engineer <a href="https://adventar.org/calendars/3976">Advent Calender 2019</a> as a candidate for CyberAgent graduated in 2020, but in fact, <font color=" Red">CyberAgent has started recruiting engineers with 21 graduates! ! </font>
I decided to join CyberAgent through a long-term internship, but I felt that CyberAgent was very interesting in <strong>various services and businesses and their connections</strong>. I feel that such an environment is a very good place for self-development. I am excited to improve my technology and contribute to the company. I decided to join the company because it was rewarding and I expected my growth.
If you are a little interested, please come! An opportunity to broaden your horizons!
<a href="https://www.cyberagent.co.jp/careers/special/engineer2021/?utm_source=twitter&amp;utm_medium=sns&amp;utm_campaign=social">https://www.cyberagent.co.jp/careers/special/engineer2021/?utm_source=twitter&amp;utm_medium=sns&amp;utm_campaign=social</a></p>

    </article>
  </div>

  
  
  
  <script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-169005401-1', 'auto');
  ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  

  
<link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.css" />
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#216942",
      "text": "#b2d192"
    },
    "button": {
      "background": "#afed71"
    }
  }
})});
</script>

</body>

</html>
