<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  <meta name="generator" content="Hugo 0.72.0" />

  
  <meta name="description" content="Some description">
  

  
  <link rel="apple-touch-icon" sizes="180x180" href="https://japan2018.github.io/apple-touch-icon.png">

  
  <link rel="icon" type="image/png" sizes="32x32" href="https://japan2018.github.io/favicon-32x32.png">

  
  <link rel="icon" type="image/png" sizes="16x16" href="https://japan2018.github.io/favicon-16x16.png">

  
  <link rel="manifest" href="https://japan2018.github.io/site.webmanifest">

  
  <link rel="mask-icon" href="https://japan2018.github.io/safari-pinned-tab.svg" color="#5bbad5">

  <meta name="msapplication-TileColor" content="#da532c">

  <meta name="theme-color" content="#ffffff">

  
  <link rel="stylesheet" href="https://japan2018.github.io/css/bootstrap.min.css" />

  
  <title>How to call PyTorch in Julia | Some Title</title>
  

  <style>
body {
  min-width: 300px;
}

.custom-navbar {
  margin-bottom: 1em;
  height: 60px;
}

.custom-navbar a {
  display: inline-block; 
  padding: 18px 0;
  margin-right: 1em; 
  font-weight: bold; 
}

.custom-navbar a:hover,
.custom-navbar a:focus {
  text-decoration: none; 
}

@media print {
  .custom-navbar {
    display: none;
  }
}

article {
  padding-bottom: 1em;
}

img {
  max-width: 100%;
}


body {
  background-color: #fff;
}



body {
  color: #212529;
}



a {
  color: #007bff;
}



a:hover,
a:focus {
  color: #0056b3;
}



.custom-navbar {
  background-color: #212529;
}



.custom-navbar a {
  color: rgba(255, 255, 255, 0.75);
}



.custom-navbar a:hover,
.custom-navbar a:focus {
  color: rgba(255, 255, 255, 1);
}



.container {
  max-width: 800px;
}



pre {
  display: block;
  padding: 9.5px;
  word-break: break-all;
  word-wrap: break-word;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre code {
  padding: 0;
  font-size: inherit;
  color: inherit; 
  white-space: pre-wrap;
  background-color: transparent;
  border: none;
  border-radius: 0;
}

code {
  padding: 2px 4px;
  color: inherit; 
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
  font-size: .9em;
}



blockquote,
.blockquote {
  padding: 10px 20px;
  margin: 0 0 20px;
  font-size: 1em;
  border-left: 5px solid #6c757d;
}

</style>
</head>

<body>
  <nav class="custom-navbar">
  <div class="container">
    
    <a href="/">Posts</a>
    
    <a href="/tags/">Tags</a>
    
    <a href="/about/">About</a>
    
    <a href="/index.xml">RSS</a>
    
  </div>
</nav>
  
  <div class="container">
    <article>
      <h1>How to call PyTorch in Julia</h1>
<p>
  <small class="text-secondary">
  
  
  Mar 5, 2020
  </small>
  

<small><code><a href="https://japan2018.github.io/tags/python">Python</a></code></small>


<small><code><a href="https://japan2018.github.io/tags/julia"> Julia</a></code></small>


<small><code><a href="https://japan2018.github.io/tags/conda"> conda</a></code></small>


<small><code><a href="https://japan2018.github.io/tags/pycall"> PyCall</a></code></small>


<small><code><a href="https://japan2018.github.io/tags/pytorch"> PyTorch</a></code></small>

</p>
<pre><code># Overview
</code></pre>
<p>Create a virtual environment with Conda, enable PyTorch in Python in that virtual environment, make PyCall recognize that Python, and call it with Julia.</p>
<ul>
<li>Conda <a href="https://conda.io/en/latest/">https://conda.io/en/latest/</a></li>
<li>Python <a href="https://docs.python.org/3/">https://docs.python.org/3/</a></li>
<li>PyTorch <a href="https://pytorch.org/docs/stable/index.html">https://pytorch.org/docs/stable/index.html</a></li>
<li>PyCall <a href="https://github.com/JuliaPy/PyCall.jl">https://github.com/JuliaPy/PyCall.jl</a></li>
<li>Julia <a href="https://docs.julialang.org/en/v1/">https://docs.julialang.org/en/v1/</a></li>
</ul>
<p>The procedure is as follows.</p>
<ol>
<li>Install Conda in a shell.</li>
<li>Create a virtual environment with Conda.</li>
<li>Make PyTorch available in the virtual environment.</li>
<li>Install Julia.</li>
<li>Install PyCall to reference Python in the virtual environment.</li>
</ol>
<p>#Details</p>
<p>The method of installing Conda is omitted.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">conda create -n my_env python<span style="color:#f92672">=</span>3.8
conda activate my_env
conda install -c pytorch pytorch
</code></pre></div><p>When you run it, you will get this log.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">paalon at paalon-mac in ~
↪ conda create -n my_env python<span style="color:#f92672">=</span>3.8 <span style="color:#f92672">(</span>base<span style="color:#f92672">)</span>
Collecting package metadata <span style="color:#f92672">(</span>current_repodata.json<span style="color:#f92672">)</span>: <span style="color:#66d9ef">done</span>
Solving environment: <span style="color:#66d9ef">done</span>

<span style="color:#75715e">## Package Plan ##</span>

  environment location: /Users/paalon/conda/envs/my_env

  added / updated specs:
    -python<span style="color:#f92672">=</span>3.8


The following NEW packages will be INSTALLED:

  ca-certificates pkgs/main/osx-64::ca-certificates-2020.1.1-0
  certifi pkgs/main/osx-64::certifi-2019.11.28-py38_0
  libcxx pkgs/main/osx-64::libcxx-4.0.1-hcfea43d_1
  libcxxabi pkgs/main/osx-64::libcxxabi-4.0.1-hcfea43d_1
  libedit pkgs/main/osx-64::libedit-3.1.20181209-hb402a30_0
  libffi pkgs/main/osx-64::libffi-3.2.1-h475c297_4
  ncurses pkgs/main/osx-64::ncurses-6.2-h0a44026_0
  openssl pkgs/main/osx-64::openssl-1.1.1d-h1de35cc_4
  pip pkgs/main/osx-64::pip-20.0.2-py38_1
  python pkgs/main/osx-64::python-3.8.1-h359304d_1
  readline pkgs/main/osx-64::readline-7.0-h1de35cc_5
  setuptools pkgs/main/osx-64::setuptools-45.2.0-py38_0
  sqlite pkgs/main/osx-64::sqlite-3.31.1-ha441bb4_0
  tk pkgs/main/osx-64::tk-8.6.8-ha441bb4_0
  wheel pkgs/main/osx-64::wheel-0.34.2-py38_0
  xz pkgs/main/osx-64::xz-5.2.4-h1de35cc_4
  zlib pkgs/main/osx-64::zlib-1.2.11-h1de35cc_3


Proceed <span style="color:#f92672">([</span>y<span style="color:#f92672">]</span>/n<span style="color:#f92672">)</span>? y

Preparing transaction: <span style="color:#66d9ef">done</span>
Verifying transaction: <span style="color:#66d9ef">done</span>
Executing transaction: <span style="color:#66d9ef">done</span>
#
<span style="color:#75715e"># To activate this environment, use</span>
#
<span style="color:#75715e"># $ conda activate my_env</span>
#
<span style="color:#75715e"># To deactivate an active environment, use</span>
#
<span style="color:#75715e"># $ conda deactivate</span>

paalon at paalon-mac in ~
↪ conda activate my_env <span style="color:#f92672">(</span>base<span style="color:#f92672">)</span>
paalon at paalon-mac in ~
↪ conda install -c pytorch pytorch <span style="color:#f92672">(</span>my_env<span style="color:#f92672">)</span>
Collecting package metadata <span style="color:#f92672">(</span>current_repodata.json<span style="color:#f92672">)</span>: <span style="color:#66d9ef">done</span>
Solving environment: <span style="color:#66d9ef">done</span>

<span style="color:#75715e">## Package Plan ##</span>

  environment location: /Users/paalon/conda/envs/my_env

  added / updated specs:
    -pytorch


The following NEW packages will be INSTALLED:

  blas pkgs/main/osx-64::blas-1.0-mkl
  intel-openmp pkgs/main/osx-64::intel-openmp-2019.4-233
  libgfortran pkgs/main/osx-64::libgfortran-3.0.1-h93005f0_2
  mkl pkgs/main/osx-64::mkl-2019.4-233
  mkl-service pkgs/main/osx-64::mkl-service-2.3.0-py38hfbe908c_0
  mkl_fft pkgs/main/osx-64::mkl_fft-1.0.15-py38h5e564d8_0
  mkl_random pkgs/main/osx-64::mkl_random-1.1.0-py38h6440ff4_0
  ninja pkgs/main/osx-64::ninja-1.9.0-py38h04f5b5a_0
  numpy pkgs/main/osx-64::numpy-1.18.1-py38h7241aed_0
  numpy-base pkgs/main/osx-64::numpy-base-1.18.1-py38h6575580_1
  pytorch pytorch/osx-64::pytorch-1.4.0-py3.8_0
  six pkgs/main/osx-64::six-1.14.0-py38_0


Proceed <span style="color:#f92672">([</span>y<span style="color:#f92672">]</span>/n<span style="color:#f92672">)</span>? y

Preparing transaction: <span style="color:#66d9ef">done</span>
Verifying transaction: <span style="color:#66d9ef">done</span>
Executing transaction: <span style="color:#66d9ef">done</span>
</code></pre></div><p>Start Julia.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">paalon at paalon-mac in ~
↪ julia <span style="color:#f92672">(</span>my_env<span style="color:#f92672">)</span>
               _
   _ _ _<span style="color:#f92672">(</span>_<span style="color:#f92672">)</span>_ | Documentation: https://docs.julialang.org
  <span style="color:#f92672">(</span>_<span style="color:#f92672">)</span> | <span style="color:#f92672">(</span>_<span style="color:#f92672">)</span> <span style="color:#f92672">(</span>_<span style="color:#f92672">)</span> |
   _ _ _| |_ __ _ | Type <span style="color:#e6db74">&#34;?&#34;</span> <span style="color:#66d9ef">for</span> help, <span style="color:#e6db74">&#34;]?&#34;</span> <span style="color:#66d9ef">for</span> Pkg help.
  | | | | | | |/ _<span style="color:#e6db74">`</span> | |
  | | |_| | | | <span style="color:#f92672">(</span>_| | | Version 1.3.1 <span style="color:#f92672">(</span>2019-12-30<span style="color:#f92672">)</span>
 _/ |<span style="color:#ae81ff">\_</span>_<span style="color:#e6db74">&#39;_|_|_|\__&#39;</span>_| | Official https://julialang.org/ release
|__/ |

</code></pre></div><p>It is available by adding PyCall, setting <code>ENV[&quot;PYCALL_JL_RUNTIME_PYTHON&quot;]</code> and <code>ENV[&quot;PYTHON&quot;]</code> to <code>Sys.which(&quot;python&quot;)</code>, and building.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-julia" data-lang="julia">(v1<span style="color:#f92672">.</span><span style="color:#ae81ff">3</span>) pkg<span style="color:#f92672">&gt;</span> add PyCall
  Updating registry at <span style="color:#e6db74">`~/.julia/registries/General`</span>
  Updating git<span style="color:#f92672">-</span>repo <span style="color:#e6db74">`https://github.com/JuliaRegistries/General.git`</span>
 Resolving package versions<span style="color:#f92672">...</span>
  Updating <span style="color:#e6db74">`~/.julia/environments/v1.3/Project.toml`</span>
  [<span style="color:#ae81ff">438e738</span>f] <span style="color:#f92672">+</span> PyCall v1<span style="color:#f92672">.</span><span style="color:#ae81ff">91.4</span>
  Updating <span style="color:#e6db74">`~/.julia/environments/v1.3/Manifest.toml`</span>
  [<span style="color:#ae81ff">8f4</span>d0f93] <span style="color:#f92672">+</span> Conda v1<span style="color:#f92672">.</span><span style="color:#ae81ff">4.1</span>
  [<span style="color:#ae81ff">438e738</span>f] <span style="color:#f92672">+</span> PyCall v1<span style="color:#f92672">.</span><span style="color:#ae81ff">91.4</span>
  [<span style="color:#ae81ff">81</span>def892] <span style="color:#f92672">+</span> VersionParsing v1<span style="color:#f92672">.</span><span style="color:#ae81ff">2.0</span>

julia<span style="color:#f92672">&gt;</span> ENV[<span style="color:#e6db74">&#34;PYCALL_JL_RUNTIME_PYTHON&#34;</span>] <span style="color:#f92672">=</span> Sys<span style="color:#f92672">.</span>which(<span style="color:#e6db74">&#34;python&#34;</span>)
<span style="color:#e6db74">&#34;/Users/paalon/conda/envs/my_env/bin/python3.8&#34;</span>

julia<span style="color:#f92672">&gt;</span> ENV[<span style="color:#e6db74">&#34;PYTHON&#34;</span>] <span style="color:#f92672">=</span> Sys<span style="color:#f92672">.</span>which(<span style="color:#e6db74">&#34;python&#34;</span>)
<span style="color:#e6db74">&#34;/Users/paalon/conda/envs/my_env/bin/python3.8&#34;</span>

(v1<span style="color:#f92672">.</span><span style="color:#ae81ff">3</span>) pkg<span style="color:#f92672">&gt;</span> build PyCall
  Building Conda ─→ <span style="color:#e6db74">`~/.julia/packages/Conda/3rPhK/deps/build.log`</span>Building PyCall → <span style="color:#e6db74">`~/.julia/packages/PyCall/zqDXB/deps/build.log`</span>

julia<span style="color:#f92672">&gt;</span> <span style="color:#66d9ef">using</span> PyCall
[ Info<span style="color:#f92672">:</span> Precompiling PyCall [<span style="color:#ae81ff">438e738</span>f<span style="color:#f92672">-</span><span style="color:#ae81ff">606</span>a<span style="color:#f92672">-</span><span style="color:#ae81ff">5</span>dbb<span style="color:#f92672">-</span>bf0a<span style="color:#f92672">-</span>cddfbfd45ab0]

julia<span style="color:#f92672">&gt;</span> torch <span style="color:#f92672">=</span> pyimport(<span style="color:#e6db74">&#34;torch&#34;</span>)
PyObject <span style="color:#f92672">&lt;</span><span style="color:#66d9ef">module</span> <span style="color:#960050;background-color:#1e0010">&#39;</span>torch<span style="color:#f92672">&#39;</span> from <span style="color:#960050;background-color:#1e0010">&#39;</span><span style="color:#f92672">/</span>Users<span style="color:#f92672">/</span>paalon<span style="color:#f92672">/</span>conda<span style="color:#f92672">/</span>envs<span style="color:#f92672">/</span>my_env<span style="color:#f92672">/</span>lib<span style="color:#f92672">/</span>python3<span style="color:#f92672">.</span><span style="color:#ae81ff">8</span><span style="color:#f92672">/</span>site<span style="color:#f92672">-</span>packages<span style="color:#f92672">/</span>torch<span style="color:#f92672">/</span>__init__<span style="color:#f92672">.</span>py<span style="color:#f92672">&#39;&gt;</span>

julia<span style="color:#f92672">&gt;</span> x <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>tensor([<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>])
PyObject tensor([<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>])
</code></pre></div><h1 id="例">例</h1>
<p>以下の<a href="https://pytorch.org/tutorials/beginner/pytorch_with_examples.html#autograd">公式チュートリアルの例に書かれているもの</a></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> torch

dtype <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>float
device <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>device(<span style="color:#e6db74">&#34;cpu&#34;</span>)
<span style="color:#75715e"># device = torch.device(&#34;cuda:0&#34;) # Uncomment this to run on GPU</span>

<span style="color:#75715e"># N is batch size; D_in is input dimension;</span>
<span style="color:#75715e"># H is hidden dimension; D_out is output dimension.</span>
N, D_in, H, D_out <span style="color:#f92672">=</span> <span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">1000</span>, <span style="color:#ae81ff">100</span>, <span style="color:#ae81ff">10</span>

<span style="color:#75715e"># Create random Tensors to hold input and outputs.</span>
<span style="color:#75715e"># Setting requires_grad=False indicates that we do not need to compute gradients</span>
<span style="color:#75715e"># with respect to these Tensors during the backward pass.</span>
x <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>randn(N, D_in, device<span style="color:#f92672">=</span>device, dtype<span style="color:#f92672">=</span>dtype)
y <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>randn(N, D_out, device<span style="color:#f92672">=</span>device, dtype<span style="color:#f92672">=</span>dtype)

<span style="color:#75715e"># Create random Tensors for weights.</span>
<span style="color:#75715e"># Setting requires_grad=True indicates that we want to compute gradients with</span>
<span style="color:#75715e"># respect to these Tensors during the backward pass.</span>
w1 <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>randn(D_in, H, device<span style="color:#f92672">=</span>device, dtype<span style="color:#f92672">=</span>dtype, requires_grad<span style="color:#f92672">=</span>True)
w2 <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>randn(H, D_out, device<span style="color:#f92672">=</span>device, dtype<span style="color:#f92672">=</span>dtype, requires_grad<span style="color:#f92672">=</span>True)

learning_rate <span style="color:#f92672">=</span> <span style="color:#ae81ff">1e-6</span>
<span style="color:#66d9ef">for</span> t <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">500</span>):
    <span style="color:#75715e"># Forward pass: compute predicted y using operations on Tensors; these</span>
    <span style="color:#75715e"># are exactly the same operations we used to compute the forward pass using</span>
    <span style="color:#75715e"># Tensors, but we do not need to keep references to intermediate values since</span>
    <span style="color:#75715e"># we are not implementing the backward pass by hand.</span>
    y_pred <span style="color:#f92672">=</span> x<span style="color:#f92672">.</span>mm(w1)<span style="color:#f92672">.</span>clamp(min<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)<span style="color:#f92672">.</span>mm(w2)

    <span style="color:#75715e"># Compute and print loss using operations on Tensors.</span>
    <span style="color:#75715e"># Now loss is a Tensor of shape (1,)</span>
    <span style="color:#75715e"># loss.item() gets the scalar value held in the loss.</span>
    loss <span style="color:#f92672">=</span> (y_pred <span style="color:#f92672">-</span> y)<span style="color:#f92672">.</span>pow(<span style="color:#ae81ff">2</span>)<span style="color:#f92672">.</span>sum()
    <span style="color:#66d9ef">if</span> t <span style="color:#f92672">%</span> <span style="color:#ae81ff">100</span> <span style="color:#f92672">==</span> <span style="color:#ae81ff">99</span>:
        <span style="color:#66d9ef">print</span>(t, loss<span style="color:#f92672">.</span>item())

    <span style="color:#75715e"># Use autograd to compute the backward pass. This call will compute the</span>
    <span style="color:#75715e"># gradient of loss with respect to all Tensors with requires_grad=True.</span>
    <span style="color:#75715e"># After this call w1.grad and w2.grad will be Tensors holding the gradient</span>
    <span style="color:#75715e"># of the loss with respect to w1 and w2 respectively.</span>
    loss<span style="color:#f92672">.</span>backward()

    <span style="color:#75715e"># Manually update weights using gradient descent. Wrap in torch.no_grad()</span>
    <span style="color:#75715e"># because weights have requires_grad=True, but we don&#39;t need to track this</span>
    <span style="color:#75715e"># in autograd.</span>
    <span style="color:#75715e"># An alternative way is to operate on weight.data and weight.grad.data.</span>
    <span style="color:#75715e"># Recall that tensor.data gives a tensor that shares the storage with</span>
    <span style="color:#75715e"># tensor, but doesn&#39;t track history.</span>
    <span style="color:#75715e"># You can also use torch.optim.SGD to achieve this.</span>
    <span style="color:#66d9ef">with</span> torch<span style="color:#f92672">.</span>no_grad():
        w1 <span style="color:#f92672">-=</span> learning_rate <span style="color:#f92672">*</span> w1<span style="color:#f92672">.</span>grad
        w2 <span style="color:#f92672">-=</span> learning_rate <span style="color:#f92672">*</span> w2<span style="color:#f92672">.</span>grad

        <span style="color:#75715e"># Manually zero the gradients after updating weights</span>
        w1<span style="color:#f92672">.</span>grad<span style="color:#f92672">.</span>zero_()
        w2<span style="color:#f92672">.</span>grad<span style="color:#f92672">.</span>zero_()

</code></pre></div><p>をほとんどそのまま Julia に移植すると</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-julia" data-lang="julia">ENV[<span style="color:#e6db74">&#34;PYCALL_JL_RUNTIME_PYTHON&#34;</span>] <span style="color:#f92672">=</span> Sys<span style="color:#f92672">.</span>which(<span style="color:#e6db74">&#34;python&#34;</span>)
ENV[<span style="color:#e6db74">&#34;PYTHON&#34;</span>] <span style="color:#f92672">=</span> Sys<span style="color:#f92672">.</span>which(<span style="color:#e6db74">&#34;python&#34;</span>)
<span style="color:#75715e"># python の構成を変えたときは次の行を実行してビルドする。</span>
<span style="color:#75715e"># using Pkg; Pkg.build(&#34;PyCall&#34;)</span>
<span style="color:#66d9ef">using</span> PyCall

torch <span style="color:#f92672">=</span> pyimport(<span style="color:#e6db74">&#34;torch&#34;</span>)

dtype <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>float
device <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>device(<span style="color:#e6db74">&#34;cpu&#34;</span>)
<span style="color:#75715e"># device = torch.device(&#34;cuda:0&#34;) # Uncomment this to run on GPU</span>

<span style="color:#75715e"># N is batch size; D_in is input dimension;</span>
<span style="color:#75715e"># H is hidden dimension; D_out is output dimension.</span>
N, D_in, H, D_out <span style="color:#f92672">=</span> <span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">1000</span>, <span style="color:#ae81ff">100</span>, <span style="color:#ae81ff">10</span>

<span style="color:#75715e"># Create random Tensors to hold input and outputs.</span>
<span style="color:#75715e"># Setting requires_grad=False indicates that we do not need to compute gradients</span>
<span style="color:#75715e"># with respect to these Tensors during the backward pass.</span>
x <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>randn(N, D_in, device<span style="color:#f92672">=</span>device, dtype<span style="color:#f92672">=</span>dtype)
y <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>randn(N, D_out, device<span style="color:#f92672">=</span>device, dtype<span style="color:#f92672">=</span>dtype)

<span style="color:#75715e"># Create random Tensors for weights.</span>
<span style="color:#75715e"># Setting requires_grad=True indicates that we want to compute gradients with</span>
<span style="color:#75715e"># respect to these Tensors during the backward pass.</span>
w1 <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>randn(D_in, H, device<span style="color:#f92672">=</span>device, dtype<span style="color:#f92672">=</span>dtype, requires_grad<span style="color:#f92672">=</span><span style="color:#66d9ef">true</span>)
w2 <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>randn(H, D_out, device<span style="color:#f92672">=</span>device, dtype<span style="color:#f92672">=</span>dtype, requires_grad<span style="color:#f92672">=</span><span style="color:#66d9ef">true</span>)

learning_rate <span style="color:#f92672">=</span> <span style="color:#ae81ff">1e-6</span>
<span style="color:#66d9ef">for</span> t <span style="color:#66d9ef">in</span> <span style="color:#ae81ff">1</span><span style="color:#f92672">:</span><span style="color:#ae81ff">500</span>
    <span style="color:#75715e"># Forward pass: compute predicted y using operations on Tensors; these</span>
    <span style="color:#75715e"># are exactly the same operations we used to compute the forward pass using</span>
    <span style="color:#75715e"># Tensors, but we do not need to keep references to intermediate values since</span>
    <span style="color:#75715e"># we are not implementing the backward pass by hand.</span>
    y_pred <span style="color:#f92672">=</span> x<span style="color:#f92672">.</span>mm(w1)<span style="color:#f92672">.</span>clamp(min<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)<span style="color:#f92672">.</span>mm(w2)

    <span style="color:#75715e"># Compute and print loss using operations on Tensors.</span>
    <span style="color:#75715e"># Now loss is a Tensor of shape (1,)</span>
    <span style="color:#75715e"># loss.item() gets the scalar value held in the loss.</span>
    loss <span style="color:#f92672">=</span> (y_pred <span style="color:#f92672">-</span> y)<span style="color:#f92672">.</span>pow(<span style="color:#ae81ff">2</span>)<span style="color:#f92672">.</span>sum()
    <span style="color:#66d9ef">if</span> t <span style="color:#f92672">%</span> <span style="color:#ae81ff">100</span> <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span>
        println(<span style="color:#e6db74">&#34;</span><span style="color:#e6db74">$</span>(t)<span style="color:#e6db74"> </span><span style="color:#e6db74">$</span>(loss<span style="color:#f92672">.</span>item())<span style="color:#e6db74">&#34;</span>)
    <span style="color:#66d9ef">end</span>

    <span style="color:#75715e"># Use autograd to compute the backward pass. This call will compute the</span>
    <span style="color:#75715e"># gradient of loss with respect to all Tensors with requires_grad=True.</span>
    <span style="color:#75715e"># After this call w1.grad and w2.grad will be Tensors holding the gradient</span>
    <span style="color:#75715e"># of the loss with respect to w1 and w2 respectively.</span>
    loss<span style="color:#f92672">.</span>backward()<span style="color:#75715e"># Manually update weights using gradient descent. Wrap in torch.no_grad()</span>
    <span style="color:#75715e"># because weights have requires_grad=True, but we don&#39;t need to track this</span>
    <span style="color:#75715e"># in autograd.</span>
    <span style="color:#75715e"># An alternative way is to operate on weight.data and weight.grad.data.</span>
    <span style="color:#75715e"># Recall that tensor.data gives a tensor that shares the storage with</span>
    <span style="color:#75715e"># tensor, but doesn&#39;t track history.</span>
    <span style="color:#75715e"># You can also use torch.optim.SGD to achieve this.</span>
    <span style="color:#a6e22e">@pywith</span> torch<span style="color:#f92672">.</span>no_grad() <span style="color:#66d9ef">begin</span>
        <span style="color:#75715e"># 代入してしまうと、置き換えてしまうので使わないこと。</span>
        <span style="color:#75715e"># w1 -= learning_rate * w1.grad</span>
        <span style="color:#75715e"># w2 -= learning_rate * w2.grad</span>
        w1<span style="color:#f92672">.</span>sub_(learning_rate <span style="color:#f92672">*</span> w1<span style="color:#f92672">.</span>grad)
        w2<span style="color:#f92672">.</span>sub_(learning_rate <span style="color:#f92672">*</span> w2<span style="color:#f92672">.</span>grad)
        <span style="color:#75715e"># Manually zero the gradients after updating weights</span>
        w1<span style="color:#f92672">.</span>grad<span style="color:#f92672">.</span>zero_()
        w2<span style="color:#f92672">.</span>grad<span style="color:#f92672">.</span>zero_()
    <span style="color:#66d9ef">end</span>
<span style="color:#66d9ef">end</span>
</code></pre></div><p>となる。</p>

    </article>
  </div>

  
  
  
  <script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-123456789-1', 'auto');
  ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  

  
<link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.css" />
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#216942",
      "text": "#b2d192"
    },
    "button": {
      "background": "#afed71"
    }
  }
})});
</script>

</body>

</html>
