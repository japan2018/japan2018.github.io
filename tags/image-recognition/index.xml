<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title> image recognition on Memo Tut</title>
    <link>https://memotut.com/tags/image-recognition/</link>
    <description>Recent content in  image recognition on Memo Tut</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 29 Jan 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://memotut.com/tags/image-recognition/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>I tried to automate the face hiding work of wear coordination images</title>
      <link>https://memotut.com/i-tried-to-automate-the-face-hiding-work-of-wear-coordination-images-dab3b/</link>
      <pubDate>Wed, 29 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/i-tried-to-automate-the-face-hiding-work-of-wear-coordination-images-dab3b/</guid>
      <description>Do you all know Wear?  WEAR is a fashion coordination site and one of our services. In short, it is an SNS where you can share your fashion coordination.
I don&amp;rsquo;t know why, but it seems to be popular to post with the face hidden by an icon. Is it because people without a face can see the coordination objectively?
However, the face hiding work is surprisingly troublesome, and I wish I could automate this&amp;hellip; so I implemented a program for automatic icon placement.</description>
    </item>
    
    <item>
      <title>The fastest way to try EfficientNet</title>
      <link>https://memotut.com/the-fastest-way-to-try-efficientnet-d90fa/</link>
      <pubDate>Mon, 27 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/the-fastest-way-to-try-efficientnet-d90fa/</guid>
      <description># TL;DR   Pre-learned weights by imagenet is published on Tensorflow Hub -EfficientNet B0-All released up to B7 -Use feature vectors for transfer learning available Transfer learning using official TensorFlow Hub and introduction of the fastest way to try EfficientNet -Run Image classification demo in Google Colabratory environment -If you can prepare the environment, you should be able to confirm the operation with the same code as the demo -All you have to do is change the URL that represents the model to be DL in tensorflow-hub library  #Introduction</description>
    </item>
    
    <item>
      <title>Judging the loss of Shadowba by image recognition</title>
      <link>https://memotut.com/judging-the-loss-of-shadowba-by-image-recognition-6bf4e/</link>
      <pubDate>Mon, 13 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/judging-the-loss-of-shadowba-by-image-recognition-6bf4e/</guid>
      <description>---  This article is a relay article of &amp;ldquo;2020 New Year Advent Calendar TechConnect!&amp;ldquo;ofLinkInformationSystem is. TechConnect! is a self-starting advent calendar relayed by a self-made group called engineer.hanzomon. (From [Link here] Facebook)
 Since the theme was free, it will be a free article. (The technique used is serious.) I made good use of the tutorial and did image recognition.
Done A program to detect Win/Lose of Shadowverse (Steam version) has been created.</description>
    </item>
    
    <item>
      <title>Can AI distinguish Carlos Ghosn and Mr. Bean (Face recognition using face landmark)</title>
      <link>https://memotut.com/can-ai-distinguish-carlos-ghosn-and-mr.-bean-face-recognition-using-face-landmark-d1b29/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/can-ai-distinguish-carlos-ghosn-and-mr.-bean-face-recognition-using-face-landmark-d1b29/</guid>
      <description>#Introduction  The news is about the news that Carlos Ghosn, the former chairman of Nissan Motor Co., Ltd., broke bail conditions and traveled to Lebanon. I&amp;rsquo;ve been thinking for a long time, but it&amp;rsquo;s similar to Mr. Bean&amp;hellip; Left: [Carlos Ghosn](https://www.google.com/search?q=Carlos+Ghosn&amp;amp;sxsrf=ACYBGNS1gsNQxqfqi7GRWUUeSSZ6CRix8w:1577813710879&amp;amp;source=lnms&amp;amp;tbm=isch&amp;amp;Ah&amp;amp;EqjQAQBQ&amp;amp;QAQBQBQ&amp;amp;QAQBQ&amp;amp;QB Right: [Mr. Bean (Rowan Atkinson)](https://www.google.com/search?q=rowan+atkinson&amp;amp;biw=1386&amp;amp;bih=710&amp;amp;sxsrf=ACYBGNTsdddnLF7jgPr9RTePeEMGgREpyA:1577813660092&amp;amp;source=lnms&amp;amp;tbm=isch&amp;amp;saQ&amp;amp;isch&amp;amp;saq
It was a year-end and New Year holiday, so I made a little classifier using a neural network. If you google it, a lot of images of the two people will appear, so it was good for CNN, but This time, as another approach, I would like to perform classification based on the position of landmarks on the face.</description>
    </item>
    
    <item>
      <title>Few shot NODOGURO turning, I tried to automatically count Nodoguro</title>
      <link>https://memotut.com/few-shot-nodoguro-turning-i-tried-to-automatically-count-nodoguro-c3ece/</link>
      <pubDate>Thu, 05 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/few-shot-nodoguro-turning-i-tried-to-automatically-count-nodoguro-c3ece/</guid>
      <description>This article is from the 5th day of [Furukawa Laboratory Advent_calendar](https://qiita.com/advent-calendar/2019/flab).  #Introduction It is said that various frameworks such as PyTorch, Chainer, Keras, and TensorFlow have appeared, making it easy for anyone to use Deep Learning. For those of you who are actually using Deep Learning, it may seem easy just to move it. However, it is more difficult for people who do not use Python much than Deep Learning.</description>
    </item>
    
    <item>
      <title>I tried extracting characters from subtitles (OpenCV: tesseract-ocr)</title>
      <link>https://memotut.com/i-tried-extracting-characters-from-subtitles-opencv-tesseract-ocr-112c6/</link>
      <pubDate>Sun, 24 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/i-tried-extracting-characters-from-subtitles-opencv-tesseract-ocr-112c6/</guid>
      <description>#Introduction  Here, I will try extracting characters from the subtitles that are displayed under the political broadcast. Since there is no background, it seems to be quite binary.
Although it is possible to get the character and the position with considerable accuracy by extracting the character with the google cloud vision API, I will try to get the character by other methods here.
tesseract-ocr / pyocr First, let&amp;rsquo;s recognize characters using tesseract and pyocr.</description>
    </item>
    
    <item>
      <title>I tried to recognize the face from the video (OpenCV: python version)</title>
      <link>https://memotut.com/i-tried-to-recognize-the-face-from-the-video-opencv-python-version-80072/</link>
      <pubDate>Sat, 16 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/i-tried-to-recognize-the-face-from-the-video-opencv-python-version-80072/</guid>
      <description># Trigger  How to save a part of a long video using OpenCV How to take captured image from video (OpenCV) And from the candidate video, I used OpenCV to prepare the environment that seems to be necessary for image processing. From here, I will try to process using the function/library. The first is face recognition.
#Preparation Since it is developed on Mac, install it from Homebrew.
brew install opencv Therefore, under /usr/local/Cellar/opencv/4.</description>
    </item>
    
  </channel>
</rss>