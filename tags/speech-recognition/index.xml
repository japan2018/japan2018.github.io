<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title> Speech recognition on Memo Tut</title>
    <link>https://memotut.com/tags/speech-recognition/</link>
    <description>Recent content in  Speech recognition on Memo Tut</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 02 Jan 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://memotut.com/tags/speech-recognition/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Investigation of relationship between voice preprocessing and transcription accuracy in Google Cloud Speech API</title>
      <link>https://memotut.com/investigation-of-relationship-between-voice-preprocessing-and-transcription-accuracy-in-google-cloud-speech-api-cfbfa/</link>
      <pubDate>Thu, 02 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/investigation-of-relationship-between-voice-preprocessing-and-transcription-accuracy-in-google-cloud-speech-api-cfbfa/</guid>
      <description>## Transcription accuracy is lower than expected  As I mentioned at the end of the previous article that summarized How to use Google Speech API, I encountered a problem that the character recognition accuracy is lower than I expected. It was.
It seems that about 80% can be transcribed in rebuild.fm, but in my case not even half recognized by experience It&amp;rsquo;s an impression. Even though it wasn&amp;rsquo;t perfect, I was hoping that reading the transcribed text would give me a sense of what the conversation was about, but it was pretty devastating.</description>
    </item>
    
    <item>
      <title>Speech transcription procedure using Python and Google Cloud Speech API</title>
      <link>https://memotut.com/speech-transcription-procedure-using-python-and-google-cloud-speech-api-bc22e/</link>
      <pubDate>Sun, 15 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/speech-transcription-procedure-using-python-and-google-cloud-speech-api-bc22e/</guid>
      <description>![Screenshot 2019-12-15 16.20.07.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/100780/160e795f-1baf-4446-2331-(eb4d0e37dbeb.png)  I have a podcast called Platinum Mining Industry.FM, so I tried Google Cloud Speech API this time to transcribe the voice data. (*Google&amp;rsquo;s transcription API is officially shaking with the names &amp;ldquo;Google Cloud Speech API&amp;rdquo; and &amp;ldquo;Cloud Speech-to-Text. Maybe they are together. Mystery.&amp;quot;)
Please refer to here for the procedure to create recording and audio data.
 [Fiscal 2019 version] Introduction to Podcast distribution for those who aim for the minimum beautiful sound quality with the minimum effort-Qiita  The following blogs are the most detailed on how to use the Google Cloud Speech API.</description>
    </item>
    
    <item>
      <title>Speech recognition by Python MFCC</title>
      <link>https://memotut.com/speech-recognition-by-python-mfcc-15968/</link>
      <pubDate>Wed, 20 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/speech-recognition-by-python-mfcc-15968/</guid>
      <description>In the [previous article](https://qiita.com/k-maru/items/4f12fd0f8344b9e093bd),vowelrecognitionwasperformedusingformantanalysis.IlearnedaboutMFCCinaninternshipat[CyceedCo.,Ltd.](http://www.sciseed.jp/), and verified the classification accuracy, so this article is a continuation of the previous article about MFCC that is often used for speech recognition. I would like to summarize.  ##table of contents
 Background What is MFCC -MFCC derivation process Implementation of MFCC derivation program -Regarding librosa -Derivation of MFCC -Phoneme class classification using MFCC Implementation of a program for continuous speech recognition -Regarding dynamic differences -Derivation of primary and secondary differences -Phoneme class classification including features of second-order differences Consideration Summary Reference  background Previous article formant analysis finds the envelope of the spectrum, and the frequencies emphasized in them are used as features from lower to F1 and F2.</description>
    </item>
    
  </channel>
</rss>