<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  <meta name="generator" content="Hugo 0.72.0" />

  
  <meta name="description" content="Some description">
  

  
  <link rel="apple-touch-icon" sizes="180x180" href="https://memotut.com/apple-touch-icon.png">

  
  <link rel="icon" type="image/png" sizes="32x32" href="https://memotut.com/favicon-32x32.png">

  
  <link rel="icon" type="image/png" sizes="16x16" href="https://memotut.com/favicon-16x16.png">

  
  <link rel="manifest" href="https://memotut.com/site.webmanifest">

  
  <link rel="mask-icon" href="https://memotut.com/safari-pinned-tab.svg" color="#5bbad5">

  <meta name="msapplication-TileColor" content="#da532c">

  <meta name="theme-color" content="#ffffff">

  
  <link rel="stylesheet" href="https://memotut.com/css/bootstrap.min.css" />

  
  <title>Machine learning with Raspberry Pi 4 and Coral USB Accelerator | Memo Tut</title>
  

  <style>
body {
  min-width: 300px;
}

.custom-navbar {
  margin-bottom: 1em;
  height: 60px;
}

.custom-navbar a {
  display: inline-block; 
  padding: 18px 0;
  margin-right: 1em; 
  font-weight: bold; 
}

.custom-navbar a:hover,
.custom-navbar a:focus {
  text-decoration: none; 
}

@media print {
  .custom-navbar {
    display: none;
  }
}

article {
  padding-bottom: 1em;
}

img {
  max-width: 100%;
}


body {
  background-color: #fff;
}



body {
  color: #212529;
}



a {
  color: #007bff;
}



a:hover,
a:focus {
  color: #0056b3;
}



.custom-navbar {
  background-color: #212529;
}



.custom-navbar a {
  color: rgba(255, 255, 255, 0.75);
}



.custom-navbar a:hover,
.custom-navbar a:focus {
  color: rgba(255, 255, 255, 1);
}



.container {
  max-width: 800px;
}



pre {
  display: block;
  padding: 9.5px;
  word-break: break-all;
  word-wrap: break-word;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre code {
  padding: 0;
  font-size: inherit;
  color: inherit; 
  white-space: pre-wrap;
  background-color: transparent;
  border: none;
  border-radius: 0;
}

code {
  padding: 2px 4px;
  color: inherit; 
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
  font-size: .9em;
}



blockquote,
.blockquote {
  padding: 10px 20px;
  margin: 0 0 20px;
  font-size: 1em;
  border-left: 5px solid #6c757d;
}

</style>
</head>

<body>
  <nav class="custom-navbar">
  <div class="container">
    
    <a href="/">Posts</a>
    
    <a href="/tags/">Tags</a>
    
    <a href="/about/">About</a>
    
    <a href="/index.xml">RSS</a>
    
  </div>
</nav>
  
  <div class="container">
    <article>
      <h1>Machine learning with Raspberry Pi 4 and Coral USB Accelerator</h1>
<p>
  <small class="text-secondary">
  
  
  Feb 19, 2020
  </small>
  

<small><code><a href="https://memotut.com/tags/python">Python</a></code></small>


<small><code><a href="https://memotut.com/tags/raspberrypi">RaspberryPi</a></code></small>


<small><code><a href="https://memotut.com/tags/tensorflowlite">TensorflowLite</a></code></small>


<small><code><a href="https://memotut.com/tags/edgetpu">EdgeTPU</a></code></small>

</p>
<pre><code>#Introduction
</code></pre>
<p>This article summarizes the installation procedure of Raspberry Pi 4 and Coral USB Accelerator as a method of machine learning with edge device.</p>
<p><strong>Raspberry Pi 4</strong> is the latest generation of the current model. The CPU and memory performance have been greatly improved, and USB 3.0 is also supported.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/221759/f0ad30f1-4f30-b877-3dfc-39b17e0f32af.jpeg" alt="Photo 2020-02-17 0 31 29.jpg"></p>
<p><strong>Coral USB Accelerator</strong> is Google&rsquo;s dedicated <a href="https://en.wikipedia.org/wiki/ASIC">ASIC</a> developed by Google for machine learning on edge devices.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/221759/196aac58-6078-e4c1-bb63-42b65b0da166.jpeg" alt="Photo 2019-12-30 0 02 35.jpg"></p>
<p>This dedicated ASIC is called Edge TPU, and you can use TensorFlow Lite&rsquo;s flake work specialized for inference at the edge. In addition, only the flake work of TensorFlow Lite is supported. In addition, USB3.0 connection is required to maximize the performance of the Coral USB Accelerator. In summary, the Raspberry Pi 4 is the best choice to bring out the performance of the Coral USB Accelerator.</p>
<h2 id="raspberry-pi4">Raspberry Pi4</h2>
<p>There is a pre-compiled image of Raspbery Pi called <strong>Edge TPU Platforms</strong> for using Edge TPU from Google, although not officially supported.</p>
<p>It has a built-in image classification model that has already been trained, so it will be useful for machine learning with Raspberry Pi.</p>
<p>I will explain the procedure to use the image of Raspberry Pi 4 from EdgeTPU Platforms.</p>
<p>Please note that the interface of the Raspberry Pi 4 is changed to <strong>USB Type-C</strong> and HDMI to <strong>Micro HDMI</strong>.</p>
<h3 id="edgetpu-platforms">EdgeTPU Platforms</h3>
<ol>
<li>Download the image of <strong>Raspberry Pi 4, Buster, Edgetpu 2.11.1</strong> from <a href="https://github.com/google-coral/edgetpu-platforms">google-coral/edgetpu-platforms</a> ..</li>
<li>Write the downloaded image to the SD card. Refer to the <a href="https://qiita.com/Brutus/items/1683b5b3eac929047d12">Raspberry Pi basics</a> that I wrote before about how to write to the SD card.</li>
<li>After writing to the SD card, start the Raspberry Pi and perform the initial setup.</li>
</ol>
<p>**If you boot with the downloaded image, you need to expand the file system according to the size of the SD card. **</p>
<h3 id="file-system-extension">File system extension</h3>
<p>The system area (/) before the file system expansion is in the following state.</p>
<pre><code class="language-console" data-lang="console">pi@raspberrypi:~ $ df -h
File system size used Remaining used% mount position
/dev/root 3.3G 3.0G 100M 97% /
devtmpfs 1.8G 0 1.8G 0% /dev
tmpfs 1.9G 0 1.9G 0% /dev/shm
tmpfs 1.9G 8.6M 1.9G 1% /run
tmpfs 5.0M 4.0K 5.0M 1% /run/lock
tmpfs 1.9G 0 1.9G 0% /sys/fs/cgroup
/dev/mmcblk0p1 253M 41M 213M 16% /boot
tmpfs 386M 0 386M 0% /run/user/1000
</code></pre><p>Execute the following command to start <code>raspi-config</code> and operate it interactively.</p>
<p><code>$ sudo raspi-config</code></p>
<p>![Screenshot 2019-12-30 17.38.27.png](<a href="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/221759/b13a0d4d-e86f-5cd0-cbc3-(331b793fd8b0.png)">https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/221759/b13a0d4d-e86f-5cd0-cbc3-(331b793fd8b0.png)</a></p>
<p>First select <strong>7 Advanced Options</strong>.</p>
<p>![Screenshot 2019-12-30 17.38.38.png](<a href="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/221759/6c271980-2bf8-2fe6-cda2-(475e3169ccc7.png)">https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/221759/6c271980-2bf8-2fe6-cda2-(475e3169ccc7.png)</a></p>
<p>Then select &ldquo;A1 Expand Filesystem&rdquo;.</p>
<p>![Screenshot 2019-12-30 17.38.54.png](<a href="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/221759/9eba4a29-4253-bcb1-d177-(be6f2662d72a.png)">https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/221759/9eba4a29-4253-bcb1-d177-(be6f2662d72a.png)</a></p>
<p>Click OK.</p>
<p>![Screenshot 2019-12-30 17.39.42.png](<a href="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/221759/a7c930e2-0b1d-4224-c730-(5b1e880f3aa8.png)">https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/221759/a7c930e2-0b1d-4224-c730-(5b1e880f3aa8.png)</a></p>
<p>Execute the following command and restart.</p>
<p><code>$ sudo systemctl reboot</code></p>
<p>After restarting, you can see that the system area (/) is expanded.</p>
<pre><code class="language-concole" data-lang="concole">pi@raspberrypi:~ $ df -h
File system size used Remaining used% mount position
/dev/root 29G 3.1G 24G 12% /
devtmpfs 1.8G 0 1.8G 0% /dev
tmpfs 1.9G 0 1.9G 0% /dev/shm
tmpfs 1.9G 8.6M 1.9G 1% /run
tmpfs 5.0M 4.0K 5.0M 1% /run/lock
tmpfs 1.9G 0 1.9G 0% /sys/fs/cgroup
/dev/mmcblk0p1 253M 41M 213M 16% /boot
tmpfs 386M 0 386M 0% /run/user/1000
</code></pre><h2 id="coral-usb-accelerator">Coral USB Accelerator</h2>
<p>To use Coral USB Accelerator, the following work is required.</p>
<ul>
<li><input checked="" disabled="" type="checkbox"> Install Edge TPU runtime</li>
<li><input checked="" disabled="" type="checkbox"> TensorFlow Lite library installation</li>
</ul>
<p>Install the Edge TPU runtime to communicate with the Edge TPU.
Also, libraries etc. are required to use TensorFlow Lite in Python. In this article, I will install a simple tflite_runtime library to use the TensorFlow Lite model in Python.</p>
<h3 id="preparation-work">preparation work</h3>
<p>Open the box containing the Coral USB Accelerator.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/221759/462722ed-a8dd-1157-ddd7-2aca709ce7a9.jpeg" alt="Picture 2019-12-30 17 08 16.jpg"></p>
<p>Connect Coral USB Accelerator to Raspberry Pi 4.
USB3.0 has an interface of <strong><font color="Blue">blue</font></strong>.</p>
<p><a href="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/221759/086d1844-6c73-1ada-844d-2556fda0b7ba.jpeg">Photo 2020-02-16 23 52 49.jpg</a></p>
<h3 id="install-edge-tpu-runtime">Install Edge TPU runtime</h3>
<ul>
<li>
<p>Add repository
<code>$ echo &quot;deb https://packages.cloud.google.com/apt coral-edgetpu-stable main&quot; | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list</code>
<code>$ curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -</code>
<code>$ sudo apt-get update</code></p>
</li>
<li>
<p>Installation
<code>$ sudo apt-get install libedgetpu1-std</code></p>
</li>
</ul>
<h3 id="install-tensorflow-lite-library">Install TensorFlow Lite library</h3>
<ul>
<li>
<p>Download library
<code>$ wget https://dl.google.com/coral/python/tflite_runtime-1.14.0-cp37-cp37m-linux_armv7l.whl</code></p>
</li>
<li>
<p>Library installation
<code>$ pip3 install tflite_runtime-1.14.0-cp37-cp37m-linux_armv7l.whl</code></p>
</li>
</ul>
<h2 id="executing-tensorflow-lite-api">Executing TensorFlow Lite API</h2>
<p>Image classification with reference to <a href="https://coral.ai/docs/accelerator/get-started/#3-run-a-model-using-the-tensorflow-lite-api">Get started with the USB Accelerator</a> Let&rsquo;s run the machine.</p>
<p><code>$ python3 classify_image.py --model models/mobilenet_v2_1.0_224_inat_bird_quant_edgetpu.tflite --labels models/inat_bird_labels.txt --input images/parrot.jpg</code></p>
<pre><code class="language-console" data-lang="console">INFO: Initialized TensorFlow Lite runtime.
- ---INFERENCE TIME----Note: The first inference on Edge TPU is slow because it includes loading the model into Edge TPU memory.
18.6ms
4.6ms
4.6ms
4.6ms
4.6ms
- ------RESULTS--------
Ara macao (Scarlet Macaw): 0.76562
</code></pre><p>I ran the inference on the Edge TPU using TensorFlow Lite.
By the way, the output result when executed with USB 2.0 is as follows. You can see that it is slower than USB 3.0.</p>
<pre><code class="language-console" data-lang="console">INFO: Initialized TensorFlow Lite runtime.
- ---INFERENCE TIME----
Note: The first inference on Edge TPU is slow because it includes loading the model into Edge TPU memory.
120.5ms
11.5ms
11.5ms
11.7ms
11.6ms
- ------RESULTS--------
Ara macao (Scarlet Macaw): 0.76562
</code></pre><h1 id="in-conclusion">in conclusion</h1>
<p>You can now do machine learning on your edge device.</p>
<p>Next, create a model with TensorFlow and convert the model to TensorFlow Lite.</p>
<h2 id="reference">Reference</h2>
<ul>
<li><a href="https://www.raspberrypi.org/documentation/configuration/raspi-config.md">raspi-config</a></li>
<li><a href="https://coral.ai/docs/edgetpu/faq/">Frequently asked questions</a></li>
<li><a href="https://aiyprojects.withgoogle.com/edge-tpu">Edge TPU Devices</a></li>
<li><a href="https://coral.ai/docs/accelerator/get-started/">Get started with the USB Accelerator</a></li>
<li><a href="https://coral.ai/docs/accelerator/datasheet/">USB Accelerator datasheet</a></li>
<li><a href="https://www.tensorflow.org/lite/guide/python">Python quickstart</a></li>
<li><a href="https://www.tensorflow.org/lite/guide/get_started">Get started with TensorFlow Lite</a></li>
<li><a href="https://github.com/tensorflow/tensorflow/tree/r1.15/tensorflow/contrib/quantize">Quantization-aware training</a></li>
<li><a href="https://www.tensorflow.org/lite/performance/post_training_quantization">Post-training quantization</a></li>
<li><a href="https://www.tensorflow.org/lite/convert">TensorFlow Lite converter</a></li>
<li><a href="https://coral.ai/docs/edgetpu/compiler/">Edge TPU Compiler</a></li>
<li><a href="https://coral.ai/docs/edgetpu/models-intro/">TensorFlow models on the Edge TPU</a></li>
<li><a href="https://coral.ai/models/">Models</a></li>
</ul>

    </article>
  </div>

  
  
  
  <script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-169005401-1', 'auto');
  ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  

  
<link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.css" />
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#216942",
      "text": "#b2d192"
    },
    "button": {
      "background": "#afed71"
    }
  }
})});
</script>

</body>

</html>
