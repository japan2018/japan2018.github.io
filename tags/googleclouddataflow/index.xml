<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>GoogleCloudDataflow on Memo Tut</title>
    <link>https://memotut.com/tags/googleclouddataflow/</link>
    <description>Recent content in GoogleCloudDataflow on Memo Tut</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 03 Jan 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://memotut.com/tags/googleclouddataflow/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>[Python] Apache Beam (Dataflow) practical introduction [Python]</title>
      <link>https://memotut.com/apache-beam-dataflow-practical-introduction-python-3c5c1/</link>
      <pubDate>Fri, 03 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/apache-beam-dataflow-practical-introduction-python-3c5c1/</guid>
      <description>#Introduction  This article is based on the content of Apache Beam Documentation.
A batch process program is implemented with Apache Beam Python SDK, and the procedure and method to execute with Cloud Dataflow are summarized. It also touches on some of the basic Apache Beam concepts, testing and design.
Getting Started with Apache Beam SDK Apache Beam SDK can be selected from Java, Python, Go, and provides the following Functions that simplify the distributed processing mechanism doing.</description>
    </item>
    
  </channel>
</rss>