<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  <meta name="generator" content="Hugo 0.72.0" />

  
  <meta name="description" content="Some description">
  

  
  <link rel="apple-touch-icon" sizes="180x180" href="https://memotut.com/apple-touch-icon.png">

  
  <link rel="icon" type="image/png" sizes="32x32" href="https://memotut.com/favicon-32x32.png">

  
  <link rel="icon" type="image/png" sizes="16x16" href="https://memotut.com/favicon-16x16.png">

  
  <link rel="manifest" href="https://memotut.com/site.webmanifest">

  
  <link rel="mask-icon" href="https://memotut.com/safari-pinned-tab.svg" color="#5bbad5">

  <meta name="msapplication-TileColor" content="#da532c">

  <meta name="theme-color" content="#ffffff">

  
  <link rel="stylesheet" href="https://memotut.com/css/bootstrap.min.css" />

  
  <title>[Python] Image classification with wide-angle fundus image dataset | Memo Tut</title>
  

  <style>
body {
  min-width: 300px;
}

.custom-navbar {
  margin-bottom: 1em;
  height: 60px;
}

.custom-navbar a {
  display: inline-block; 
  padding: 18px 0;
  margin-right: 1em; 
  font-weight: bold; 
}

.custom-navbar a:hover,
.custom-navbar a:focus {
  text-decoration: none; 
}

@media print {
  .custom-navbar {
    display: none;
  }
}

article {
  padding-bottom: 1em;
}

img {
  max-width: 100%;
}


body {
  background-color: #fff;
}



body {
  color: #212529;
}



a {
  color: #007bff;
}



a:hover,
a:focus {
  color: #0056b3;
}



.custom-navbar {
  background-color: #212529;
}



.custom-navbar a {
  color: rgba(255, 255, 255, 0.75);
}



.custom-navbar a:hover,
.custom-navbar a:focus {
  color: rgba(255, 255, 255, 1);
}



.container {
  max-width: 800px;
}



pre {
  display: block;
  padding: 9.5px;
  word-break: break-all;
  word-wrap: break-word;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre code {
  padding: 0;
  font-size: inherit;
  color: inherit; 
  white-space: pre-wrap;
  background-color: transparent;
  border: none;
  border-radius: 0;
}

code {
  padding: 2px 4px;
  color: inherit; 
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
  font-size: .9em;
}



blockquote,
.blockquote {
  padding: 10px 20px;
  margin: 0 0 20px;
  font-size: 1em;
  border-left: 5px solid #6c757d;
}

</style>
</head>

<body>
  <nav class="custom-navbar">
  <div class="container">
    
    <a href="/">Posts</a>
    
    <a href="/tags/">Tags</a>
    
    <a href="/about/">About</a>
    
    <a href="/index.xml">RSS</a>
    
  </div>
</nav>
  
  <div class="container">
    <article>
      <h1>[Python] Image classification with wide-angle fundus image dataset</h1>
<p>
  <small class="text-secondary">
  
  
  Mar 2, 2020
  </small>
  

<small><code><a href="https://memotut.com/tags/python">Python</a></code></small>


<small><code><a href="https://memotut.com/tags/machine-learning"> machine learning</a></code></small>


<small><code><a href="https://memotut.com/tags/deeplearning"> DeepLearning</a></code></small>


<small><code><a href="https://memotut.com/tags/keras"> Keras</a></code></small>


<small><code><a href="https://memotut.com/tags/tensorflow"> TensorFlow</a></code></small>

</p>
<pre><code># 1.First of all
</code></pre>
<p>In this article, as an introduction, we aim to use TensorFlow 2.0 and perform image classification with Deep Learning for the time being. The image dataset is not so interesting as MNIST, so we will use the wide-angle fundus image dataset <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> published by Tsukazaki Hospital. The network is a simple 10-layer CNN.</p>
<p><a href="https://github.com/burokoron/StaDeep/tree/master/simple_cnn_classifier">All Code</a></p>
<h1 id="2-environment">2. Environment</h1>
<ul>
<li>PC specs
-CPU: Intel Core i9-9900K
-RAM: 16GB
-GPU: NVIDIA GeForce GTX 1080 Ti</li>
<li>Library
-Python: 3.7.4
-matplotlib: 3.1.1
-pandas: 0.25.1
-tqdm: 4.31.1
-pillow: 6.1.0
-scikit-learn: 0.21.3
-tensorflow-gpu: 2.0.0</li>
</ul>
<h1 id="3-wide-angle-fundus-image-data-set">3. Wide-angle fundus image data set</h1>
<p>13047 wide-angle fundus data set (5,389 people, 8588 eyes) released by Tsukazaki Hospital. Click the link below to download a csv file that associates images with disease labels.
Tsukazaki Optos Public Project
<a href="https://tsukazaki-ai.github.io/optos_dataset/">https://tsukazaki-ai.github.io/optos_dataset/</a></p>
<p>The breakdown of the disease label is as follows.</p>
<table>
<thead>
<tr>
<th align="center">Label</th>
<th align="center">Disease</th>
<th align="center">Number of sheets</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">AMD</td>
<td align="center">Age-related macular degeneration</td>
<td align="center">413</td>
</tr>
<tr>
<td align="center">RVO</td>
<td align="center">Retinal Vein Occlusion</td>
<td align="center">778</td>
</tr>
<tr>
<td align="center">Gla</td>
<td align="center">Glaucoma</td>
<td align="center">2619</td>
</tr>
<tr>
<td align="center">MH</td>
<td align="center">Macular hole</td>
<td align="center">222</td>
</tr>
<tr>
<td align="center">DR</td>
<td align="center">Diabetic retinopathy</td>
<td align="center">3323</td>
</tr>
<tr>
<td align="center">RD</td>
<td align="center">Retinal detachment</td>
<td align="center">974</td>
</tr>
<tr>
<td align="center">RP</td>
<td align="center">Retinitis pigmentosa</td>
<td align="center">258</td>
</tr>
<tr>
<td align="center">AO</td>
<td align="center">Arterial occlusion</td>
<td align="center">21</td>
</tr>
<tr>
<td align="center">DM</td>
<td align="center">Diabetes</td>
<td align="center">3895</td>
</tr>
</tbody>
</table>
<p>Is the total number of images on the table different from the number of images? I think some people think that, so let&rsquo;s take a look at the actual csv file.</p>
<p>|filename|age|sex|LR|AMD|RVO|Gla|MH|DR|RD|RP|AO|DM|
|:&ndash;:|:&ndash;:|:&ndash;:|:&ndash;:|:&ndash;:|:::::::::&ndash;:|:&ndash;:|:&ndash;: |:&ndash;:|:&ndash;:|:&ndash;:|
|000000_00.jpg|78|M|L|0|0|0|0|0|0|0|0|0|
|000000_01.jpg|78|M|R|0|0|0|0|0|0|0|0|0|
|─|─|─|─|─|─|─|─|─|─|─|─|─|
|000001_02.jpg|69|M|L|0|0|1|0|0|0|0|0|0|
|─|─|─|─|─|─|─|─|─|─|─|─|─|
|000011_01.jpg|70|F|L|0|0|0|0|1|0|0|0|1|</p>
<p>This is a multi-label problem with multiple labels (complications) for one image. Unlabeled images are unlabeled, for a total of 4364 images. Also, an image sample is shown below.</p>
<details><summary>Includes grotesque images</summary><div>
<img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/405329/6ec6ed5a-7fda-b18d-3e14-ff9d689b0f71.jpeg" width=40%>
000000_00.jpg
<img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/405329/002df0f2-1ef9-2e49-e965-7136ab6fbe92.jpeg" width=40%>
000000_01.jpg
<img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/405329/1f2b1be3-8767-d522-2676-5fa003682bfb.jpeg" width=40%>
000001_02.jpg
<img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/405329/74989400-d328-2fc9-9eb3-25e1344cff60.jpeg" width=40%>
000011_01.jpg
</div></details>
<p>There is an imbalance in the number of data, and with multi-labels it is quite a ~ ~ troublesome ~ ~ It is a practical data set, but in this article, only non-multi-label images are used, and it is easy to use only those with many classes. Classify.</p>
<h1 id="4-data-division">4. Data division</h1>
<p>First, extract only the images that are not multi-labels from the csv file. However, since there are DM images in DR, we also extract images in which both DR and DM are present. However, we decided not to use DR and AO, which only have 3 and 11 images, respectively. Also, since there were 3113 DR+DM and 530 DM with overlapping labels, we decided not to use the DM with the smaller number this time. In addition, the format of the csv file has been changed so that it can be processed later.</p>
<details><summary>Code that extracts images that are not multi-labels and combines them into a csv file</summary><div>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#f92672">from</span> collections <span style="color:#f92672">import</span> defaultdict
<span style="color:#f92672">import</span> pandas <span style="color:#f92672">as</span> pd


<span style="color:#75715e"># Load csv file of wide angle fundus dataset</span>
df <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>read_csv(<span style="color:#e6db74">&#39;data.csv&#39;</span>)

dataset <span style="color:#f92672">=</span> defaultdict(list)

<span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(len(df)):
    Characterize labels <span style="color:#66d9ef">with</span> <span style="color:#75715e">#</span>
    labels <span style="color:#f92672">=</span><span style="color:#e6db74">&#39;&#39;</span>
    <span style="color:#66d9ef">if</span> df<span style="color:#f92672">.</span>iloc[i][<span style="color:#e6db74">&#39;AMD&#39;</span>] <span style="color:#f92672">==</span> <span style="color:#ae81ff">1</span>:
        labels <span style="color:#f92672">+=</span><span style="color:#e6db74">&#39;_AMD&#39;</span>
    <span style="color:#66d9ef">if</span> df<span style="color:#f92672">.</span>iloc[i][<span style="color:#e6db74">&#39;RVO&#39;</span>] <span style="color:#f92672">==</span> <span style="color:#ae81ff">1</span>:
        labels <span style="color:#f92672">+=</span><span style="color:#e6db74">&#39;_RVO&#39;</span>
    <span style="color:#66d9ef">if</span> df<span style="color:#f92672">.</span>iloc[i][<span style="color:#e6db74">&#39;Gla&#39;</span>] <span style="color:#f92672">==</span> <span style="color:#ae81ff">1</span>:
        labels <span style="color:#f92672">+=</span><span style="color:#e6db74">&#39;_Gla&#39;</span>
    <span style="color:#66d9ef">if</span> df<span style="color:#f92672">.</span>iloc[i][<span style="color:#e6db74">&#39;MH&#39;</span>] <span style="color:#f92672">==</span> <span style="color:#ae81ff">1</span>:
        labels <span style="color:#f92672">+=</span><span style="color:#e6db74">&#39;_MH&#39;</span>
    <span style="color:#66d9ef">if</span> df<span style="color:#f92672">.</span>iloc[i][<span style="color:#e6db74">&#39;DR&#39;</span>] <span style="color:#f92672">==</span> <span style="color:#ae81ff">1</span>:
        labels <span style="color:#f92672">+=</span><span style="color:#e6db74">&#39;_DR&#39;</span>
    <span style="color:#66d9ef">if</span> df<span style="color:#f92672">.</span>iloc[i][<span style="color:#e6db74">&#39;RD&#39;</span>] <span style="color:#f92672">==</span> <span style="color:#ae81ff">1</span>:
        labels <span style="color:#f92672">+=</span><span style="color:#e6db74">&#39;_RD&#39;</span>
    <span style="color:#66d9ef">if</span> df<span style="color:#f92672">.</span>iloc[i][<span style="color:#e6db74">&#39;RP&#39;</span>] <span style="color:#f92672">==</span> <span style="color:#ae81ff">1</span>:
        labels <span style="color:#f92672">+=</span><span style="color:#e6db74">&#39;_RP&#39;</span>
    <span style="color:#66d9ef">if</span> df<span style="color:#f92672">.</span>iloc[i][<span style="color:#e6db74">&#39;AO&#39;</span>] <span style="color:#f92672">==</span> <span style="color:#ae81ff">1</span>:
        labels <span style="color:#f92672">+=</span><span style="color:#e6db74">&#39;_AO&#39;</span>
    <span style="color:#66d9ef">if</span> df<span style="color:#f92672">.</span>iloc[i][<span style="color:#e6db74">&#39;DM&#39;</span>] <span style="color:#f92672">==</span> <span style="color:#ae81ff">1</span>:
        labels <span style="color:#f92672">+=</span><span style="color:#e6db74">&#39;_DM&#39;</span>
    <span style="color:#66d9ef">if</span> labels <span style="color:#f92672">==</span> <span style="color:#e6db74">``</span>:
        labels <span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Normal&#39;</span>
    <span style="color:#66d9ef">else</span>:
        labels <span style="color:#f92672">=</span> labels[<span style="color:#ae81ff">1</span>:]

    <span style="color:#75715e"># Images that are not multi-label (except DR+DM) and</span>
    <span style="color:#75715e">#Low DR, DM and</span>
    <span style="color:#75715e"># Extract the image except DM which has the same label but fewer than DR+DM</span>
    <span style="color:#66d9ef">if</span><span style="color:#e6db74">&#39;_&#39;</span> <span style="color:#f92672">not</span> <span style="color:#f92672">in</span> labels <span style="color:#f92672">or</span> labels <span style="color:#f92672">==</span><span style="color:#e6db74">&#39;DR_DM&#39;</span>:
        <span style="color:#66d9ef">if</span> labels <span style="color:#f92672">not</span> <span style="color:#f92672">in</span> (<span style="color:#e6db74">&#39;DR&#39;</span>,<span style="color:#e6db74">&#39;AO&#39;</span>,<span style="color:#e6db74">&#39;DM&#39;</span>):
            dataset[<span style="color:#e6db74">&#39;filename&#39;</span>]<span style="color:#f92672">.</span>append(df<span style="color:#f92672">.</span>iloc[i][<span style="color:#e6db74">&#39;filename&#39;</span>])
            dataset[<span style="color:#e6db74">&#39;id&#39;</span>]<span style="color:#f92672">.</span>append(df<span style="color:#f92672">.</span>iloc[i][<span style="color:#e6db74">&#39;filename&#39;</span>]<span style="color:#f92672">.</span>split(<span style="color:#e6db74">&#39;_&#39;</span>)[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>split(<span style="color:#e6db74">&#39;.&#39;</span>)[<span style="color:#ae81ff">0</span>])
            dataset[<span style="color:#e6db74">&#39;label&#39;</span>]<span style="color:#f92672">.</span>append(labels)

<span style="color:#75715e"># Save as csv file</span>
dataset <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame(dataset)
dataset<span style="color:#f92672">.</span>to_csv(<span style="color:#e6db74">&#39;dataset.csv&#39;</span>, index<span style="color:#f92672">=</span>False)
</code></pre></div></div></details>
<p>I have created the following csv file with the above code. The images are named according to the rule of {serial number}_{serial number}.jpg, so the serial number is used as id.</p>
<table>
<thead>
<tr>
<th align="center">filename</th>
<th align="center">id</th>
<th align="center">label</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">000000_00.jpg</td>
<td align="center">0</td>
<td align="center">Normal</td>
</tr>
<tr>
<td align="center">000000_01.jpg</td>
<td align="center">0</td>
<td align="center">Normal</td>
</tr>
<tr>
<td align="center">─</td>
<td align="center">─</td>
<td align="center">─</td>
</tr>
<tr>
<td align="center">000001_02.jpg</td>
<td align="center">1</td>
<td align="center">Gla</td>
</tr>
<tr>
<td align="center">─</td>
<td align="center">─</td>
<td align="center">─</td>
</tr>
<tr>
<td align="center">000011_01.jpg</td>
<td align="center">11</td>
<td align="center">DR_DM</td>
</tr>
</tbody>
</table>
<p>As a result of the extraction, the breakdown of the classification class and the number of images is as follows. Normal is an image that is not sick.</p>
<table>
<thead>
<tr>
<th align="center">Label</th>
<th align="center">Qty</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">Normal</td>
<td align="center">4364</td>
</tr>
<tr>
<td align="center">Gla</td>
<td align="center">2293</td>
</tr>
<tr>
<td align="center">AMD</td>
<td align="center">375</td>
</tr>
<tr>
<td align="center">RP</td>
<td align="center">247</td>
</tr>
<tr>
<td align="center">DR_DM</td>
<td align="center">3113</td>
</tr>
<tr>
<td align="center">RD</td>
<td align="center">883</td>
</tr>
<tr>
<td align="center">RVO</td>
<td align="center">537</td>
</tr>
<tr>
<td align="center">MH</td>
<td align="center">161</td>
</tr>
</tbody>
</table>
<p>Next, divide the image data. There are 13047 images (5389 people with 8588 eyes) in the dataset, so images of the same person and eyes are included. Images of the same person or eyes have similar features and labels, which can cause data leaks. Therefore, the same person is divided so that it does not exist across the training data and the test data. Furthermore, the ratio of the breakdown of each class of the training data and the test data should be roughly the same.
This time, learning data was 60%, verification data was 20%, and test data was 20%.</p>
<p><a href="https://gist.github.com/burokoron/54cb382d26c626fea8ca60d8c5d4c7bc">Code for grouping into K layers</a></p>
<h1 id="5-model-building--learning">5. Model building &amp; learning</h1>
<p>First, import the library to be used.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#f92672">as</span> plt
<span style="color:#f92672">import</span> pandas <span style="color:#f92672">as</span> pd
<span style="color:#f92672">from</span> tensorflow.keras.callbacks <span style="color:#f92672">import</span> ModelCheckpoint, ReduceLROnPlateau
<span style="color:#f92672">from</span> tensorflow.keras.callbacks <span style="color:#f92672">import</span> EarlyStopping
<span style="color:#f92672">from</span> tensorflow.keras.preprocessing.image <span style="color:#f92672">import</span> ImageDataGenerator
<span style="color:#f92672">from</span> tensorflow.keras.models <span style="color:#f92672">import</span> Model
<span style="color:#f92672">from</span> tensorflow.keras.layers <span style="color:#f92672">import</span> GlobalAveragePooling2D, Input, MaxPool2D
<span style="color:#f92672">from</span> tensorflow.keras.layers <span style="color:#f92672">import</span> Conv2D, Dense, BatchNormalization, Activation
<span style="color:#f92672">from</span> tensorflow.keras.optimizers <span style="color:#f92672">import</span> Adam
<span style="color:#e6db74">```Next, describe parameters etc. `</span>label_list<span style="color:#960050;background-color:#1e0010">`</span> <span style="color:#f92672">is</span> arranged <span style="color:#f92672">in</span> abc order <span style="color:#66d9ef">for</span> the convenience of the library<span style="color:#f92672">.</span>

<span style="color:#e6db74">``</span><span style="color:#960050;background-color:#1e0010">`</span>py
directory <span style="color:#f92672">=</span><span style="color:#e6db74">&#39;img&#39;</span> <span style="color:#75715e"># folder where images are stored</span>
df_train <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>read_csv(<span style="color:#e6db74">&#39;train.csv&#39;</span>) <span style="color:#75715e"># DataFrame with training data information</span>
df_validation <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>read_csv(<span style="color:#e6db74">&#39;val.csv&#39;</span>) <span style="color:#75715e"># DataFrame with validation data information</span>
label_list <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;AMD&#39;</span>,<span style="color:#e6db74">&#39;DR_DM&#39;</span>,<span style="color:#e6db74">&#39;Gla&#39;</span>,<span style="color:#e6db74">&#39;MH&#39;</span>,<span style="color:#e6db74">&#39;Normal&#39;</span>,<span style="color:#e6db74">&#39;RD&#39;</span>,<span style="color:#e6db74">&#39;RP&#39;</span>,<span style="color:#e6db74">&#39;RVO&#39;</span>] <span style="color:#75715e"># label name</span>
image_size <span style="color:#f92672">=</span> (<span style="color:#ae81ff">224</span>, <span style="color:#ae81ff">224</span>) <span style="color:#75715e"># input image size</span>
classes <span style="color:#f92672">=</span> len(label_list) <span style="color:#75715e"># number of classification classes</span>
batch_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">32</span> <span style="color:#75715e"># batch size</span>
epochs <span style="color:#f92672">=</span> <span style="color:#ae81ff">300</span> <span style="color:#75715e"># number of epochs</span>
loss <span style="color:#f92672">=</span><span style="color:#e6db74">&#39;categorical_crossentropy&#39;</span> <span style="color:#75715e"># loss function</span>
optimizer <span style="color:#f92672">=</span> Adam(lr<span style="color:#f92672">=</span><span style="color:#ae81ff">0.001</span>, amsgrad<span style="color:#f92672">=</span>True) <span style="color:#75715e"># Optimizer function</span>
metrics <span style="color:#f92672">=</span><span style="color:#e6db74">&#39;accuracy&#39;</span> <span style="color:#75715e"># evaluation method</span>
<span style="color:#75715e"># ImageDataGenerator Image amplification parameters</span>
aug_params <span style="color:#f92672">=</span> (<span style="color:#e6db74">&#39;rotation_range&#39;</span>: <span style="color:#ae81ff">5</span>,
              <span style="color:#e6db74">&#39;width_shift_range&#39;</span>: <span style="color:#ae81ff">0.05</span>,
              <span style="color:#e6db74">&#39;height_shift_range&#39;</span>: <span style="color:#ae81ff">0.05</span>,
              <span style="color:#e6db74">&#39;shear_range&#39;</span>: <span style="color:#ae81ff">0.1</span>,
              <span style="color:#e6db74">&#39;zoom_range&#39;</span>: <span style="color:#ae81ff">0.05</span>,
              <span style="color:#e6db74">&#39;horizontal_flip&#39;</span>: True,
              <span style="color:#e6db74">&#39;vertical_flip&#39;</span>: True}
</code></pre></div><p>The following is applied as a callback process during learning.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">Save model only when <span style="color:#75715e">#val_loss becomes minimum</span>
mc_cb <span style="color:#f92672">=</span> ModelCheckpoint(<span style="color:#e6db74">&#39;model_weights.h5&#39;</span>,
                        monitor<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;val_loss&#39;</span>, verbose<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,
                        save_best_only<span style="color:#f92672">=</span>True, mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;min&#39;</span>)
<span style="color:#75715e"># Increase learning rate by 0.2 when learning is stagnant</span>
rl_cb <span style="color:#f92672">=</span> ReduceLROnPlateau(monitor<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;loss&#39;</span>, factor<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>, patience<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>,
                          verbose<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>, mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;auto&#39;</span>,
                          min_delta<span style="color:#f92672">=</span><span style="color:#ae81ff">0.0001</span>, cooldown<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>, min_lr<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)
<span style="color:#75715e"># If learning does not progress, forcibly end learning</span>
es_cb <span style="color:#f92672">=</span> EarlyStopping(monitor<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;loss&#39;</span>, min_delta<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>,
                      patience<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>, verbose<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>, mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;auto&#39;</span>)
</code></pre></div><p>The number of data in each class is unbalanced, so if you make a mistake in a class with a small number of data, you will increase the loss.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#75715e">#Adjust loss weight according to the number of data</span>
weight_balanced <span style="color:#f92672">=</span> {}
<span style="color:#66d9ef">for</span> i, label <span style="color:#f92672">in</span> enumerate(label_list):
    weight_balanced[i] <span style="color:#f92672">=</span> (df_train[<span style="color:#e6db74">&#39;label&#39;</span>] <span style="color:#f92672">==</span> label)<span style="color:#f92672">.</span>sum()
max_count <span style="color:#f92672">=</span> max(weight_balanced<span style="color:#f92672">.</span>values())
<span style="color:#66d9ef">for</span> label <span style="color:#f92672">in</span> weight_balanced:
    weight_balanced[label] <span style="color:#f92672">=</span> max_count <span style="color:#f92672">/</span> weight_balanced[label]
<span style="color:#66d9ef">print</span>(weight_balanced)
</code></pre></div><p>Generate a generator of training and validation data. Use ImageDataGenerator for data expansion and load the image from DataFrame with flow_from_dataframe. The reason why <code>label_list</code> is set to abc is that when you load an image with flow_from_dataframe, the classes are assigned in the order of abc in the character string, so that you can see the correspondence between class numbers and label names. You can check the correspondence later, but it is troublesome&hellip;</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#75715e">#Generate generator</span>
<span style="color:#75715e">## Learning data generator</span>
datagen <span style="color:#f92672">=</span> ImageDataGenerator(rescale<span style="color:#f92672">=</span><span style="color:#ae81ff">1.</span><span style="color:#f92672">/</span><span style="color:#ae81ff">255</span>, <span style="color:#f92672">**</span>aug_params)
train_generator <span style="color:#f92672">=</span> datagen<span style="color:#f92672">.</span>flow_from_dataframe(
    dataframe<span style="color:#f92672">=</span>df_train, directory<span style="color:#f92672">=</span>directory,
    x_col<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;filename&#39;</span>, y_col<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;label&#39;</span>,
    target_size<span style="color:#f92672">=</span>image_size, class_mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;categorical&#39;</span>,
    classes<span style="color:#f92672">=</span>label_list,
    batch_size<span style="color:#f92672">=</span>batch_size)
step_size_train <span style="color:#f92672">=</span> train_generator<span style="color:#f92672">.</span>n <span style="color:#f92672">//</span> train_generator<span style="color:#f92672">.</span>batch_size
<span style="color:#75715e">## Verification data generator</span>
datagen <span style="color:#f92672">=</span> ImageDataGenerator(rescale<span style="color:#f92672">=</span><span style="color:#ae81ff">1.</span><span style="color:#f92672">/</span><span style="color:#ae81ff">255</span>)
validation_generator <span style="color:#f92672">=</span> datagen<span style="color:#f92672">.</span>flow_from_dataframe(
    dataframe<span style="color:#f92672">=</span>df_validation, directory<span style="color:#f92672">=</span>directory,
    x_col<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;filename&#39;</span>, y_col<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;label&#39;</span>,
    target_size<span style="color:#f92672">=</span>image_size, class_mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;categorical&#39;</span>,
    classes<span style="color:#f92672">=</span>label_list,
    batch_size<span style="color:#f92672">=</span>batch_size)
step_size_validation <span style="color:#f92672">=</span> validation_generator<span style="color:#f92672">.</span>n <span style="color:#f92672">//</span> validation_generator<span style="color:#f92672">.</span>batch_size
</code></pre></div><p>Build a simple 10-layer CNN.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#75715e">#10 Layer CNN Construction</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">cnn</span>(input_shape, classes):
    <span style="color:#75715e">#Input layer</span>
    inputs <span style="color:#f92672">=</span> Input(shape<span style="color:#f92672">=</span>(input_shape[<span style="color:#ae81ff">0</span>], input_shape[<span style="color:#ae81ff">1</span>], <span style="color:#ae81ff">3</span>))

    <span style="color:#75715e"># 1st layer</span>
    x <span style="color:#f92672">=</span> Conv2D(<span style="color:#ae81ff">32</span>, (<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), padding<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;same&#39;</span>, kernel_initializer<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;he_normal&#39;</span>)(inputs)
    x <span style="color:#f92672">=</span> BatchNormalization()(x)
    x <span style="color:#f92672">=</span> Activation(<span style="color:#e6db74">&#39;relu&#39;</span>)(x)
    x <span style="color:#f92672">=</span> MaxPool2D(pool_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>))(x)

    <span style="color:#75715e"># Second layer</span>
    x <span style="color:#f92672">=</span> Conv2D(<span style="color:#ae81ff">64</span>, (<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), strides<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;same&#39;</span>, kernel_initializer<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;he_normal&#39;</span>)(x)
    x <span style="color:#f92672">=</span> BatchNormalization()(x)
    x <span style="color:#f92672">=</span> Activation(<span style="color:#e6db74">&#39;relu&#39;</span>)(x)
    x <span style="color:#f92672">=</span> MaxPool2D(pool_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>))(x)

    <span style="color:#75715e">#Third layer</span>
    x <span style="color:#f92672">=</span> Conv2D(<span style="color:#ae81ff">128</span>, (<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), strides<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;same&#39;</span>, kernel_initializer<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;he_normal&#39;</span>)(x)
    x <span style="color:#f92672">=</span> BatchNormalization()(x)
    x <span style="color:#f92672">=</span> Activation(<span style="color:#e6db74">&#39;relu&#39;</span>)(x)
    x <span style="color:#f92672">=</span> MaxPool2D(pool_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>))(x)

    <span style="color:#75715e">#4th layer</span>
    x <span style="color:#f92672">=</span> Conv2D(<span style="color:#ae81ff">256</span>, (<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), strides<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;same&#39;</span>, kernel_initializer<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;he_normal&#39;</span>)(x)
    x <span style="color:#f92672">=</span> BatchNormalization()(x)
    x <span style="color:#f92672">=</span> Activation(<span style="color:#e6db74">&#39;relu&#39;</span>)(x)
    x <span style="color:#f92672">=</span> MaxPool2D(pool_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>))(x)

    <span style="color:#75715e">#5th and 6th layers</span>
    x <span style="color:#f92672">=</span> Conv2D(<span style="color:#ae81ff">512</span>, (<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), strides<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;same&#39;</span>, kernel_initializer<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;he_normal&#39;</span>)(x)
    x <span style="color:#f92672">=</span> BatchNormalization()(x)
    x <span style="color:#f92672">=</span> Activation(<span style="color:#e6db74">&#39;relu&#39;</span>)(x)
    x <span style="color:#f92672">=</span> Conv2D(<span style="color:#ae81ff">512</span>, (<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), strides<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;same&#39;</span>, kernel_initializer<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;he_normal&#39;</span>)(x)
    x <span style="color:#f92672">=</span> BatchNormalization()(x)
    x <span style="color:#f92672">=</span> Activation(<span style="color:#e6db74">&#39;relu&#39;</span>)(x)
    x <span style="color:#f92672">=</span> MaxPool2D(pool_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>))(x)

    <span style="color:#75715e">#7th and 8th layers</span>
    x <span style="color:#f92672">=</span> Conv2D(<span style="color:#ae81ff">1024</span>, (<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), strides<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;same&#39;</span>, kernel_initializer<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;he_normal&#39;</span>)(x)
    x <span style="color:#f92672">=</span> BatchNormalization()(x)
    x <span style="color:#f92672">=</span> Activation(<span style="color:#e6db74">&#39;relu&#39;</span>)(x)
    x <span style="color:#f92672">=</span> Conv2D(<span style="color:#ae81ff">1024</span>, (<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), strides<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;same&#39;</span>, kernel_initializer<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;he_normal&#39;</span>)(x)
    x <span style="color:#f92672">=</span> BatchNormalization()(x)
    x <span style="color:#f92672">=</span> Activation(<span style="color:#e6db74">&#39;relu&#39;</span>)(x)
    x <span style="color:#f92672">=</span> GlobalAveragePooling2D()(x)

    <span style="color:#75715e"># 9th and 10th layers</span>
    x <span style="color:#f92672">=</span> Dense(<span style="color:#ae81ff">256</span>, kernel_initializer<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;he_normal&#39;</span>)(x)
    x <span style="color:#f92672">=</span> Dense(classes, kernel_initializer<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;he_normal&#39;</span>)(x)
    outputs <span style="color:#f92672">=</span> Activation(<span style="color:#e6db74">&#39;softmax&#39;</span>)(x)


    <span style="color:#66d9ef">return</span> Model(inputs<span style="color:#f92672">=</span>inputs, outputs<span style="color:#f92672">=</span>outputs)

<span style="color:#75715e"># Network construction</span>
model <span style="color:#f92672">=</span> cnn(image_size, classes)
model<span style="color:#f92672">.</span>summary()
model<span style="color:#f92672">.</span>compile(loss<span style="color:#f92672">=</span>loss, optimizer<span style="color:#f92672">=</span>optimizer, metrics<span style="color:#f92672">=</span>[metrics])
</code></pre></div><p>Learn the network.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#75715e">#Learning</span>
history <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>fit_generator(
    train_generator, steps_per_epoch<span style="color:#f92672">=</span>step_size_train,
    epochs<span style="color:#f92672">=</span>epochs, verbose<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>, callbacks<span style="color:#f92672">=</span>[mc_cb, rl_cb, es_cb],validation_data<span style="color:#f92672">=</span>validation_generator,
    validation_steps<span style="color:#f92672">=</span>step_size_validation,
    class_weight<span style="color:#f92672">=</span>weight_balanced,
    workers<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>)
</code></pre></div><p>Finally, save the learning curve graph as an image.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#75715e"># Draw and save the learning curve graph</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">plot_history</span>(history):
    fig, (axL, axR) <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>subplots(ncols<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>, figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">4</span>))

    <span style="color:#75715e"># [Left] Graph about metrics</span>
    L_title <span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Accuracy_vs_Epoch&#39;</span>
    axL<span style="color:#f92672">.</span>plot(history<span style="color:#f92672">.</span>history[<span style="color:#e6db74">&#39;accuracy&#39;</span>])
    axL<span style="color:#f92672">.</span>plot(history<span style="color:#f92672">.</span>history[<span style="color:#e6db74">&#39;val_accuracy&#39;</span>])
    axL<span style="color:#f92672">.</span>grid(True)
    axL<span style="color:#f92672">.</span>set_title(L_title)
    axL<span style="color:#f92672">.</span>set_ylabel(<span style="color:#e6db74">&#39;accuracy&#39;</span>)
    axL<span style="color:#f92672">.</span>set_xlabel(<span style="color:#e6db74">&#39;epoch&#39;</span>)
    axL<span style="color:#f92672">.</span>legend([<span style="color:#e6db74">&#39;train&#39;</span>,<span style="color:#e6db74">&#39;test&#39;</span>], loc<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;upper left&#39;</span>)

    <span style="color:#75715e"># [Right] Graph about loss</span>
    R_title <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;Loss_vs_Epoch&#34;</span>
    axR<span style="color:#f92672">.</span>plot(history<span style="color:#f92672">.</span>history[<span style="color:#e6db74">&#39;loss&#39;</span>])
    axR<span style="color:#f92672">.</span>plot(history<span style="color:#f92672">.</span>history[<span style="color:#e6db74">&#39;val_loss&#39;</span>])
    axR<span style="color:#f92672">.</span>grid(True)
    axR<span style="color:#f92672">.</span>set_title(R_title)
    axR<span style="color:#f92672">.</span>set_ylabel(<span style="color:#e6db74">&#39;loss&#39;</span>)
    axR<span style="color:#f92672">.</span>set_xlabel(<span style="color:#e6db74">&#39;epoch&#39;</span>)
    axR<span style="color:#f92672">.</span>legend([<span style="color:#e6db74">&#39;train&#39;</span>,<span style="color:#e6db74">&#39;test&#39;</span>], loc<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;upper left&#39;</span>)

    <span style="color:#75715e"># Save graph as image</span>
    fig<span style="color:#f92672">.</span>savefig(<span style="color:#e6db74">&#39;history.jpg&#39;</span>)
    plt<span style="color:#f92672">.</span>close()

<span style="color:#75715e">#Save learning curve</span>
plot_history(history)
</code></pre></div><p>The learning result is as follows.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/405329/57e9f622-27d0-cc7a-7971-1eeb93f6ca7b.jpeg" alt="history.jpg"></p>
<h1 id="6-rating">6. Rating</h1>
<p>As the evaluation is unbalanced data, use F1 Score.
First, infer test data with the model learned earlier.</p>
<p>Additional import.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">from</span> PIL <span style="color:#f92672">import</span> Image
<span style="color:#f92672">from</span> sklearn.metrics <span style="color:#f92672">import</span> classification_report
<span style="color:#f92672">from</span> tqdm <span style="color:#f92672">import</span> tqdm
</code></pre></div><p>Describe the parameters. This time read the test csv file.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">directory <span style="color:#f92672">=</span><span style="color:#e6db74">&#39;img&#39;</span> <span style="color:#75715e"># folder where images are stored</span>
df_test <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>read_csv(<span style="color:#e6db74">&#39;test.csv&#39;</span>) <span style="color:#75715e"># DataFrame with test data information</span>
label_list <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;AMD&#39;</span>,<span style="color:#e6db74">&#39;DR_DM&#39;</span>,<span style="color:#e6db74">&#39;Gla&#39;</span>,<span style="color:#e6db74">&#39;MH&#39;</span>,<span style="color:#e6db74">&#39;Normal&#39;</span>,<span style="color:#e6db74">&#39;RD&#39;</span>,<span style="color:#e6db74">&#39;RP&#39;</span>,<span style="color:#e6db74">&#39;RVO&#39;</span>] <span style="color:#75715e"># label name</span>
image_size <span style="color:#f92672">=</span> (<span style="color:#ae81ff">224</span>, <span style="color:#ae81ff">224</span>) <span style="color:#75715e"># input image size</span>
classes <span style="color:#f92672">=</span> len(label_list) <span style="color:#75715e"># number of classification classes</span>
</code></pre></div><p>Build the learned network and load the weights learned earlier.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#75715e"># Network construction &amp; loading of learned weights</span>
model <span style="color:#f92672">=</span> cnn(image_size, classes)
model<span style="color:#f92672">.</span>load_weights(<span style="color:#e6db74">&#39;model_weights.h5&#39;</span>)
</code></pre></div><p>The image is read and converted so that the conditions are the same as when learning, and inference is performed.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#75715e"># Inference</span>
X <span style="color:#f92672">=</span> df_test[<span style="color:#e6db74">&#39;filename&#39;</span>]<span style="color:#f92672">.</span>values
y_true <span style="color:#f92672">=</span> list(map(<span style="color:#66d9ef">lambda</span> x: label_list<span style="color:#f92672">.</span>index(x), df_test[<span style="color:#e6db74">&#39;label&#39;</span>]<span style="color:#f92672">.</span>values))
y_pred <span style="color:#f92672">=</span> []
<span style="color:#66d9ef">for</span> file <span style="color:#f92672">in</span> tqdm(X, desc<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;pred&#39;</span>):
    <span style="color:#75715e"># Resize and convert the image so that it has the same conditions as when learning</span>
    img <span style="color:#f92672">=</span> Image<span style="color:#f92672">.</span>open(f<span style="color:#e6db74">&#39;{directory}/{file}&#39;</span>)
    img <span style="color:#f92672">=</span> img<span style="color:#f92672">.</span>resize(image_size, Image<span style="color:#f92672">.</span>LANCZOS)
    img <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(img, dtype<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>float32)
    img <span style="color:#f92672">*=</span> <span style="color:#ae81ff">1.</span><span style="color:#f92672">/</span><span style="color:#ae81ff">255</span>
    img <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>expand_dims(img, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)

    y_pred<span style="color:#f92672">.</span>append(np<span style="color:#f92672">.</span>argmax(model<span style="color:#f92672">.</span>predict(img)[<span style="color:#ae81ff">0</span>]))
</code></pre></div><p>Calculate F1 score using scikit-learn.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#75715e">#Evaluation</span>
<span style="color:#66d9ef">print</span>(classification_report(y_true, y_pred, target_names<span style="color:#f92672">=</span>label_list))
</code></pre></div><p>Below are the evaluation results. As expected, AMD and MH, which have few data, have low scores.</p>
<pre><code>              precision recall f1-score support

         AMD 0.17 0.67 0.27 75
       DR_DM 0.72 0.75 0.73 620
         Gla 0.76 0.69 0.72 459
          MH 0.09 0.34 0.14 32
      Normal 0.81 0.50 0.62 871
          RD 0.87 0.79 0.83 176
          RP 0.81 0.86 0.83 50
         RVO 0.45 0.65 0.53 107

    accuracy 0.64 2390
   macro avg 0.58 0.66 0.59 2390
weighted avg 0.73 0.64 0.67 2390
</code></pre><h1 id="7-summary">7. Summary</h1>
<p>In this article, we used a simple 10-layer CNN to classify images of the wide-angle fundus dataset released by Tsukazaki Hospital. In the future, based on this result, we will improve the performance while incorporating the latest methods such as network structure and data expansion method.</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p><a href="https://tsukazaki-ai.github.io/optos_dataset/">Tsukazaki Optos Public Project</a> <a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>

    </article>
  </div>

  
  
  
  <script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-169005401-1', 'auto');
  ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  

  
<link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.css" />
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#216942",
      "text": "#b2d192"
    },
    "button": {
      "background": "#afed71"
    }
  }
})});
</script>

</body>

</html>
