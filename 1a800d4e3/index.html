<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  <meta name="generator" content="Hugo 0.72.0" />

  
  <meta name="description" content="Some description">
  

  
  <link rel="apple-touch-icon" sizes="180x180" href="https://memotut.com/apple-touch-icon.png">

  
  <link rel="icon" type="image/png" sizes="32x32" href="https://memotut.com/favicon-32x32.png">

  
  <link rel="icon" type="image/png" sizes="16x16" href="https://memotut.com/favicon-16x16.png">

  
  <link rel="manifest" href="https://memotut.com/site.webmanifest">

  
  <link rel="mask-icon" href="https://memotut.com/safari-pinned-tab.svg" color="#5bbad5">

  <meta name="msapplication-TileColor" content="#da532c">

  <meta name="theme-color" content="#ffffff">

  
  <link rel="stylesheet" href="https://memotut.com/css/bootstrap.min.css" />

  
  <title>[Python] [Dimension curse] Can the number of sensors be changed to ∞ to detect anomalies? | Memo Tut</title>
  

  <style>
body {
  min-width: 300px;
}

.custom-navbar {
  margin-bottom: 1em;
  height: 60px;
}

.custom-navbar a {
  display: inline-block; 
  padding: 18px 0;
  margin-right: 1em; 
  font-weight: bold; 
}

.custom-navbar a:hover,
.custom-navbar a:focus {
  text-decoration: none; 
}

@media print {
  .custom-navbar {
    display: none;
  }
}

article {
  padding-bottom: 1em;
}

img {
  max-width: 100%;
}


body {
  background-color: #fff;
}



body {
  color: #212529;
}



a {
  color: #007bff;
}



a:hover,
a:focus {
  color: #0056b3;
}



.custom-navbar {
  background-color: #212529;
}



.custom-navbar a {
  color: rgba(255, 255, 255, 0.75);
}



.custom-navbar a:hover,
.custom-navbar a:focus {
  color: rgba(255, 255, 255, 1);
}



.container {
  max-width: 800px;
}



pre {
  display: block;
  padding: 9.5px;
  word-break: break-all;
  word-wrap: break-word;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre code {
  padding: 0;
  font-size: inherit;
  color: inherit; 
  white-space: pre-wrap;
  background-color: transparent;
  border: none;
  border-radius: 0;
}

code {
  padding: 2px 4px;
  color: inherit; 
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
  font-size: .9em;
}



blockquote,
.blockquote {
  padding: 10px 20px;
  margin: 0 0 20px;
  font-size: 1em;
  border-left: 5px solid #6c757d;
}

</style>
</head>

<body>
  <nav class="custom-navbar">
  <div class="container">
    
    <a href="/">Posts</a>
    
    <a href="/tags/">Tags</a>
    
    <a href="/about/">About</a>
    
    <a href="/index.xml">RSS</a>
    
  </div>
</nav>
  
  <div class="container">
    <article>
      <h1>[Python] [Dimension curse] Can the number of sensors be changed to ∞ to detect anomalies?</h1>
<p>
  <small class="text-secondary">
  
  
  Feb 10, 2020
  </small>
  

<small><code><a href="https://memotut.com/tags/python">Python</a></code></small>


<small><code><a href="https://memotut.com/tags/machine-learning"> machine learning</a></code></small>


<small><code><a href="https://memotut.com/tags/machinelearning"> MachineLearning</a></code></small>


<small><code><a href="https://memotut.com/tags/anomaly-detection"> anomaly detection</a></code></small>

</p>
<pre><code>Since the IOT became popular, efforts have been made to increase the number of sensors in order to predictively maintain machinery.
</code></pre>
<p>Is being done.</p>
<p>Rumor has it that there are cases where 100 sensors are attached to one machine.</p>
<p>The question is, is it justified to increase the number of sensors?
In other words, does **adding extra sensors not affect the anomaly detection performance? When
That is it.</p>
<p>In this paper, we focus on the curse of dimension, “When we increase the number of extra sensors, we detect anomalies.
What will the performance be like?&rdquo;</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/264781/11e65aa5-cb7e-415c-1e50-6d41c2f91f25.png" alt="image.png"></p>
<p>*The entire code is placed on <a href="https://github.com/shinmura0/Number-of-Sensor/blob/master/Infinity_sensor.ipynb.ipynb">here</a>.
*This is the presentation material of <a href="https://pythondata.connpass.com/event/165642/">Python Data Analysis Study Group #17</a>.</p>
<p>#From the conclusion</p>
<ul>
<li>Excessive sensor information may reduce the anomaly detection performance</li>
<li>To avoid it, it is necessary to take measures such as reducing extra sensors</li>
</ul>
<h1 id="assumed-scene">Assumed scene</h1>
<ul>
<li>Only two effective sensors for anomaly detection</li>
<li>It has an extra sensor and outputs almost zero signal, but it contains <strong>noise (important)</strong></li>
<li>What happens to the anomaly score when increasing the number of extra sensors?</li>
</ul>
<p>From the conclusion, if the extra sensor continues to output zero signal, the anomaly detection performance will be
It can be said that it hardly changes. However, because it contains noise, it curses the plane.
As the number of sensors increases, the anomaly detection performance deteriorates.</p>
<p>##noise
The sensor is almost always noisy. Even if the sensor has high accuracy
It contains a small amount of noise. Low (high) pass filter to remove noise
There is also a measure to install such as, but such processing is out of scope of this article.</p>
<p>In this article, we assume a scene that uses <strong>raw sensor sensor data</strong>.</p>
<p>What is #dimensional curse?
As the number of dimensions of the data is increased, the surface volume occupies most of the volume.
It is a phenomenon that becomes like. The problem in machine learning is that the difference between the distance between the nearest point and the farthest point is
It almost disappears, and it becomes difficult to distinguish by distance. For details, see the following article.</p>
<p><a href="https://qiita.com/tn1031/items/96e7131cd41df1aebe85">About the curse of dimension</a></p>
<h2 id="effects-on-supervised-learning">Effects on supervised learning</h2>
<p>Personally, in supervised learning, **dimension reduction etc. can be explicitly incorporated, so
I don&rsquo;t think it will be affected. ** Extreme talk, even if there is extra sensor information
It can be said that it is better to reduce unnecessary feature quantities and use the feature quantity with the highest accuracy.</p>
<h2 id="impact-on-unsupervised-learning">Impact on unsupervised learning</h2>
<p>However, in unsupervised learning such as abnormality detection, there is basically no abnormal data, or
It is possible that the scene has only a small amount of abnormal data. And a small amount of abnormal data
If you reduce the feature amount for reference, there is a risk of <strong>reducing the really required feature amount</strong>.
Therefore, if the dimension is easily reduced by unsupervised learning, the anomaly detection performance may deteriorate.
There is.</p>
<p>However, is it ok to put unnecessary sensor information in the detector as it is? Anomaly detection performance
Is it going to deteriorate? I also have the question. In other words, unnecessary sensor information
The number of dimensions increases because it is inserted, and it is difficult to distinguish between normal and abnormal due to the curse of the dimension
Will it be? I doubt. Therefore, we will conduct an experiment using dummy data.</p>
<p>#Experiment</p>
<ul>
<li>Only two effective sensors for anomaly detection</li>
<li>It has an extra sensor and outputs almost zero signal, but it contains noise.</li>
<li>What happens to the anomaly score when increasing the number of extra sensors? To observe</li>
</ul>
<p>As mentioned at the beginning, we will experiment with the above settings.
The following two are used as anomaly detection methods.</p>
<ul>
<li>MT method</li>
<li>Isolation Forest</li>
</ul>
<p>I will omit a detailed introduction, but <a href="https://qiita.com/shinmura0/items/901593e3d8a5238f8ae4#mt%E6%B3%95">MT method</a> applies normal data to the normal distribution and uses the Mahalanobis distance.
Determine if it is abnormal. The greater the Mahalanobis distance, the higher the degree of abnormality.
Isolation Forest is a decision tree-based anomaly detection method. <a href="https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/tkdd11.pdf">Original paper</a>
It has been shown to be valid for data in excess.</p>
<p>I put the whole code in <a href="https://github.com/shinmura0/Number-of-Sensor/blob/master/Infinity_sensor.ipynb.ipynb">here</a>.</p>
<h2 id="mt-method-result">MT method result</h2>
<p>First, generate a valid sensor ($x_1,x_2$) using random numbers.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/264781/33a37fa1-73ea-34f0-d9e1-dbd4e52d7f0f.png" alt="image.png"></p>
<p>From the above left figure, you can see that there is a correlation between $x_1,x_2$.
The green dots are the learning data. If you replace $x_1$ with temperature, $x_2$ with pressure, etc.
It may be easy to understand.</p>
<p>The purple points are normal data and the red points are abnormal data.</p>
<p>When the MT method is applied in the $x_1,x_2$ space, it is normal/abnormal as shown in the right figure above.
The difference clearly appears in the anomaly score (MD = Mahalanobis distance).
The greater the Mahalanobis distance, the higher the degree of abnormality. By the way, the light blue line
The area with the same Mahalanobis distance is called a line, called an equal probability ellipse.</p>
<h3 id="when-the-number-of-dimensions-is-changed-from-2-to-3">When the number of dimensions is changed from 2 to 3</h3>
<p>Increase the number of dimensions by 1 ($x_3$).</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/264781/f0b24ec0-c55b-9672-c00b-e3d9ac65fd52.png" alt="image.png"></p>
<p>I added one extra sensor info like the one on the right ($x_3$). $x_3$ is the brightness sensor, for example
It may be attached. $x_1,x_2$ (left and middle figures) were correlated and meaningful data,
$x_3$ has no correlation and is just noise.</p>
<p>The figure below shows $x_1,x_3$ space.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/264781/9d8f8d2d-efc0-e183-7c80-0ad529f556bc.png" alt="image.png"></p>
<p>Looking only at this figure, the difference between normal/abnormal data is not very large,
Therefore, it is likely that normal data will be an outlier. And that is
This is a factor that makes it difficult to distinguish abnormal/normal.</p>
<p>When the MT method is applied to the entire $x_1,x_2,x_3$ space, the anomaly score is as follows.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/264781/dd146733-75a6-476b-3810-0f745c24631f.png" alt="image.png"></p>
<p>The difference is smaller than when the number of dimensions is 2, but the anomalous data still has a higher score.
It is getting bigger.</p>
<h3 id="when-the-number-of-dimensions-is-changed-from-3-to-100">When the number of dimensions is changed from 3 to 100</h3>
<p>The result of continuing increasing $x_3$ up to 98 like the previous one is as follows.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/264781/11e65aa5-cb7e-415c-1e50-6d41c2f91f25.png" alt="image.png"></p>
<p>The horizontal axis is the number of dimensions, and the vertical axis is the anomaly score (MD = Mahalanobis distance).
As you can see, the normal and abnormal scores are reversed when the number of dimensions is 20.
In other words, it is a false positive.</p>
<p>Since the experiment uses random numbers, the result will change from experiment to experiment, but as long as the number of dimensions is small for all results
Normal and abnormal can be detected correctly.</p>
<p>##Isolation Forest results</p>
<h3 id="when-the-number-of-dimensions-is-changed-from-2-to-100">When the number of dimensions is changed from 2 to 100</h3>
<p>The result was similar to the MT method.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/264781/9dfe416c-1ffb-dec0-41ab-850dcf2a5dae.png" alt="image.png"></p>
<p>After all, when the number of dimensions is 20, normal and abnormal are reversed, and false detection is made.
Note that Isolation Forest uses scikit-learn, but the anomaly score is for clarity.
The numbers are reversed. (In the figure above, the higher the abnormality score, the higher the degree of abnormality.)</p>
<p>#To avoid the curse of dimension
As a result, if you insert unnecessary sensor information too much, the number of dimensions increases, and the curse of dimension causes
It has become difficult to distinguish normal/abnormal. However, sensor information is blindly
If dropped, there is a risk that the abnormality detection performance will deteriorate. Solve this dilemma
The methods are listed below.</p>
<ul>
<li>
<p>Cosine similarity
~~ Generally, angle-based methods such as <strong>cosine similarity</strong> are less susceptible to dimensional curses.
It is said. ~~ (← I think I saw it somewhere, but I can&rsquo;t remember the source, so far
I am turning it off. If anyone knows any references or articles, please let me know. )</p>
</li>
<li>
<p>Subdivide sensor information
For example, if you have information on 100 sensors, instead of plunging them into one detector,
Here, the idea is to create a detector by dividing the sensor information into two pieces. This allows the curse of dimension
The impact can be mitigated. Assuming that we made detectors by brute force, we would make $100C_2=4950$ detectors
Become. I am concerned about the processing speed of 4950 detectors, but the MT method can process at high speed.
Isolation Forest is heavy processing, so real-time processing is difficult, but if offline
I think it is a usable level. However, since we are only looking at two relationships, there are three or more relationships
In some cases, you may miss an anomaly.</p>
</li>
<li>
<p>Reduce extra sensors
This is the easiest and clearest. **If abnormal data is on hand, which sensor information is effective?
You can squeeze. **This eliminates extra sensors and avoids higher dimensions.
I can do it. However, as mentioned at the beginning, if there is a small amount of abnormal data, the sensor that really needs
If there is a risk of reduction and there is no abnormal data, while collecting abnormal data
The drawback is that the detector needs to be upgraded. The MT method uses the SN ratioYou can narrow down the effective sensors. <a href="https://qiita.com/shinmura0/items/40b83ca472b05519b1c7">Next article</a> says that not only MT method but also other methods
We will show you how to narrow down the effective sensors.</p>
</li>
</ul>
<p>#Summary</p>
<ul>
<li>If you continue to add extra sensor information, the anomaly detection performance may decrease.</li>
<li>In order to avoid it, it is necessary to devise ~~ cosine similarity, ~~ subdivide sensor information, etc.</li>
<li>If you can reduce the number of extra sensors, you can avoid the deterioration of the anomaly detection performance and reduce the cost.</li>
</ul>
<p><a href="https://qiita.com/shinmura0/items/40b83ca472b05519b1c7">Next time</a> introduces a method for investigating the cause of abnormality detection.
Using this method, it is possible to narrow down the effective sensors and reduce the extra sensors. **</p>

    </article>
  </div>

  
  
  
  <script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-169005401-1', 'auto');
  ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  

  
<link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.css" />
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#216942",
      "text": "#b2d192"
    },
    "button": {
      "background": "#afed71"
    }
  }
})});
</script>

</body>

</html>
