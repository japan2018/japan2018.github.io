<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  <meta name="generator" content="Hugo 0.72.0" />

  
  <meta name="description" content="Some description">
  

  
  <link rel="apple-touch-icon" sizes="180x180" href="https://memotut.com/apple-touch-icon.png">

  
  <link rel="icon" type="image/png" sizes="32x32" href="https://memotut.com/favicon-32x32.png">

  
  <link rel="icon" type="image/png" sizes="16x16" href="https://memotut.com/favicon-16x16.png">

  
  <link rel="manifest" href="https://memotut.com/site.webmanifest">

  
  <link rel="mask-icon" href="https://memotut.com/safari-pinned-tab.svg" color="#5bbad5">

  <meta name="msapplication-TileColor" content="#da532c">

  <meta name="theme-color" content="#ffffff">

  
  <link rel="stylesheet" href="https://memotut.com/css/bootstrap.min.css" />

  
  <title>[Python] I tried using magenta/TensorFlow | Memo Tut</title>
  

  <style>
body {
  min-width: 300px;
}

.custom-navbar {
  margin-bottom: 1em;
  height: 60px;
}

.custom-navbar a {
  display: inline-block; 
  padding: 18px 0;
  margin-right: 1em; 
  font-weight: bold; 
}

.custom-navbar a:hover,
.custom-navbar a:focus {
  text-decoration: none; 
}

@media print {
  .custom-navbar {
    display: none;
  }
}

article {
  padding-bottom: 1em;
}

img {
  max-width: 100%;
}


body {
  background-color: #fff;
}



body {
  color: #212529;
}



a {
  color: #007bff;
}



a:hover,
a:focus {
  color: #0056b3;
}



.custom-navbar {
  background-color: #212529;
}



.custom-navbar a {
  color: rgba(255, 255, 255, 0.75);
}



.custom-navbar a:hover,
.custom-navbar a:focus {
  color: rgba(255, 255, 255, 1);
}



.container {
  max-width: 800px;
}



pre {
  display: block;
  padding: 9.5px;
  word-break: break-all;
  word-wrap: break-word;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre code {
  padding: 0;
  font-size: inherit;
  color: inherit; 
  white-space: pre-wrap;
  background-color: transparent;
  border: none;
  border-radius: 0;
}

code {
  padding: 2px 4px;
  color: inherit; 
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
  font-size: .9em;
}



blockquote,
.blockquote {
  padding: 10px 20px;
  margin: 0 0 20px;
  font-size: 1em;
  border-left: 5px solid #6c757d;
}

</style>
</head>

<body>
  <nav class="custom-navbar">
  <div class="container">
    
    <a href="/">Posts</a>
    
    <a href="/tags/">Tags</a>
    
    <a href="/about/">About</a>
    
    <a href="/index.xml">RSS</a>
    
  </div>
</nav>
  
  <div class="container">
    <article>
      <h1>[Python] I tried using magenta/TensorFlow</h1>
<p>
  <small class="text-secondary">
  
  
  Apr 17, 2020
  </small>
  

<small><code><a href="https://memotut.com/tags/python">Python</a></code></small>


<small><code><a href="https://memotut.com/tags/deeplearning">DeepLearning</a></code></small>


<small><code><a href="https://memotut.com/tags/tensorflow">TensorFlow</a></code></small>


<small><code><a href="https://memotut.com/tags/magenta">magenta</a></code></small>

</p>
<pre><code>Automatic generation of melody using # magenta/TensorFlow
</code></pre>
<h2 id="background">background</h2>
<p>Since I want to be able to manipulate MIDI data using Python this time, I came to a tool called Magenta while browsing various sites.</p>
<blockquote>
<p>What is #Magenta
Recently, a new project called Magenta from Google was opened on Github.
<a href="https://github.com/tensorflow/magenta">https://github.com/tensorflow/magenta</a></p>
</blockquote>
<blockquote>
<p>Magenta is a project that uses neural networks to generate art and music.</p>
</blockquote>
<blockquote>
<p>It aims to evolve machine learning creativity and to be a community of artists and machine learning.</p>
</blockquote>
<blockquote>
<h1 id="recurrent-neural-network-to-compose">Recurrent neural network to compose</h1>
</blockquote>
<p>As the first version of Magenta, a model of recurrent neural network (RNN) that composes was released.
LSTM (Long Short-Term Memory) is adopted.
According to the magenta official website (<a href="http://magenta.tensorflow.org/">http://magenta.tensorflow.org/</a> ),</p>
<blockquote>
<blockquote>
<p>It’s purposefully a simple model, so don’t expect stellar music results. We’ll post more complex models soon.
This is a deliberately simplified model, and you can&rsquo;t expect to have outstanding music. However, we will publish more complex models in the future.</p>
</blockquote>
</blockquote>
<p>Magenta was released in 2016.
First of all, I need to study RNN and LSTM, but I will use this tool because I will try using it for the time being.</p>
<h2 id="environment">Environment</h2>
<ul>
<li>MacBookPro (macOS Catalina (10.15.4))</li>
<li>Docker for Mac</li>
</ul>
<h2 id="references">References</h2>
<ul>
<li>
<p><a href="https://github.com/PyDataOkinawa/meetup017">PyDataOkinawa/meetup017</a></p>
</li>
<li>
<p><a href="https://qiita.com/tackey/items/860f408e43397f55b160">Extract the sound of a specific instrument from the MIDI file and save it as a separate file
</a></p>
</li>
</ul>
<h2 id="extract-a-specific-part">Extract a specific part</h2>
<p>I checked the MIDI data (the title song of Hyugazaka46, 4 songs) purchased from YAMAHA online shop.</p>
<img width="1920" alt="Screenshot 2020-04-17 22.53.40.png" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/512948/5b603377-d40a-4f95-21d9-5f7a09d0f661.png">
<p>It was divided into various tracks like this. (Drum part, accompaniment, etc.)
As will be described later, the learning was performed using the data as it was without doing anything. I confirmed the results, but it is not good if there are many data genres used. Therefore, it is necessary to focus only on the melody.</p>
<p>So let&rsquo;s extract only the melody part using the Python package <code>pretty-midi</code>.</p>
<pre><code class="language-terminal:terminal" data-lang="terminal:terminal">pip install pretty_midi
</code></pre><p>For reference, the resource allocation is as follows.</p>
<img width="997" alt="Screenshots 2020-04-17 22.56.58.png" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/512948/def7b061-8ba4-b3e9-4949-45803d5fd9c5.png">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-Python:cut_out.py" data-lang="Python:cut_out.py">
<span style="color:#f92672">import</span> pretty_midi
<span style="color:#f92672">import</span> os

os<span style="color:#f92672">.</span>chdir(<span style="color:#e6db74">&#34;~/WorkSpace/MIDI_data/cut_out&#34;</span>)

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">func</span>():
  midi_name <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#34;00&#34;</span>, <span style="color:#e6db74">&#34;01&#34;</span>, <span style="color:#e6db74">&#34;02&#34;</span>, <span style="color:#e6db74">&#34;03&#34;</span>]

  <span style="color:#66d9ef">for</span> m_name <span style="color:#f92672">in</span> midi_name:
    midi_data <span style="color:#f92672">=</span> pretty_midi<span style="color:#f92672">.</span>PrettyMIDI(<span style="color:#e6db74">&#34;resource&#34;</span> <span style="color:#f92672">+</span> m_name <span style="color:#f92672">+</span><span style="color:#e6db74">&#39;.mid&#39;</span>)

    <span style="color:#75715e">#Select instrument number and save</span>
    midi_track <span style="color:#f92672">=</span> midi_data<span style="color:#f92672">.</span>instruments
    <span style="color:#75715e"># print(&#34;midi_track = {0}&#34; .format(midi_track))</span>
    <span style="color:#66d9ef">for</span> m_track <span style="color:#f92672">in</span> midi_track:
        <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;midi_track = {0}&#34;</span> <span style="color:#f92672">.</span>format(m_track))

    <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;select track-nunber =&gt; &#34;</span>)
    i <span style="color:#f92672">=</span> int(input())

    <span style="color:#75715e"># Take out the selected instrument and make it an instance</span>
    <span style="color:#66d9ef">for</span> instrument <span style="color:#f92672">in</span> midi_track:
        <span style="color:#66d9ef">if</span> instrument<span style="color:#f92672">.</span>program <span style="color:#f92672">==</span> i:
            ins <span style="color:#f92672">=</span> instrument

    <span style="color:#75715e">#Create a new Pretty MIDI object</span>
    rev_en_chord <span style="color:#f92672">=</span> pretty_midi<span style="color:#f92672">.</span>PrettyMIDI()

    <span style="color:#75715e">#Add to Pretty MIDI Object</span>
    rev_en_chord<span style="color:#f92672">.</span>instruments<span style="color:#f92672">.</span>append(ins)

    <span style="color:#75715e"># save</span>
    rev_en_chord<span style="color:#f92672">.</span>write(<span style="color:#e6db74">&#39;./result/ins_&#39;</span> <span style="color:#f92672">+</span> m_name <span style="color:#f92672">+</span><span style="color:#e6db74">&#39;.mid&#39;</span>)

  <span style="color:#66d9ef">return</span>

func()
</code></pre></div><p>This code refers to each MIDI file, specifies the instrument number, and saves only that track.</p>
<p><a href="https://digi-pal.link/midi-note-number/">Various correspondence table of MIDI note numbers. Rhythm instrument name in GM, GS, XG. Program number, instrument name and sound range. </a></p>
<p>See the above site for musical instrument chords. Most people seem to mess with the instrument chords when touching MIDI data from programming.</p>
<h2 id="finally-learning">Finally Learning</h2>
<p>Start Docker and pull the <code>magenta/tensorflow</code> image.
Since TensorBoard is also used, specify the Port number.</p>
<pre><code class="language-terminal:Terminal" data-lang="terminal:Terminal">docker run -it -p 6006:6006 -v /tmp/magenta:/magenta-data tensorflow/magenta
</code></pre><p>Basically, I did not specify it here because the procedure on the following site was reasonably advanced.</p>
<p><a href="https://github.com/PyDataOkinawa/meetup017">PyDataOkinawa/meetup017</a></p>
<p>However, I needed to hit the shell script in the image, but it stopped with an error.
I hadn&rsquo;t touched the shell script until now, so it took a while to decipher it. Perhaps the environment was different, the name of the specified programming file was different, or the condition of the parameter settings was bad, resulting in an error. (I learned about shell scripts.)</p>
<p>For reference, it was possible to learn by making the following changes in my environment.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell:build_dataset.sh" data-lang="shell:build_dataset.sh">
convert_midi_dir_to_note_sequences <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>    --midi_dir<span style="color:#f92672">=</span>$MIDI_DIR <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>    --output_file<span style="color:#f92672">=</span>$SEQUENCES_TFRECORD <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>    --recursive

<span style="color:#75715e">###### Change to ######</span>

convert_dir_to_note_sequences <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>    --midi_dir<span style="color:#f92672">=</span>$MIDI_DIR <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>    --output_file<span style="color:#f92672">=</span>$SEQUENCES_TFRECORD <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>    --recursive
</code></pre></div><p>Learning&hellip;
I also saw TensorBoard for the first time. I have to study more because it is exactly what is written.
<img width="1920" alt="Screenshot 2020-04-16 17.29.32.png" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/512948/a718defc-d583-c0c4-73aa-3a579bf58229.png"></p>
<p>![Screenshot 2020-04-15 18.37.07.png](<a href="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/512948/5c35c2e7-4032-96b4-b538-(d54ba73ea65f.png)">https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/512948/5c35c2e7-4032-96b4-b538-(d54ba73ea65f.png)</a></p>
<p>I tried turning it on a MacBook for the time being
I have to be able to use Deep Infinity next week&hellip;</p>
<p>Since the number of steps was set to 1200, it took 1 hour and 30 minutes to learn on a MacBook Pro.
The model used is <code>Basic RNN</code>
<img width="578" alt="Screenshots 2020-04-16 18.50.52.png" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/512948/586a22bc-143f-19e3-c648-4dfdc17d936b.png"></p>
<p>The accuracy (Accuracy) had risen to 0.8.</p>
<h2 id="generate">Generate</h2>
<p>A MIDI file was generated using this training data.
The number of steps was specified as 500. Also, the number of generated files is 5.</p>
<p>The generated MIDI data was converted to <code>wav</code> using <code>timidity</code> and uploaded to Goolge Drive.</p>
<p><a href="https://drive.google.com/drive/folders/1R2SpHmvkjver7Zsy-4wYlSY4Axsk-jxb?usp=sharing">Google Drive</a></p>
<p>The time has come here, but I feel that a melody line reminiscent of the original song has been generated while listening to the song.</p>

    </article>
  </div>

  
  
  
  <script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-169005401-1', 'auto');
  ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  

  
<link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.css" />
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#216942",
      "text": "#b2d192"
    },
    "button": {
      "background": "#afed71"
    }
  }
})});
</script>

</body>

</html>
