<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  <meta name="generator" content="Hugo 0.72.0" />

  
  <meta name="description" content="Some description">
  

  
  <link rel="apple-touch-icon" sizes="180x180" href="https://memotut.com/apple-touch-icon.png">

  
  <link rel="icon" type="image/png" sizes="32x32" href="https://memotut.com/favicon-32x32.png">

  
  <link rel="icon" type="image/png" sizes="16x16" href="https://memotut.com/favicon-16x16.png">

  
  <link rel="manifest" href="https://memotut.com/site.webmanifest">

  
  <link rel="mask-icon" href="https://memotut.com/safari-pinned-tab.svg" color="#5bbad5">

  <meta name="msapplication-TileColor" content="#da532c">

  <meta name="theme-color" content="#ffffff">

  
  <link rel="stylesheet" href="https://memotut.com/css/bootstrap.min.css" />

  
  <title>[Python] For those who want to start machine learning with TensorFlow2 | Memo Tut</title>
  

  <style>
body {
  min-width: 300px;
}

.custom-navbar {
  margin-bottom: 1em;
  height: 60px;
}

.custom-navbar a {
  display: inline-block; 
  padding: 18px 0;
  margin-right: 1em; 
  font-weight: bold; 
}

.custom-navbar a:hover,
.custom-navbar a:focus {
  text-decoration: none; 
}

@media print {
  .custom-navbar {
    display: none;
  }
}

article {
  padding-bottom: 1em;
}

img {
  max-width: 100%;
}


body {
  background-color: #fff;
}



body {
  color: #212529;
}



a {
  color: #007bff;
}



a:hover,
a:focus {
  color: #0056b3;
}



.custom-navbar {
  background-color: #212529;
}



.custom-navbar a {
  color: rgba(255, 255, 255, 0.75);
}



.custom-navbar a:hover,
.custom-navbar a:focus {
  color: rgba(255, 255, 255, 1);
}



.container {
  max-width: 800px;
}



pre {
  display: block;
  padding: 9.5px;
  word-break: break-all;
  word-wrap: break-word;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre code {
  padding: 0;
  font-size: inherit;
  color: inherit; 
  white-space: pre-wrap;
  background-color: transparent;
  border: none;
  border-radius: 0;
}

code {
  padding: 2px 4px;
  color: inherit; 
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
  font-size: .9em;
}



blockquote,
.blockquote {
  padding: 10px 20px;
  margin: 0 0 20px;
  font-size: 1em;
  border-left: 5px solid #6c757d;
}

</style>
</head>

<body>
  <nav class="custom-navbar">
  <div class="container">
    
    <a href="/">Posts</a>
    
    <a href="/tags/">Tags</a>
    
    <a href="/about/">About</a>
    
    <a href="/index.xml">RSS</a>
    
  </div>
</nav>
  
  <div class="container">
    <article>
      <h1>[Python] For those who want to start machine learning with TensorFlow2</h1>
<p>
  <small class="text-secondary">
  
  
  Apr 20, 2020
  </small>
  

<small><code><a href="https://memotut.com/tags/python">Python</a></code></small>


<small><code><a href="https://memotut.com/tags/machine-learning"> machine learning</a></code></small>


<small><code><a href="https://memotut.com/tags/machinelearning"> MachineLearning</a></code></small>


<small><code><a href="https://memotut.com/tags/cnn"> CNN</a></code></small>


<small><code><a href="https://memotut.com/tags/tensorflow"> TensorFlow</a></code></small>

</p>
<pre><code>#Introduction
</code></pre>
<p>I am currently a M2 student majoring in CS. I usually write machine learning code in PyTorch. It&rsquo;s easy to write for the time being.
PyTorch is said to be &ldquo;Define by Run&rdquo;**, and what is good at the same time when the calculation graph and data are sent is that it is easy to debug because you can check the calculation results on the way. As a PyTorch believer, I need to write code in TensorFlow this time, so I will keep a memo so that I don&rsquo;t forget the know-how at that time.</p>
<p>Before I touched PyTorch, I used to touch TensorFlow and keras, so I was able to understand it somehow, but since I did not understand much about TensorFlow2, it was a good study this time. By the way, TensorFlow1 (TF1) adopted the method of flowing data to the place where static graph was created by the method called &ldquo;Define and Run&rdquo; <strong>, but TensorFlow2 (TF2) ** It uses the same method as &ldquo;Define by Run&rdquo;</strong> and PyTorch.</p>
<h1 id="target-of-this-article">Target of this article</h1>
<p>This article is for anyone who wants to get started with machine learning with TensorFlow2. Looking at other people&rsquo;s articles, there were many articles about TensorFlow1 and I couldn&rsquo;t find many articles about TensorFlow2(TF2), so I think it will be helpful for those who are thinking about touching TF2. Also, rather than a sklearn-like way of learning with <code>model.fit</code> etc., I wrote mainly about the expert method in the TensorFlow tutorial, so I hope that anyone interested can read it.</p>
<h3 id="rough-content">rough content</h3>
<p><strong>1. TensorFlow basics</strong>
<strong>2. Easy model building and learning with keras (Beginner Version)</strong>
<strong>3. Transfer learning (+Fine Tuning)</strong>
<strong>4. Build your own model</strong>
<strong>5. Model building and training with TensorFLow2 (Expert Version)</strong></p>
<h3 id="other-useful-things-to-know">Other useful things to know</h3>
<p><strong>[1]. When using your own data set</strong>
<strong>[2]. About Augmentaion</strong>
<strong>[3]. TensorBoard</strong>
<strong>[4]. TFRecord</strong></p>
<h1 id="1-tensorflow-basics">1. TensorFlow basics</h1>
<p>First, the basics.</p>
<p>You can define a constant with <code>tf.constant(value, dtype=None, shape=None, name='Const', verify_shape=False)</code>.</p>
<pre><code>&gt;&gt;&gt; import tensorflow as tf
&gt;&gt;&gt;
&gt;&gt;&gt; tf.constant([1, 2, 3])
&lt;tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 3], dtype=int32)&gt;
&gt;&gt;&gt;
&gt;&gt;&gt; b = tf.constant('Hello') # string ok
&lt;tf.Tensor: shape=(), dtype=string, numpy=b'Hello'&gt;
&gt;&gt;&gt;
</code></pre><p>If you specify <code>shape</code>, all elements will have the same value.</p>
<pre><code>&gt;&gt;&gt; tf.constant(3, shape=[1, 3])
&lt;tf.Tensor: shape=(1, 3), dtype=int32, numpy=array([[3, 3, 3]], dtype=int32)&gt;
&gt;&gt;&gt;
&gt;&gt;&gt;
</code></pre><ul>
<li>Addition <code>tf.add()</code>, subtraction <code>tf.subtract()</code>, multiplication <code>tf.mul()</code>, division <code>tf.divide()</code></li>
</ul>
<pre><code>&gt;&gt;&gt; tf.add(2,3)
&lt;tf.Tensor: shape=(), dtype=int32, numpy=5&gt;
&gt;&gt;&gt;
&gt;&gt;&gt; tf.subtract(5,3)
&lt;tf.Tensor: shape=(), dtype=int32, numpy=2&gt;
&gt;&gt;&gt;
&gt;&gt;&gt; tf.multiply(3,4)
&lt;tf.Tensor: shape=(), dtype=int32, numpy=12&gt;
&gt;&gt;&gt;
&gt;&gt;&gt; tf.divide(2,3)
0.6666666666666666
</code></pre><h3 id="convert-numpy-to-tensor">Convert Numpy to Tensor</h3>
<p>Use <code>tf.convert_to_tensor</code>.
If it is a Numpy array, use <code>.numpy()</code>.</p>
<pre><code>&gt;&gt;&gt; a = np.asarray([1,2,3])
&gt;&gt;&gt; a
array([1, 2, 3])
&gt;&gt;&gt; a.shape
(3,)
&gt;&gt;&gt; tf.convert_to_tensor(a)
&lt;tf.Tensor: shape=(3,), dtype=int64, numpy=array([1, 2, 3])&gt;
&gt;&gt;&gt; a
array([1, 2, 3])
&gt;&gt;&gt; c = tf.convert_to_tensor(a)
&gt;&gt;&gt; c
&lt;tf.Tensor: shape=(3,), dtype=int64, numpy=array([1, 2, 3])&gt;
&gt;&gt;&gt; c.numpy()
array([1, 2, 3])

</code></pre><p>Add dimension number <code>tf.expand_dims(input, axis, name=None)</code>
Used when adding batch size to image size</p>
<pre><code>&gt;&gt;&gt; a = tf.constant([2,3])
&gt;&gt;&gt; a.shape
TensorShape([2])
&gt;&gt;&gt; b = tf.expand_dims(a,0)
&gt;&gt;&gt; b.shape
TensorShape([1, 2])
&gt;&gt;&gt;
</code></pre><p><code>tf.stack(values, axis=0, name='stack')</code></p>
<pre><code>&gt;&gt;&gt; x = tf.constant([1, 4])
&gt;&gt;&gt; y = tf.constant([2, 5])
&gt;&gt;&gt; z = tf.constant([3, 6])
&gt;&gt;&gt; tf.stack([x, y, z], axis=0)
&lt;tf.Tensor: shape=(3, 2), dtype=int32, numpy=
array([[1, 4],
       [twenty five],
       [3, 6]], dtype=int32)&gt;
&gt;&gt;&gt; tf.stack([x, y, z], axis=1)
&lt;tf.Tensor: shape=(2, 3), dtype=int32, numpy=
array([[1, 2, 3],
       [4, 5, 6]], dtype=int32)&gt;
&gt;&gt;&gt;
</code></pre><p><code>tf.concat(values, axis, name='concat')</code></p>
<pre><code>&gt;&gt;&gt; t1 = [[1, 2, 3], [4, 5, 6]]
&gt;&gt;&gt; t2 = [[7, 8, 9], [10, 11, 12]]
&gt;&gt;&gt; tf.concat([t1,t2],0)
&lt;tf.Tensor: shape=(4, 3), dtype=int32, numpy=
array([[ 1, 2, 3],
       [4, 5, 6],
       [7, 8, 9],
       [10, 11, 12]], dtype=int32)&gt;
&gt;&gt;&gt; tf.concat([t1,t2],1)
&lt;tf.Tensor: shape=(2, 6), dtype=int32, numpy=
array([[ 1, 2, 3, 7, 8, 9],
       [4, 5, 6, 10, 11, 12]], dtype=int32)&gt;
&gt;&gt;&gt;
</code></pre><p>#2. Easy model building and learning with keras (Beginner Version)
Next, I would like to try a classification problem using mnist data.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-sample1.py" data-lang="sample1.py">
<span style="color:#f92672">import</span> tensorflow <span style="color:#f92672">as</span> tf

mnist <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>datasets<span style="color:#f92672">.</span>mnist

(x_train, y_train), (x_test, y_test) <span style="color:#f92672">=</span> mnist<span style="color:#f92672">.</span>load_data() <span style="color:#75715e"># load data</span>
x_train, x_test <span style="color:#f92672">=</span> x_train <span style="color:#f92672">/</span> <span style="color:#ae81ff">255.0</span>, x_test <span style="color:#f92672">/</span> <span style="color:#ae81ff">255.0</span> <span style="color:#75715e">#Data normalization</span>


<span style="color:#75715e"># Build the model</span>
<span style="color:#75715e"># Sequential API</span>
model <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>models<span style="color:#f92672">.</span>Sequential((
  tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>layers<span style="color:#f92672">.</span>Flatten(input_shape<span style="color:#f92672">=</span>(<span style="color:#ae81ff">28</span>, <span style="color:#ae81ff">28</span>)),
  tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>layers<span style="color:#f92672">.</span>Dense(<span style="color:#ae81ff">128</span>, activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;relu&#39;</span>),
  tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>layers<span style="color:#f92672">.</span>Dropout(<span style="color:#ae81ff">0.2</span>),
  tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>layers<span style="color:#f92672">.</span>Dense(<span style="color:#ae81ff">10</span>, activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;softmax&#39;</span>)
])


<span style="color:#75715e"># optimizer, loss, metrics settings (learning settings)</span>
model<span style="color:#f92672">.</span>compile(optimizer<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;adam&#39;</span>,
              loss<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;sparse_categorical_crossentropy&#39;</span>,
              metrics<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;accuracy&#39;</span>])

<span style="color:#75715e">#Learning</span>
model<span style="color:#f92672">.</span>fit(x_train, y_train, epochs<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>)

<span style="color:#75715e">#Evaluation</span>
test_loss, test_acc <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>evaluate(x_test, y_test, verbose<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>)

<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">Test accuracy:&#39;</span>, test_acc)

</code></pre></div><p>I think it&rsquo;s a writing style that you often see. In this model, the input 28x28 image is transformed into a one-dimensional array 784 using <code>Flatten()</code>. After that, connect all connected layers, and the last fully connected layer <code>10</code> is the number of classes (the number you want to classify). Especially at the end, you can get the probability of each class by specifying <code>softmax</code> as activation. For learning and evaluation, you can use <code>model.fit</code>, <code>model.evaluate</code>, <code>model.predict</code> etc.</p>
<p>The basic flow is ① reading data, ② data pre-processing, ③ model building, ④ detailed settings for learning, ⑤ learning, ⑥ evaluation.</p>
<p>#3. Transfer learning (+Fine Tuning)</p>
<p>If you can build and learn a simple model with mnist, let&rsquo;s try transfer learning next. Transfer learning is to use weights learned in advance on a large number of images such as imagenet. It has the advantage of shortening the learning time and providing some accuracy even if there is little data. Although transfer learning and fine tuning are not often distinguished, in transfer learning, the weight of the first layer is fixed, and only the layers that are replaced or added by themselves are learned. Fine Tuning does not fix the weights of the first layer, but retrains all parameters.</p>
<p>In TensorFlow transfer learning, we use <code>tf.keras.applicacctions</code> to load the model.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-.py" data-lang=".py"><span style="color:#f92672">import</span> tensorflow <span style="color:#f92672">as</span> tf
<span style="color:#f92672">from</span> tensorflow.keras.layers <span style="color:#f92672">import</span> Dense, GlobalAveragePooling2D

<span style="color:#75715e"># Please specify the input_shape when loading the model</span>
Output layer will <span style="color:#f92672">not</span> be read by setting <span style="color:#75715e">#include_top = False</span>
IMG_SIZE <span style="color:#f92672">=</span> (<span style="color:#ae81ff">224</span>,<span style="color:#ae81ff">224</span>,<span style="color:#ae81ff">3</span>)base_model <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>applications<span style="color:#f92672">.</span>MobileNetV2(input_shape<span style="color:#f92672">=</span>IMG_SIZE,
                                               include_top <span style="color:#f92672">=</span> False,
                                               weights<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;imagenet&#39;</span>)

When fixing the weight of <span style="color:#75715e"># base model</span>
base_model<span style="color:#f92672">.</span>trainable <span style="color:#f92672">=</span> False


<span style="color:#75715e"># You can reduce the amount of calculation by using Global Average Pooling without fully connecting layers</span>
GAP_layer <span style="color:#f92672">=</span> GlobalAveragePooling2D()
Since it <span style="color:#f92672">is</span> a <span style="color:#75715e">#10 class classification, it is 10. Replace this with your own task.</span>
pred_layer <span style="color:#f92672">=</span> Dense(<span style="color:#ae81ff">10</span>, activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;softmax&#39;</span>)

model <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>Sequential((
    base_model,
    GAP_layer,
    pred_layer
])

Check the model <span style="color:#66d9ef">with</span> <span style="color:#75715e"># model.summary()</span>
</code></pre></div><p>See <a href="https://www.tensorflow.org/api_docs/python/tf/keras/applications">Module: tf.keras.applications</a> for other easy-to-use models.</p>
<p><strong>+α</strong>
Although it is MobileNetV2, this model is a very “light model” that works even on edge terminals. A technique called <code>Depthwise Separable Convolution</code> that calculates the convolution separately in the spatial direction and the channel direction is used, or the activation value that makes the output value up to 6 after passing the activation function called <code>ReLU</code> into <code>ReLU6</code> is activated. It is a very interesting model that uses functions. If you are interested, please check it out.</p>
<h1 id="4-build-your-own-model">4. Build your own model</h1>
<p>Starting with TF2, you can use the sub classing API when building models. I will now introduce you to build a model like PyTorch.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-.py" data-lang=".py">

<span style="color:#f92672">import</span> tensorflow <span style="color:#f92672">as</span> tf

<span style="color:#f92672">from</span> tensorflow.keras.layers <span style="color:#f92672">import</span> Dense, Flatten, Conv2D
<span style="color:#f92672">from</span> tensorflow.keras <span style="color:#f92672">import</span> Model

<span style="color:#66d9ef">class</span> <span style="color:#a6e22e">Net</span>(Model):
  <span style="color:#66d9ef">def</span> __init__(self):
    super(Net, self)<span style="color:#f92672">.</span>__init__()
    self<span style="color:#f92672">.</span>conv1 <span style="color:#f92672">=</span> Conv2D(<span style="color:#ae81ff">32</span>, <span style="color:#ae81ff">3</span>, activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;relu&#39;</span>) <span style="color:#75715e">#Conv2D(filters, kernel_size, activation)</span>
    self<span style="color:#f92672">.</span>flatten <span style="color:#f92672">=</span> Flatten()
    self<span style="color:#f92672">.</span>d1 <span style="color:#f92672">=</span> Dense(<span style="color:#ae81ff">128</span>, activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;relu&#39;</span>) <span style="color:#75715e"># Dense(units, activation)</span>
    self<span style="color:#f92672">.</span>d2 <span style="color:#f92672">=</span> Dense(<span style="color:#ae81ff">10</span>, activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;softmax&#39;</span>) <span style="color:#75715e"># Dense(units, activation)</span>

  <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">call</span>(self, x):
    x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>conv1(x)
    x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>flatten(x)
    x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>d1(x)
    <span style="color:#66d9ef">return</span> self<span style="color:#f92672">.</span>d2(x)

<span style="color:#75715e">#Create model instance</span>
model <span style="color:#f92672">=</span> Net()
</code></pre></div><ul>
<li>Layer definition used in <code>__init__</code></li>
<li><code>Conv2D()</code> is Conv2D (number of filters, kernel size, activation function)</li>
<li><code>Flatten()</code> converts the feature map into one dimension. Example 28x28 -&gt; 784</li>
<li><code>Dense()</code> is a fully connected layer. Specify the number of dimensions in the output space</li>
<li>Write layers in order of data flow with <code>def call(self, x):</code></li>
<li>In PyTorch, when passing data to Conv, it is necessary to pass the number of filters for input and output, but TF2 does not have that.</li>
<li>Of course, you can initialize kernel and bias, so please refer to <a href="https://keras.io/ja/">Keras Documentation</a>.</li>
</ul>
<h1 id="5-model-building-and-learning-with-tf2-expert-version">5. Model building and learning with TF2 (Expert Version)</h1>
<p>For model building, refer to 4. Building your own model.</p>
<p>##Loss, optimizer, metrics settings</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-.py" data-lang=".py">
<span style="color:#75715e">#Define loss function</span>
loss_object <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>losses<span style="color:#f92672">.</span>SparseCategoricalCrossentropy()
<span style="color:#75715e"># optimizer settings</span>
optimizer <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>optimizers<span style="color:#f92672">.</span>Adam()

<span style="color:#75715e">### Used to calculate loss and accracy</span>
train_loss <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>metrics<span style="color:#f92672">.</span>Mean(name<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;train_loss&#39;</span>)
train_accuracy <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>metrics<span style="color:#f92672">.</span>SparseCategoricalAccuracy(name<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;train_accuracy&#39;</span>)

test_loss <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>metrics<span style="color:#f92672">.</span>Mean(name<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;test_loss&#39;</span>)
test_accuracy <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>metrics<span style="color:#f92672">.</span>SparseCategoricalAccuracy(name<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;test_accuracy&#39;</span>)

</code></pre></div><h3 id="implementation-of-learning-part-from-tensorflow-tutorial">Implementation of learning part (from TensorFlow tutorial)</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-.py" data-lang=".py"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">train_step</span>(images, labels):
    <span style="color:#66d9ef">with</span> tf<span style="color:#f92672">.</span>GradientTape() <span style="color:#66d9ef">as</span> tape: <span style="color:#75715e"># Keep the history for the calculation</span>
        predictions <span style="color:#f92672">=</span> model(images) <span style="color:#75715e"># put images in model to get predictions</span>
        loss <span style="color:#f92672">=</span> loss_object(labels, predictions) <span style="color:#75715e"># Calculate loss from correct labels and predictions</span>
  gradients <span style="color:#f92672">=</span> tape<span style="color:#f92672">.</span>gradient(loss, model<span style="color:#f92672">.</span>trainable_variables) Differentiate the <span style="color:#75715e">#loss function with a learnable parameter</span>
  optimizer<span style="color:#f92672">.</span>apply_gradients(zip(gradients, model<span style="color:#f92672">.</span>trainable_variables)) <span style="color:#75715e"># Update using gradient information</span>

  train_loss(loss)
  train_accuracy(labels, predictions)
</code></pre></div><h4 id="about-tfgradienttape">About tf.GradientTape()</h4>
<ul>
<li>Differentiation is absolutely necessary for machine learning</li>
<li>Use <code>tf.GradientTape</code> where you want to keep the calculation history</li>
<li>In other words, <code>tf.GradientTape</code> is a class for finding the gradient</li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-.py" data-lang=".py"><span style="color:#f92672">import</span> tensorflow <span style="color:#f92672">as</span> tf

x <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>constant(<span style="color:#ae81ff">3.0</span>)
<span style="color:#66d9ef">with</span> tf<span style="color:#f92672">.</span>GradientTape() <span style="color:#66d9ef">as</span> tape:
    tape<span style="color:#f92672">.</span>watch(x)
    y <span style="color:#f92672">=</span> <span style="color:#ae81ff">3</span>x<span style="color:#f92672">+</span><span style="color:#ae81ff">2</span>
gradient <span style="color:#f92672">=</span> tape<span style="color:#f92672">.</span>gradient(y,x)
<span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#39;y = {y}&#39;</span>)
<span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#39;x = {x}&#39;</span>)
<span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#39;grad = {gradient}&#39;</span>)
</code></pre></div><p>Output</p>
<pre><code>y = 11.0
x = 3.0
grad = 3.0
</code></pre><p>Finally, I posted the code for my train and val.
It is full of Tsukkomi places, but please refer to it.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-.py" data-lang=".py">
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">train</span>(model, train_dataset, loss_object, optimizer, train_loss, train_acc, CONFIG, train_count):
    cnt <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
    max_value <span style="color:#f92672">=</span> train_count <span style="color:#f92672">+</span> CONFIG<span style="color:#f92672">.</span>batch_size
    <span style="color:#66d9ef">with</span> progressbar<span style="color:#f92672">.</span>ProgressBar(max_value<span style="color:#f92672">=</span>max_value) <span style="color:#66d9ef">as</span> bar:
        <span style="color:#66d9ef">for</span> imgs, labels <span style="color:#f92672">in</span> train_dataset:
            
            <span style="color:#66d9ef">with</span> tf<span style="color:#f92672">.</span>GradientTape() <span style="color:#66d9ef">as</span> tape:
                preds <span style="color:#f92672">=</span> model(imgs, training<span style="color:#f92672">=</span>True)
                loss <span style="color:#f92672">=</span> loss_object(labels, preds)
            gradients <span style="color:#f92672">=</span> tape<span style="color:#f92672">.</span>gradient(loss, model<span style="color:#f92672">.</span>trainable_variables)
            optimizer<span style="color:#f92672">.</span>apply_gradients(zip(gradients, model<span style="color:#f92672">.</span>trainable_variables))

            train_loss<span style="color:#f92672">.</span>update_state(values<span style="color:#f92672">=</span>loss)
            train_acc<span style="color:#f92672">.</span>update_state(labels, preds)
            cnt <span style="color:#f92672">=</span> cnt <span style="color:#f92672">+</span> CONFIG<span style="color:#f92672">.</span>batch_size
            bar<span style="color:#f92672">.</span>update(cnt)

    loss_t <span style="color:#f92672">=</span> train_loss<span style="color:#f92672">.</span>result()<span style="color:#f92672">.</span>numpy()
    acc_t <span style="color:#f92672">=</span> train_acc<span style="color:#f92672">.</span>result()<span style="color:#f92672">.</span>numpy()

    train_loss<span style="color:#f92672">.</span>reset_states()
    train_acc<span style="color:#f92672">.</span>reset_states()

    <span style="color:#66d9ef">return</span> loss_t, acc_t




<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">val</span>(model, val_dataset, loss_object,optimizer, val_loss, val_acc,CONFIG, val_count):

    cnt <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
    max_value <span style="color:#f92672">=</span> val_count <span style="color:#f92672">+</span> CONFIG<span style="color:#f92672">.</span>batch_size
    <span style="color:#66d9ef">with</span> progressbar<span style="color:#f92672">.</span>ProgressBar(max_value<span style="color:#f92672">=</span>max_value) <span style="color:#66d9ef">as</span> bar:
        <span style="color:#66d9ef">for</span> imgs, labels <span style="color:#f92672">in</span> val_dataset:
      
            preds <span style="color:#f92672">=</span> model(imgs, training<span style="color:#f92672">=</span>False)
            loss <span style="color:#f92672">=</span> loss_object(labels, preds)

            val_loss<span style="color:#f92672">.</span>update_state(values<span style="color:#f92672">=</span>loss)
            val_acc<span style="color:#f92672">.</span>update_state(labels, preds)
            cnt <span style="color:#f92672">=</span> cnt <span style="color:#f92672">+</span> CONFIG<span style="color:#f92672">.</span>batch_size
            bar<span style="color:#f92672">.</span>update(cnt)

    loss_v <span style="color:#f92672">=</span> val_loss<span style="color:#f92672">.</span>result()<span style="color:#f92672">.</span>numpy()
    acc_v <span style="color:#f92672">=</span> val_acc<span style="color:#f92672">.</span>result()<span style="color:#f92672">.</span>numpy()

    val_loss<span style="color:#f92672">.</span>reset_states()
    val_acc<span style="color:#f92672">.</span>reset_states()<span style="color:#66d9ef">return</span> loss_v, acc_v

</code></pre></div><ul>
<li><code>tqdm</code> doesn&rsquo;t work well in my environment and I am using <code>progressbar</code></li>
<li>acc and loss are updated with <code>.update_state()</code></li>
<li>acc and loss metrics need to be reset every epoch, so reset them with <code>.reset_states()</code></li>
<li>You can specify <code>training</code> like <code>model(imgs, training=False)</code>, but it applies <code>Dropout</code> at the time of learning but does not apply <code>Dropout</code> at the time of testing. I am</li>
</ul>
<p>#Other useful things to know</p>
<h1 id="1-when-using-your-own-dataset">[1]. When using your own dataset</h1>
<p>When learning with your own data set, I think there are roughly two.</p>
<ul>
<li>(1) Specify the folder and load the image</li>
<li>(2) Read from image path</li>
</ul>
<h3 id="1-specify-the-folder-and-load-the-image">(1) Specify the folder and load the image</h3>
<ul>
<li>use <code>flow_from_directory()</code></li>
<li>Need to set target_size, batch_size, class_mode, etc.</li>
<li>Used in combination with Augmentation</li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-.py" data-lang=".py">train_aug <span style="color:#f92672">=</span> ImageDataGenerator(
        rescale<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1.</span><span style="color:#f92672">/</span><span style="color:#ae81ff">255</span>),
        horizontal_flip<span style="color:#f92672">=</span>True,
        vertical_flip<span style="color:#f92672">=</span>True,
        width_shift_range<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>,
        height_shift_range<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>,
        shear_range<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>,
        zoom_range<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>,
        rotation_range<span style="color:#f92672">=</span><span style="color:#ae81ff">30</span>,
        )

test_aug <span style="color:#f92672">=</span> ImageDataGenerator(
        rescale<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1.</span><span style="color:#f92672">/</span><span style="color:#ae81ff">255</span>),
        )

train_generator <span style="color:#f92672">=</span> train_aug<span style="color:#f92672">.</span>flow_from_directory(
        <span style="color:#e6db74">&#39;data/train&#39;</span>,
        target_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">224</span>,<span style="color:#ae81ff">224</span>),
        batch_size<span style="color:#f92672">=</span>batch_size,
        class_mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;categorical&#39;</span>
        )

test_generator <span style="color:#f92672">=</span> test_aug<span style="color:#f92672">.</span>flow_from_directory(
        <span style="color:#e6db74">&#39;data/val&#39;</span>,
        target_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">224</span>,<span style="color:#ae81ff">224</span>),
        batch_size<span style="color:#f92672">=</span>batch_size,
        class_mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;categorical&#39;</span>
        )

</code></pre></div><h3 id="2-read-from-image-path">(2) Read from image path</h3>
<p>If you write out the image path and label to csv and put it in and read it, I think this is the most common method. I think any library can be used to load images. Below, I&rsquo;ll write the image file path and create a dataset from it.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-.py" data-lang=".py">

<span style="color:#f92672">import</span> os
<span style="color:#f92672">import</span> pathlib
<span style="color:#f92672">import</span> tensorflow <span style="color:#f92672">as</span> tf


<span style="color:#75715e"># Path specification of data</span>
data_root_dir <span style="color:#f92672">=</span><span style="color:#e6db74">&#39;data/train&#39;</span>

data_root <span style="color:#f92672">=</span> pathlib<span style="color:#f92672">.</span>Path(data_root_dir)
<span style="color:#75715e"># Get image path</span>
all_image_paths <span style="color:#f92672">=</span> [str(path) <span style="color:#66d9ef">for</span> path <span style="color:#f92672">in</span> list(data_root<span style="color:#f92672">.</span>glob(<span style="color:#e6db74">&#39;*/*&#39;</span>))]
<span style="color:#75715e"># Sort</span>
all_image_paths <span style="color:#f92672">=</span> sorted(all_image_paths)

<span style="color:#75715e"># Confirmation</span>
<span style="color:#66d9ef">print</span>(all_image_paths)
<span style="color:#66d9ef">print</span>(len(all_image_paths))



<span style="color:#75715e"># Get label: Get from directory name</span>
label_names <span style="color:#f92672">=</span> sorted(item<span style="color:#f92672">.</span>name <span style="color:#66d9ef">for</span> item <span style="color:#f92672">in</span> data_root<span style="color:#f92672">.</span>glob(<span style="color:#e6db74">&#39;*/&#39;</span>))
<span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#39; label: {label_names}&#39;</span>)

<span style="color:#75715e"># Create a label dictionary dict {label:index}</span>
 
label_to_index <span style="color:#f92672">=</span> dict((label, index) <span style="color:#66d9ef">for</span> index, label <span style="color:#f92672">in</span> enumerate(label_names))
<span style="color:#66d9ef">print</span>(label_to_index)


<span style="color:#75715e"># Get label for all images</span>
all_image_labels <span style="color:#f92672">=</span> [label_to_index[pathlib<span style="color:#f92672">.</span>Path(image_path)<span style="color:#f92672">.</span>parent<span style="color:#f92672">.</span>name] <span style="color:#66d9ef">for</span> image_path <span style="color:#f92672">in</span> all_image_paths]
<span style="color:#66d9ef">print</span>(all_image_labels)
  

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">load_data</span>(all_image_paths, all_image_labels):
    img_list <span style="color:#f92672">=</span> []
    <span style="color:#66d9ef">for</span> filename <span style="color:#f92672">in</span> all_image_paths:
         <span style="color:#75715e"># Load image</span>
         img <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>io<span style="color:#f92672">.</span>read_file(filename)
         <span style="color:#75715e">#Decode</span>
         img <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>io<span style="color:#f92672">.</span>decode_image(img,channels <span style="color:#f92672">=</span> <span style="color:#ae81ff">3</span>)
         <span style="color:#75715e">#Resize, error when creating dataset if not resized</span>
         img <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>image<span style="color:#f92672">.</span>resize(img, [<span style="color:#ae81ff">224</span>,<span style="color:#ae81ff">224</span>])
         img_list<span style="color:#f92672">.</span>append(img)
     images <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>stack(img_list, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)
     labels <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>stack(all_image_labels, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)
     <span style="color:#66d9ef">return</span> tf<span style="color:#f92672">.</span>cast(images, tf<span style="color:#f92672">.</span>float32), tf<span style="color:#f92672">.</span>cast(labels, tf<span style="color:#f92672">.</span>int32)

<span style="color:#75715e"># Get image and label</span>
imgs, labels <span style="color:#f92672">=</span> load_data(all_image_paths, all_image_labels)


<span style="color:#75715e"># Shuffle data and create batch</span>
dataset <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>Dataset<span style="color:#f92672">.</span>from_tensor_slices((img_list, label_list))<span style="color:#f92672">.</span>shuffle(len(all_image_labels))<span style="color:#f92672">.</span>batch(<span style="color:#ae81ff">8</span>)
<span style="color:#75715e"># Confirmation</span>
<span style="color:#66d9ef">for</span> data1, data2 <span style="color:#f92672">in</span> dataset<span style="color:#f92672">.</span>take(<span style="color:#ae81ff">10</span>):
     <span style="color:#66d9ef">print</span>(data1, data2)
</code></pre></div><ul>
<li><strong>pathlib</strong> It&rsquo;s convenient, so I want you to use it.</li>
<li>When creating a dataset, you can create it with <code>tf.data.Dataset.from_tensor_slices()</code></li>
<li>If you want to shuffle the dataset, use <code>shuffle()</code></li>
<li>Use <code>batch()</code> when you want to group by batch</li>
<li>Be careful because the behavior changes if you reverse the order of <code>shuffle</code> and <code>batch</code></li>
</ul>
<p>#[2]. Augmentaion</p>
<ul>
<li>There is something that can be used for Augmentaion in tf.image so please check on the official website</li>
<li>The following code is a simple example. Please use it as a function.</li>
<li>If you feel the writing style,</li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-.py" data-lang=".py">
 image <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>io<span style="color:#f92672">.</span>decode_image(contents<span style="color:#f92672">=</span>image,
                            channels<span style="color:#f92672">=</span>CONFIG<span style="color:#f92672">.</span>channels,
                            dtype<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>dtypes<span style="color:#f92672">.</span>float32)

<span style="color:#75715e"># Normalization</span>
 image <span style="color:#f92672">=</span> (image <span style="color:#f92672">/</span> <span style="color:#ae81ff">0.5</span>) <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>

<span style="color:#75715e"># data_aug = True</span>
 <span style="color:#66d9ef">if</span> data_aug:
     image <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>image<span style="color:#f92672">.</span>random_flip_left_right(image<span style="color:#f92672">=</span>image)
     image <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>image<span style="color:#f92672">.</span>resize_with_crop_or_pad(image<span style="color:#f92672">=</span>image,
                                           target_height<span style="color:#f92672">=</span>int(CONFIG<span style="color:#f92672">.</span>img_height<span style="color:#f92672">*</span><span style="color:#ae81ff">1.2</span>),
                                           target_width<span style="color:#f92672">=</span>int(CONFIG<span style="color:#f92672">.</span>img_width<span style="color:#f92672">*</span><span style="color:#ae81ff">1.2</span>))
     image <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>image<span style="color:#f92672">.</span>random_crop(value<span style="color:#f92672">=</span>image, size<span style="color:#f92672">=</span>[CONFIG<span style="color:#f92672">.</span>img_height,CONFIG<span style="color:#f92672">.</span>img_width, CONFIG<span style="color:#f92672">.</span>channels])

<span style="color:#66d9ef">else</span>:
     image <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>image<span style="color:#f92672">.</span>resize(image_tensor, [CONFIG<span style="color:#f92672">.</span>img_height, CONFIG<span style="color:#f92672">.</span>img_width])


</code></pre></div><ul>
<li>For Augmentation, <a href="https://github.com/albumentations-team/albumentations">albumentaions</a> is recommended</li>
<li>There is a habit of writing a little, but it&rsquo;s very convenient. (Cutout etc. are also included as standard)</li>
</ul>
<h1 id="3-tensorboard">[3]. TensorBoard</h1>
<ul>
<li>By using TensorBoard, you can easily check the transition of train acuuracy and loss</li>
<li>Check usage using a simple example</li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-.py" data-lang=".py"><span style="color:#f92672">import</span> tensorflow <span style="color:#f92672">as</span> tf
   
<span style="color:#75715e">#Specify the location of log output</span>

     
writer <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>summary<span style="color:#f92672">.</span>create_file_writer(<span style="color:#e6db74">&#39;tmp/mylogs&#39;</span>)
   
<span style="color:#66d9ef">with</span> writer<span style="color:#f92672">.</span>as_default():
    <span style="color:#66d9ef">for</span> step <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">100</span>):
        tf<span style="color:#f92672">.</span>summary<span style="color:#f92672">.</span>scalar(<span style="color:#e6db74">&#34;acc/train&#34;</span>, <span style="color:#ae81ff">0.7</span>, step<span style="color:#f92672">=</span>step)
        tf<span style="color:#f92672">.</span>summary<span style="color:#f92672">.</span>scalar(<span style="color:#e6db74">&#34;acc/val&#34;</span>, <span style="color:#ae81ff">0.5</span>, step<span style="color:#f92672">=</span>step)
        tf<span style="color:#f92672">.</span>summary<span style="color:#f92672">.</span>scalar(<span style="color:#e6db74">&#34;loss/train&#34;</span>, <span style="color:#ae81ff">0.7</span>, step<span style="color:#f92672">=</span>step)
        tf<span style="color:#f92672">.</span>summary<span style="color:#f92672">.</span>scalar(<span style="color:#e6db74">&#34;loss/val&#34;</span>, <span style="color:#ae81ff">0.5</span>, step<span style="color:#f92672">=</span>step)
        writer<span style="color:#f92672">.</span>flush()
</code></pre></div><ul>
<li>Write like <code>tf.summary.scalar(tag, value, step)</code></li>
<li>In this example, it is specified with a constant such as 0.5 or 0.7, but you can pass the actual loss or acc</li>
<li>Besides values, you can also create images, so please try various things.</li>
</ul>
<p>When checking, specify the dir of the log that has been emitted as follows and try accessing <code>http://localhost:6006/</code>.</p>
<pre><code>$ tensorboard --logdir='./tmp/mylogs'
Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_allTensorBoard 2.1.1 at http://localhost:6006/ (Press CTRL+C to quit)
</code></pre><ul>
<li>It is also one way to write the log as csv and display it later in matplot etc., but you can not check it until all learning is completed. TensorBoard is useful because you can see it in real time as the value is updated</li>
</ul>
<h1 id="4-tfrecord">[4]. TFRecord</h1>
<ul>
<li>TFRecord is a binary format of data in TensorFlow recommended format</li>
<li>Large amounts of data can be serialized and stored in a continuously readable format</li>
<li>Read a large amount of data sequentially and put it in the learning device</li>
<li>TFRecord saves each line information in a unit called Example</li>
<li>I think that it is like a map with type information</li>
<li>The following is an example of saving images and labels with TFRecoed</li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-.py" data-lang=".py">

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">_bytes_feature</span>(value):
    <span style="color:#66d9ef">if</span> isinstance(value, type(tf<span style="color:#f92672">.</span>constant(<span style="color:#ae81ff">0.</span>))):
        value <span style="color:#f92672">=</span> value<span style="color:#f92672">.</span>numpy()
    <span style="color:#66d9ef">return</span> tf<span style="color:#f92672">.</span>train<span style="color:#f92672">.</span>Feature(bytes_list<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>train<span style="color:#f92672">.</span>BytesList(value<span style="color:#f92672">=</span>[value]))

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">_float_feature</span>(value):
    <span style="color:#66d9ef">return</span> tf<span style="color:#f92672">.</span>train<span style="color:#f92672">.</span>Feature(float_list<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>train<span style="color:#f92672">.</span>FloatList(value<span style="color:#f92672">=</span>[value]))

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">_int64_feature</span>(value):
    <span style="color:#66d9ef">return</span> tf<span style="color:#f92672">.</span>train<span style="color:#f92672">.</span>Feature(int64_list<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>train<span style="color:#f92672">.</span>Int64List(value<span style="color:#f92672">=</span>[value]))


<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">get_info</span>(data_root_dir):

    data_root <span style="color:#f92672">=</span> pathlib<span style="color:#f92672">.</span>Path(data_root_dir)
    all_image_paths <span style="color:#f92672">=</span> [str(path) <span style="color:#66d9ef">for</span> path <span style="color:#f92672">in</span> list(data_root<span style="color:#f92672">.</span>glob(<span style="color:#e6db74">&#39;*/*&#39;</span>))]
    <span style="color:#75715e"># Get label</span>
    label_names <span style="color:#f92672">=</span> sorted(item<span style="color:#f92672">.</span>name <span style="color:#66d9ef">for</span> item <span style="color:#f92672">in</span> data_root<span style="color:#f92672">.</span>glob(<span style="color:#e6db74">&#39;*/&#39;</span>))
    <span style="color:#75715e"># dict {label:index}</span>
    label_to_index <span style="color:#f92672">=</span> dict((label, index) <span style="color:#66d9ef">for</span> index, label <span style="color:#f92672">in</span> enumerate(label_names))
    <span style="color:#66d9ef">print</span>(label_to_index)
    <span style="color:#75715e"># Get all images label</span>
    all_image_labels <span style="color:#f92672">=</span> [label_to_index[pathlib<span style="color:#f92672">.</span>Path(image_path)<span style="color:#f92672">.</span>parent<span style="color:#f92672">.</span>name] <span style="color:#66d9ef">for</span> image_path <span style="color:#f92672">in</span> all_image_paths]

    <span style="color:#66d9ef">return</span> all_image_paths, all_image_labels


<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">dataset_to_tfrecord</span>(dataset_dir, tfrecord_name):

    <span style="color:#75715e"># Get images and labels in each directory</span>
    image_paths, image_labels <span style="color:#f92672">=</span> get_info(dataset_dir)
    image_paths_and_labels_dict <span style="color:#f92672">=</span> {}
    <span style="color:#75715e"># Convert to dictionary</span>
    <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(len(image_paths)):
        image_paths_and_labels_dict[image_paths[i]] <span style="color:#f92672">=</span> image_labels[i]

    <span style="color:#66d9ef">with</span> tf<span style="color:#f92672">.</span>io<span style="color:#f92672">.</span>TFRecordWriter(path<span style="color:#f92672">=</span>tfrecord_name) <span style="color:#66d9ef">as</span> writer:
        <span style="color:#66d9ef">for</span> image_path, label <span style="color:#f92672">in</span> image_paths_and_labels_dict<span style="color:#f92672">.</span>items():
            image_string <span style="color:#f92672">=</span> open(image_path,<span style="color:#e6db74">&#39;rb&#39;</span>)<span style="color:#f92672">.</span>read()
            feature <span style="color:#f92672">=</span> {
              <span style="color:#e6db74">&#39;label&#39;</span>: _int64_feature(label),
              <span style="color:#e6db74">&#39;image&#39;</span>: _bytes_feature(image_string)
            }
            tf_example <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>train<span style="color:#f92672">.</span>Example(features<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>train<span style="color:#f92672">.</span>Features(feature<span style="color:#f92672">=</span>feature))
            writer<span style="color:#f92672">.</span>write(tf_example<span style="color:#f92672">.</span>SerializeToString())


</code></pre></div><p>For more information, see <a href="https://www.tensorflow.org/tutorials/load_data/tfrecord">TensorFLow TFRecord and tf.Example</a>.</p>
<h1 id="at-the-end">At the end</h1>
<p>We have seen how to classify images in TensorFLow. In TF1, <code>Session</code> and <code>placeholder</code> have disappeared, <code>Eager Mode</code> has been defaulted, and keras is a high-level API of TensorFLow standard. It was It takes a while to get used to, but once I got used to it, TensorFLow was easy to write. In the future, I would like to be able to use both Pytorch and TensorFlow. There are many useful libraries such as <strong>pathlib</strong> and <strong>albumentaions</strong> that I introduced in the middle of the article, so I would like people who do not use it to use it.</p>
<h1 id="references">References</h1>
<ul>
<li><a href="https://keras.io/ja/">Keras Documentation</a></li>
<li><a href="https://www.tensorflow.org/versions/r2.0/api_docs/python/tf">TensorFlow</a></li>
</ul>

    </article>
  </div>

  
  
  
  <script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-169005401-1', 'auto');
  ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  

  
<link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.css" />
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#216942",
      "text": "#b2d192"
    },
    "button": {
      "background": "#afed71"
    }
  }
})});
</script>

</body>

</html>
