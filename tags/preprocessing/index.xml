<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title> preprocessing on Memo Tut</title>
    <link>https://memotut.com/tags/preprocessing/</link>
    <description>Recent content in  preprocessing on Memo Tut</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 26 May 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://memotut.com/tags/preprocessing/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Application of affine transformation by tensor-From basics to object detection-</title>
      <link>https://memotut.com/application-of-affine-transformation-by-tensor-from-basics-to-object-detection-11cbd/</link>
      <pubDate>Tue, 26 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/application-of-affine-transformation-by-tensor-from-basics-to-object-detection-11cbd/</guid>
      <description>This article is about simplifying preprocessing by using affine transformation with tensors. The affine transformation can be applied to images, but the same transformation can be applied to annotations such as Bounding Box. You can also apply different transformations to one object at the same time by extending it to a tensor.  Affine transformation basics The affine transformation represents the movement of points in the following formula.
$$\begin{bmatrix}x&amp;rsquo; \\ y&amp;rsquo;\\ 1 \end{bmatrix} = \begin{bmatrix}a &amp;amp; b &amp;amp; c \\ d &amp;amp; e &amp;amp; f \\ 0 &amp;amp; 0 &amp;amp; 1 \end{bmatrix} \begin{bmatrix}x \\ y \\ 1 \end{bmatrix} \tag{1}$$</description>
    </item>
    
    <item>
      <title>Extract only Python for preprocessing</title>
      <link>https://memotut.com/extract-only-python-for-preprocessing-dad2f/</link>
      <pubDate>Sat, 09 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/extract-only-python-for-preprocessing-dad2f/</guid>
      <description>I&#39;ve been wandering around the code on the author&#39;s github each time, so I&#39;ll put it together for immediate use.  Original story Pre-processing Daizen [SQL/R/Python practice technique for data analysis]
https://github.com/ghmagazine/awesomebook
Extract the Python part from github below. See the book for detailed explanation.
Also, these source codes are licensed under the BSD 3 terms.
 BSD 3-Clause License
Copyright (c) 2018, Tomomitsu Motohashi All rights reserved.
 Data read # Read from library from preprocess.</description>
    </item>
    
    <item>
      <title>Performance verification of data preprocessing for machine learning (numerical data edition) (1)</title>
      <link>https://memotut.com/performance-verification-of-data-preprocessing-for-machine-learning-numerical-data-edition-1-cf176/</link>
      <pubDate>Tue, 10 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/performance-verification-of-data-preprocessing-for-machine-learning-numerical-data-edition-1-cf176/</guid>
      <description>First Edition: March 10, 2020 &amp;lt;br&amp;gt;  Author: Soichi Takashige, Masahiro Ito, Hitachi, Ltd.
#Introduction In this post, I will introduce the design know-how of data preprocessing and the results of performance verification of data preprocessing when designing a system incorporating a machine learning model.
The second article introduces know-how for performance improvement and verification results in data preprocessing using Python.
Post list:
 Data preprocessing for systems that use machine learning Performance Verification of Data Preprocessing for Machine Learning (Numerical Data) (Part 1) (Posted) Performance Verification of Data Preprocessing for Machine Learning (Numerical Data) (Part 2)  #About the benchmark (BigBench) referenced in the performance verification Before introducing design know-how and performance verification results, we will introduce the benchmarks that were referenced as references in verification.</description>
    </item>
    
    <item>
      <title>Data preprocessing for systems using machine learning</title>
      <link>https://memotut.com/data-preprocessing-for-systems-using-machine-learning-48825/</link>
      <pubDate>Tue, 03 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/data-preprocessing-for-systems-using-machine-learning-48825/</guid>
      <description>First Edition: March 3, 2020 &amp;lt;br&amp;gt;  Author: Soichi Takashige, Masahiro Ito, Hitachi, Ltd.
#Introduction In this post, I will introduce the design know-how of data preprocessing and the performance verification results of numerical data preprocessing when designing a system incorporating a machine learning model.
The first article introduces the data preprocessing of machine learning system and its design.
Post list:
 Data preprocessing for systems that use machine learning (this post) Performance verification of data preprocessing for machine learning (numerical data) (1) Performance Verification of Data Preprocessing for Machine Learning (Numerical Data) (Part 2)  #Outline and flow of AI projects Data analysis utilizing AI technology such as machine learning is drawing attention, and the number of projects utilizing AI is increasing.</description>
    </item>
    
    <item>
      <title>Memory-saving conversion of log data into sequential category features considering time series</title>
      <link>https://memotut.com/memory-saving-conversion-of-log-data-into-sequential-category-features-considering-time-series-91c39/</link>
      <pubDate>Mon, 02 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/memory-saving-conversion-of-log-data-into-sequential-category-features-considering-time-series-91c39/</guid>
      <description>#Introduction  Hi, I&amp;rsquo;m a machine learning engineer. I&amp;rsquo;m Kawamoto. I had a cold because it was too cold. Today, I will write about how to perform preprocessing while suppressing memory consumption for log data that needs to consider time series information.
Thing you want to do Assuming there is a data set containing behavior logs for each user like this,
 userid itemid categoryid timestamp 0 0 3 1 2019-01-04 1 0 4 1 2019-01-08 2 0 4 1 2019-01-19 3 0 5 1 2019-01-02 4 0 7 2 2019-01-17 5 0 8 2 2019-01-07 6 1 0 0 2019-01-06 7 1 1 0 2019-01-14 8 1 2 0 2019-01-20 9 1 6 2 2019-01-01 10 1 7 2 2019-01-12 11 1 8 2 2019-01-18 12 2 3 1 2019-01-16 13 2 4 1 2019-01-15 14 2 5 1 2019-01-10 15 2 5 1 2019-01-13 16 2 6 2 2019-01-03 17 2 7 2 2019-01-05 18 2 8 2 2019-01-11 19 2 8 2 2019-01-21 20 2 9 3 2019-01-09 Variable length series data sorted by time for each user as follows,</description>
    </item>
    
  </channel>
</rss>