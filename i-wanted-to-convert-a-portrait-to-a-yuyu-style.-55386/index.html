<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  <meta name="generator" content="Hugo 0.72.0" />

  
  <meta name="description" content="Some description">
  

  
  <link rel="apple-touch-icon" sizes="180x180" href="https://memotut.com/apple-touch-icon.png">

  
  <link rel="icon" type="image/png" sizes="32x32" href="https://memotut.com/favicon-32x32.png">

  
  <link rel="icon" type="image/png" sizes="16x16" href="https://memotut.com/favicon-16x16.png">

  
  <link rel="manifest" href="https://memotut.com/site.webmanifest">

  
  <link rel="mask-icon" href="https://memotut.com/safari-pinned-tab.svg" color="#5bbad5">

  <meta name="msapplication-TileColor" content="#da532c">

  <meta name="theme-color" content="#ffffff">

  
  <link rel="stylesheet" href="https://memotut.com/css/bootstrap.min.css" />

  
  <title>I wanted to convert a portrait to a Yuyu style. | Memo Tut</title>
  

  <style>
body {
  min-width: 300px;
}

.custom-navbar {
  margin-bottom: 1em;
  height: 60px;
}

.custom-navbar a {
  display: inline-block; 
  padding: 18px 0;
  margin-right: 1em; 
  font-weight: bold; 
}

.custom-navbar a:hover,
.custom-navbar a:focus {
  text-decoration: none; 
}

@media print {
  .custom-navbar {
    display: none;
  }
}

article {
  padding-bottom: 1em;
}

img {
  max-width: 100%;
}


body {
  background-color: #fff;
}



body {
  color: #212529;
}



a {
  color: #007bff;
}



a:hover,
a:focus {
  color: #0056b3;
}



.custom-navbar {
  background-color: #212529;
}



.custom-navbar a {
  color: rgba(255, 255, 255, 0.75);
}



.custom-navbar a:hover,
.custom-navbar a:focus {
  color: rgba(255, 255, 255, 1);
}



.container {
  max-width: 800px;
}



pre {
  display: block;
  padding: 9.5px;
  word-break: break-all;
  word-wrap: break-word;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre code {
  padding: 0;
  font-size: inherit;
  color: inherit; 
  white-space: pre-wrap;
  background-color: transparent;
  border: none;
  border-radius: 0;
}

code {
  padding: 2px 4px;
  color: inherit; 
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
  font-size: .9em;
}



blockquote,
.blockquote {
  padding: 10px 20px;
  margin: 0 0 20px;
  font-size: 1em;
  border-left: 5px solid #6c757d;
}

</style>
</head>

<body>
  <nav class="custom-navbar">
  <div class="container">
    
    <a href="/">Posts</a>
    
    <a href="/tags/">Tags</a>
    
    <a href="/about/">About</a>
    
    <a href="/index.xml">RSS</a>
    
  </div>
</nav>
  
  <div class="container">
    <article>
      <h1>I wanted to convert a portrait to a Yuyu style.</h1>
<p>
  <small class="text-secondary">
  
  
  Dec 24, 2019
  </small>
  

<small><code><a href="https://memotut.com/tags/python">Python</a></code></small>


<small><code><a href="https://memotut.com/tags/deeplearning">DeepLearning</a></code></small>


<small><code><a href="https://memotut.com/tags/gans">GANs</a></code></small>


<small><code><a href="https://memotut.com/tags/ugatit">UGATIT</a></code></small>

</p>
<pre><code># 1.First of all
</code></pre>
<p>This article is the 24th day article of <a href="https://adventar.org/calendars/4096">Yuyuki AdventCalender 2019</a>.</p>
<h1 id="2-what-you-want-to-do">2. What you want to do</h1>
<ul>
<li><del>I want to go to the world of Yuyu</del>
→ <strong>I want to convert a facial photograph into a Yuyu style</strong></li>
</ul>
<p>Last year at Advent Calender, I tried automatic coloring of black and white cartoons with CycleGAN. (<a href="https://qiita.com/navist99/items/a08aaec58a1737cf60c1">Trying to colorize manga in CycleGAN ~Yuyu ceremony~</a>))
CycleGAN is good at style conversion such as changing colors and textures, but it is not good at shape conversion.</p>
<p>Therefore, this year, we will use GAN <a href="https://arxiv.org/abs/1907.10830">U-GAT-IT</a>, which is a GAN that realizes both style conversion and shape conversion, to create a yukata-style illustration from a facial photograph. Try to generate.</p>
<p>The image looks something like this ↓
<img width="873" alt="example.png" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/304057/376d9705-df28-71a7-3613-59a543788b80.png">
(Quoted from <a href="https://mantan-web.jp/photo/20150603dog00m200056000c.html?page=007">mantan-web</a>)</p>
<h1 id="3-u-gat-it">3. U-GAT-IT</h1>
<img width="885" alt="model.png" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/304057/0f3457dc-5b56-d313-3343-3ca1446041e0.png">
<p>U-GAT-IT can also perform shape conversion, which CycleGAN was not good at.</p>
<p>The following are the results published in the paper by the author.
The leftmost is the original photo, but you can see that the change accompanying the shape conversion of cat → dog etc. is well done.
<img width="559" alt="result.png" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/304057/47e10a01-1dcf-b639-e139-4c3bed9093da.png"></p>
<p>All figures are quoted from <a href="https://arxiv.org/abs/1907.10830">U-GAT-IT: Unsupervised Generative Attentional Networks with Adaptive Layer-Instance Normalization for Image-to-Image Translation</a></p>
<h1 id="4-yuyu-ceremony">4. Yuyu ceremony</h1>
<img width="350" alt="Screenshots 2019-12-23 23.08.48.png" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/304057/b1e0219c-ba39-f380-926f-ae44709a8558.png">
[Yuyu Shiki](https://www.yuyushiki.net) is a four-frame cartoon by Kogami Mikami, who is serialized in Manga Time Kirara.
<h1 id="5-learning">5. Learning</h1>
<p>Learning was done at Google Colaboratory.
You can learn from <a href="https://github.com/taki0112/UGATIT">this repository</a> by pasting it into the notebook cell in the order of util -&gt; ops -&gt; UGATIT -&gt; main.</p>
<p>However, parser will give an error when running in Notebook, so change it as follows.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Comment out the following</span>
<span style="color:#75715e">#parser = argparse.ArgumentParser(description=desc)</span>
<span style="color:#75715e"># Omitted</span>
<span style="color:#75715e">#parser.add_argument(...)</span>

<span style="color:#75715e"># Add below</span>
<span style="color:#960050;background-color:#1e0010">!</span>pip install easydict
<span style="color:#f92672">import</span> easydict
args <span style="color:#f92672">=</span> easydict<span style="color:#f92672">.</span>EasyDict({
       <span style="color:#e6db74">&#39;phase&#39;</span>:<span style="color:#e6db74">&#39;train&#39;</span>,
       <span style="color:#e6db74">&#39;light&#39;</span>: False,
       <span style="color:#e6db74">&#39;dataset&#39;</span>:<span style="color:#e6db74">&#39;yuyu&#39;</span>,
       <span style="color:#75715e">### below</span>
})
</code></pre></div><p>Place the dataset directly below the current directory as shown below.</p>
<pre><code>└─ dataset
    └─ yuyu
        ├─ trainA # Photo of a woman for learning (diverted from selfie2anime)
        ├─ trainB # Yuyu-style characters for learning
        ├─ testA # For test (ry
        └─ testB # for test (ry
</code></pre><p>Now, when you have prepared this far, we will start learning!</p>
<p>This model is very large, and even with a dataset with only about 100 images, we often get errors that it does not fit in memory. ..
In that case, if you set the&rsquo;light&rsquo; of args to True, you will learn in the light version. (There is a tradeoff with accuracy, but)
This time, I learned about 100 iteration 1500epoch, a little over-learning.</p>
<p><strong>○Result</strong>
Original photo/conversion result photo.
<img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/304057/0753ce1a-0429-6c60-f24c-229562567b9c.png" alt="female12.png">![female12.png]](<a href="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/304057/8e9e23e3-9f42-e9c0-0bcc-5b4be2b713f9.png">https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/304057/8e9e23e3-9f42-e9c0-0bcc-5b4be2b713f9.png</a>)
<img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/304057/cbb190f1-cbba-29fa-2e0b-f94c2cdc7433.png" alt="female77.png">![female77.png]](<a href="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/304057/5dedbd54-c092-bfed-af94-39e08a48f3e1.png">https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/304057/5dedbd54-c092-bfed-af94-39e08a48f3e1.png</a>)
<img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/304057/d30c8ca5-3610-e836-89f3-01d40def6611.png" alt="female66.png"><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/304057/dd3c5b15-1129-b9a7-66de-b0d76eeceb7e.png" alt="female66.png"></p>
<p>It&rsquo;s a Yuyu-style touch, but it&rsquo;s subtle&hellip;</p>
<h1 id="6-at-the-end">6. At the end</h1>
<p>This time, I couldn&rsquo;t get the desired results.
I&rsquo;m sorry I didn&rsquo;t bring out the performance of the model.</p>
<p>I think the main reason is that the training dataset is too small. I feel the limits of my resources. ..
(I want someone to make a Yuyu-style dataset)
<br>
Tomorrow is the last day.
Have a nice Christmas everyone!</p>

    </article>
  </div>

  
  
  
  <script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-169005401-1', 'auto');
  ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  

  
<link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.css" />
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#216942",
      "text": "#b2d192"
    },
    "button": {
      "background": "#afed71"
    }
  }
})});
</script>

</body>

</html>
