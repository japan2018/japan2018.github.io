<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  <meta name="generator" content="Hugo 0.72.0" />

  
  <meta name="description" content="Some description">
  

  
  <link rel="apple-touch-icon" sizes="180x180" href="https://memotut.com/apple-touch-icon.png">

  
  <link rel="icon" type="image/png" sizes="32x32" href="https://memotut.com/favicon-32x32.png">

  
  <link rel="icon" type="image/png" sizes="16x16" href="https://memotut.com/favicon-16x16.png">

  
  <link rel="manifest" href="https://memotut.com/site.webmanifest">

  
  <link rel="mask-icon" href="https://memotut.com/safari-pinned-tab.svg" color="#5bbad5">

  <meta name="msapplication-TileColor" content="#da532c">

  <meta name="theme-color" content="#ffffff">

  
  <link rel="stylesheet" href="https://memotut.com/css/bootstrap.min.css" />

  
  <title>[Python] ``First time learning&#39;&#39; that even university students with no knowledge can do-AWS SageMaker | Memo Tut</title>
  

  <style>
body {
  min-width: 300px;
}

.custom-navbar {
  margin-bottom: 1em;
  height: 60px;
}

.custom-navbar a {
  display: inline-block; 
  padding: 18px 0;
  margin-right: 1em; 
  font-weight: bold; 
}

.custom-navbar a:hover,
.custom-navbar a:focus {
  text-decoration: none; 
}

@media print {
  .custom-navbar {
    display: none;
  }
}

article {
  padding-bottom: 1em;
}

img {
  max-width: 100%;
}


body {
  background-color: #fff;
}



body {
  color: #212529;
}



a {
  color: #007bff;
}



a:hover,
a:focus {
  color: #0056b3;
}



.custom-navbar {
  background-color: #212529;
}



.custom-navbar a {
  color: rgba(255, 255, 255, 0.75);
}



.custom-navbar a:hover,
.custom-navbar a:focus {
  color: rgba(255, 255, 255, 1);
}



.container {
  max-width: 800px;
}



pre {
  display: block;
  padding: 9.5px;
  word-break: break-all;
  word-wrap: break-word;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre code {
  padding: 0;
  font-size: inherit;
  color: inherit; 
  white-space: pre-wrap;
  background-color: transparent;
  border: none;
  border-radius: 0;
}

code {
  padding: 2px 4px;
  color: inherit; 
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
  font-size: .9em;
}



blockquote,
.blockquote {
  padding: 10px 20px;
  margin: 0 0 20px;
  font-size: 1em;
  border-left: 5px solid #6c757d;
}

</style>
</head>

<body>
  <nav class="custom-navbar">
  <div class="container">
    
    <a href="/">Posts</a>
    
    <a href="/tags/">Tags</a>
    
    <a href="/about/">About</a>
    
    <a href="/index.xml">RSS</a>
    
  </div>
</nav>
  
  <div class="container">
    <article>
      <h1>[Python] ``First time learning&rsquo;&rsquo; that even university students with no knowledge can do-AWS SageMaker</h1>
<p>
  <small class="text-secondary">
  
  
  Nov 20, 2019
  </small>
  

<small><code><a href="https://memotut.com/tags/python">Python</a></code></small>


<small><code><a href="https://memotut.com/tags/aws"> AWS</a></code></small>


<small><code><a href="https://memotut.com/tags/beginners"> beginners</a></code></small>


<small><code><a href="https://memotut.com/tags/machine-learning"> machine learning</a></code></small>


<small><code><a href="https://memotut.com/tags/sagemaker"> SageMaker</a></code></small>

</p>
<pre><code># My background
</code></pre>
<p>Amazon? Ah, you know, you know, a mail order app.
Not long ago, knowledge about Amazon was that much.
Of course, I didn&rsquo;t even know AWS.</p>
<p><font color="Blue"> I&rsquo;m ashamed as an information undergraduate student. </font></p>
<p>However, as a 3rd year university student, I was introduced to the lab and learned about AWS.
In addition, I am addicted to the topic <a href="https://www.youtube.com/channel/UCFo4kqllbcQ4nV83WCyraiw">&ldquo;Atsuhiko Nakata&rsquo;s YouTube University&rdquo;</a>, which is a hot topic in this street.
While watching the video, AWS cloud service at exactly the same time
I had acquired a vague knowledge that there was.</p>
<p>☟ The blockchain, which is the video that the author was aware of the existence of AWS
The technology was also very interesting.
<img width="301" alt="Capture.PNG" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/233735/9e5b1ce4-7528-999e-880b-242efd2898bd.png">
<a href="https://www.youtube.com/watch?v=HfIqAQUPrjA">[Economy] The final weapon in the 5G era &ldquo;Blockchain&rdquo; ~ Part 1 ~ A big invention that will change the future of humanity! -Atsuhiko Nakata&rsquo;s YouTube University</a></p>
<p>With the above process, I came to know AWS, and although I have no knowledge, I can do various things.
Let&rsquo;s actually use it!
.
.
.
It became.</p>
<p>#Amazon SageMaker
I wanted to try machine learning using AWS,
I decided to try a service called <a href="https://aws.amazon.com/jp/sagemaker/">Amazon SageMaker</a>.</p>
<blockquote>
<p>SageMaker is a fully managed end-to-end machine learning service just announced and released at re:invent 2017.
It provides services to manage the model development process of machine learning, and takes over the complicated and troublesome part of the model development process.
Not only does it lower the threshold for engineers looking to start machine learning, but it also enables data scientists, AI engineers, and machine learning experts to quickly build models for scalable training and rapid release (deployment).</p>
</blockquote>
<p>In other words, <font color="Red">Amazon SageMaker is a service that allows easy machine learning</font>.
As a beginner, I am very grateful.</p>
<h3 id="overview-of-sagemaker">Overview of SageMaker</h3>
<p>SageMaker consists of three modules: &ldquo;authoring&rdquo;, &ldquo;training&rdquo; and &ldquo;hosting&rdquo;.
<img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/233735/9a7ecf27-2eb5-3652-cbd1-d102a4f8fecf.png" alt="image.png">
<strong><Authoring></strong>
The so-called data set pre-treatment process. It is an important process that it is said that 90% of machine learning is pre-processing of dataset.
With AWS SageMaker, you can easily set up and use Jupyter Notebook on the cloud, such as CPU-based or GPU-based, according to the usage situation.</p>
<p><strong><Training></strong>
You can train models using the built-in algorithms provided by SageMaker, the Deep Learning framework, and the unique learning environment of Docker.
The generated model is saved in S3.
This model can be hosted on SageMaker as it is, or can be taken out of AWS and deployed on IoT devices etc.</p>
<p><strong><model hosting></strong>
An HTTPS endpoint is provided so that the model you build can be used in real time.</p>
<p>#SageMaker Tutorial</p>
<p>That said, the reality is not so weak that you can do machine learning just by wanting to do it.</p>
<p>Because if you are going to do machine learning by yourself
** ① Data set used for machine learning **
** ② Knowledge of analysis method and its surroundings necessary for model construction **
** ③ Knowledge of Python and libraries required for pre-processing of data before that **</p>
<p>This is because the above is required.
.
.
.
.
.
No, I was in trouble.
Although I was enthusiastic about trying to do machine learning with a light feeling, I didn&rsquo;t really want to analyze what I was doing. Since I had skipped programming until now, I have almost no knowledge of Python.</p>
<p><strong>But</strong> there is a tutorial in SageMaker where you can find the dataset,
The library to be used and the procedure for writing the code are explained in detail.</p>
<p>Simply put, <font color="Red"> If you use SageMaker following the tutorial, you can experience the series of machine learning even with zero knowledge, and you can also learn the practicality of the analysis method. That is </font>.</p>
<h2 id="forecasting-prospective-customers-for-bank-time-deposits-using-xgboost">Forecasting prospective customers for bank time deposits using XGboost</h2>
<p>Then, I will explain the outline of the tutorial that is actually performed this time.</p>
<p>Tutorial used this time (published on GitHub) ☟
<a href="https://github.com/awslabs/amazon-sagemaker-examples/blob/master/introduction_to_applying_machine_learning/xgboost_direct_marketing/xgboost_direct_marketing_sagemaker.ipynb">Targeting Direct Marketing with Amazon SageMaker XGBoost</a></p>
<p>This tutorial is written entirely in English, but since some people did this tutorial in Japanese, I also refer to that page. ☟
<a href="https://www.codexa.net/amazon-sagemaker-tutorial-marketing-offers/">Predict potential bank time deposit customers using Amazon SageMaker [SageMaker + XGBoost Machine Learning Beginner Tutorial]-codExa</a></p>
<p>The data set used this time is the result of the direct marketing of the fixed-term savings by telephone, which was actually carried out by a Portuguese bank. There is data such as age and occupation of each user, as well as educational background. As a result of direct marketing, those who applied for time deposit (label = 1) and those who did not apply (label = 0 ) Is given.</p>
<p>If you&rsquo;re a machine learning engineer, is it a very famous dataset for beginners that you hear once? (Of course I knew for the first time.)</p>
<p>This dataset is analyzed using a learning method called XGboost to predict whether direct marketing to customers will be successful. Then, the rough flow of this tutorial is to compare the prediction result with the actual data and verify how accurate the prediction was.</p>
<h3 id="xgboost-overview">XGboost overview</h3>
<p>This time, the outline of the analysis method &ldquo;XGboost&rdquo; used when constructing the model will be explained.</p>
<blockquote>
<p>XGBoost is a well known and efficient open source implementation of the gradient boost tree algorithm. Gradient boosting is a supervised learning algorithm that attempts to accurately predict target variables by combining an ensemble of estimates from a simpler, weaker set of models. XGBoost has been extremely successful in machine learning competitions such as kaggle because it can robustly handle a large number of hyperparameters that can be switched and adjusted to suit different data types, trust relationships, distributions and needs.</p>
</blockquote>
<p>So XGboost is the strongest supervised learning method! I have interpreted that.
<font color="lightGray"> Recently, it seems that the learning method called LightGBM is taking away the throne&hellip;w</p>
<h3 id="what-is-supervised-learning-introducing-other-learning-methods">What is supervised learning? Introducing other learning methods</h3>
<p>I mentioned XGboost as supervised learning earlier, but I don&rsquo;t know much about &ldquo;supervised learning&rdquo; either, so I did some research.</p>
<p>There are three methods of machine learning: &ldquo;supervised learning&rdquo;, &ldquo;unsupervised learning&rdquo; and &ldquo;reinforcement learning&rdquo;.</p>
<p><strong><Supervised learning></strong></p>
<blockquote>
<p>Supervised learning is a method in which a computer learns using a learning model constructed from data with known correct labels and numerical values. It is the simplest of the learning methods of machine learning, and it is easy to obtain results close to the predictions made by humans in classification and prediction.
Examples of use include market forecasts in transactions and estimates of clients who often buy their products.</p>
</blockquote>
<p><strong><Unsupervised learning></strong></p>
<blockquote>
<p>Unsupervised learning is a learning method that finds groups with common features and extracts information that characterizes data from input data that is not labeled as correct.
A typical use example is clustering. Clustering is to automatically find data with similar characteristics from the data and divide it into several types of groups.</p>
</blockquote>
<p><strong><Reinforcement learning></strong></p>
<blockquote>
<p>Reinforcement learning is a method that, unlike supervised learning and unsupervised learning, finds the optimal judgment while actually acting on tasks that take time to produce results or require many iterations. It is used for automatic driving of cars, control of robots, and games represented by AlphaGo.</p>
</blockquote>
<p><Reference> <a href="https://mag.sweeep.ai/column/3_ml/">What are the three learning methods of &ldquo;machine learning&rdquo; (supervised learning, unsupervised learning, and reinforcement learning)? -sweeep magazine
</a></p>
<p>#SageMaker tutorial flow
The introduction has become long, but I will explain how to proceed with the analysis from here.</p>
<p>For the AWS account required to use SageMaker, we used the AWS Educate Starter account.
There are basically charges when using AWS services.
However, since the AWS Educate Starter account is given a credit of several tens of dollars by default, you can use the AWS service for practically free for a while. This is a very nice privilege for the author who is a poor college student.
However, there are some regulations that can not be used for some services, so be careful. Details will be described later.
In addition, regarding the flow of analysis described this time, I will also describe in detail the part where I failed and got stuck, and explain the solution procedure.
In the future, for those who are familiar with SageMaker with their AWS Educate Starter account, I would like to use this article as a troubleshooting tool.</p>
<p>First, a brief explanation of the analysis procedure is as follows.</p>
<p><strong>⓪ Open AWS Management Console screen
① Create an Amazon S3 bucket
② Creating an Amazon SageMaker notebook instance
③ Create Jupyter notebook
④ Download, survey and convert training data⑤ Train the model
⑥ Model hosting
⑦ Verify the model</strong></p>
<p>Then, I will explain each step in detail.
It&rsquo;s been very long, so I hope you will take a quick look.</p>
<p>##⓪ Open the AWS Management Console screen (this is surprisingly important)
First, log in to your AWS Educate account and click &ldquo;AWS Account&rdquo; in the upper left to transition to the screen below. <img width="918" alt="Capture1.PNG" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/233735/bd7b1f72-c39a-0357-917a-71c1111dd2d6.png">
After that, when you start the AWS Console according to the instructions on the screen, the &ldquo;AWS Management Console&rdquo; screen opens as shown below.</p>
<p>Search for &ldquo;Search for service&rdquo; and specify the service you want to use.
This time, I use &ldquo;S3&rdquo; and &ldquo;Amazon SageMaker&rdquo;.
<img width="685" alt="capture.PNG" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/233735/6139ba9c-fa63-280f-b278-eaa30fcfde57.png">
.
.
.
.
.
If a beginner goes smoothly, it will be like this, but as mentioned above, the AWS Educate Starter account has limited services that can be used! ! !</p>
<h4 id="list-of-services-available-for-aws-educate-starter-account">List of services available for AWS Educate Starter account</h4>
<p><a href="https://s3.amazonaws.com/awseducate-starter-account-services/AWS_Educate_Starter_Accounts_and_AWS_Services.pdf">https://s3.amazonaws.com/awseducate-starter-account-services/AWS_Educate_Starter_Accounts_and_AWS_Services.pdf</a></p>
<p>If you look at this table, you can see that SageMaker instance cannot be used.</p>
<p>In other words, you can&rsquo;t use SageMaker just because you created an AWS Educate Starter account.
If I proceeded without knowing it at first, the following error occurred at the last model fitting in &ldquo;⑤ Train a model&rdquo;.</p>
<pre><code>ClientError: An error occurred (AccessDeniedException) when calling the CreateTrainingJob operation: User: arn:aws:sts::780079846795:assumed-role/AmazonSageMaker-ExecutionRole-20191119T213649/SageMaker is not authorized to perform: sagemaker:CreateTrainingJob on resource: arn: aws:sagemaker:us-east-1:780079846795:training-job/xgboost-2019-11-19-13-34-49-653 with an explicit deny
</code></pre><p>So how can we eliminate this?</p>
<p>Looking again at the list of services that can be used, it seems that SageMaker can be used even with a Starter account by using &ldquo;Classroom&rdquo; called &ldquo;Machine Learning and AI&rdquo;.</p>
<p><a href="https://aws.amazon.com/jp/blogs/publicsector/introducing-aws-educate-classrooms/">Introduction to AWS Educate Classrooms (all in English)</a></p>
<p>After somehow translating the content on the above page, the educator opens Classroom, sets up its own AWS Educate virtual education space, and invites students to check usage. Since it was written, the professor of the laboratory to which the university belongs opened a Classroom. (By the way, it can be done fairly quickly from application to opening of Classroom. As expected Amazon)</p>
<p>If you are invited to Classroom, press &ldquo;My Classrooms&rdquo; at the top left of the AWS Educate top screen to move to the screen shown below.
<img width="924" alt="Capture 21.PNG" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/233735/2ea928f1-b1d3-e13b-290d-f561b4c2195c.png">
You can go to the classroom AWS Management Console screen by pressing &ldquo;Go to classroom&rdquo; and following the on-screen instructions.</p>
<p>Finally, with this, you can start (crying</p>
<h2 id="-create-an-amazon-s3-bucket">① Create an Amazon S3 bucket</h2>
<p>The transition to the S3 service screen is as follows. Create by pressing &ldquo;Create Bucket&rdquo; on the left side.
<img width="911" alt="Capture2.PNG" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/233735/22f8df85-fec8-d6e0-823f-f0c1ddcea9a7.png">
You can name the bucket freely. This time, I named it &ldquo;bank-xgboost&rdquo;. However, please note that you cannot create a name that is already in use. The region specifies the US East (N. Virginia).</p>
<ul>
<li>Remember the bucket name created here because it will be used later.
<img width="883" alt="Capture3.PNG" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/233735/df8c15c6-c2c2-8206-c11b-0add52dbc1bd.png">
After that, do nothing and create a bucket according to the instructions on the screen. Once the bucket is created, you can see that the bucket you named is created as shown in the figure below.
<img width="889" alt="Capture 4.PNG" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/233735/75d00b00-45be-617d-a400-6ae139a83b03.png"></li>
</ul>
<h2 id="-creating-an-amazon-sagemaker-notebook-instance">② Creating an Amazon SageMaker notebook instance</h2>
<p>The transition to the Amazon SageMaker service screen is as follows.
<img width="741" alt="Capture5.PNG" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/233735/ca201c62-4a51-26c7-f4fe-4e485715e46d.png">
Click &ldquo;Notebook Instance&rdquo; in the above figure to move to the following figure.
Press &ldquo;Create notebook Instance&rdquo; to proceed to create a notebook instance.
<img width="949" alt="Capture6.PNG" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/233735/4f71f08d-871c-ef2b-4591-d40f44618707.png">
You can name the instance freely. This time, I named it &ldquo;bank-tutorial&rdquo;.
The instance type of the notebook build is <font color="Red">&quot;ml.t2.medium&quot;</font> and the default.
<img width="380" alt="Capture 7.PNG" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/233735/d967c9cf-7425-53e5-93f1-9e7cba3753a3.png">
In &ldquo;Create IAM role&rdquo; under &ldquo;Notebook instance settings&rdquo;, specify the S3 packet to be specified as &ldquo;Arbitrary S3 packet&rdquo; and create the role.
<img width="369" alt="Capture8.PNG" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/233735/2df17eb8-d4d6-c200-1d2a-afe289ff0887.png">
Once you have created the IAM role, it will look like the one below, so click &ldquo;Create Notebook Instance&rdquo; in the lower right to complete the creation.
<img width="442" alt="Capture 9.PNG" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/233735/cd1609ca-b542-549f-503f-e0c5728e3354.png">
Immediately after creation, the status is &ldquo;Pending&rdquo;, but after about 5 minutes, it becomes &ldquo;InService&rdquo; and the process proceeds to the next step.
<img width="952" alt="Capture 10.PNG" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/233735/ef0f8c48-5c8f-4fe6-faeb-14631d2696dc.png">
##③ Create Jupyter notebook
When the status becomes &ldquo;In Service&rdquo;, press &ldquo;Open Jupyter&rdquo; to move to the top screen of Jupyter notebook.
<img width="947" alt="Capture 11.PNG" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/233735/851d29d4-f535-aba5-2454-d3a1031d03ed.png">
Go to the top screen of Jupyter notebook, specify &ldquo;conda_python3&rdquo; in &ldquo;new&rdquo; on the upper right, and create a notebook as shown below.
<img width="700" alt="capture.PNG" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/233735/97d764a6-a2ad-b9b9-2237-ef68fd8d3312.png"></p>
<p>Import the necessary configuration variables and libraries. Change the bucket item below to the S3 bucket name you decided earlier. Also, it will not work if the regions of SageMaker and S3 are different, so be careful if the regions are the same.
The folder specified by prefix is newly created in S3. No particular change is necessary, but there is no problem if changed appropriately.Finally, declare the roles of boto3 and IAM. Although it is boto3, it is a library that integrates Python developed by AWS and various AWS services.</p>
<p>To execute a cell, press Shift + Enter. When the execution is completed, the numbers will be numbered as shown in In[1] below. Sometimes the cell name is In[*], but it only takes a while for the cell to execute, so wait for a while and proceed to the next step.</p>
<pre><code class="language-python:In[1]" data-lang="python:In[1]">Set the bucket name of #S3 to the following
Set #S3 prefix (no change required)
bucket ='bank-xgboost'
prefix ='sagemaker/xgboost-dm'
 
# IAM role declaration
import boto3
import re
from sagemaker import get_execution_role
 
role = get_execution_role()
</code></pre><p>Next, import various libraries used for building the model this time.
In addition to Numpy, Pandas, and Matplotlib, which are the standard machine learning methods, the module that plots tables with ipython (Jupyter Notebook), and the SageMaker Python SDK are also imported.</p>
<pre><code class="language-python:In[2]" data-lang="python:In[2]">import numpy as np # for matrix operations and numerical processing
import pandas as pd # for modifying tabular data
import matplotlib.pyplot as plt # For visualization of diagrams etc.
to display an image in from IPython.display import Image # notebook
to display output with from IPython.display import display # notebook
from time import gmtime, strftime # For labeling SageMaker models, endpoints, etc.
For writing output to import sys # notebook
import math # for ceiling function
import json # for parsing hosting output
import os # to manipulate file pathnames
import sagemaker # Many helper functions are provided by using Python SDK of Amazon SageMaker
from sagemaker.predictor import csv_serializer # Convert HTTP POST request string during inference
</code></pre><p>##④ Download, survey and convert training data
The dataset is publicly available on the site of the University of California, Irvine, so obtain it directly from there. Download directly from URL with wget and unizip.</p>
<pre><code class="language-python:In[3]" data-lang="python:In[3]"># Download the dataset from the public URL of the University of California Irvine
!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank-additional.zip
!unzip -o bank-additional.zip
</code></pre><p>Read the downloaded dataset of this csv file as a Pandas data frame.</p>
<pre><code class="language-python:In[4]" data-lang="python:In[4]">#bank-additional-full.csv is stored in data
data = pd.read_csv('./bank-additional/bank-additional-full.csv', sep=';')
 
Change the setting of maximum display column number and row number of # Pandas
pd.set_option('display.max_columns', 500)
pd.set_option('display.max_rows', 30)
 
# Show first 10 lines
data.head(10)
</code></pre><p>If you display the first 10 rows of the dataset, you can see that the customer information is stored. I will introduce a part of the outline of the item.</p>
<p>· Age – the age of the customer
• job – job category
· Marital – Marriage status
・ Education – Educational background
• default – status of credit delay
・Housing – Presence or absence of real estate loan
・Loan – Whether or not you have a personal loan, etc&hellip;
<img width="483" alt="Capture 20.PNG" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/233735/058f6a3b-aae3-62c5-cab8-eb1c8c8c5135.png"></p>
<p>Confirm missing data. When there is missing data, it is necessary to discuss how to deal with it, which is troublesome.</p>
<pre><code class="language-python:In[5]" data-lang="python:In[5]">#Table function to collect missing data in data frame
def missing_values_table(df):
        mis_val = df.isnull().sum()
        mis_val_percent = 100 * df.isnull().sum()/len(df)
        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)
        mis_val_table_ren_columns = mis_val_table.rename(
        columns = (0:'Missing Values', 1 :'% of Total Values'})
        return mis_val_table_ren_columns
 
Check if #data is missing
missing_values_table(data)
</code></pre><p>From the figure below, it can be observed that there is no data loss.
As expected, bank data set.
<img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/233735/89bf766a-7d25-cafe-25a3-f637790395e8.png" alt="image.png"></p>
<p>Next, data cleansing (data set preprocessing) is performed.
Cleansing a dataset is an essential step in almost every machine learning process.</p>
<p>This time, four types of pre-processing are performed.</p>
<p>** ① Extract customers who have not been contacted from pdays **
For pdays (how many days have passed since the last contact), there is a very large amount of data of &ldquo;999&rdquo;, and it can be said that most customers have not contacted since the last time. Data processing is performed with &ldquo;1&rdquo; for 999 days (that is, a customer who has not been contacted) and &ldquo;0&rdquo; for other cases.</p>
<p>** ② Extract customers who do not currently have a job from job **
There are 12 types of job items, including unknown. This item includes customers who do not currently have a job, such as &ldquo;student&rdquo; and &ldquo;unemployed&rdquo;. Therefore, processing is performed to determine whether or not the worker is currently working and to add a new item &ldquo;not_working&rdquo; (not working).</p>
<p><strong>③ Convert categorical data into dummy variables</strong>
The method of digitizing non-numeric data is called dummy variable.
For example, in the data this time, the predicted target is &ldquo;y&rdquo;, but the values it holds are &ldquo;yes&rdquo; and &ldquo;no&rdquo;. If this is made into a dummy variable, originally one item &ldquo;y&rdquo; is divided into two items &ldquo;y_yes&rdquo; and &ldquo;y_no&rdquo;, and &ldquo;0&rdquo; and &ldquo;1&rdquo; are given according to each value.</p>
<p>** ④ Delete items that are not included in the prediction model **
Finally, use pd.drop to delete items that are not used in this training, such as the external environment factor index (emp.var.rate), from the data frame.</p>
<pre><code class="language-python:In[7]" data-lang="python:In[7]"># New item added to determine who has never been contacted before
data['no_previous_contact'] = np.where(data['pdays'] == 999, 1, 0)
 
# Add a flag of &quot;people not in work&quot; (students etc.) from occupation
data['not_working'] = np.where(np.in1d(data['job'], ['student','retired','unemployed']), 1, 0)
 
# Convert categorical data to dummy variable
model_data = pd.get_dummies(data)
 
# Delete items not used in this model
model_data = model_data.drop(['duration','emp.var.rate','cons.price.idx','cons.conf.idx','euribor3m','nr.employed'], axis=1)
</code></pre><p>After the pre-processing is completed, the next step is to divide the data into training data, verification data, and test data.</p>
<p>Regarding the reason for dividing, I would like to briefly explain it because I want to make it learn many times and improve the accuracy of the model, so I will leave it as a point of view this time.</p>
<pre><code class="language-python:In[8]" data-lang="python:In[8]"># Randomly sort pre-processed model_data into 3 data frames
train_data, validation_data, test_data = np.split(model_data.sample(frac=1, random_state=1729), [int(0.7 * len(model_data)), int(0.9 * len(model_data))]) # Randomly sort the data then split out first 70%, second 20%, and last 10%
</code></pre><p>Next is the final step of data preprocessing. The data format of Amazon SageMaker XGBoost container is libSVM. It is a libSVM format, but since the feature (feature quantity) and the prediction target (objective variable) must be set as separate arguments, that processing is performed.
Finally, send this training data set (libSVM format) to AWS S3 via boto3.</p>
<pre><code class="language-python:In[9]" data-lang="python:In[9]"># Export libSVM filedump_svmlight_file(X=train_data.drop(['y_no','y_yes'], axis=1), y=train_data['y_yes'], f='train.libsvm')
dump_svmlight_file(X=validation_data.drop(['y_no','y_yes'], axis=1), y=validation_data['y_yes'], f='validation.libsvm')
dump_svmlight_file(X=test_data.drop(['y_no','y_yes'], axis=1), y=test_data['y_yes'], f='test.libsvm')
 
# Copy files to S3 using Boto3
boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix,'train/train.libsvm')).upload_file('train.libsvm')
boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix,'validation/validation.libsvm')).upload_file('validation.libsvm')
</code></pre><p>Now you have a new folder called &ldquo;sagemaker&rdquo; in the AWS S3 bucket you specified.
As shown in the figure below, if train.libsvm is newly created in the directory of S3&gt; bucket name&gt; sagemaker&gt; xgboost-dm&gt; train, it has proceeded to this point without problems.
<img width="881" alt="Capture 22.PNG" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/233735/0f82d016-f856-5095-900e-59fc50205668.png">
##⑤ Train the model
Since the pre-processing is completed, it is finally time to build the model using XGBoost.</p>
<p>First, specify the location of the ECR container for Amazon SageMaker XGBoost, and link the training data (libSVM) with S3.</p>
<pre><code class="language-python:In[10]" data-lang="python:In[10]"># Specify ECR container for SageMaker XGBoost
containers = {'us-west-2': '433757028032.dkr.ecr.us-west-2.amazonaws.com/xgboost:latest',
              'us-east-1': '811284229777.dkr.ecr.us-east-1.amazonaws.com/xgboost:latest',
              'us-east-2': '825641698319.dkr.ecr.us-east-2.amazonaws.com/xgboost:latest',
              'eu-west-1': '685385470294.dkr.ecr.eu-west-1.amazonaws.com/xgboost:latest'}

# Link the training data and S3
s3_input_train = sagemaker.s3_input(s3_data='s3://{}/{}/train'.format(bucket, prefix), content_type='libsvm')
s3_input_validation = sagemaker.s3_input(s3_data='s3://{}/{}/validation/'.format(bucket, prefix), content_type='libsvm')
</code></pre><p>Next, specify the necessary parameters and hyperparameters to the Estimator of SageMaker and perform fitting. The code below uses <font color="Red">&quot;ml.m4.xlarge&quot;</font> as an instance for training. The process is completed in about 10 minutes.</p>
<pre><code class="language-python:In[11]" data-lang="python:In[11]"># SageMaker session
sess = sagemaker.Session()
 
# Specify required items in estimator of sagemaker
xgb = sagemaker.estimator.Estimator(containers[boto3.Session().region_name],
                                    role,
                                    train_instance_count=1,
                                    train_instance_type='ml.m4.xlarge',
                                    output_path='s3://{}/{}/output'.format(bucket, prefix),
                                    sagemaker_session=sess)
 
# Specify hyperparameters
xgb.set_hyperparameters(max_depth=5,
                        eta=0.2,
                        gamma=4,
                        min_child_weight=6,
                        subsample=0.8,
                        silent=0,
                        objective='binary:logistic',
                        (num_round=100)
 
#Model fitting and output destination specification (S3)
xgb.fit({'train': s3_input_train,'validation': s3_input_validation})
</code></pre><p>If the processing is successful, the following words will appear.</p>
<pre><code>2019-11-18 16:36:46 Uploading-Uploading generated training model
2019-11-18 16:36:46 Completed-Training job completed
Training seconds: 63
Billable seconds: 63
</code></pre><p>##⑥ Model hosting (this is also an important point)
After the fitting is completed, next model hosting is performed. The code below uses an instance of <font color="Red">&quot;ml.t2.medium&quot;</font>. It also takes about 10 minutes to complete the process.</p>
<pre><code class="language-python:In[12]" data-lang="python:In[12]">Deploy with #ml.t2.medium instance
xgb_predictor = xgb.deploy(initial_instance_count=1,
                           instance_type='ml.t2.medium')
</code></pre><p>.
.
.
.
.
Regarding this model hosting, I was initially trying to deploy it with a <font color="Red">&quot;ml.c4.xlarge&quot;</font> instance. This is because the code in the <a href="https://www.codexa.net/amazon-sagemaker-tutorial-marketing-offers/">Referenced page</a> is that way.</p>
<p>However, I got the following error.</p>
<pre><code>ResourceLimitExceeded: An error occurred (ResourceLimitExceeded) when calling the CreateEndpoint operation: The account-level service limit'ml.c4.xlarge for endpoint usage' is 0 Instances, with current utilization of 0 Instances and a request delta of 1 Instances. Please contact AWS support to request an increase for this limit.
</code></pre><p>In simple terms, the resource limit for this account was reached, so I contacted AWS Support to free up the cap and say something.</p>
<p>As expected, Starter account.
Low resources&hellip;</p>
<p>Since various instances were posted on the <a href="https://aws.amazon.com/jp/sagemaker/pricing/">Amazon SageMaker instance charges</a> page, I tried variously, but regarding the deployment of the model, , Only the ml.t2.medium instance worked.</p>
<p>Even so, the instance used for the time being,
・Construction ** &ldquo;ml.t2.medium&rdquo;**
・Training ** &ldquo;ml.m4.xlarge&rdquo;**
・Deployment ** &ldquo;ml.t2.medium&rdquo; **</p>
<p>If you set it as such, it will not be stuck until the end, so if there is someone who will do the same thing with Starter account in the future, please refer to it.
(Cost is cheap = If you adopt an instance that does not use much resources, will you not get caught up in the resource limit?)</p>
<p>By the way, when I contacted AWS Support by e-mail about whether the upper limit can be released, it is said that the starter account of the free tier can not release the upper limit in the first place&hellip;
##⑦ Validate the model
As the first step, specify how to pass and receive the data used for evaluation. It&rsquo;s test data, but it&rsquo;s currently placed as a Numpy array on an instance of a SageMaker notebook. In order to send this to the prediction model by HTTP POST request, serialize it using &ldquo;serializer&rdquo; of SageMaker and specify the content_type as well.</p>
<pre><code class="language-python:In[13]" data-lang="python:In[13]"># Make settings for passing data
xgb_predictor.content_type ='text/csv'
xgb_predictor.serializer = csv_serializer
</code></pre><p>Next, divide the test_data created in the previous step into small batches of 500 rows each, make predictions at the XGBoost endpoint, and output as a Numpy array.</p>
<pre><code class="language-python:In[14]" data-lang="python:In[14]"># Divide into small batches of 500 rows and calculate with xgb_predictor
def predict(data, rows=500):
    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))predictions =''
    for array in split_array:
        predictions =','.join([predictions, xgb_predictor.predict(array).decode('utf-8')])
 
    return np.fromstring(predictions[1:], sep=',')
 
#Delete target item from test_data created in previous item and output prediction
predictions = predict(test_data.drop(['y_no','y_yes'], axis=1).as_matrix())
 
# Comparison table of prediction and correct answer data
pd.crosstab(index=test_data['y_yes'], columns=np.round(predictions), rownames=['actuals'], colnames=['predictions'])
</code></pre><p>The predicted values are now stored in the Numpy array as predictions.
Finally, use Pandas to make a table of the actual correct data and the predicted &ldquo;predictions&rdquo; results.
.
.
.
.
.
<img width="190" alt="Capture.PNG" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/233735/a308d929-e773-d0da-6d0e-2258d913e8ed.png"></p>
<p>The forecast result this time is as shown in the above figure.</p>
<p>As it is, it is hard to see, so I summarized it as shown in the table below.
<img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/233735/19b0e678-4937-7bdf-4eda-661970d2af29.png" alt="image.png">
When you read this,</p>
<p>I predicted that there were 77 people who answered Yes, but only three of those 77 people actually answered Yes.
Furthermore, among those who predicted No, there were 480 people who actually answered Yes.</p>
<p>This time, I can&rsquo;t say that the analysis results are very accurate, but this time I felt like I would try machine learning for the time being&hellip;
There seems to be plenty of room for improving the prediction accuracy by adjusting the features and adjusting the hyperparameters.</p>
<p>** Still important work at the end. **</p>
<p>After completing this tutorial, delete the endpoint created this time so that no extra charge is incurred.</p>
<pre><code class="language-python:In[16]" data-lang="python:In[16]"># Delete the created endpoint
sagemaker.Session().delete_endpoint(xgb_predictor.endpoint)
</code></pre><p>In addition to this, I can check the status of &ldquo;Model&rdquo;, &ldquo;Endpoint&rdquo;, and &ldquo;Notebook&rdquo; on the management screen of SageMaker, so I deleted unnecessary items as appropriate.
#Finally
This time, I think that I learned a little about how to use SageMaker, how to machine learning, and some knowledge by doing the AWS SageMaker tutorial.</p>
<p>There are many more than the tutorials I did this time, so if you have time, I definitely want to try it.</p>
<p>List of other tutorials (English) ☞ <a href="https://github.com/awslabs/amazon-sagemaker-examples">Amazon SageMaker Examples</a></p>
<p>I feel like I&rsquo;ve finally reached the starting line of machine learning, so I hope to continue to input various things and output again to Qiita like this time.</p>
<p>I think it was a poor text, but thank you for reading.</p>

    </article>
  </div>

  
  
  
  <script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-169005401-1', 'auto');
  ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  

  
<link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.css" />
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#216942",
      "text": "#b2d192"
    },
    "button": {
      "background": "#afed71"
    }
  }
})});
</script>

</body>

</html>
