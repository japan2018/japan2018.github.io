<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  <meta name="generator" content="Hugo 0.72.0" />

  
  <meta name="description" content="Some description">
  

  
  <link rel="apple-touch-icon" sizes="180x180" href="https://memotut.com/apple-touch-icon.png">

  
  <link rel="icon" type="image/png" sizes="32x32" href="https://memotut.com/favicon-32x32.png">

  
  <link rel="icon" type="image/png" sizes="16x16" href="https://memotut.com/favicon-16x16.png">

  
  <link rel="manifest" href="https://memotut.com/site.webmanifest">

  
  <link rel="mask-icon" href="https://memotut.com/safari-pinned-tab.svg" color="#5bbad5">

  <meta name="msapplication-TileColor" content="#da532c">

  <meta name="theme-color" content="#ffffff">

  
  <link rel="stylesheet" href="https://memotut.com/css/bootstrap.min.css" />

  
  <title>Head direction estimation using Python and OpenCV&#43;dlib | Memo Tut</title>
  

  <style>
body {
  min-width: 300px;
}

.custom-navbar {
  margin-bottom: 1em;
  height: 60px;
}

.custom-navbar a {
  display: inline-block; 
  padding: 18px 0;
  margin-right: 1em; 
  font-weight: bold; 
}

.custom-navbar a:hover,
.custom-navbar a:focus {
  text-decoration: none; 
}

@media print {
  .custom-navbar {
    display: none;
  }
}

article {
  padding-bottom: 1em;
}

img {
  max-width: 100%;
}


body {
  background-color: #fff;
}



body {
  color: #212529;
}



a {
  color: #007bff;
}



a:hover,
a:focus {
  color: #0056b3;
}



.custom-navbar {
  background-color: #212529;
}



.custom-navbar a {
  color: rgba(255, 255, 255, 0.75);
}



.custom-navbar a:hover,
.custom-navbar a:focus {
  color: rgba(255, 255, 255, 1);
}



.container {
  max-width: 800px;
}



pre {
  display: block;
  padding: 9.5px;
  word-break: break-all;
  word-wrap: break-word;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre code {
  padding: 0;
  font-size: inherit;
  color: inherit; 
  white-space: pre-wrap;
  background-color: transparent;
  border: none;
  border-radius: 0;
}

code {
  padding: 2px 4px;
  color: inherit; 
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
  font-size: .9em;
}



blockquote,
.blockquote {
  padding: 10px 20px;
  margin: 0 0 20px;
  font-size: 1em;
  border-left: 5px solid #6c757d;
}

</style>
</head>

<body>
  <nav class="custom-navbar">
  <div class="container">
    
    <a href="/">Posts</a>
    
    <a href="/tags/">Tags</a>
    
    <a href="/about/">About</a>
    
    <a href="/index.xml">RSS</a>
    
  </div>
</nav>
  
  <div class="container">
    <article>
      <h1>Head direction estimation using Python and OpenCV+dlib</h1>
<p>
  <small class="text-secondary">
  
  
  Dec 4, 2019
  </small>
  

<small><code><a href="https://memotut.com/tags/python">Python</a></code></small>


<small><code><a href="https://memotut.com/tags/opencv"> OpenCV</a></code></small>


<small><code><a href="https://memotut.com/tags/dedicated"> Dedicated</a></code></small>

</p>
<pre><code>#Head direction estimation?
</code></pre>
<p>Head direction estimation, or Head Pose Estimation in English. It is an algorithm that estimates the direction of the face and the inclination of the head from the input image information and facial feature amount data. Recently, it is widely used for Vtuber development.</p>
<h1 id="head-direction-estimation-method">Head direction estimation method</h1>
<p>Qiita has already introduced several methods for estimating the head direction. This is very well summarized in the Qiita article.
<a href="https://qiita.com/nonbiri15/items/f6910a993457a1862632">Under investigation on face orientation estimation</a></p>
<p>I think this is the article that you are probably referring to for head estimation methods using Python and OpenCV+dlib.
<a href="https://www.learnopencv.com/head-pose-estimation-using-opencv-and-dlib/">Head Pose Estimation using OpenCV and Dlib</a></p>
<p>The face direction estimation algorithm is described in detail in the section &ldquo;How do pose estimation algorithms work ?&rdquo; on this page.</p>
<p>#Example program</p>
<p>For now, let&rsquo;s write the program introduced in the article.
You can download the dat file for face recognition from here.
<a href="http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2">[dlib.net] 68 points learned data for face recognition [DL]</a></p>
<h4 id="module-loading">Module loading</h4>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-HeadPoseEstimation.py" data-lang="HeadPoseEstimation.py"><span style="color:#75715e">#!/usr/bin/env python3</span>
<span style="color:#75715e"># -*- coding: utf-8 -*-</span>

<span style="color:#f92672">import</span> cv2 <span style="color:#75715e">#OpenCV: Image processing library</span>
<span style="color:#f92672">import</span> dlib <span style="color:#75715e"># Machine learning library</span>
<span style="color:#f92672">import</span> imutils <span style="color:#75715e">#OpenCV assistance</span>
<span style="color:#f92672">from</span> imutils <span style="color:#f92672">import</span> face_utils
<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
</code></pre></div><p>It imports OpenCV for image processing, dlib for image recognition, and imutils as an aid to display on screen.</p>
<h4 id="camera-and-face-detector-settings">Camera and face detector settings</h4>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-HeadPoseEstimation.py" data-lang="HeadPoseEstimation.py">DEVICE_ID <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span> <span style="color:#75715e"># Camera ID used is 0 for standard webcam</span>
capture <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>VideoCapture(DEVICE_ID)<span style="color:#75715e">#Read the learned data of dlib</span>
predictor_path <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;,,,/shape_predictor_68_face_landmarks.dat&#34;</span>
<span style="color:#75715e"># Copy and paste the path of the learned dat file</span>

detector <span style="color:#f92672">=</span> dlib<span style="color:#f92672">.</span>get_frontal_face_detector() <span style="color:#75715e"># Face detector call. It only detects faces.</span>
predictor <span style="color:#f92672">=</span> dlib<span style="color:#f92672">.</span>shape_predictor(predictor_path) <span style="color:#75715e"># Output landmarks such as face, eyes and nose</span>
</code></pre></div><p>See here for detailed dlib functions.
<a href="http://dlib.net/python/index.html">dlib documentation</a></p>
<h4 id="contents-of-head-direction-estimation">Contents of head direction estimation</h4>
<p>It acquires each frame from the camera and processes it.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-HeadPoseEstimation.py" data-lang="HeadPoseEstimation.py"><span style="color:#66d9ef">while</span>(True): <span style="color:#75715e"># Acquire images continuously from the camera</span>
    ret, frame <span style="color:#f92672">=</span> capture<span style="color:#f92672">.</span>read() <span style="color:#75715e">#Capture from camera and put 1 frame of image data in frame</span>
    
    frame <span style="color:#f92672">=</span> imutils<span style="color:#f92672">.</span>resize(frame, width<span style="color:#f92672">=</span><span style="color:#ae81ff">1000</span>) <span style="color:#75715e"># Adjust the display size of the frame image</span>
    gray <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>cvtColor(frame, cv2<span style="color:#f92672">.</span>COLOR_BGR2GRAY) convert to <span style="color:#75715e">#gray scale</span>
    rects <span style="color:#f92672">=</span> detector(gray, <span style="color:#ae81ff">0</span>) <span style="color:#75715e"># detect faces from gray</span>
    image_points <span style="color:#f92672">=</span> None
     
    <span style="color:#66d9ef">for</span> rect <span style="color:#f92672">in</span> rects:
        shape <span style="color:#f92672">=</span> predictor(gray, rect)
        shape <span style="color:#f92672">=</span> face_utils<span style="color:#f92672">.</span>shape_to_np(shape)
        
        <span style="color:#66d9ef">for</span> (x, y) <span style="color:#f92672">in</span> shape: <span style="color:#75715e">#Plot 68 landmarks on the whole face</span>
            cv2<span style="color:#f92672">.</span>circle(frame, (x, y), <span style="color:#ae81ff">1</span>, (<span style="color:#ae81ff">255</span>, <span style="color:#ae81ff">255</span>, <span style="color:#ae81ff">255</span>), <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>)

        image_points <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array([
                tuple(shape[<span style="color:#ae81ff">30</span>]), <span style="color:#75715e">#nasal head</span>
                tuple(shape[<span style="color:#ae81ff">21</span>]),
                tuple(shape[<span style="color:#ae81ff">22</span>]),
                tuple(shape[<span style="color:#ae81ff">39</span>]),
                tuple(shape[<span style="color:#ae81ff">42</span>]),
                tuple(shape[<span style="color:#ae81ff">31</span>]),
                tuple(shape[<span style="color:#ae81ff">35</span>]),
                tuple(shape[<span style="color:#ae81ff">48</span>]),
                tuple(shape[<span style="color:#ae81ff">54</span>]),
                tuple(shape[<span style="color:#ae81ff">57</span>]),
                tuple(shape[<span style="color:#ae81ff">8</span>]),
                ],dtype<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;double&#39;</span>)
    
    <span style="color:#66d9ef">if</span> len(rects)<span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0</span>:
        cv2<span style="color:#f92672">.</span>FONT_HERSHEY_PLAIN, <span style="color:#ae81ff">0.7</span>, (<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">255</span>), <span style="color:#ae81ff">2</span>)
        model_points <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array([
                (<span style="color:#ae81ff">0.0</span>,<span style="color:#ae81ff">0.0</span>,<span style="color:#ae81ff">0.0</span>), <span style="color:#75715e">#30</span>
                (<span style="color:#f92672">-</span><span style="color:#ae81ff">30.0</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">125.0</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">30.0</span>), <span style="color:#75715e">#21</span>
                (<span style="color:#ae81ff">30.0</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">125.0</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">30.0</span>), <span style="color:#75715e">#22</span>
                (<span style="color:#f92672">-</span><span style="color:#ae81ff">60.0</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">70.0</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">60.0</span>), <span style="color:#75715e"># 39</span>
                (<span style="color:#ae81ff">60.0</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">70.0</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">60.0</span>), <span style="color:#75715e"># 42</span>
                (<span style="color:#f92672">-</span><span style="color:#ae81ff">40.0</span>,<span style="color:#ae81ff">40.0</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">50.0</span>), <span style="color:#75715e"># 31</span>
                (<span style="color:#ae81ff">40.0</span>,<span style="color:#ae81ff">40.0</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">50.0</span>), <span style="color:#75715e">#35</span>
                (<span style="color:#f92672">-</span><span style="color:#ae81ff">70.0</span>,<span style="color:#ae81ff">130.0</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">100.0</span>), <span style="color:#75715e"># 48</span>
                (<span style="color:#ae81ff">70.0</span>,<span style="color:#ae81ff">130.0</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">100.0</span>), <span style="color:#75715e">#54</span>
                (<span style="color:#ae81ff">0.0</span>,<span style="color:#ae81ff">158.0</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">10.0</span>), <span style="color:#75715e">#57</span>
                (<span style="color:#ae81ff">0.0</span>,<span style="color:#ae81ff">250.0</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">50.0</span>) <span style="color:#75715e"># 8</span>
                ])

        size <span style="color:#f92672">=</span> frame<span style="color:#f92672">.</span>shape

        focal_length <span style="color:#f92672">=</span> size[<span style="color:#ae81ff">1</span>]
        center <span style="color:#f92672">=</span> (size[<span style="color:#ae81ff">1</span>] <span style="color:#f92672">//</span> <span style="color:#ae81ff">2</span>, size[<span style="color:#ae81ff">0</span>] <span style="color:#f92672">//</span> <span style="color:#ae81ff">2</span>) <span style="color:#75715e"># center coordinates of face</span>

        camera_matrix <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array([
            [focal_length, <span style="color:#ae81ff">0</span>, center[<span style="color:#ae81ff">0</span>]],
            [<span style="color:#ae81ff">0</span>, focal_length, center[<span style="color:#ae81ff">1</span>]],
            [<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>]
        ], dtype<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;double&#39;</span>)

        dist_coeffs <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>zeros((<span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">1</span>))

        (success, rotation_vector, translation_vector) <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>solvePnP(model_points, image_points, camera_matrix,
                                                                      dist_coeffs, flags<span style="color:#f92672">=</span>cv2<span style="color:#f92672">.</span>SOLVEPNP_ITERATIVE)
        <span style="color:#75715e">#Rotation matrix and Jacobian</span>
        (rotation_matrix, jacobian) <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>Rodrigues(rotation_vector)
        mat <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>hstack((rotation_matrix, translation_vector))

        Extracting <span style="color:#75715e">#yaw,pitch,roll</span>
        (_, _, _, _, _, _, eulerAngles) <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>decomposeProjectionMatrix(mat)
        yaw <span style="color:#f92672">=</span> eulerAngles[<span style="color:#ae81ff">1</span>]
        pitch <span style="color:#f92672">=</span> eulerAngles[<span style="color:#ae81ff">0</span>]
        roll <span style="color:#f92672">=</span> eulerAngles[<span style="color:#ae81ff">2</span>]
        
        <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;yaw&#34;</span>,int(yaw),<span style="color:#e6db74">&#34;pitch&#34;</span>,int(pitch),<span style="color:#e6db74">&#34;roll&#34;</span>,int(roll))<span style="color:#75715e">#Retrieve head posture data</span>

        cv2<span style="color:#f92672">.</span>putText(frame,<span style="color:#e6db74">&#39;yaw :&#39;</span><span style="color:#f92672">+</span> str(int(yaw)), (<span style="color:#ae81ff">20</span>, <span style="color:#ae81ff">10</span>), cv2<span style="color:#f92672">.</span>FONT_HERSHEY_PLAIN, <span style="color:#ae81ff">1</span>, (<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">255</span>), <span style="color:#ae81ff">2</span>)
        cv2<span style="color:#f92672">.</span>putText(frame,<span style="color:#e6db74">&#39;pitch :&#39;</span><span style="color:#f92672">+</span> str(int(pitch)), (<span style="color:#ae81ff">20</span>, <span style="color:#ae81ff">25</span>), cv2<span style="color:#f92672">.</span>FONT_HERSHEY_PLAIN, <span style="color:#ae81ff">1</span>, (<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">255</span>), <span style="color:#ae81ff">2</span>)
        cv2<span style="color:#f92672">.</span>putText(frame,<span style="color:#e6db74">&#39;roll :&#39;</span><span style="color:#f92672">+</span> str(int(roll)), (<span style="color:#ae81ff">20</span>, <span style="color:#ae81ff">40</span>), cv2<span style="color:#f92672">.</span>FONT_HERSHEY_PLAIN, <span style="color:#ae81ff">1</span>, (<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">255</span>), <span style="color:#ae81ff">2</span>)

        (nose_end_point2D, _) <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>projectPoints(np<span style="color:#f92672">.</span>array([(<span style="color:#ae81ff">0.0</span>, <span style="color:#ae81ff">0.0</span>, <span style="color:#ae81ff">500.0</span>)]), rotation_vector,
                                                         translation_vector, camera_matrix, dist_coeffs)
        <span style="color:#75715e">#Plot of points used for calculation/display of face direction vector</span>
        <span style="color:#66d9ef">for</span> p <span style="color:#f92672">in</span> image_points:
            cv2<span style="color:#f92672">.</span>drawMarker(frame, (int(p[<span style="color:#ae81ff">0</span>]), int(p[<span style="color:#ae81ff">1</span>])), (<span style="color:#ae81ff">0.0</span>, <span style="color:#ae81ff">1.409845</span>, <span style="color:#ae81ff">255</span>),markerType<span style="color:#f92672">=</span>cv2<span style="color:#f92672">.</span>MARKER_CROSS, thickness<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)

        p1 <span style="color:#f92672">=</span> (int(image_points[<span style="color:#ae81ff">0</span>][<span style="color:#ae81ff">0</span>]), int(image_points[<span style="color:#ae81ff">0</span>][<span style="color:#ae81ff">1</span>]))
        p2 <span style="color:#f92672">=</span> (int(nose_end_point2D[<span style="color:#ae81ff">0</span>][<span style="color:#ae81ff">0</span>][<span style="color:#ae81ff">0</span>]), int(nose_end_point2D[<span style="color:#ae81ff">0</span>][<span style="color:#ae81ff">0</span>][<span style="color:#ae81ff">1</span>]))

        cv2<span style="color:#f92672">.</span>arrowedLine(frame, p1, p2, (<span style="color:#ae81ff">255</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>), <span style="color:#ae81ff">2</span>)
    
    cv2<span style="color:#f92672">.</span>imshow(<span style="color:#e6db74">&#39;frame&#39;</span>,frame) <span style="color:#75715e"># show imageif cv2.waitKey(1) &amp; 0xFF == ord(&#39;q&#39;): press #q to break and exit while</span>
        <span style="color:#66d9ef">break</span>


capture<span style="color:#f92672">.</span>release() <span style="color:#75715e">#video capture ends</span>
cv2<span style="color:#f92672">.</span>destroyAllWindows() <span style="color:#75715e"># close window</span>

</code></pre></div><p>If it works properly, it will be like this.
<img width="1265" alt="Screenshots 2019-11-24 23.32.58.png" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/543519/48481f5f-9ded-0fcb-04d5-d00021a719fe.png"></p>
<h1 id="parameter-explanations-and-notes">Parameter explanations and notes</h1>
<p>###yaw,roll,pitch
Head pose parameters yaw,roll,pitch look like this. (Same as an airplane)
<img width="1006" alt="IMG_0240.jpg" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/543519/c7d9bbdb-260a-ba03-5eca-b1993c817088.jpeg"></p>
<h3 id="face-features-to-use">Face features to use</h3>
<p>See here for the location of image_points defined this time.
The points I used this time
・Inside of eyebrows (22,23)
・Inside of eyes (40,43)
・ Nose head (31)
・Both sides of nose (32,36)
・Outside of mouth (49,55)
・Under the lips (58)
・Chin (9)
11 points. Algorithmically, the head direction can be estimated with 5 points, but when I tried it and the number of points was small, the vector of the tip of the nose was pointing around everywhere, so I am increasing the number of points. (Because the learned data is based on Westerners&hellip;)
<a href="https://www.pyimagesearch.com/2017/04/03/facial-landmarks-dlib-opencv-python/">Facial landmarks with dlib, OpenCV, and Python</a>
<img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/543519/14e1111e-f392-3327-c75e-9be872e1808d.jpeg" alt="facial_landmarks_68markup-1024x825.jpg">
The more you use the points outside the face, the better the accuracy will be. However, if the eyebrows etc. are cut off when facing sideways, the feature amount will be erroneously determined, so try to use the point at the center of the face as much as possible. <img width="638" alt="IMG_18D234CF6CC9-1.jpeg" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/543519/9cc12aa3-958f-0940-9737-84a999dfacbf.jpeg"></p>
<p>And what I&rsquo;m worried about is model_points, that is, what to do with the position coordinates of the parts of my face, but I defined it forcefully from the following program. The (x,y) coordinate data of the face with the head of the nose as the origin will appear in the image, so please extend it straight to the camera as much as possible and read it with a good spirit. I have no idea about the z coordinate. Please measure the distance from the head of your nose to the space between your eyes and hit the height of your nose to calculate the number. Hang in there!</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-HPEcal.py" data-lang="HPEcal.py"><span style="color:#75715e">#!/usr/bin/env python3</span>
<span style="color:#75715e"># -*- coding: utf-8 -*-</span>

<span style="color:#f92672">import</span> cv2 <span style="color:#75715e">#OpenCV: Image processing library</span>
<span style="color:#f92672">import</span> dlib <span style="color:#75715e"># Machine learning library</span>
<span style="color:#f92672">import</span> imutils <span style="color:#75715e">#OpenCV assistance</span>
<span style="color:#f92672">from</span> imutils <span style="color:#f92672">import</span> face_utils
<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np


<span style="color:#75715e">#Get the VideoCapture object</span>
DEVICE_ID <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span> <span style="color:#75715e">#ID 0 is standard web cam</span>
capture <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>VideoCapture(DEVICE_ID)<span style="color:#75715e">#Read the learned data of dlib</span>
predictor_path <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;/shape_predictor_68_face_landmarks.dat&#34;</span>

<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;[INFO] loading facial landmark predictor...&#34;</span>)
detector <span style="color:#f92672">=</span> dlib<span style="color:#f92672">.</span>get_frontal_face_detector() <span style="color:#75715e"># Face detector call. It only detects faces.</span>
predictor <span style="color:#f92672">=</span> dlib<span style="color:#f92672">.</span>shape_predictor(predictor_path) <span style="color:#75715e"># Output landmarks such as face, eyes and nose</span>

<span style="color:#66d9ef">while</span>(True): <span style="color:#75715e"># Acquire images continuously from the camera</span>
    ret, frame <span style="color:#f92672">=</span> capture<span style="color:#f92672">.</span>read() <span style="color:#75715e">#Capture from camera and put 1 frame of image data in frame</span>
    
    frame <span style="color:#f92672">=</span> imutils<span style="color:#f92672">.</span>resize(frame, width<span style="color:#f92672">=</span><span style="color:#ae81ff">2000</span>) <span style="color:#75715e"># Adjust the display size of the frame image</span>
    gray <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>cvtColor(frame, cv2<span style="color:#f92672">.</span>COLOR_BGR2GRAY) convert to <span style="color:#75715e">#gray scale</span>
    rects <span style="color:#f92672">=</span> detector(gray, <span style="color:#ae81ff">0</span>) <span style="color:#75715e"># detect faces from gray</span>
    image_points <span style="color:#f92672">=</span> None
     
    <span style="color:#66d9ef">for</span> rect <span style="color:#f92672">in</span> rects:
        shape <span style="color:#f92672">=</span> predictor(gray, rect)
        shape <span style="color:#f92672">=</span> face_utils<span style="color:#f92672">.</span>shape_to_np(shape)
        <span style="color:#75715e">#print(shape[30]) # coordinate of nose</span>
        cal <span style="color:#f92672">=</span> shape<span style="color:#f92672">-</span>shape[<span style="color:#ae81ff">30</span>]
        <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;######[X,Y]#######&#34;</span>,
              <span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74"> point18=&#34;</span>,cal[<span style="color:#ae81ff">17</span>],
              <span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74"> point22=&#34;</span>,cal[<span style="color:#ae81ff">21</span>],
              <span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74"> point37=&#34;</span>,cal[<span style="color:#ae81ff">36</span>],
              <span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74"> point40=&#34;</span>,cal[<span style="color:#ae81ff">39</span>],
              <span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74"> point28=&#34;</span>,cal[<span style="color:#ae81ff">27</span>],
              <span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74"> point31=&#34;</span>,cal[<span style="color:#ae81ff">30</span>],
              <span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74"> point32=&#34;</span>,cal[<span style="color:#ae81ff">31</span>],
              <span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74"> point49=&#34;</span>,cal[<span style="color:#ae81ff">48</span>],
              <span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74"> point58=&#34;</span>,cal[<span style="color:#ae81ff">57</span>],
              <span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74"> point9=&#34;</span>,cal[<span style="color:#ae81ff">8</span>])
        
        <span style="color:#66d9ef">for</span> (x, y) <span style="color:#f92672">in</span> shape: <span style="color:#75715e">#Plot 68 landmarks on the whole face</span>
            cv2<span style="color:#f92672">.</span>circle(frame, (x, y), <span style="color:#ae81ff">1</span>, (<span style="color:#ae81ff">255</span>, <span style="color:#ae81ff">255</span>, <span style="color:#ae81ff">255</span>), <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>)
            cv2<span style="color:#f92672">.</span>putText(frame,str((x, y)<span style="color:#f92672">-</span>shape[<span style="color:#ae81ff">30</span>]),(x,y), cv2<span style="color:#f92672">.</span>FONT_HERSHEY_PLAIN, <span style="color:#ae81ff">1.0</span>, (<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">255</span>), <span style="color:#ae81ff">2</span>)

    
    cv2<span style="color:#f92672">.</span>imshow(<span style="color:#e6db74">&#39;frame&#39;</span>,frame) <span style="color:#75715e"># show image</span>
    <span style="color:#66d9ef">if</span> cv2<span style="color:#f92672">.</span>waitKey(<span style="color:#ae81ff">1</span>) <span style="color:#f92672">&amp;</span> <span style="color:#ae81ff">0xFF</span> <span style="color:#f92672">==</span> ord(<span style="color:#e6db74">&#39;q&#39;</span>): press <span style="color:#75715e">#q to break and exit while</span>
        <span style="color:#66d9ef">break</span>

capture<span style="color:#f92672">.</span>release() <span style="color:#75715e">#video capture ends</span>
cv2<span style="color:#f92672">.</span>destroyAllWindows() <span style="color:#75715e"># close window</span>
</code></pre></div><p>#Finally
Finally, throw the whole program and end it.
Thank you for your hard work.</p>
<p>###program</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-HeadPoseEstimation.py" data-lang="HeadPoseEstimation.py"><span style="color:#f92672">import</span> cv2 <span style="color:#75715e">#OpenCV: Image processing library</span>
<span style="color:#f92672">import</span> dlib <span style="color:#75715e"># Machine learning library</span>
<span style="color:#f92672">import</span> imutils <span style="color:#75715e">#OpenCV assistance</span>
<span style="color:#f92672">from</span> imutils <span style="color:#f92672">import</span> face_utils
<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np


<span style="color:#75715e">#Get the VideoCapture object</span>
DEVICE_ID <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span> <span style="color:#75715e">#ID 0 is standard web cam</span>
capture <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>VideoCapture(DEVICE_ID)<span style="color:#75715e">#Read the learned data of dlib</span>
predictor_path <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;.../shape_predictor_68_face_landmarks.dat&#34;</span>

detector <span style="color:#f92672">=</span> dlib<span style="color:#f92672">.</span>get_frontal_face_detector() <span style="color:#75715e"># Face detector call. It only detects faces.</span>
predictor <span style="color:#f92672">=</span> dlib<span style="color:#f92672">.</span>shape_predictor(predictor_path) <span style="color:#75715e"># Output landmarks such as face, eyes and nose</span>

<span style="color:#66d9ef">while</span>(True): <span style="color:#75715e"># Acquire images continuously from the camera</span>
    ret, frame <span style="color:#f92672">=</span> capture<span style="color:#f92672">.</span>read() <span style="color:#75715e">#Capture from camera and put 1 frame of image data in frame</span>
    
    frame <span style="color:#f92672">=</span> imutils<span style="color:#f92672">.</span>resize(frame, width<span style="color:#f92672">=</span><span style="color:#ae81ff">1000</span>) <span style="color:#75715e"># Adjust the display size of the frame image</span>
    gray <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>cvtColor(frame, cv2<span style="color:#f92672">.</span>COLOR_BGR2GRAY) convert to <span style="color:#75715e">#gray scale</span>
    rects <span style="color:#f92672">=</span> detector(gray, <span style="color:#ae81ff">0</span>) <span style="color:#75715e"># detect faces from gray</span>
    image_points <span style="color:#f92672">=</span> None
     
    <span style="color:#66d9ef">for</span> rect <span style="color:#f92672">in</span> rects:
        shape <span style="color:#f92672">=</span> predictor(gray, rect)
        shape <span style="color:#f92672">=</span> face_utils<span style="color:#f92672">.</span>shape_to_np(shape)

        <span style="color:#66d9ef">for</span> (x, y) <span style="color:#f92672">in</span> shape: <span style="color:#75715e">#Plot 68 landmarks on the whole face</span>
            cv2<span style="color:#f92672">.</span>circle(frame, (x, y), <span style="color:#ae81ff">1</span>, (<span style="color:#ae81ff">255</span>, <span style="color:#ae81ff">255</span>, <span style="color:#ae81ff">255</span>), <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>)

        image_points <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array([
                tuple(shape[<span style="color:#ae81ff">30</span>]), <span style="color:#75715e">#nasal head</span>
                tuple(shape[<span style="color:#ae81ff">21</span>]),
                tuple(shape[<span style="color:#ae81ff">22</span>]),
                tuple(shape[<span style="color:#ae81ff">39</span>]),
                tuple(shape[<span style="color:#ae81ff">42</span>]),
                tuple(shape[<span style="color:#ae81ff">31</span>]),
                tuple(shape[<span style="color:#ae81ff">35</span>]),
                tuple(shape[<span style="color:#ae81ff">48</span>]),
                tuple(shape[<span style="color:#ae81ff">54</span>]),
                tuple(shape[<span style="color:#ae81ff">57</span>]),
                tuple(shape[<span style="color:#ae81ff">8</span>]),
                ],dtype<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;double&#39;</span>)
    
    <span style="color:#66d9ef">if</span> len(rects)<span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0</span>:
        model_points <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array([(<span style="color:#ae81ff">0.0</span>,<span style="color:#ae81ff">0.0</span>,<span style="color:#ae81ff">0.0</span>), <span style="color:#75715e"># 30</span>
                (<span style="color:#f92672">-</span><span style="color:#ae81ff">30.0</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">125.0</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">30.0</span>), <span style="color:#75715e"># 21</span>
                (<span style="color:#ae81ff">30.0</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">125.0</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">30.0</span>), <span style="color:#75715e"># 22</span>
                (<span style="color:#f92672">-</span><span style="color:#ae81ff">60.0</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">70.0</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">60.0</span>), <span style="color:#75715e"># 39</span>
                (<span style="color:#ae81ff">60.0</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">70.0</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">60.0</span>), <span style="color:#75715e"># 42</span>
                (<span style="color:#f92672">-</span><span style="color:#ae81ff">40.0</span>,<span style="color:#ae81ff">40.0</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">50.0</span>), <span style="color:#75715e"># 31</span>
                (<span style="color:#ae81ff">40.0</span>,<span style="color:#ae81ff">40.0</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">50.0</span>), <span style="color:#75715e"># 35</span>
                (<span style="color:#f92672">-</span><span style="color:#ae81ff">70.0</span>,<span style="color:#ae81ff">130.0</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">100.0</span>), <span style="color:#75715e"># 48</span>
                (<span style="color:#ae81ff">70.0</span>,<span style="color:#ae81ff">130.0</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">100.0</span>), <span style="color:#75715e"># 54</span>
                (<span style="color:#ae81ff">0.0</span>,<span style="color:#ae81ff">158.0</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">10.0</span>), <span style="color:#75715e"># 57</span>
                (<span style="color:#ae81ff">0.0</span>,<span style="color:#ae81ff">250.0</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">50.0</span>) <span style="color:#75715e"># 8</span>
                ])

        size <span style="color:#f92672">=</span> frame<span style="color:#f92672">.</span>shape

        focal_length <span style="color:#f92672">=</span> size[<span style="color:#ae81ff">1</span>]
        center <span style="color:#f92672">=</span> (size[<span style="color:#ae81ff">1</span>] <span style="color:#f92672">//</span> <span style="color:#ae81ff">2</span>, size[<span style="color:#ae81ff">0</span>] <span style="color:#f92672">//</span> <span style="color:#ae81ff">2</span>) <span style="color:#75715e">#顔の中心座標</span>

        camera_matrix <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array([
            [focal_length, <span style="color:#ae81ff">0</span>, center[<span style="color:#ae81ff">0</span>]],
            [<span style="color:#ae81ff">0</span>, focal_length, center[<span style="color:#ae81ff">1</span>]],
            [<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>]
        ], dtype<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;double&#39;</span>)

        dist_coeffs <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>zeros((<span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">1</span>))

        (success, rotation_vector, translation_vector) <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>solvePnP(model_points, image_points, camera_matrix,
                                                                      dist_coeffs, flags<span style="color:#f92672">=</span>cv2<span style="color:#f92672">.</span>SOLVEPNP_ITERATIVE)
        <span style="color:#75715e">#回転行列とヤコビアン</span>
        (rotation_matrix, jacobian) <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>Rodrigues(rotation_vector)
        mat <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>hstack((rotation_matrix, translation_vector))

        <span style="color:#75715e">#yaw,pitch,rollの取り出し</span>
        (_, _, _, _, _, _, eulerAngles) <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>decomposeProjectionMatrix(mat)
        yaw <span style="color:#f92672">=</span> eulerAngles[<span style="color:#ae81ff">1</span>]
        pitch <span style="color:#f92672">=</span> eulerAngles[<span style="color:#ae81ff">0</span>]
        roll <span style="color:#f92672">=</span> eulerAngles[<span style="color:#ae81ff">2</span>]
        
        <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;yaw&#34;</span>,int(yaw),<span style="color:#e6db74">&#34;pitch&#34;</span>,int(pitch),<span style="color:#e6db74">&#34;roll&#34;</span>,int(roll))<span style="color:#75715e">#頭部姿勢データの取り出し</span>

        cv2<span style="color:#f92672">.</span>putText(frame, <span style="color:#e6db74">&#39;yaw : &#39;</span> <span style="color:#f92672">+</span> str(int(yaw)), (<span style="color:#ae81ff">20</span>, <span style="color:#ae81ff">10</span>), cv2<span style="color:#f92672">.</span>FONT_HERSHEY_PLAIN, <span style="color:#ae81ff">1</span>, (<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">255</span>), <span style="color:#ae81ff">2</span>)
        cv2<span style="color:#f92672">.</span>putText(frame, <span style="color:#e6db74">&#39;pitch : &#39;</span> <span style="color:#f92672">+</span> str(int(pitch)), (<span style="color:#ae81ff">20</span>, <span style="color:#ae81ff">25</span>), cv2<span style="color:#f92672">.</span>FONT_HERSHEY_PLAIN, <span style="color:#ae81ff">1</span>, (<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">255</span>), <span style="color:#ae81ff">2</span>)
        cv2<span style="color:#f92672">.</span>putText(frame, <span style="color:#e6db74">&#39;roll : &#39;</span> <span style="color:#f92672">+</span> str(int(roll)), (<span style="color:#ae81ff">20</span>, <span style="color:#ae81ff">40</span>), cv2<span style="color:#f92672">.</span>FONT_HERSHEY_PLAIN, <span style="color:#ae81ff">1</span>, (<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">255</span>), <span style="color:#ae81ff">2</span>)

        (nose_end_point2D, _) <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>projectPoints(np<span style="color:#f92672">.</span>array([(<span style="color:#ae81ff">0.0</span>, <span style="color:#ae81ff">0.0</span>, <span style="color:#ae81ff">500.0</span>)]), rotation_vector,
                                                         translation_vector, camera_matrix, dist_coeffs)
        <span style="color:#75715e">#計算に使用した点のプロット/顔方向のベクトルの表示</span>
        <span style="color:#66d9ef">for</span> p <span style="color:#f92672">in</span> image_points:
            cv2<span style="color:#f92672">.</span>drawMarker(frame, (int(p[<span style="color:#ae81ff">0</span>]), int(p[<span style="color:#ae81ff">1</span>])),  (<span style="color:#ae81ff">0.0</span>, <span style="color:#ae81ff">1.409845</span>, <span style="color:#ae81ff">255</span>),markerType<span style="color:#f92672">=</span>cv2<span style="color:#f92672">.</span>MARKER_CROSS, thickness<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)

        p1 <span style="color:#f92672">=</span> (int(image_points[<span style="color:#ae81ff">0</span>][<span style="color:#ae81ff">0</span>]), int(image_points[<span style="color:#ae81ff">0</span>][<span style="color:#ae81ff">1</span>]))
        p2 <span style="color:#f92672">=</span> (int(nose_end_point2D[<span style="color:#ae81ff">0</span>][<span style="color:#ae81ff">0</span>][<span style="color:#ae81ff">0</span>]), int(nose_end_point2D[<span style="color:#ae81ff">0</span>][<span style="color:#ae81ff">0</span>][<span style="color:#ae81ff">1</span>]))

        cv2<span style="color:#f92672">.</span>arrowedLine(frame, p1, p2, (<span style="color:#ae81ff">255</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>), <span style="color:#ae81ff">2</span>)
    
    cv2<span style="color:#f92672">.</span>imshow(<span style="color:#e6db74">&#39;frame&#39;</span>,frame) <span style="color:#75715e"># 画像を表示する</span>
    <span style="color:#66d9ef">if</span> cv2<span style="color:#f92672">.</span>waitKey(<span style="color:#ae81ff">1</span>) <span style="color:#f92672">&amp;</span> <span style="color:#ae81ff">0xFF</span> <span style="color:#f92672">==</span> ord(<span style="color:#e6db74">&#39;q&#39;</span>): <span style="color:#75715e">#qを押すとbreakしてwhileから抜ける</span>
        <span style="color:#66d9ef">break</span>


capture<span style="color:#f92672">.</span>release() <span style="color:#75715e">#video captureを終了する</span>
cv2<span style="color:#f92672">.</span>destroyAllWindows() <span style="color:#75715e">#windowを閉じる</span>

</code></pre></div><p>#2020/4/2追記
##OpenCVがQt関連のエラーで動かない！
最近こんなエラーが出ました</p>
<pre><code>qt.qpa.plugin: Could not find the Qt platform plugin &quot;cocoa&quot; in &quot;&quot;
This application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem.
</code></pre><p>どうも新しくopenCVをpipインストールするとこんなエラーが出るみたいです。
バージョンを下げると動きます。</p>
<pre><code>pip3 install opencv-python==4.1.2.30
</code></pre><p>#参考まとめ</p>
<p>###Qiita
<a href="https://qiita.com/nonbiri15/items/f6910a993457a186263">顔向き推定について調査中</a></p>
<p>###外部
<a href="https://www.learnopencv.com/head-pose-estimation-using-opencv-and-dlib/">Head Pose Estimation using OpenCV and Dlib</a>
<a href="http://dlib.net/python/index.html">dlib documentation</a>
<a href="https://www.pyimagesearch.com/2017/04/03/facial-landmarks-dlib-opencv-python/">Facial landmarks with dlib, OpenCV, and Python</a></p>

    </article>
  </div>

  
  
  
  <script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-169005401-1', 'auto');
  ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  

  
<link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.css" />
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#216942",
      "text": "#b2d192"
    },
    "button": {
      "background": "#afed71"
    }
  }
})});
</script>

</body>

</html>
