<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  <meta name="generator" content="Hugo 0.72.0" />

  
  <meta name="description" content="Some description">
  

  
  <link rel="apple-touch-icon" sizes="180x180" href="https://memotut.com/apple-touch-icon.png">

  
  <link rel="icon" type="image/png" sizes="32x32" href="https://memotut.com/favicon-32x32.png">

  
  <link rel="icon" type="image/png" sizes="16x16" href="https://memotut.com/favicon-16x16.png">

  
  <link rel="manifest" href="https://memotut.com/site.webmanifest">

  
  <link rel="mask-icon" href="https://memotut.com/safari-pinned-tab.svg" color="#5bbad5">

  <meta name="msapplication-TileColor" content="#da532c">

  <meta name="theme-color" content="#ffffff">

  
  <link rel="stylesheet" href="https://memotut.com/css/bootstrap.min.css" />

  
  <title>How to Data Augmentation with PyTorch | Memo Tut</title>
  

  <style>
body {
  min-width: 300px;
}

.custom-navbar {
  margin-bottom: 1em;
  height: 60px;
}

.custom-navbar a {
  display: inline-block; 
  padding: 18px 0;
  margin-right: 1em; 
  font-weight: bold; 
}

.custom-navbar a:hover,
.custom-navbar a:focus {
  text-decoration: none; 
}

@media print {
  .custom-navbar {
    display: none;
  }
}

article {
  padding-bottom: 1em;
}

img {
  max-width: 100%;
}


body {
  background-color: #fff;
}



body {
  color: #212529;
}



a {
  color: #007bff;
}



a:hover,
a:focus {
  color: #0056b3;
}



.custom-navbar {
  background-color: #212529;
}



.custom-navbar a {
  color: rgba(255, 255, 255, 0.75);
}



.custom-navbar a:hover,
.custom-navbar a:focus {
  color: rgba(255, 255, 255, 1);
}



.container {
  max-width: 800px;
}



pre {
  display: block;
  padding: 9.5px;
  word-break: break-all;
  word-wrap: break-word;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre code {
  padding: 0;
  font-size: inherit;
  color: inherit; 
  white-space: pre-wrap;
  background-color: transparent;
  border: none;
  border-radius: 0;
}

code {
  padding: 2px 4px;
  color: inherit; 
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
  font-size: .9em;
}



blockquote,
.blockquote {
  padding: 10px 20px;
  margin: 0 0 20px;
  font-size: 1em;
  border-left: 5px solid #6c757d;
}

</style>
</head>

<body>
  <nav class="custom-navbar">
  <div class="container">
    
    <a href="/">Posts</a>
    
    <a href="/tags/">Tags</a>
    
    <a href="/about/">About</a>
    
    <a href="/index.xml">RSS</a>
    
  </div>
</nav>
  
  <div class="container">
    <article>
      <h1>How to Data Augmentation with PyTorch</h1>
<p>
  <small class="text-secondary">
  
  
  Mar 16, 2020
  </small>
  

<small><code><a href="https://memotut.com/tags/python">Python</a></code></small>


<small><code><a href="https://memotut.com/tags/pytorch">PyTorch</a></code></small>


<small><code><a href="https://memotut.com/tags/dataaugmentation">dataaugmentation</a></code></small>


<small><code><a href="https://memotut.com/tags/googlecolaboratory">GoogleColaboratory</a></code></small>


<small><code><a href="https://memotut.com/tags/albumentations">albumentations</a></code></small>

</p>
<pre><code>Inflating data with #PyTorch (Data Augmentation)
</code></pre>
<p>I will summarize the method of padding data with PyTorch. Regarding PyTorch itself, I wrote an introductory article on the blog before, so please refer to the following if you like.</p>
<p><a href="https://karaage.hatenadiary.jp/entry/2020/02/03/073000">Introduction to the featured deep learning framework &ldquo;PyTorch&rdquo;</a></p>
<p>Please refer to the following article for the reason for implementing data padding and specific examples.</p>
<p><a href="https://karaage.hatenadiary.jp/entry/2019/07/22/073000">Image Augmentation Method for Improving Deep Learning Accuracy by Playing with Free Materials</a></p>
<p>Also, this article is written on the assumption that it will be executed on &ldquo;Google Colaboratory (Google Colab)&rdquo;. Google Colab itself is beyond the scope of this article. If you do not know, please refer to the following article.</p>
<p><a href="https://karaage.hatenadiary.jp/entry/2018/03/21/073000">Use of Google Colaboratory does not require environment construction and is the best to do Python machine learning for free</a></p>
<p>The code used in this article is summarized in the notebook below.</p>
<p><a href="https://github.com/karaage0703/pytorch-example/blob/master/pytorch_data_preprocessing.ipynb">pytorch_data_preprocessing.ipynb</a></p>
<p>Click the &ldquo;Open in Colab&rdquo; icon in the middle to open it in Google Colab and run it as is.</p>
<h1 id="handling-data-in-pytorch">Handling data in PyTorch</h1>
<p>First, let&rsquo;s check how data is handled in PyTorch.</p>
<h2 id="download-teacher-data">Download teacher data</h2>
<p>First, download the teacher data. The description is omitted.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-sh" data-lang="sh">!git clone https://github.com/karaage0703/janken_dataset datasets
!rm -rf /content/datasets/.git
!rm /content/datasets/LICENSE
</code></pre></div><p>The directory has the following structure. choki, gu, pa, each directory contains pictures of the hands of choki, gu and par.</p>
<pre><code>datasets
├── choki
├── gu
└── pa
</code></pre><p>≪Define <code>dataset_root_dir</code> as follows.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">dataset_root_dir <span style="color:#f92672">=</span><span style="color:#e6db74">&#39;/content/datasets&#39;</span>
</code></pre></div><h2 id="creating-a-dataset">Creating a dataset</h2>
<p>First, import the necessary libraries.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> torch
<span style="color:#f92672">from</span> torchvision <span style="color:#f92672">import</span> transforms, datasets
<span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#f92672">as</span> plt
<span style="color:#f92672">import</span> PIL
</code></pre></div><p>Use ImageFolder to load the images in the folder as a dataset.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">dataset <span style="color:#f92672">=</span> datasets<span style="color:#f92672">.</span>ImageFolder(root<span style="color:#f92672">=</span>dataset_root_dir)
</code></pre></div><h2 id="check-the-dataset">Check the dataset</h2>
<p>You can check the contents of the dataset with getitem. (The following is the execution result).</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">print</span>(dataset<span style="color:#f92672">.</span>__getitem__(<span style="color:#ae81ff">0</span>))
<span style="color:#66d9ef">print</span>(dataset<span style="color:#f92672">.</span>__getitem__(<span style="color:#ae81ff">100</span>))
<span style="color:#66d9ef">print</span>(dataset<span style="color:#f92672">.</span>__getitem__(<span style="color:#ae81ff">150</span>))
<span style="color:#75715e"># (&lt;PIL.Image.Image image mode=RGB size=320x240 at 0x7F11DB6DC160&gt;, 0)</span>
<span style="color:#75715e"># (&lt;PIL.Image.Image image mode=RGB size=320x240 at 0x7F11DB6DCF28&gt;, 1)</span>
<span style="color:#75715e"># (&lt;PIL.Image.Image image mode=RGB size=320x240 at 0x7F12297D2C50&gt;, 2)</span>
</code></pre></div><p>The following is to check the contents with matplotlib.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">image_numb <span style="color:#f92672">=</span> <span style="color:#ae81ff">6</span> Please specify a multiple of <span style="color:#ae81ff">3</span>
<span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">0</span>, image_numb):
  ax <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>subplot(image_numb <span style="color:#f92672">/</span> <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>, i <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>)
  plt<span style="color:#f92672">.</span>tight_layout()
  ax<span style="color:#f92672">.</span>set_title(str(i))
  plt<span style="color:#f92672">.</span>imshow(dataset[i][<span style="color:#ae81ff">0</span>])
</code></pre></div><p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/81919/2e08c490-33ba-d689-47fb-b9d0f9665009.png" alt="data_01.png"></p>
<h1 id="torchvisiontransforms">torchvision.transforms</h1>
<p>With PyTorch, you can perform pre-processing of various image processing including Data Augmentation with transforms.</p>
<p>For typical left/right inversion/vertical inversion, transforms are written in the following form.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">data_transform <span style="color:#f92672">=</span> transforms<span style="color:#f92672">.</span>Compose((
    transforms<span style="color:#f92672">.</span>RandomHorizontalFlip(),
    transforms<span style="color:#f92672">.</span>RandomVerticalFlip(),
])
</code></pre></div><p>After that, if you specify it in the argument of transform of ImageFolder, the dataset that has undergone the image processing specified in transforms will be defined.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">dataset_augmentated <span style="color:#f92672">=</span> datasets<span style="color:#f92672">.</span>ImageFolder(root<span style="color:#f92672">=</span>dataset_root_dir, transform<span style="color:#f92672">=</span>data_transform)
</code></pre></div><p>I will check the data.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">image_numb <span style="color:#f92672">=</span> <span style="color:#ae81ff">6</span> Please specify a multiple of <span style="color:#ae81ff">3</span>
<span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">0</span>, image_numb):
  ax <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>subplot(image_numb <span style="color:#f92672">/</span> <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>, i <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>)
  plt<span style="color:#f92672">.</span>tight_layout()
  ax<span style="color:#f92672">.</span>set_title(str(i))
  plt<span style="color:#f92672">.</span>imshow(dataset_augmentated[i][<span style="color:#ae81ff">0</span>])
</code></pre></div><p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/81919/eb81d118-79ef-ef89-bd72-6d33a0e37e97.png" alt="data_02.png"></p>
<p>It is upside down.</p>
<p>Please refer to the Google Colab notebook for examples of other transforms functions. Techniques such as Random Erasing are also implemented as standard. If you want to know everything, please refer to the official document.</p>
<h1 id="albumentations-implementation">albumentations implementation</h1>
<p>This is a method to easily use the library for Data Augmentation called albumations in PyTorch.</p>
<p>First, install albumations with the following command.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-sh" data-lang="sh">! pip install albumentations
</code></pre></div><p>Import the required libraries.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> albumentations <span style="color:#f92672">as</span> albu
<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">from</span> PIL <span style="color:#f92672">import</span> Image
</code></pre></div><p>Similar to the case of transform, I would like to pad the data with albumation with ImageFolder, but a little technique is required.</p>
<p>The function of albumations can be easily used with Image Folder by doing the following.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">albu_transforms <span style="color:#f92672">=</span> albu<span style="color:#f92672">.</span>Compose((
  albu<span style="color:#f92672">.</span>RandomRotate90(p<span style="color:#f92672">=</span><span style="color:#ae81ff">0.5</span>),
  albu<span style="color:#f92672">.</span>RandomGamma(gamma_limit<span style="color:#f92672">=</span>(<span style="color:#ae81ff">85</span>, <span style="color:#ae81ff">115</span>), p<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>),
])

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">albumentations_transform</span>(image, transform<span style="color:#f92672">=</span>albu_transforms):
  <span style="color:#66d9ef">if</span> transform:
    image_np <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(image)
    augmented <span style="color:#f92672">=</span> transform(image<span style="color:#f92672">=</span>image_np)
    image <span style="color:#f92672">=</span> Image<span style="color:#f92672">.</span>fromarray(augmented[<span style="color:#e6db74">&#39;image&#39;</span>])
  <span style="color:#66d9ef">return</span> image

data_transform <span style="color:#f92672">=</span> transforms<span style="color:#f92672">.</span>Compose((
  transforms<span style="color:#f92672">.</span>Lambda(albumentations_transform),
])

dataset_augmentated <span style="color:#f92672">=</span> datasets<span style="color:#f92672">.</span>ImageFolder(root<span style="color:#f92672">=</span>dataset_root_dir, transform<span style="color:#f92672">=</span>data_transform)
</code></pre></div><p>I will check the contents of the data.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">image_numb <span style="color:#f92672">=</span> <span style="color:#ae81ff">6</span> Please specify a multiple of <span style="color:#ae81ff">3</span>
<span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">0</span>, image_numb):
  ax <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>subplot(image_numb <span style="color:#f92672">/</span> <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>, i <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>)
  plt<span style="color:#f92672">.</span>tight_layout()
  ax<span style="color:#f92672">.</span>set_title(str(i))
  plt<span style="color:#f92672">.</span>imshow(dataset_augmentated[i][<span style="color:#ae81ff">0</span>])
</code></pre></div><p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/81919/2f3e1718-8ef4-ca3b-651d-1fd9040013b7.png" alt="data_albu.png"></p>
<p>You can see that the image processing of albumations is being performed.</p>
<p>It seems that in many cases when using observations, you often implement your own dataset without using ImageFolder, but it is a convenient technique when you want to try it easily with ImageFolder.</p>
<p>@Kazuhito&rsquo;s Jupiter Notebook of <a href="https://github.com/Kazuhito00/albumentations-examples">albumentations-examples</a> published on GitHub is very helpful for what kind of functions albumentations have. Become.</p>
<p>Also, the notebook that @Kazuhito&rsquo;s Jupyter Notebook has been modified to work with Google Colab is published below, so please refer to those who want to actually move it with their own hands.<a href="https://github.com/karaage0703/pytorch-example/blob/master/albumentations_examples.ipynb">albumentations_examples.ipynb (Google Colab compatible version)</a></p>
<h1 id="mixup">mixup</h1>
<p>The following GitHub repository was used as a reference when using the data inflating technique mixup in PyTorch due to its performance.</p>
<p><a href="https://github.com/hongyi-zhang/mixup">hongyi-zhang/mixup</a></p>
<p>Please refer to the Google Colab notebook for details on how to mix up and how to check the data after mixing up.</p>
<p><a href="https://github.com/karaage0703/pytorch-example/blob/master/pytorch_data_preprocessing.ipynb">pytorch_data_preprocessing.ipynb</a></p>
<p>In case of Keras, the following articles are likely to be helpful.</p>
<p><a href="https://st1990.hatenablog.com/entry/2019/03/02/131554">Keras mixup augmentation</a></p>
<p>#Summary
↑We have summarized the method for data augmentation with PyTorch and the method for checking data. Please let us know if there are more convenient functions or smart ways.</p>
<h1 id="related-article">Related article</h1>
<p><a href="https://qiita.com/karaage0703/items/cba4e6f284cc81070a45">Move and check what you are doing with Data Augmentation of Object Detection API of TensorFlow</a></p>

    </article>
  </div>

  
  
  
  <script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-169005401-1', 'auto');
  ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  

  
<link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.css" />
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#216942",
      "text": "#b2d192"
    },
    "button": {
      "background": "#afed71"
    }
  }
})});
</script>

</body>

</html>
