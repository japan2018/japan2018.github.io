<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  <meta name="generator" content="Hugo 0.72.0" />

  
  <meta name="description" content="Some description">
  

  
  <link rel="apple-touch-icon" sizes="180x180" href="https://memotut.com/apple-touch-icon.png">

  
  <link rel="icon" type="image/png" sizes="32x32" href="https://memotut.com/favicon-32x32.png">

  
  <link rel="icon" type="image/png" sizes="16x16" href="https://memotut.com/favicon-16x16.png">

  
  <link rel="manifest" href="https://memotut.com/site.webmanifest">

  
  <link rel="mask-icon" href="https://memotut.com/safari-pinned-tab.svg" color="#5bbad5">

  <meta name="msapplication-TileColor" content="#da532c">

  <meta name="theme-color" content="#ffffff">

  
  <link rel="stylesheet" href="https://memotut.com/css/bootstrap.min.css" />

  
  <title>Library tsfresh that automatically extracts features from time series data | Memo Tut</title>
  

  <style>
body {
  min-width: 300px;
}

.custom-navbar {
  margin-bottom: 1em;
  height: 60px;
}

.custom-navbar a {
  display: inline-block; 
  padding: 18px 0;
  margin-right: 1em; 
  font-weight: bold; 
}

.custom-navbar a:hover,
.custom-navbar a:focus {
  text-decoration: none; 
}

@media print {
  .custom-navbar {
    display: none;
  }
}

article {
  padding-bottom: 1em;
}

img {
  max-width: 100%;
}


body {
  background-color: #fff;
}



body {
  color: #212529;
}



a {
  color: #007bff;
}



a:hover,
a:focus {
  color: #0056b3;
}



.custom-navbar {
  background-color: #212529;
}



.custom-navbar a {
  color: rgba(255, 255, 255, 0.75);
}



.custom-navbar a:hover,
.custom-navbar a:focus {
  color: rgba(255, 255, 255, 1);
}



.container {
  max-width: 800px;
}



pre {
  display: block;
  padding: 9.5px;
  word-break: break-all;
  word-wrap: break-word;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre code {
  padding: 0;
  font-size: inherit;
  color: inherit; 
  white-space: pre-wrap;
  background-color: transparent;
  border: none;
  border-radius: 0;
}

code {
  padding: 2px 4px;
  color: inherit; 
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
  font-size: .9em;
}



blockquote,
.blockquote {
  padding: 10px 20px;
  margin: 0 0 20px;
  font-size: 1em;
  border-left: 5px solid #6c757d;
}

</style>
</head>

<body>
  <nav class="custom-navbar">
  <div class="container">
    
    <a href="/">Posts</a>
    
    <a href="/tags/">Tags</a>
    
    <a href="/about/">About</a>
    
    <a href="/index.xml">RSS</a>
    
  </div>
</nav>
  
  <div class="container">
    <article>
      <h1>Library tsfresh that automatically extracts features from time series data</h1>
<p>
  <small class="text-secondary">
  
  
  Dec 2, 2019
  </small>
  

<small><code><a href="https://memotut.com/tags/python">Python</a></code></small>


<small><code><a href="https://memotut.com/tags/feature-engineering"> feature engineering</a></code></small>


<small><code><a href="https://memotut.com/tags/tsfresh"> tsfresh</a></code></small>

</p>
<pre><code>On the 5th day of [Ateam Lifestyle Advent Calendar 2019](https://qiita.com/advent-calendar/2019/ateam-lifestyle),
</code></pre>
<p>Ateam Lifestyle Co., Ltd. CTO Office Engineer Kobayashi is in charge.
The company is working on a machine learning project.</p>
<p>#Introduction</p>
<p>Recently, I have been working on time series data at work, and a convenient library called <a href="https://tsfresh.readthedocs.io/en/latest/index.html">tsfresh</a> that automatically extracts features from time series data. It was introduced because I used.
The order of time-series data has meaning, but since the meaning of the order was not well defined, the background was that we investigated the feature extraction method.
In the example of forecasting time series data,</p>
<ul>
<li>Predict future sales from past product sales</li>
<li>Predict next action from user&rsquo;s action log</li>
<li>Detect anomalies from the data captured by the sensor</li>
</ul>
<p>And so on. In each case, it is expected that it will be more accurate to handle the data in order, rather than to handle the data arranged in chronological order individually.
Since tsfresh extracts features from time series data, it seems that it can contribute to accuracy improvement.</p>
<p>There is a <a href="https://github.com/blue-yonder/tsfresh/blob/master/notebooks/human_activity_recognition_multi_class_example.ipynb">how to use notebook</a>onGithuboftsfresh,sopleaserefertoit<a href="https://colab.research.google.com/notebooks/welcome.ipynb?hl=ja#scrollTo=xitplqMNk_Hc">GoogleColaboratory</a>.
Google Colaboratory is an environment where you can use Jupyter Notebook for free.
Its use is limited to machine learning research and education, but it is recommended because it is a great service that you can use GPU and TPU for free and have a Python library for machine learning from the beginning.</p>
<p>#Preparation</p>
<p>First, install tsfresh.
The following is the description method on Jupyter Notebook.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#960050;background-color:#1e0010">!</span>pip install tsfresh
</code></pre></div><p>Import required packages</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#f92672">%</span>matplotlib inline
<span style="color:#f92672">import</span> matplotlib.pylab <span style="color:#f92672">as</span> plt
<span style="color:#f92672">from</span> tsfresh.examples.har_dataset <span style="color:#f92672">import</span> download_har_dataset, load_har_dataset, load_har_classes
<span style="color:#f92672">from</span> tsfresh <span style="color:#f92672">import</span> extract_features, extract_relevant_features, select_features
<span style="color:#f92672">from</span> sklearn.model_selection <span style="color:#f92672">import</span> train_test_split
<span style="color:#f92672">from</span> sklearn.metrics <span style="color:#f92672">import</span> classification_report
<span style="color:#f92672">import</span> xgboost <span style="color:#f92672">as</span> xgb
<span style="color:#f92672">import</span> pandas <span style="color:#f92672">as</span> pd
<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
</code></pre></div><p>Download data</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#75715e"># fetch dataset from uci</span>
download_har_dataset()
df <span style="color:#f92672">=</span> load_har_dataset()
<span style="color:#66d9ef">print</span>(df<span style="color:#f92672">.</span>head())
df<span style="color:#f92672">.</span>shape
</code></pre></div><pre><code>        0 1 2 ... 125 126 127
0 0.000181 0.010139 0.009276 ... -0.001147 -0.000222 0.001576
1 0.001094 0.004550 0.002879 ... -0.004646 -0.002941 -0.001599
2 0.003531 0.002285 -0.000420 ... 0.001246 0.003117 0.002178
3 -0.001772 -0.001311 0.000388 ... -0.000867 -0.001172 -0.000028
4 0.000087 -0.000272 0.001022 ... -0.000698 -0.001223 -0.003328

[5 rows x 128 columns]
(7352, 128)
</code></pre><p>This data is the value of 128 time series acceleration sensors in each line,
It seems to be classified into 6 categories (walking, climbing stairs, descending stairs, sitting, standing, sleeping).
Data source: <a href="https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones">https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones</a></p>
<p>Let&rsquo;s display one line as a graph.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#39;accelerometer reading&#39;</span>)
plt<span style="color:#f92672">.</span>plot(df<span style="color:#f92672">.</span>ix[<span style="color:#ae81ff">0</span>,:])
plt<span style="color:#f92672">.</span>show()
</code></pre></div><p>![Screenshot 2019-12-02 6.29.13.png](<a href="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/12305/3d905233-a18a-38f9-43f2-(6b313156256c.png)">https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/12305/3d905233-a18a-38f9-43f2-(6b313156256c.png)</a></p>
<h1 id="feature-extraction">Feature extraction</h1>
<p>Sample and shape the data.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">N <span style="color:#f92672">=</span> <span style="color:#ae81ff">500</span>
master_df <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame({<span style="color:#ae81ff">0</span>: df[:N]<span style="color:#f92672">.</span>values<span style="color:#f92672">.</span>flatten(),
                          <span style="color:#ae81ff">1</span>: np<span style="color:#f92672">.</span>arange(N)<span style="color:#f92672">.</span>repeat(df<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">1</span>])})
master_df<span style="color:#f92672">.</span>head()
</code></pre></div><pre><code>0 1
0 0.000181 0
1 0.010139 0
2 0.009276 0
3 0.005066 0
4 0.010810 0
</code></pre><p>In order to handle tsfresh, the data that was arranged in 128 columns horizontally is rearranged vertically. Column 0 is data and column 1 is index (row number of original data).
We will extract features using this data.
The column of the index is specified by column_id.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">X <span style="color:#f92672">=</span> extract_features(master_df, column_id<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</code></pre></div><pre><code>Feature Extraction: 100%|██████████| 5/5 [01:02&lt;00:00, 12.48s/it]
</code></pre><p>It took about 1 minute with 500 lines.
It actually takes a lot of time when trying with 100,000 or more rows of data, and it also required memory, so it seems necessary to devise it when applying it to large-scale data.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">X<span style="color:#f92672">.</span>shape
</code></pre></div><pre><code>(500, 754)
</code></pre><p>As many as 754 features have been extracted.
Although the details have not been confirmed in detail, it seems that various features such as Fourier transform are calculated from basic things such as average and median.</p>
<h1 id="accuracy-verification">Accuracy verification</h1>
<p>Try learning and prediction using the extracted features.
First, prepare teacher data.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">y <span style="color:#f92672">=</span> load_har_classes()[:N]
y<span style="color:#f92672">.</span>hist(bins<span style="color:#f92672">=</span><span style="color:#ae81ff">12</span>)
</code></pre></div><p>![Screenshot 2019-12-02 8.55.10.png](<a href="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/12305/2e7bb488-5c3e-7436-f303-(ff28768252b6.png)">https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/12305/2e7bb488-5c3e-7436-f303-(ff28768252b6.png)</a></p>
<p>It seems unlikely that there will be such extreme variations.
It is divided into learning data and test data.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">X_train, X_test, y_train, y_test <span style="color:#f92672">=</span> train_test_split(X, y, test_size<span style="color:#f92672">=.</span><span style="color:#ae81ff">2</span>)
</code></pre></div><p>Let&rsquo;s try learning and prediction with xgboost.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">cl <span style="color:#f92672">=</span> xgb<span style="color:#f92672">.</span>XGBClassifier()
cl<span style="color:#f92672">.</span>fit(X_train, y_train)
<span style="color:#66d9ef">print</span>(classification_report(y_test, cl<span style="color:#f92672">.</span>predict(X_test)))
</code></pre></div><pre><code>              precision recall f1-score support

           1 1.00 1.00 1.00 24
           2 1.00 1.00 1.00 11
           3 1.00 1.00 1.00 12
           4 0.62 0.53 0.57 15
           5 0.70 0.74 0.72 19
           6 0.60 0.63 0.62 19

    accuracy 0.81 100
   macro avg 0.82 0.82 0.82 100
weighted avg 0.81 0.81 0.81 100
</code></pre><p>It seems that the accuracy is about 80%.
Let&rsquo;s also look at the importance of features.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">importances <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>Series(index<span style="color:#f92672">=</span>X_train<span style="color:#f92672">.</span>columns, data<span style="color:#f92672">=</span>cl<span style="color:#f92672">.</span>feature_importances_)
importances<span style="color:#f92672">.</span>sort_values(ascending<span style="color:#f92672">=</span>False)<span style="color:#f92672">.</span>head(<span style="color:#ae81ff">10</span>)
</code></pre></div><pre><code>variable
0__spkt_welch_density__coeff_8 0.054569
0__time_reversal_asymmetry_statistic__lag_3 0.041737
0__agg_linear_trend__f_agg_&quot;max&quot;__chunk_len_5__attr_&quot;stderr&quot; 0.036145
0__standard_deviation 0.035886
0__change_quantiles__f_agg_&quot;var&quot;__isabs_False__qh_0.4__ql_0.0 0.028676
0__spkt_welch_density__coeff_2 0.027741
0__augmented_dickey_fuller__attr_&quot;pvalue&quot; 0.0191720__autocorrelation__lag_2 0.018580
0__linear_trend__attr_&quot;stderr&quot; 0.018235
0__cid_ce__normalize_True 0.018181
dtype: float32
</code></pre><p>It seems that you can understand what kind of feature quantity you are making from the variable name.
Let&rsquo;s also train on the original data set for comparison.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">X_1 <span style="color:#f92672">=</span> df<span style="color:#f92672">.</span>ix[:N<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>,:]
X_1<span style="color:#f92672">.</span>shape
</code></pre></div><pre><code>(500, 128)
</code></pre><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">X_train, X_test, y_train, y_test <span style="color:#f92672">=</span> train_test_split(X_1, y, test_size<span style="color:#f92672">=.</span><span style="color:#ae81ff">2</span>)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">cl <span style="color:#f92672">=</span> xgb<span style="color:#f92672">.</span>XGBClassifier()
cl<span style="color:#f92672">.</span>fit(X_train, y_train)
<span style="color:#66d9ef">print</span>(classification_report(y_test, cl<span style="color:#f92672">.</span>predict(X_test)))
</code></pre></div><pre><code>              precision recall f1-score support

           1 0.79 0.83 0.81 36
           2 0.71 0.67 0.69 15
           3 0.58 0.58 0.58 12
           4 0.25 0.43 0.32 7
           5 0.67 0.53 0.59 19
           6 0.44 0.36 0.40 11

    accuracy 0.64 100
   macro avg 0.57 0.57 0.56 100
weighted avg 0.65 0.64 0.64 100
</code></pre><p>The original data is about 64% accurate, so the data extracted by tsfresh is more accurate.</p>
<p>#Summary</p>
<p>We were able to improve the accuracy by extracting the features from the time series data using tsfresh.
Before extraction, the order of the time series data was not meaningful, so I think that it is the result that can be meaningful,
I haven&rsquo;t seen in detail what data was extracted, so I would like to investigate what kind of data it was.</p>
<p>@Maonem will send you on the 7th day of <a href="https://qiita.com/advent-calendar/2019/ateam-lifestyle">Ateam Lifestyle Advent Calendar 2019</a>. I&rsquo;m looking forward to it!</p>
<p>The Ateam Group, which values &ldquo;challenge&rdquo;, is looking for colleagues with a strong challenge spirit to work together. If you are interested, please visit the Ateam Group recruitment site.
<a href="https://www.a-tm.co.jp/recruit/">https://www.a-tm.co.jp/recruit/</a></p>

    </article>
  </div>

  
  
  
  <script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-169005401-1', 'auto');
  ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  

  
<link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.css" />
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#216942",
      "text": "#b2d192"
    },
    "button": {
      "background": "#afed71"
    }
  }
})});
</script>

</body>

</html>
