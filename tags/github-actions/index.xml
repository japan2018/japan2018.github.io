<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title> GitHub Actions on Memo Tut</title>
    <link>https://memotut.com/tags/github-actions/</link>
    <description>Recent content in  GitHub Actions on Memo Tut</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 12 Mar 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://memotut.com/tags/github-actions/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>[Python] COVID-19 Hokkaido Data Edition (2) Toward Open Data &#43; Automatic Update</title>
      <link>https://memotut.com/covid-19-hokkaido-data-edition-2-toward-open-data-automatic-update-8f076/</link>
      <pubDate>Thu, 12 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/covid-19-hokkaido-data-edition-2-toward-open-data-automatic-update-8f076/</guid>
      <description>## Table of contents  COVID-19 Hokkaido data edition (1) Initial data creation by scraping etc. COVID-19 Hokkaido Data Edition (2) To open data + automatic update ←This article! COVID-19 Hokkaido data edition ③ Fully automated
![Screenshot 2020-03-10 17.37.10.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/73197/cfee968c-cffb-cc29-67c0-(76b076fa30cd.png)
In ①, we have summarized V0 in the above figure, but this article will summarize the use of external APIs such as open data portal.
Issues with V0 In V0, data acquisition relied on (1) scraping from the road website and (2) static CSV files provided by Sapporo City.</description>
    </item>
    
  </channel>
</rss>