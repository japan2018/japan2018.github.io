<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  <meta name="generator" content="Hugo 0.72.0" />

  
  <meta name="description" content="Some description">
  

  
  <link rel="apple-touch-icon" sizes="180x180" href="https://memotut.com/apple-touch-icon.png">

  
  <link rel="icon" type="image/png" sizes="32x32" href="https://memotut.com/favicon-32x32.png">

  
  <link rel="icon" type="image/png" sizes="16x16" href="https://memotut.com/favicon-16x16.png">

  
  <link rel="manifest" href="https://memotut.com/site.webmanifest">

  
  <link rel="mask-icon" href="https://memotut.com/safari-pinned-tab.svg" color="#5bbad5">

  <meta name="msapplication-TileColor" content="#da532c">

  <meta name="theme-color" content="#ffffff">

  
  <link rel="stylesheet" href="https://memotut.com/css/bootstrap.min.css" />

  
  <title>Generate physically robust shapes with GAN and print on a 3D printer | Memo Tut</title>
  

  <style>
body {
  min-width: 300px;
}

.custom-navbar {
  margin-bottom: 1em;
  height: 60px;
}

.custom-navbar a {
  display: inline-block; 
  padding: 18px 0;
  margin-right: 1em; 
  font-weight: bold; 
}

.custom-navbar a:hover,
.custom-navbar a:focus {
  text-decoration: none; 
}

@media print {
  .custom-navbar {
    display: none;
  }
}

article {
  padding-bottom: 1em;
}

img {
  max-width: 100%;
}


body {
  background-color: #fff;
}



body {
  color: #212529;
}



a {
  color: #007bff;
}



a:hover,
a:focus {
  color: #0056b3;
}



.custom-navbar {
  background-color: #212529;
}



.custom-navbar a {
  color: rgba(255, 255, 255, 0.75);
}



.custom-navbar a:hover,
.custom-navbar a:focus {
  color: rgba(255, 255, 255, 1);
}



.container {
  max-width: 800px;
}



pre {
  display: block;
  padding: 9.5px;
  word-break: break-all;
  word-wrap: break-word;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre code {
  padding: 0;
  font-size: inherit;
  color: inherit; 
  white-space: pre-wrap;
  background-color: transparent;
  border: none;
  border-radius: 0;
}

code {
  padding: 2px 4px;
  color: inherit; 
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
  font-size: .9em;
}



blockquote,
.blockquote {
  padding: 10px 20px;
  margin: 0 0 20px;
  font-size: 1em;
  border-left: 5px solid #6c757d;
}

</style>
</head>

<body>
  <nav class="custom-navbar">
  <div class="container">
    
    <a href="/">Posts</a>
    
    <a href="/tags/">Tags</a>
    
    <a href="/about/">About</a>
    
    <a href="/index.xml">RSS</a>
    
  </div>
</nav>
  
  <div class="container">
    <article>
      <h1>Generate physically robust shapes with GAN and print on a 3D printer</h1>
<p>
  <small class="text-secondary">
  
  
  May 28, 2020
  </small>
  

<small><code><a href="https://memotut.com/tags/python">Python</a></code></small>


<small><code><a href="https://memotut.com/tags/blender"> Blender</a></code></small>


<small><code><a href="https://memotut.com/tags/deep-learning"> Deep Learning</a></code></small>


<small><code><a href="https://memotut.com/tags/3d-printer"> 3D Printer</a></code></small>


<small><code><a href="https://memotut.com/tags/tensorflow2.0"> TensorFlow2.0</a></code></small>

</p>
<pre><code># 0. What makes me happy about this article
</code></pre>
<ul>
<li>You can see the flow of printing the data generated by deep learning on a 3D printer (10. In the experimental code, I have posted it to GitHub for all the codes **. The same thing can be done if you make an environment by <code>git clone</code> It should be easy.I wrote in <a href="https://qiita.com/HyperPigeon/items/e6c37dc143039b75d0e4">here</a>howtocreatetheenvironment.)</li>
<li>It becomes a study of material mechanics (I am writing while studying&hellip;)</li>
<li>Learn how TensorFlow 2.0 tensor operations are applied to material mechanics</li>
</ul>
<p>*This is a recommended article for a PC, as it seems to break when viewed on a smartphone.</p>
<h1 id="1-overview">1. Overview</h1>
<ul>
<li>Use DCGAN (Radford et al., 2016)<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> and add intensity information to the loss function to generate high intensity numbers.</li>
<li>Manipulate strength while maintaining the concept of data</li>
<li>Strength can be increased or decreased by designing loss and changing parameters</li>
<li>Discovered a trade-off between FID (Heusel et al., 2017)<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>(howmuchoriginaldataiskeptdiverseandshape) and intensity of generated image</li>
<li>We found the possibility of application to medical images, etc., and the possibility of improving GAN itself</li>
<li>The generated cross section was printed with a 3D printer</li>
<li>Name it Danmen-GAN (because it&rsquo;s hard to call without a name)</li>
</ul>
<p>(The article is long, but I think you can read it soon because it is about 3/4 images or bonus.)</p>
<h1 id="2-background">2. Background</h1>
<p>I recently got a 3D printer, so I was wondering if I could do something with a combination of <strong>3D printer x deep learning</strong>, so I decided to give it a try.</p>
<p>It seems that the basic theory of material mechanics has not changed in the last 100 years, so I wanted to approach from the deep learning side, which has a high degree of freedom.</p>
<p>You may enjoy reading any of the numbers in the <code>0-9</code> book as sturdy as you might expect. There is one type of head and a sturdy number.</p>
<p>(* I&rsquo;m doing it while reading the book on material mechanics (Japan Society of Mechanical Engineers, 2007) <sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>, so I may be saying something appropriate. If there is an error, I will correct it. For the time being, I will briefly look for research on GAN side. I couldn&rsquo;t find any similar research in the range I mentioned, but please let me know if there is any.)</p>
<h1 id="3-theory">3. Theory</h1>
<p>If you are not interested, you can skip it at all.</p>
<h2 id="31-moment-of-inertia-of-area">3.1 Moment of inertia of area</h2>
<p>In the first place, the rough term strength has multiple indicators.
I don&rsquo;t know how the material shop uses the word strength, but we ordinary people use the word strength in various ways.</p>
<p>Mohs hardness, Vickers hardness, yield stress (tensile strength), etc&hellip;
Of these, the dominant force is particularly strong, and the strength determined by the shape of the cross-section independently of the material is the <strong>second moment of area</strong>. This is a coefficient of how hard the member is to bend.</p>
<p>When force is applied, most things subtly bend in proportion to the force at an invisible level.
And if it bends too much, most things will snap and won&rsquo;t come back.
Conversely, a member with a stronger cross section is less likely to break.</p>
<p>For example, newspapers can&rsquo;t support anything if they&rsquo;re fluffy, but just rolling them makes them reasonably stiff.
(Although there is a factor that the thickness of the paper increases)</p>
<p>The Japan Society of Mechanical Engineers, in <sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup> Chapter 5, p63, states that when a slender rod is subjected to a lateral load that causes bending in the plane including the axis of the rod from the lateral direction, such a rod is called a beam. .&rdquo; is defined.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/bbd1a8a8-4256-ebb0-0036-0b68265c1356.png"><caption>↑ MNIST [ ^MNIST] Relationship between geometrical cross-section, geometrical moment of inertia and orientation, image of 3D printing </caption></img><br/></p>
<p>If you fix both sides of the elongated rod in the shape of &ldquo;2&rdquo; in this image, it becomes a beam.
At this time, the geometrical moment of inertia for the vertical force is $I_x$ and the geometrical moment of inertia for the lateral force is $I_y$** for the direction of the arrow.</p>
<p>The direction of $x$ and $y$ is transposed with the axis of image processing, so it is a little complicated.
Wikipedia senior <sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup> says so, and this is probably the standard.</p>
<p>Next, the calculation method of the second moment of area is explained.</p>
<p>The second moment of area $I_x$ with respect to the force from the vertical axis is</p>
<p>$$
I_x = \int_A y^2 dA \tag{1}
$$</p>
<p>Can be calculated with.
Where $A$ is the cross-sectional area and $y$ is the vertical distance from the neutral axis (the center of gravity of the cross section).</p>
<p>Similarly, the second moment of area $I_y$ for the force from the horizontal axis is</p>
<p>$$
I_y = \int_A x^2 dA \tag{2}
$$</p>
<p>Can be calculated with. Where $x$ represents the horizontal distance from the neutral axis.</p>
<p>In addition, there is also an index that represents the strength of the cross section against &ldquo;torsion&rdquo; called the second polar moment of area,</p>
<p>$$
I_r = I_x + I_y \tag{3}
$$</p>
<p>Can be calculated. This strength will be introduced in the experiment as well.
&ldquo;Twisting&rdquo; is easy to understand if you imagine the rotational force that occurs when you squeeze the rag.</p>
<p>The unit of all these three indicators is m^4.
This is because the square of the distance difference [m^2] is integrated [m^2] by the area.</p>
<p>Specifically, the second moment of area for a simple rectangular section is</p>
<ul>
<li>$I_x$ is (thickness cube) $\times$ (width square)</li>
<li>$I_y$ is (thickness square) $\times$ (width cube)</li>
</ul>
<p>You can intuitively understand that it is proportional to.</p>
<p>So what happens in this case?</p>
<p>First, for ease of understanding, visualize the second moment of inertia of the image with all pixel values = 1.0 (maximum value).</p>
<table>
<thead>
<tr>
<th>Image</th>
<th>$\Delta I_x$</th>
<th>$\Delta I_y$</th>
</tr>
</thead>
<tbody>
<tr>
<td><img width=300 src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/036586c6-ea54-3bd4-2dbf-26875e1f4a72.png">&lt;/ br&gt;</td>
<td><img width=300 src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/d466e60b-5044-68a6-db31-0358241c65e6.png"> </br>$I_x=1.000$ (MAX)</td>
<td><img width=300 src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/497f728d-502e-0fd6-4791-11d3a0704468.png"> $I_y=1.000$ (MAX)</td>
</tr>
</tbody>
</table>
<p>Where $\Delta I_x$ is the influence on the unit moment of inertia of area $I_x$ per unit pixel, and $\Delta I_y$ is the influence on the moment of inertia of area $I_y$ per pixel. By summing these, $I_x$ and $I_y$ can be obtained.</p>
<p>This time, separate it from the metric unit and set this square as the maximum moment of inertia of area $1.0$.</p>
<p>Let&rsquo;s display a similar figure with some data from MNIST.</p>
<p>(For values of 0.0 &lt;pixel value &lt;1.0, it is approximated that the pixel value and the area are proportional.
In other words, if the pixel value is <code>0.5</code>, the cross section does not exist in half of the pixels, and if it is <code>0.1</code>, 90% is missing. * This will be another approximation when it is finally printed. )</p>
<table>
<thead>
<tr>
<th>Image</th>
<th>$\Delta I_x$</th>
<th>$\Delta I_y$</th>
</tr>
</thead>
<tbody>
<tr>
<td><img width=300 src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/a9a06593-d321-94e3-267a-ea4cff194f91.png">&lt;/ br&gt;</td>
<td><img width=300 src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/89608e74-517e-abf4-9f1b-79ff7382a643.png"> <br/> $I_x=0.112$</td>
<td><img width=300 src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/ac674fd5-87b3-a8fb-1f24-e8ef9b0425b4.png"> $I_y=0.093$</td>
</tr>
<tr>
<td><img width=300 src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/28c30081-4d9a-8ca6-03af-87ed0e96beae.png">&lt;/ br&gt;</td>
<td><img width=300 src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/ce71d486-ad0c-1c22-227a-fb371ba03d76.png"> $I_x=0.060$</td>
<td><img width=300 src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/0ca6b1f1-04c7-fceb-fa88-a564c2d7a687.png"> $I_y=0.036$</td>
</tr>
<tr>
<td>On the contrary, &ldquo;1&rdquo; is low in both $I_x$ and $I_y$, and there is almost no lateral strength.</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>When calculating the second moment of area, the strength has a stronger influence as the distance from the neutral axis increases, and the influence decreases as the distance from the neutral axis increases. Considering these, most of the structures in the world are hollow (the contents are squashed) because the moment of inertia of section is reasonably large.</p>
<p>From the above, typical cross sections with high strength while suppressing the material and weight are hollow circles and squares, and H type/I type (only one axis has strong strength). This time, since there are no particular restrictions on the weight of the material, the most robust shape is the <strong>&ldquo;square&rdquo;</strong>, which is filled with the pixel values of the image.</p>
<p>So how do you maintain the shape of the numbers while maintaining their strength?</p>
<h2 id="32-generative-adversarial-nets-goodfellow-et-al-2014gan">3.2 Generative Adversarial Nets (Goodfellow et al., 2014)<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup></h2>
<p>Basic Generative Adversarial Nets (=GAN) uses two neural network models, one of which is a generator that outputs a distribution close to the data, the other is a generator, or it is generated for the input of data. Consists of a Discriminator that determines whether it is a thing or not.</p>
<p>The more accurate the Discriminator&rsquo;s judgment is, the more error backpropagation will be applied to the parameters of the Generator, and the more likely the Generator will generate a more data-like distribution.
On the other hand, the low accuracy of Discriminator&rsquo;s judgment is a penalty of Discriminator itself, and the parameters are modified so that the accuracy of judgment can be improved.</p>
<p>These come from the formulation <sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup> of Goodfellow&rsquo;s equation (4).</p>
<pre><code class="language-math" data-lang="math">\min _{G} \max _{D} V(D, G)=\mathbb{E}_{\boldsymbol{x} \sim p_{\text {data }}(\boldsymbol{x})}[ \log D(\boldsymbol{x})]+\mathbb{E}_{\boldsymbol{z} \sim p_{\boldsymbol{z}}(\boldsymbol{z})}[\log (1-D( G(\boldsymbol{z})))] \tag{4}
</code></pre><p>In a nutshell, if you apply this to image data of numbers, the Generator side will learn to generate number-like images, and if learning is successful, it will even generate numbers that do not exist in the dataset. is.</p>
<p>Also, various methods have been devised for GAN theory and learning methods, but this time it is based on the classical DCGAN <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. In short, DCGAN is a paper that applies the basic method of GAN to convolutional neural networks.</p>
<h2 id="33-danmen-gan">3.3 Danmen-GAN</h2>
<p>Now that we&rsquo;ve covered the basics, it&rsquo;s time to write the logic to create a sturdy number.</p>
<p>In the normal GAN learning, the loss on the Generator is given by Equation (5).
This is a ratio in which the discriminator receives the generated result of the generator when noise is input and the discriminator corrects the loss, and the loss becomes stronger.</p>
<pre><code class="language-math" data-lang="math">\mathcal{L}_{G} = \mathbb{E} [\log (1-D(G(z))] \tag{5}
</code></pre><p>However, if it is only this, learning will proceed so that numbers will be randomly generated, so a function $S(\cdot)$ that calculates the second moment of area from the cross-sectional shape of the input image is incorporated and the generated cross-sectional image Create a new loss $\mathcal{L}_{S}$, where the lower the second moment of area is, the more penalized the Generator is.</p>
<pre><code class="language-math" data-lang="math">\mathcal{L}_{S} = \mathbb{E} \left[\|1-S(G(z))\|_{2}\right] \tag{6}
</code></pre><p>In addition, by introducing the axes of the vertical direction x, the horizontal direction y, and the twist r into $S(\cdot)$, and weighting them with the parameters α, β, and γ, Equation (6) becomes Equation (7). Become.</p>
<pre><code class="language-math" data-lang="math">\mathcal{L}_{S} = \alpha \cdot\mathbb{E} \left[|1-S_x(G(z))|_2\right] + \beta \cdot\mathbb{E} \left[ |1-S_y(G(z))|_2\right] + \gamma \cdot\mathbb{E} \left[|1-S_r(G(z))|_2\right]
</code></pre><p>Finally, add equation (7) to the loss on the generator side of GAN to obtain equation (8), and you are done.</p>
<pre><code class="language-math" data-lang="math">\mathcal{L}_{All} = \mathcal{L}_{G} + \mathcal{L}_{S} \tag{8}
</code></pre><p>By using equation (8) as the objective function of the Generator, it is the logic that the second moment of area can be increased while maintaining the shape of the number in the section.</p>
<h1 id="4-data-analysis">4. Data analysis</h1>
<p>The dataset is MNIST <sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>.
Since we only need the source of the generated data this time, we will use only the learning data.</p>
<p>First, I want to understand how strong the data set is, so I&rsquo;ll calculate it.</p>
<h2 id="41-global-strength">4.1 Global strength</h2>
<p>Average second moment of area for each axis of the entire dataset $\mathbb{E} \left[I_x\right]$, $\mathbb{E} \left[I_y\right]$, $\mathbb{E} \left I asked for [I_r\right]$.
We also calculated the standard deviations of the second moments of area $\sigma_{Ix}$, $\sigma_{Iy}$, $\sigma_{Ir}$ for each statistic.</p>
<table>
<thead>
<tr>
<th>$E[I_x]$ ($\sigma_{Ix}$)</th>
<th>$E[I_y]$ ($\sigma_{Iy}$)</th>
<th>$E[I_r]$ ($\sigma_{Ir}$)</th>
</tr>
</thead>
<tbody>
<tr>
<td>0.088(0.032)</td>
<td>0.063(0.034)</td>
<td>0.076(0.031)</td>
</tr>
</tbody>
</table>
<p>Looking at this table, I feel that the second moment of area varies depending on the data.
You can also see that the strength in the vertical direction is higher than that in the horizontal direction as a whole.</p>
<h2 id="42-strength-by-number">4.2 Strength by number</h2>
<p>Next, we considered that there is a bias in the shape for each number, and summarized the statistical values of the second moment of area for each number.
This is represented by a box plot and a set of tables. No processing is performed for abnormal values.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/b666c774-7c3b-e584-8aff-2cfd88811a0a.png" width=400></img ></p>
<table>
<thead>
<tr>
<th>Number(n)</th>
<th>$E[I_{xn}]$ ($\sigma_{Ixn}$)</th>
<th>$E[I_{yn}]$ ($\sigma_{Iyn}$)</th>
<th>$E[I_{rn }] $ ($\sigma_{Irn}$)</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td><font color="red">0.121</font>(0.029)</td>
<td><font color="red">0.110</font>(0.034)</td>
<td><font color="red">0.116</font> (0.030)</td>
</tr>
<tr>
<td>1</td>
<td><font color="blue">0.052</font>(0.015)</td>
<td><font color="blue">0.020</font>(0.014)</td>
<td><font color="blue">0.036</font> (0.013)</td>
</tr>
<tr>
<td>2</td>
<td>0.107(0.031)</td>
<td>0.078(0.027)</td>
<td>0.093(0.027)</td>
</tr>
<tr>
<td>3</td>
<td>0.106(0.028)</td>
<td>0.066(0.026)</td>
<td>0.086(0.026)</td>
</tr>
<tr>
<td>4</td>
<td>0.064(0.018)</td>
<td>0.063(0.026)</td>
<td>0.064(0.021)</td>
</tr>
<tr>
<td>5</td>
<td>0.093(0.031)</td>
<td>0.065(0.024)</td>
<td>0.079(0.026)</td>
</tr>
<tr>
<td>6</td>
<td>0.083(0.022)</td>
<td>0.065(0.028)</td>
<td>0.074(0.024)</td>
</tr>
<tr>
<td>7</td>
<td>0.079(0.021)</td>
<td>0.053(0.022)</td>
<td>0.066(0.020)</td>
</tr>
<tr>
<td>8</td>
<td>0.105(0.027)</td>
<td>0.067(0.027)</td>
<td>0.086(0.026)</td>
</tr>
<tr>
<td>9</td>
<td>0.074(0.019)</td>
<td>0.054(0.024)</td>
<td>0.064(0.021)</td>
</tr>
</tbody>
</table>
<p>From these, we can see that:</p>
<ul>
<li>Basically, &ldquo;0&rdquo; is strong for both $I_x$ and $I_y$</li>
<li>&ldquo;I&rdquo; $I_y$ is overwhelmingly low</li>
<li>When it&rsquo;s a subtle place, &ldquo;2&rdquo; &ldquo;3&rdquo; &ldquo;8&rdquo; is moderately strong</li>
<li>Looking at the average value, there is a bias in the second moment of area depending on the number, but (other than 1) the variation is large depending on the image, so if you work hard you may be able to beat &ldquo;0&rdquo;</li>
</ul>
<h2 id="43-strongest-and-weakest">4.3 Strongest and weakest</h2>
<p>I checked the numbers with the strongest strength and the weakest numbers with <code>argmax</code>/<code>argmin</code>.</p>
<p>The strongest is of course &ldquo;0&rdquo;,</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/330294cf-6a81-0ae1-0af5-f05a644c2df4.png" alt="allmax.png"></p>
<p>The pen is too wide&hellip;
By the way, it is the top in all fields with $I_x=0.259$, $I_y=0.244$, $I_r=0.251$.
The person who wrote this is proud.</p>
<p>Next, I will introduce the weakest of $I_x$.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/8e4a92d1-7037-4366-31d5-0290b5401b7d.png" alt="minIxa.png"></p>
<p>It&rsquo;s &ldquo;2&rdquo;, but it&rsquo;s really crushed.
I think that it is the most crushed number both in terms of calculation.
Looks weak. ($I_x=0.013$)</p>
<p>And the weakest of $I_y$</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/a8f42473-6426-8f16-9cde-92ef6af3c12f.png" alt="minIy.png"></p>
<p>Too thin. It will break if you apply pressure from the side. ($I_y=0.0015$ ← I lowered the digit because it is too small)</p>
<p>Finally, the weakest $I_r$<img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/03090b99-038c-e890-9c90-e7b3ca279f09.png" alt="minIx.png"></p>
<p>At first glance, it is similar to the previous one, but it is slightly tilted. ($I_r=0.010$)
Machine learning datasets can be unique.</p>
<h1 id="5-experiment">5. Experiment</h1>
<p>Let&rsquo;s do an experiment.</p>
<p>I built a theoretical model with TensorFlow 2.0 and learned GAN in which the loss function of equation (8) was applied to Generator.
The model is attached to Appendix as a bonus.
I&rsquo;ve posted all the code on GitHub.</p>
<ul>
<li>All experiments are done at Colaboratory (K80)</li>
<li>Computation time is about one hour per learning (mostly FID computation time)</li>
<li>Batch size: 50</li>
<li>Number of epochs: 20 (24,000 total iterations)</li>
<li>Comparing 5,000 FIDs</li>
<li>No data expansion</li>
</ul>
<p>Version etc.</p>
<ul>
<li>numpy 1.18.4</li>
<li>tensorflow 2.2.0</li>
<li>stealthflow 0.0.13</li>
<li>Other matplot, seaborn, etc. (does not affect calculation)</li>
</ul>
<h2 id="51-various-parameters-and-generation-results">5.1 Various parameters and generation results</h2>
<h3 id="511-danmen-gan">5.1.1 Danmen-GAN</h3>
<p>The minimum FID is the lowest FID value reached during that learning. (The smaller the FID, the better.)
The comparison target of FID is the generated image and the learning data.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/7535567a-4d97-4347-214d-4526476eccba.png" alt="GAN-I_x-to-1.0 alpha (2).png"></p>
<p>The graph shows changes in $I_x$, $FID$, and $\frac{I_x}{FID}$ when α is changed (β=γ=0).
From this graph it becomes clear that instead of getting the second moment of area, we sacrifice FID.</p>
<p>Change in output image (β=γ=0).
The lower it goes, the stronger it becomes in the vertical direction.</p>
<table>
<thead>
<tr>
<th>$\alpha$</th>
<th>Output (Last Epoch)</th>
<th>Minimum FID</th>
<th>Maximum $I_x$</th>
<th>Maximum $I_y$</th>
<th>Maximum $I_r$</th>
</tr>
</thead>
<tbody>
<tr>
<td>$\alpha=0$ (regular GAN)</td>
<td><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/e4fbac2c-c819-6b2c-a645-832a850f9b2a.png" alt="_vanillaGAN_24000_image.png"></td>
<td>36.0</td>
<td>0.109</td>
<td>0.090</td>
<td>0.083</td>
</tr>
<tr>
<td>$0.1$</td>
<td><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/5ac9acdf-a152-65bb-b3d3-bbb77d0b8d58.png" alt="_I_x01_24000_image.png"></td>
<td>36.9</td>
<td>0.106</td>
<td>0.082</td>
<td>0.095</td>
</tr>
<tr>
<td>$1.0$</td>
<td><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/9897e80b-0105-76ca-549c-93ac2de47bcc.png" alt="_I_x1_24000_image.png"></td>
<td>32.8</td>
<td>0.103</td>
<td>0.077</td>
<td>0.090</td>
</tr>
<tr>
<td>$5.0$</td>
<td><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/ed39773a-8c02-3173-0e61-db780aa44e71.png" alt="_I_x5_24000_image.png"></td>
<td>59.5</td>
<td>0.126</td>
<td>0.097</td>
<td>0.111</td>
</tr>
<tr>
<td>$10.0$</td>
<td><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/657d2990-6ce3-c1a0-5cd0-164c49ea5518.png" alt="_I_x10_24000_image.png"></td>
<td>69.4</td>
<td>0.145</td>
<td>0.116</td>
<td>0.130</td>
</tr>
<tr>
<td>$25.0$</td>
<td><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/b479b3e0-7089-6bed-0eb6-c08e41909327.png" alt="_I_x25_24000_image.png"></td>
<td>96.0</td>
<td>0.193</td>
<td>0.160</td>
<td>0.176</td>
</tr>
<tr>
<td>$50.0$</td>
<td><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/1457074a-d86c-bdb4-00f5-adca8675a92a.png" alt="_I_x50_24000_image.png"></td>
<td>135.8</td>
<td>0.249</td>
<td>0.212</td>
<td>0.230</td>
</tr>
<tr>
<td>$75.0$</td>
<td><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/344f2663-5f68-e368-d8c3-9368e861d3d0.png" alt="_I_x+75_24000_image.png"></td>
<td>180.4</td>
<td>0.317</td>
<td>0.278</td>
<td>0.297</td>
</tr>
<tr>
<td>$100.0$</td>
<td><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/849e3765-0c95-1e04-6ff7-3fbc633557a1.png" alt="_I_x100_24000_image.png"></td>
<td>208.7</td>
<td>0.374</td>
<td>0.354</td>
<td>0.364</td>
</tr>
</tbody>
</table>
<p>After all, &ldquo;0&rdquo; is strong. I think it&rsquo;s because of the dataset bias.</p>
<p>Even without loss, a cross section with a second moment of area 20% higher than the average $I_x$ is generated, so it seems that the normal GAN itself is biased in the first place.
This may be due to the basic behavior of GAN, such as being prone to noise.</p>
<p>Going to the $\alpha=50.0$ level, it seems that the intensity of the outlier class of the original data can be generated on average, so I feel that it may be applicable to data expansion to generate a small number of data with GAN* *. For example, in the case of images for medical diagnosis, there are nuclear magnetic resonance method T1/T2 weighted images, etc., but at T1, the tumor seems to appear a little white <sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup>, so it is possible to increase the pixel value of the image , It is possible that you can make a generated image with an extremely large tumor. After that, since the characteristics of the brain and the like change outside (outer groove and cerebral cortex) and inside (hippocampus and corpus callosum) of the cross section, the tendency of the disease should probably change. By doing this, we thought that it would be possible to generate an image similar to the disease by expanding the GAN data according to the disease of interest.
(Medical: I don&rsquo;t know anything, so I may have said something appropriate&hellip;)</p>
<p>Example of $I_y$, $I_r$</p>
<table>
<thead>
<tr>
<th>Parameters</th>
<th>Output (Last Epoch)</th>
<th>Minimum FID</th>
<th>Maximum $I_x$</th>
<th>Maximum $I_y$</th>
<th>Maximum $I_r$</th>
</tr>
</thead>
<tbody>
<tr>
<td>$\beta=25.0, \alpha=\gamma=0$</td>
<td><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/1f215a1d-4bdd-5d29-eaf0-0938d9791c8f.png" alt="_I_y+25_24000_image.png"></td>
<td>122.2</td>
<td>0.180</td>
<td>0.178</td>
<td>0.179</td>
</tr>
<tr>
<td>$\beta=75.0, \alpha=\gamma=0$</td>
<td><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/32267fe8-f8fe-b7ce-891b-acd695e08cfb.png" alt="_I_y+75_24000_image.png"></td>
<td>160.8</td>
<td>0.267</td>
<td>0.284</td>
<td>0.275</td>
</tr>
<tr>
<td>$\gamma=25.0, \alpha=\beta=0$</td>
<td><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/ba7c6d5c-616e-64c2-6f86-3bc2b95779bb.png" alt="_I_r+25_24000_image.png"></td>
<td>113.2</td>
<td>0.181</td>
<td>0.165</td>
<td>0.173</td>
</tr>
<tr>
<td>$\gamma=75.0, \alpha=\beta=0$</td>
<td><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/9475a477-fb58-d2fc-985c-3a9b30cdb7a6.png" alt="_I_r+75_24000_image.png"></td>
<td>170.5</td>
<td>0.285</td>
<td>0.284</td>
<td>0.285</td>
</tr>
</tbody>
</table>
<p>&ldquo;0&rdquo; is also strong in these. Since other numbers are properly displayed, it does not seem to be mode collapse.</p>
<h3 id="512-number-weakening">5.1.2 Number weakening</h3>
<p>By applying the theory of Danmen-GAN, the desired second moment of area can be set to <code>0.0</code> and the strength can be reduced.
This can be expressed by equation (9)</p>
<pre><code class="language-math" data-lang="math">\mathcal{L}_{S} = \mathbb{E} \left[\| S(G(z))\|_{2}\right] \tag{9}
</code></pre><p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/64447c71-9b4b-d9db-edbe-9ee62ba9a347.png" alt="GAN-I_x-to-0.0 alpha (2).png"></p>
<p>This graph shows changes in $I_x$, FID, and $\frac{1}{I_x\times FID}$ (β=γ=0) when $\alpha$ is changed.
FID is also sacrificed when reducing the second moment of area. This is because moving away from the original data distribution is the same as increasing it.</p>
<p>Change of output image ($\beta=\gamma=0$)</p>
<p>$\alpha$ | Output (Final Epoch) | Minimum FID | Minimum $I_x$ | Minimum $I_y$ | Minimum $I_r$ |
| &mdash; | &mdash; | &mdash; | &mdash; | &mdash; | &mdash; || $0.1$ | <img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/55139193-a619-49b7-dbbe-9102ee0773bd.png" alt="_I_x-01_24000_image.png">| 38.6 | 0.093 | 0.058 | 0.076 |
| $1.0$ | <img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/c51263e7-9194-f217-7374-c5257229564d.png" alt="_I_x-1_24000_image.png"> | 40.5 | 0.091 | 0.058 | 0.073 |
| $5.0$ | <img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/d6e3a4cc-2e79-53e1-f746-4b3d21429dc0.png" alt="_I_x-5_24000_image.png">| 35.3 | 0.084 | 0.050 | 0.067 |
| $10.0$ | <img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/4d2ee6ee-b88c-8c9a-f8a7-e747fcc0acce.png" alt="_I_x-10_24000_image.png"> | 36.4 | 0.086 | 0.053 | 0.070 |
| $25.0$ | <img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/f1eb2347-4b1b-d90c-e300-ed3d219d00d1.png" alt="_I_x-25_24000_image.png"> | 30.0 | 0.069 | 0.042 | 0.056 |
| $50.0$ | <img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/53094d94-210f-3ed7-8bc1-201adf0b912a.png" alt="_I_x-50_24000_image.png"> | 41.5 | 0.062 | 0.033 | 0.048 |
| $100.0$ | <img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/018adb85-4155-8c28-73e4-c9f1e7031212.png" alt="_I_x-100_24000_image.png">| 48.6 | 0.055 | 0.026 | 0.040 |
| $500.0$ | <img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/f1456695-2c6a-cced-d587-b106e99c5a3d.png" alt="_I_x-500_24000_image.png"> | 112.4 | 0.043 | 0.013 | 0.028 |</p>
<p>やはり、元々強度の低い「1」が多く出る傾向になります。しかもほっそりしてる気がする。</p>
<p>パラメータのスケールが断面二次モーメントを強化するときと変化しており、こちらのほうが強くかけても影響がでにくいようです(おそらくピクセルの比率のせい)。</p>
<p>$I_y$, $I_r$ の例</p>
<table>
<thead>
<tr>
<th>パラメータ</th>
<th>出力(最終エポック)</th>
<th>最小FID</th>
<th>最小 $I_x$</th>
<th>最小 $I_y$</th>
<th>最小 $I_r$</th>
</tr>
</thead>
<tbody>
<tr>
<td>$\beta=25.0, \alpha=\gamma=0$</td>
<td><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/8afff004-e986-6c3c-4f81-2f0ff38ec888.png" alt="_I_y+25_24000_image.png"></td>
<td>32.0</td>
<td>0.079</td>
<td>0.047</td>
<td>0.063</td>
</tr>
<tr>
<td>$\beta=500.0, \alpha=\gamma=0$</td>
<td><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/7f6e583c-b4a8-b836-fc6f-3af15c5f0c2c.png" alt="_I_y-500_24000_image.png"></td>
<td>136.3</td>
<td>0.049</td>
<td>0.015</td>
<td>0.032</td>
</tr>
<tr>
<td>$\gamma=25.0, \alpha=\beta=0$</td>
<td><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/6e0c3b7a-f6b2-60c8-b673-0c898baee391.png" alt="_I_r+25_24000_image.png"></td>
<td>30.2</td>
<td>0.074</td>
<td>0.047</td>
<td>0.061</td>
</tr>
<tr>
<td>$\gamma=500.0, \alpha=\beta=0$</td>
<td><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/03674d31-9b6b-2b68-b102-2ce632816196.png" alt="_I_r-500_24000_image.png"></td>
<td>139.7</td>
<td>0.046</td>
<td>0.013</td>
<td>0.030</td>
</tr>
</tbody>
</table>
<p>これは可能性の話ですが、強度を下げる方にロスをかけると、<strong>ノイズごと抑制され、FID が改善される可能性</strong> を考えています。特に、断面二次モーメントの計算は画面の端に強いロスをかける性質を持っており、CNN は画面の端の処理で padding などの怪しいことを行っているので、相性が噛み合っている可能性はあります。特に断面二次極モーメント $I_r$ は画面の端全体に影響が及ぶので効果的かもしれません。</p>
<p>これは、ただの偶然の結果かもしれないので、個人的に深堀りしてみようと思います。</p>
<h2 id="52-断面二次モーメント-vs-fid">5.2 断面二次モーメント vs FID</h2>
<p>断面二次モーメントの伸びに対して FID の上昇をどれだけ抑えられているか確かめました。
$\frac{I_x}{FID}$ は学習中で最大のものを取得しています。
断面二次モーメントの微妙な上昇に対し、FID は爆増してしまうので、強度を得る代わりに元データの分布から離れてしまうようです。</p>
<table>
<thead>
<tr>
<th>$\alpha$</th>
<th>$\frac{I_x}{FID}$</th>
</tr>
</thead>
<tbody>
<tr>
<td>$\alpha=0.0$</td>
<td>0.00250</td>
</tr>
<tr>
<td>$\alpha=0.1$</td>
<td>0.00250</td>
</tr>
<tr>
<td>$\alpha=1.0$</td>
<td>0.00277</td>
</tr>
<tr>
<td>$\alpha=5.0$</td>
<td>0.00207</td>
</tr>
<tr>
<td>$\alpha=10.0$</td>
<td>0.00220</td>
</tr>
<tr>
<td>$\alpha=25.0$</td>
<td>0.00180</td>
</tr>
<tr>
<td>$\alpha=50.0$</td>
<td>0.00150</td>
</tr>
<tr>
<td>$\alpha=75.0$</td>
<td>0.00130</td>
</tr>
<tr>
<td>$\alpha=100.0$</td>
<td>0.00120</td>
</tr>
<tr>
<td>ones</td>
<td>0.00257</td>
</tr>
</tbody>
</table>
<p>ones は、全てが 1.0 の場合の断面です。このときの FID は 394.5 でした。
これだと、全て 1.0 の出力か、愚直に数字を出力するほうが $\frac{I_x}{FID}$ のパフォーマンスはいいことになってしまいます。逆に考えると、FID を計算するレイヤーを作り、$\frac{I_x}{FID}$ をロスとして設計したら、また異なる結果が出てきそうで面白そうですね。
(FID のレイヤーは作れましたが<sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>、どうしても行列の平方根を求める部分が計算としてボトルネックになりすぎたので、やめました。原理的には可能という概念。)</p>
<p>最終的に、データセットの最強を超える断面の生成には成功しましたが、最弱より弱い断面の生成はまだ確認できていません (もっと強くロスをかければいけるかもしれませんが)。</p>
<h1 id="6-3d-プリンタによる印刷">6. 3D プリンタによる印刷</h1>
<p><img height=360 src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/70285afc-1c0e-51c7-caa7-c95ba8571b22.jpeg"></img></p>
<p>せっかくなので、3Dプリンタ で印刷して強度を確認してみましょう。</p>
<p>使用したのは、Ender-3 という機種で通販サイトなどで2-3万する機種です。</p>
<h2 id="61-blender-で-tensorflow-20-を動かし数字ポリゴンの自動生成">6.1 Blender で TensorFlow 2.0 を動かし、数字ポリゴンの自動生成</h2>
<p>Blender 側では、こんな感じで自動生成を行います。
下の画像は MNIST データにある一番目の「0」です。</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/3a2a8ba0-fc1b-fef7-e67b-a607b6a36fc9.png" alt="1.png"></p>
<p>ピクセルに対応する部分を <code>add_cube</code> で自動生成しています。
(やり方がかなり雑なので3D屋さんに怒られてしまいそう)</p>
<p>下の画像は、$\alpha=75$ でペナルティをかけた Danmen-GAN で生成した「8」っぽい数字です。
<code>bpy</code> というモジュールで、Blender の API を Python で操作できるので、Blender 上の Python で TensorFlow の学習済みモデルを読み込み、その場で生成を行います。とても便利。</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/02ea914f-1872-0f3d-d79b-ae51c5ea701e.png" alt="2.png"></p>
<p><code>0.25</code> 以下のピクセル値は <code>0</code>、<code>0.25~0.75</code> のピクセル値はランダムに穴を開け 3/4 の面積に (少し穴が開いて強度が下がる)、<code>0.75</code> 以上のピクセル値は <code>1.0</code> とするヒューリスティックで、とりあえず曖昧なピクセルを処理します。</p>
<p>強度に関係ない部分は、手作業で除去します。
(印刷効率を上げるため)</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/d6f06929-703f-45a5-44cc-52eb466f1e1a.png" alt="3.png"></p>
<p>以下が整えた後の断面になります。</p>
<img height="300" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/fc5edaac-e886-226e-6a96-62f228c47be0.png">
<p>数字の下側にある断片みたいなものは、部材を固定するための台座みたいなイメージで作りました。This is done by inverting (<code>1.0-img</code>) the number pixels, rounding up with <code>np.ceil()</code>, applying scikit-image contraction processing (<code>skimage.morphology.binary_erosion</code>), adjusting, It is a set with a for` statement.</p>
<p>Below is the screen of the software called Cura which generates Gcode (nozzle control command of 3D printer) for 3D printer.</p>
<p><img height="300" src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/03728315-53bf-763f-72cc-c0068dbeeb1a.png">&lt; img height=&quot;300&rdquo; src=&quot;https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/2ca089aa-6d47-5ae9-be7c-dd62c91a7eb4.png&quot;&gt;</p>
<p>Originally I made it with a total length of 60 mm, but the printing time was displayed as 3-4 hours, so I reduced it by 40% and printed it. (Because Cura can perform basic operations such as scaling on the model, Blender does not need to worry about scale.)</p>
<h2 id="62-print-result">6.2 Print result</h2>
<p>The left side is &ldquo;0&rdquo; and the right side is &ldquo;8&rdquo;.
(I noticed that the base of &ldquo;8&rdquo; has been separated on the left and right.)</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/bc7420fa-0450-e553-3e69-4ac9a392f314.jpeg" alt="IMG_4978.JPG"></p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/09428e91-403b-7276-b511-bec6dc42b2fc.jpeg" alt="IMG_1209.JPG"></p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/689f34fd-f507-8a26-717f-9f473250bf84.jpeg" alt="IMG_6556.JPG"></p>
<p>(I noticed that &ldquo;8&rdquo; would stabilize after turning over.)</p>
<p>It&rsquo;s like this.</p>
<h2 id="63-durability">6.3 Durability</h2>
<p>Since it is a big deal, let&rsquo;s do a durability test.
Since I didn&rsquo;t make a slight movement in the half-hearted stress test, there was no other way to do it, so I finally put my weight on it.</p>
<p>&ldquo;0&rdquo; in the data set</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/e329684a-7335-f33c-b8ff-608070223c62.gif" alt="ezgif-2-632e2eb25ad3-compressor.gif"></p>
<p>Generated numbers</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/4a7cd777-3b97-fcb7-e59c-a4215e547333.gif" alt="ezgif-2-aaaf95b89279-compressor.gif"></p>
<p>Both have broken&hellip;
(I regret that if I put on both weights at the same time, I might have found that the stronger one.
For the time being, GAN generation results are in line with the random seed, so it is easy to reproduce. )</p>
<p>When I checked the cross section, they both broke along the laminated surface of the filament of the 3D printer.</p>
<h1 id="7-conclusion">7. Conclusion</h1>
<p>Conclusion</p>
<ul>
<li>Succeeded in improving theoretical sectional performance by adding the second moment of area to GAN loss</li>
<li>By applying this principle in reverse, cross-section design with low strength is also possible</li>
<li>The second moment of area can be traded off with FID regardless of whether it is raised or lowered.</li>
<li>Finally, make sure you can print to a 3D printer via Blender</li>
</ul>
<p>New hypothesis obtained from the experiment</p>
<ul>
<li>By using the loss of the second moment of area and aiming to generate rare data, I thought that it can be used as a GAN for data expansion used for Few-Show Learning (Is this someone working together)</li>
<li>We hypothesized that FID could be improved by applying a slight loss such that the second moment of area decreases (also d)</li>
</ul>
<h1 id="8-conclusion">8. Conclusion</h1>
<p>This time, I tried it with MNIST in order to reduce the complexity and learning complexity of GAN, but I think that it is theoretically applicable to other data.</p>
<p>Also, since these are biased, I think that it is necessary to generate them by conditioning them with Conditional GAN etc. in order to output the target number while manipulating the strength. As an application, it should be theoretically possible to give strength information to the conditional part of Conditional GAN and generate a cross section according to that strength.</p>
<p>Finally, we think that it is possible to apply them to three-dimensional structures by applying these, using FEM (= Finite Element Method), calculating the force balance of the structure, and adding loss. (Please let me know if you already have)</p>
<p>I think that it also works well with &ldquo;alchemy of fonts with StackGAN <sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup>&rdquo; that nardtree did.</p>
<h1 id="9-acknowledgments">9. Acknowledgments</h1>
<p>Mr. Shichiya (<a href="https://twitter.com/sitiya78">@sitiya78</a>): The 3D printer was personally requested by Amazon. Thank you very much for this section. I cannot thank you enough.</p>
<h1 id="10-experimental-code">10. Experimental code</h1>
<p>Here: I put everything on <a href="https://github.com/p-geon/DanmenGAN">https://github.com/p-geon/DanmenGAN</a>.</p>
<ul>
<li>
<p>Code for Blender: <a href="https://github.com/p-geon/DanmenGAN/blob/master/Blender/blender_mesh_generator.py">https://github.com/p-geon/DanmenGAN/blob/master/Blender/blender_mesh_generator.py</a></p>
</li>
<li>
<p>DanmenGAN body: <a href="https://github.com/p-geon/DanmenGAN/blob/master/Colaboratory/DanmenGAN.ipynb">https://github.com/p-geon/DanmenGAN/blob/master/Colaboratory/DanmenGAN.ipynb</a></p>
</li>
<li>
<p>Statistics calculation: <a href="https://github.com/p-geon/DanmenGAN/tree/master/calcstats">https://github.com/p-geon/DanmenGAN/tree/master/calcstats</a></p>
</li>
<li>
<p>Various images, weights, learning curves, scores, etc.: <a href="https://github.com/p-geon/DanmenGAN/tree/master/ExperimentalResults">https://github.com/p-geon/DanmenGAN/tree/master/ExperimentalResults</a></p>
</li>
</ul>
<h1 id="appendix">Appendix</h1>
<p>Bonus</p>
<h2 id="a-tensorflow-layer-structure">A. TensorFlow layer structure</h2>
<p>Describes the layer structure of TensorFlow 2.0.
Roughly, I will explain about Generator/Discriminator/Generator&amp;Discriminator. For enthusiasts.</p>
<h3 id="a-1-generator">A-1. Generator</h3>
<p><img width=400 src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/8d294f3b-5b76-3f1a-f3b5-4403ade96f69.png"></img ></p>
<p>(Click the image to check the details.)</p>
<p>Generator is roughly a graph that generates an image (<font color="steelblue">Generator</font>), a normalized graph (<font color="SlateBlue">Normalize</font>), and a graph that calculates the density ( <font color="Orange">Density</font>), second moment of area $I_x$ graph (<font color="coral">Ix</font>), second moment of area $I_y$ It can be divided into a graph (<font color="LimeGreen">Iy</font>) and a graph $I_r$ (<font color="LightSlateGray">Ir</font>) that calculates the second polar moment of area.</p>
<h4 id="generator-image-generation-graph--normalization-graph">Generator: Image Generation Graph ~ Normalization Graph</h4>
<p>Below is the code from Generator image generator to normalization.</p>
<p>Basic is the same as normal GAN.
Also, there is a lot of information about GAN on the internet, so I will omit it here.</p>
<p><code>smoa</code> is a class for calculating the second moment of area, and the density calculation to the second moment of area is calculated inside this class.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">build_generator</span>(params, smoa):
    <span style="color:#75715e"># Noise</span>
    z <span style="color:#f92672">=</span> z_in <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>layers<span style="color:#f92672">.</span>Input(shape<span style="color:#f92672">=</span>(params<span style="color:#f92672">.</span>NOISE_DIM, ), name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;noise&#34;</span>)

    <span style="color:#75715e"># (NOISE_DIM,) -&gt; (1024,)</span>
    x <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>layers<span style="color:#f92672">.</span>Dense(<span style="color:#ae81ff">1024</span>)(z)
    x <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>layers<span style="color:#f92672">.</span>LeakyReLU(alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>)(x)
    x <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>layers<span style="color:#f92672">.</span>BatchNormalization(momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.8</span>)(x)

    <span style="color:#75715e"># (1024,) -&gt; (7*7*64,) -&gt; (7, 7, 64)</span>
    x <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>layers<span style="color:#f92672">.</span>Dense(<span style="color:#ae81ff">7</span><span style="color:#f92672">*</span><span style="color:#ae81ff">7</span><span style="color:#f92672">*</span><span style="color:#ae81ff">64</span>)(z)
    x <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>layers<span style="color:#f92672">.</span>LeakyReLU(alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>)(x)
    x <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>layers<span style="color:#f92672">.</span>BatchNormalization(momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.8</span>)(x)
    x <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>layers<span style="color:#f92672">.</span>Reshape(target_shape<span style="color:#f92672">=</span>(<span style="color:#ae81ff">7</span>, <span style="color:#ae81ff">7</span>, <span style="color:#ae81ff">64</span>))(x)

    <span style="color:#75715e"># (7, 7, 64) -&gt; (14, 14, 32)</span>
    x <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>layers<span style="color:#f92672">.</span>Conv2DTranspose(<span style="color:#ae81ff">32</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">5</span>)
        , padding<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;same&#39;</span>, strides<span style="color:#f92672">=</span>(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>), use_bias<span style="color:#f92672">=</span>False, activation<span style="color:#f92672">=</span>None)(x)
    x <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>layers<span style="color:#f92672">.</span>BatchNormalization(momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.8</span>)(x)
    x <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>layers<span style="color:#f92672">.</span>LeakyReLU(alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>)(x)

    <span style="color:#75715e"># (14, 14, 128) -&gt; (28, 28, 1)</span>
    x <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>layers<span style="color:#f92672">.</span>Conv2DTranspose(<span style="color:#ae81ff">1</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">5</span>)
        , padding<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;same&#39;</span>, strides<span style="color:#f92672">=</span>(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>), use_bias<span style="color:#f92672">=</span>False, activation<span style="color:#f92672">=</span>None)(x)
    img <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>math<span style="color:#f92672">.</span>tanh(x)y <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>layers<span style="color:#f92672">.</span>Lambda(<span style="color:#66d9ef">lambda</span> x: x, name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;generated_image&#34;</span>)(img) <span style="color:#75715e"># img is used later, so change the variable name to y</span>

    <span style="color:#e6db74">&#34;&#34;&#34;
</span><span style="color:#e6db74">    Calculation of the moment of inertia of area (It becomes a graph like ResNet)
</span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
    <span style="color:#75715e"># range: [-1.0, 1.0] -&gt; [0.0, 1.0]</span>
    img <span style="color:#f92672">=</span> (img <span style="color:#f92672">+</span> <span style="color:#ae81ff">1.0</span>)<span style="color:#f92672">/</span><span style="color:#ae81ff">2.0</span>
    I_x, I_y, I_r <span style="color:#f92672">=</span> smoa<span style="color:#f92672">.</span>calc_second_moment_of_area(img)

    <span style="color:#66d9ef">return</span> tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>Model(inputs<span style="color:#f92672">=</span>z_in, outputs<span style="color:#f92672">=</span>[y, I_x, I_y, I_r])
</code></pre></div><h4 id="generator-density-calculation-graph--second-moment-of-area-calculation-graph">Generator: Density calculation graph ~ Second moment of area calculation graph</h4>
<p>The following is the graph construction method to obtain the second moment of area by tensor calculation only.</p>
<p>First, calculate the constants in the calculation graph first and prepare the tensor using <code>tf.constant()</code> as the class variable.</p>
<p>It uses <code>self.arange_x</code>, <code>self.arange_y</code>, <code>self.distance_matrix_x</code>, <code>self.distance_matrix_y</code>, <code>self.norm_I_x</code>, <code>self.norm_I_y</code>.</p>
<p>As an explanation of variables,</p>
<ul>
<li><code>self.arange_x</code>/<code>self.arange_y</code>: Vectors in simple order</li>
<li><code>self.distance_matrix_x</code>/<code>self.distance_matrix_y</code>: Tensor representing the distance from the axis</li>
<li><code>self.norm_I_x</code>/<code>self.norm_y</code>: maximum moment of inertia of area (scalar) for normalization</li>
</ul>
<p>Will be.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">SecondMomentOfArea</span>:
    <span style="color:#66d9ef">def</span> __init__(self, img_shape<span style="color:#f92672">=</span>(<span style="color:#ae81ff">28</span>, <span style="color:#ae81ff">28</span>)):
        distance_vector_x <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>asarray([<span style="color:#ae81ff">0.5</span><span style="color:#f92672">+</span>d <span style="color:#66d9ef">for</span> d <span style="color:#f92672">in</span> range(img_shape[<span style="color:#ae81ff">1</span>])])
        distance_matrix_x <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>tile(distance_vector_x, (img_shape[<span style="color:#ae81ff">0</span>], <span style="color:#ae81ff">1</span>))
        distance_matrix_y <span style="color:#f92672">=</span> distance_matrix_x<span style="color:#f92672">.</span>T
        <span style="color:#e6db74">&#34;&#34;&#34;
</span><span style="color:#e6db74">        Normalization matrix
</span><span style="color:#e6db74">        &#34;&#34;&#34;</span>
        matrix_for_norm_I_x <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>tile(np<span style="color:#f92672">.</span>abs(arange_y<span style="color:#f92672">-</span>img_shape[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">/</span><span style="color:#ae81ff">2.0</span>), (img_shape[<span style="color:#ae81ff">1</span>], <span style="color:#ae81ff">1</span>))<span style="color:#f92672">.</span>T
        norm_I_x <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>sum(matrix_for_norm_I_x)

        matrix_for_norm_I_y <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>tile(np<span style="color:#f92672">.</span>abs(arange_x<span style="color:#f92672">-</span>img_shape[<span style="color:#ae81ff">1</span>]<span style="color:#f92672">/</span><span style="color:#ae81ff">2.0</span>), (img_shape[<span style="color:#ae81ff">0</span>], <span style="color:#ae81ff">1</span>))<span style="color:#f92672">.</span>T
        norm_I_y <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>sum(matrix_for_norm_I_y)

        <span style="color:#e6db74">&#34;&#34;&#34;
</span><span style="color:#e6db74">        to TFconstant
</span><span style="color:#e6db74">        &#34;&#34;&#34;</span>
        self<span style="color:#f92672">.</span>arange_x <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>constant(arange_x, dtype<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>float32) <span style="color:#75715e"># (28,)</span>
        self<span style="color:#f92672">.</span>arange_y <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>constant(arange_y, dtype<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>float32) <span style="color:#75715e"># (28,)</span>
        self<span style="color:#f92672">.</span>distance_matrix_x <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>constant(distance_matrix_x[np<span style="color:#f92672">.</span>newaxis, :, :, np<span style="color:#f92672">.</span>newaxis], dtype<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>float32) <span style="color:#75715e"># (1, 28, 28, 1)</span>
        self<span style="color:#f92672">.</span>distance_matrix_y <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>constant(distance_matrix_y[np<span style="color:#f92672">.</span>newaxis, :, :, np<span style="color:#f92672">.</span>newaxis], dtype<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>float32) <span style="color:#75715e">#(1, 28, 28, 1)</span>
        self<span style="color:#f92672">.</span>norm_I_x <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>constant(norm_I_x, dtype<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>float32) <span style="color:#75715e">#()</span>
        self<span style="color:#f92672">.</span>norm_I_y <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>constant(norm_I_y, dtype<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>float32) <span style="color:#75715e">#()</span>
</code></pre></div><p>The distance_matrix is normalized and <code>[0, :, :, 0]</code> is cut out and shown in the figure below.</p>
<table>
<thead>
<tr>
<th>distance_matrix_x</th>
<th>distance_matrix_y</th>
</tr>
</thead>
<tbody>
<tr>
<td><img width=300 src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/80ce2241-975c-7cf4-a05a-68e0af8660ce.png">&lt;/ img&gt;</td>
<td><img width=300 src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/45e45515-f1a3-9eef-1db8-071113b91ad3.png"> </img></td>
</tr>
</tbody>
</table>
<p>I will write the continuation of the previous class.</p>
<p>In order to calculate the second moment of area, it is necessary to first calculate the center of gravity (neutral axis) of the section.
Then calculate the density (sum of all pixels / number of pixels in the image) to calculate the neutral axis.</p>
<p>First, calculate the moment by multiplying the <code>distance_matrix</code> and the pixel value of the image for each element. Next, the moment is corrected using the density, and when the moments are even, the neutral axis will be at the center of the image.</p>
<p>After the calculation of the neutral axis, create a tensor that represents the distance to the neutral axis by the process of subtraction → absolute value → deformation → tiling → axis addition.</p>
<p>After that, the tensor representing the distance and the image are calculated by multiplication for each element, the total is calculated, and if normalized, the calculation of the second moment of area is completed.</p>
<p>To calculate the polar moment of inertia $I_r$, add $I_x$ and $I_y$ as defined, and normalize the maximum to 1.0.</p>
<p><code>tf.keras.layers.Lambda(lambda x: x)(・)</code> does nothing, but it is written to increase the visibility of layers.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">calc_second_moment_of_area</span>(self, img): <span style="color:#75715e"># (None, 28, 28, 1)</span>
        <span style="color:#e6db74">&#34;&#34;&#34;
</span><span style="color:#e6db74">        Neutral axis calculation
</span><span style="color:#e6db74">        &#34;&#34;&#34;</span>
        density <span style="color:#f92672">=</span> (tf<span style="color:#f92672">.</span>reduce_sum(img, axis<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>], keepdims<span style="color:#f92672">=</span>True)<span style="color:#f92672">/</span>(img<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">1</span>]<span style="color:#f92672">*</span>img<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">2</span>]))
        <span style="color:#75715e"># (1, 28, 28, 1) x (None, 28, 28, 1) -&gt; (None, 28, 28, 1)</span>
        x_moment <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>math<span style="color:#f92672">.</span>divide_no_nan(tf<span style="color:#f92672">.</span>math<span style="color:#f92672">.</span>multiply(self<span style="color:#f92672">.</span>distance_matrix_x, img), density)
        y_moment <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>math<span style="color:#f92672">.</span>divide_no_nan(tf<span style="color:#f92672">.</span>math<span style="color:#f92672">.</span>multiply(self<span style="color:#f92672">.</span>distance_matrix_y, img), density)

        <span style="color:#75715e"># (None, 28, 28, 1) -&gt; (None,)</span>
        neutral_axis_x <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>math<span style="color:#f92672">.</span>reduce_mean(x_moment, axis<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>])
        neutral_axis_y <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>math<span style="color:#f92672">.</span>reduce_mean(y_moment, axis<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>])

        <span style="color:#e6db74">&#34;&#34;&#34;
</span><span style="color:#e6db74">        Second moment of area (vertical)
</span><span style="color:#e6db74">        I_x = ∫_A y^2 dA
</span><span style="color:#e6db74">        &#34;&#34;&#34;</span>
        <span style="color:#75715e"># sub: (None, 28,)-(None,) -&gt; abs: (None, 28)</span>
        dy <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>math<span style="color:#f92672">.</span>abs(self<span style="color:#f92672">.</span>arange_y<span style="color:#f92672">-</span>neutral_axis_y)
        <span style="color:#75715e"># (None, 28) -&gt; (None, 1, 28)</span>
        dy <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>reshape(dy, shape<span style="color:#f92672">=</span>[<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, img<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">1</span>], <span style="color:#ae81ff">1</span>])
        <span style="color:#75715e"># (None, 1, 28) -&gt; (None, 28, 28)</span>
        matrix_x <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>tile(dy, multiples<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, img<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">2</span>]])
        <span style="color:#75715e"># (None, 28, 28) -&gt; (None, 28, 28, 1)</span>
        matrix_x <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>expand_dims(matrix_x, <span style="color:#ae81ff">3</span>)
        <span style="color:#75715e"># (None, 28, 28, 1)x(None, 28, 28, 1) -&gt; (None, 28, 28, 1) -&gt; (None,)</span>
        I_x <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>math<span style="color:#f92672">.</span>reduce_sum(tf<span style="color:#f92672">.</span>math<span style="color:#f92672">.</span>multiply(matrix_x, img), axis<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>])<span style="color:#f92672">/</span>self<span style="color:#f92672">.</span>norm_I_x

        <span style="color:#e6db74">&#34;&#34;&#34;
</span><span style="color:#e6db74">        Second moment of area (lateral)
</span><span style="color:#e6db74">        I_y = ∫_A x^2 dA
</span><span style="color:#e6db74">        &#34;&#34;&#34;</span>
        <span style="color:#75715e"># sub: (None, 28,)-(None,) -&gt; abs: (None, 28)</span>
        dx <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>math<span style="color:#f92672">.</span>abs(self<span style="color:#f92672">.</span>arange_x<span style="color:#f92672">-</span>neutral_axis_x)
        <span style="color:#75715e"># (None, 28) -&gt; (None, 28, 1)</span>
        dx <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>reshape(dx, shape<span style="color:#f92672">=</span>[<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, img<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">2</span>]])
        <span style="color:#75715e"># (None, 1, 28) -&gt; (None, 28, 28)</span>
        matrix_y <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>tile(dx, multiples<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, img<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">1</span>], <span style="color:#ae81ff">1</span>])
        <span style="color:#75715e"># (None, 28, 28) -&gt; (None, 28, 28, 1)</span>
        matrix_y <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>expand_dims(matrix_y, <span style="color:#ae81ff">3</span>)
        <span style="color:#75715e"># (None, 28, 28, 1)x(None, 28, 28, 1) -&gt; (None, 28, 28, 1) -&gt; (None,)</span>
        I_y <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>math<span style="color:#f92672">.</span>reduce_sum(tf<span style="color:#f92672">.</span>math<span style="color:#f92672">.</span>multiply(matrix_y, img), axis<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>])<span style="color:#f92672">/</span>self<span style="color:#f92672">.</span>norm_I_y
        <span style="color:#e6db74">&#34;&#34;&#34;
</span><span style="color:#e6db74">        Second polar moment of area (divided by 2.0 for normalization)
</span><span style="color:#e6db74">        &#34;&#34;&#34;</span>
        I_r <span style="color:#f92672">=</span> (I_x <span style="color:#f92672">+</span> I_y)<span style="color:#f92672">/</span><span style="color:#ae81ff">2.0</span>
        <span style="color:#e6db74">&#34;&#34;&#34;Lambda
</span><span style="color:#e6db74">        &#34;&#34;&#34;</span>
        I_x <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>layers<span style="color:#f92672">.</span>Lambda(<span style="color:#66d9ef">lambda</span> x: x, name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;I_x&#34;</span>)(I_x)
        I_y <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>layers<span style="color:#f92672">.</span>Lambda(<span style="color:#66d9ef">lambda</span> x: x, name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;I_y&#34;</span>)(I_y)
        I_r <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>layers<span style="color:#f92672">.</span>Lambda(<span style="color:#66d9ef">lambda</span> x: x, name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;I_z&#34;</span>)(I_r)

        <span style="color:#66d9ef">return</span> I_x, I_y, I_r
</code></pre></div><p>When you generate it on Blender side, there is no need to calculate the second moment of area, so you can output three tensors of <code>(None, )</code> by an appropriate function.
I did it with <code>tf.reduce_sum(img)</code>.</p>
<h3 id="a-2-discriminator">A-2. Discriminator</h3>
<p>Discriminator is no different from regular GAN. The classic DCGAN look.</p>
<p><img width=200 src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/c3600a0e-9bc6-cdb3-9d3e-8cff6292ac91.png"></img ></p>
<h3 id="a-3-generator--discriminator">A-3. Generator &amp; Discriminator</h3>
<p>In order to learn GAN, we will also create a graph combining Generator and Disctiminator.</p>
<p>The input is only noise <code>z</code>, and the output is the prediction probabilities <code>p</code> and <code>I_x</code>, <code>I_y</code>, <code>I_r</code> output by Discriminator.</p>
<p>The three kinds of second moments of area can be calculated, and the coefficient can be adjusted when applying the loss, so you can also learn normal GAN and strengthen the second moment of area. .. If you want to weaken the second moment of area, you can change the target value of $I$ from <code>1.0</code> to <code>0.0</code>.</p>
<p><img width=400 src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/208566/ae3e96b9-b261-132e-3a10-f8c2005504bd.png"></img ></p>
<p>#References</p>
<p>Mainly my notes that I wrote to make this</p>
<ul>
<li>When using tf.print(), the contents of the tensor cannot be displayed inside the f-string: <a href="https://qiita.com/HyperPigeon/items/007c5adca9a4e78bc6d1">https://qiita.com/HyperPigeon/items/007c5adca9a4e78bc6d1</a></li>
<li>First-aid when Nan comes out at tf.linalg.sqrtm() in TensorFlow 2.0 Frechet Inception Distance (FID) calculation: <a href="https://qiita.com/HyperPigeon/items/f3f20f480269e2594724">https://qiita.com/HyperPigeon/items/f3f20f480269e2594724</a></li>
<li>When using tf.keras.utils.plot_model() with TensorFlow 2.0, AttributeError:&lsquo;dict&rsquo; object has no attribute&rsquo;name&rsquo; error and its solution: <a href="https://qiita.com/HyperPigeon/items/fb22b555e76b52b3d688">https://qiita.com/HyperPigeon/items/fb22b555e76b52b3d688</a></li>
<li>Solution for crashing Colaboratory (Jupyter Notebook) session with tensorflow_addons (tfa.image.rotate): <a href="https://qiita.com/HyperPigeon/items/94831b8a9af75527b67b">https://qiita.com/HyperPigeon/items/94831b8a9af75527b67b</a></li>
<li>Dimension (meter etc.) display method in Blender 2.8 or later: <a href="https://qiita.com/HyperPigeon/items/c5d2ec3264e8fd14d167">https://qiita.com/HyperPigeon/items/c5d2ec3264e8fd14d167</a></li>
<li>Install TensorFlow 2.0 (CPU) with Blender 2.8.2 and HelloWorld (Windows10): <a href="https://qiita.com/HyperPigeon/items/e6c37dc143039b75d0e4">https://qiita.com/HyperPigeon/items/e6c37dc143039b75d0e4</a></li>
</ul>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>Alec Radford, Luke Metz, Soumith Chintala. Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks. In ICLR 2016. <a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, Sepp Hochreiter. GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium. In NIPS, 2017. <a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>JSME Text Series Material Mechanics, Japan Society of Mechanical Engineers, 2007. <a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4" role="doc-endnote">
<p><a href="https://en.wikipedia.org/wiki/Second_moment_of_area">https://en.wikipedia.org/wiki/Second_moment_of_area</a> <a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5" role="doc-endnote">
<p>Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair,Aaron Courville, and Yoshua Bengio. Generative Adversarial Networks. In NIPS, 2014. <a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6" role="doc-endnote">
<p>LeCun, Yann and Cortes, Corinna. MNIST handwritten digit database, 2010. <a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7" role="doc-endnote">
<p><a href="http://www2.kyu-dent.ac.jp/depart/hoshasen/tf-2010/tf-2010/tf-aboutMRI.html">http://www2.kyu-dent.ac.jp/depart/hoshasen/tf-2010/tf-2010/tf-aboutMRI.html</a> <a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8" role="doc-endnote">
<p><a href="https://github.com/p-geon/StealthFlow/blob/master/stealthflow/fid.py">https://github.com/p-geon/StealthFlow/blob/master/stealthflow/fid.py</a> <a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9" role="doc-endnote">
<p><a href="https://catindog.hatenablog.com/entry/2017/02/05/160156">https://catindog.hatenablog.com/entry/2017/02/05/160156</a> <a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>

    </article>
  </div>

  
  
  
  <script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-169005401-1', 'auto');
  ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  

  
<link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.css" />
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#216942",
      "text": "#b2d192"
    },
    "button": {
      "background": "#afed71"
    }
  }
})});
</script>

</body>

</html>
