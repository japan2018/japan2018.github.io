<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  <meta name="generator" content="Hugo 0.72.0" />

  
  <meta name="description" content="Some description">
  

  
  <link rel="apple-touch-icon" sizes="180x180" href="https://memotut.com/apple-touch-icon.png">

  
  <link rel="icon" type="image/png" sizes="32x32" href="https://memotut.com/favicon-32x32.png">

  
  <link rel="icon" type="image/png" sizes="16x16" href="https://memotut.com/favicon-16x16.png">

  
  <link rel="manifest" href="https://memotut.com/site.webmanifest">

  
  <link rel="mask-icon" href="https://memotut.com/safari-pinned-tab.svg" color="#5bbad5">

  <meta name="msapplication-TileColor" content="#da532c">

  <meta name="theme-color" content="#ffffff">

  
  <link rel="stylesheet" href="https://memotut.com/css/bootstrap.min.css" />

  
  <title>I tried to summarize the relationship between probability distributions starting from the Bernoulli distribution | Memo Tut</title>
  

  <style>
body {
  min-width: 300px;
}

.custom-navbar {
  margin-bottom: 1em;
  height: 60px;
}

.custom-navbar a {
  display: inline-block; 
  padding: 18px 0;
  margin-right: 1em; 
  font-weight: bold; 
}

.custom-navbar a:hover,
.custom-navbar a:focus {
  text-decoration: none; 
}

@media print {
  .custom-navbar {
    display: none;
  }
}

article {
  padding-bottom: 1em;
}

img {
  max-width: 100%;
}


body {
  background-color: #fff;
}



body {
  color: #212529;
}



a {
  color: #007bff;
}



a:hover,
a:focus {
  color: #0056b3;
}



.custom-navbar {
  background-color: #212529;
}



.custom-navbar a {
  color: rgba(255, 255, 255, 0.75);
}



.custom-navbar a:hover,
.custom-navbar a:focus {
  color: rgba(255, 255, 255, 1);
}



.container {
  max-width: 800px;
}



pre {
  display: block;
  padding: 9.5px;
  word-break: break-all;
  word-wrap: break-word;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre code {
  padding: 0;
  font-size: inherit;
  color: inherit; 
  white-space: pre-wrap;
  background-color: transparent;
  border: none;
  border-radius: 0;
}

code {
  padding: 2px 4px;
  color: inherit; 
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
  font-size: .9em;
}



blockquote,
.blockquote {
  padding: 10px 20px;
  margin: 0 0 20px;
  font-size: 1em;
  border-left: 5px solid #6c757d;
}

</style>
</head>

<body>
  <nav class="custom-navbar">
  <div class="container">
    
    <a href="/">Posts</a>
    
    <a href="/tags/">Tags</a>
    
    <a href="/about/">About</a>
    
    <a href="/index.xml">RSS</a>
    
  </div>
</nav>
  
  <div class="container">
    <article>
      <h1>I tried to summarize the relationship between probability distributions starting from the Bernoulli distribution</h1>
<p>
  <small class="text-secondary">
  
  
  Mar 12, 2020
  </small>
  

<small><code><a href="https://memotut.com/tags/python">Python</a></code></small>


<small><code><a href="https://memotut.com/tags/distribution-of-accuracy"> distribution of accuracy</a></code></small>


<small><code><a href="https://memotut.com/tags/statistics"> statistics</a></code></small>


<small><code><a href="https://memotut.com/tags/statistics"> statistics</a></code></small>

</p>
<pre><code>#Introduction
</code></pre>
<p>For the purpose of understanding the relationship between probability distributions, we have implemented and summarized functions that generate various probability distributions starting from Bernoulli distribution in Python. This article is for the following people.</p>
<ul>
<li>I have studied the basic probability distribution</li>
<li>I have touched Python</li>
<li>I want to understand the relationship between probability distributions</li>
</ul>
<p>The implemented Python functions are as follows. The function names are <code>bernolli</code> and <code>binom</code>.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/571330/3ef28e31-3972-53c3-fda2-844657a600b5.png" alt="kankei1.png"></p>
<p>For example, a uniform distribution can be generated by following the order below.
<code>Bernoulli distribution -&gt; Geometric distribution -&gt; Exponential distribution -&gt; Gamma distribution -&gt; Beta distribution -&gt; Uniform distribution</code>
The definition of function names and probability distributions follows <a href="https://docs.scipy.org/doc/scipy/reference/stats.html">scipy.stats</a>.
‥
Then, I will explain each function in turn.</p>
<h1 id="bernoulli-distribution">Bernoulli distribution</h1>
<p>First, generate a sample that follows the Bernoulli distribution of the starting point. The Bernoulli distribution is a probability distribution that follows the &ldquo;number of hits when one lottery with a probability of winning is $p$&rdquo;. As you can see from the definition, the possible values are 0 or 1. The probability function is given by</p>
<pre><code class="language-math" data-lang="math">f(x;p) = p^x (1-p)^{1-x}\ \ (x=0,1)
</code></pre><p>Proceed to Python implementation. Import numpy and scipy.stats in advance.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-Python" data-lang="Python"><span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">from</span> scipy <span style="color:#f92672">import</span> stats
</code></pre></div><p>The function that generates sampleSize samples that follow the Bernoulli distribution with probability $p$ is as follows.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-Python" data-lang="Python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">bernoulli</span>(p, sampleSize):
    <span style="color:#66d9ef">return</span> stats<span style="color:#f92672">.</span>bernoulli<span style="color:#f92672">.</span>rvs(p, size<span style="color:#f92672">=</span>sampleSize)
</code></pre></div><p>Let&rsquo;s try to generate 20 samples from this function.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-Python" data-lang="Python">bernoulli(<span style="color:#ae81ff">0.2</span>, <span style="color:#ae81ff">20</span>)
<span style="color:#f92672">&gt;</span> array([<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>])
</code></pre></div><p>As set, 1 appears with a probability of about 0.2.
This is the last time to use scipy.stats, and thereafter the probability distribution is generated based on this <code>bernoulli function</code>.</p>
<h1 id="bernoulli-to-binomial-distribution">Bernoulli to binomial distribution</h1>
<p>Binomial distribution is a probability distribution that follows the &ldquo;number of hits when a lottery with a winning probability of $p$ is drawn $n$ times&rdquo;. The probability function is given by</p>
<pre><code class="language-math" data-lang="math">f(x;n,p) = \left(
\begin{matrix}
n\\
x
\end{matrix}
\right) p^x(1-p)^{n-x}\ \ (x=0,1,\cdots,n)
</code></pre><p>Binomial distribution is the number of times of drawing lots in Bernoulli distribution multiplied by $n$. sampleSize &ldquo;samples generated from binomial distribution with number of trials $n$ and probability $p$&rdquo; are created from $n\times$ sampleSize &ldquo;samples generated from Bernoulli distribution with probability $p$&rdquo; can do. The implementation is as below.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-Python" data-lang="Python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">binom</span>(n, p, sampleSize):
    x <span style="color:#f92672">=</span> bernoulli(p, n <span style="color:#f92672">*</span> sampleSize)
    x <span style="color:#f92672">=</span> x<span style="color:#f92672">.</span>reshape([n, sampleSize])
    <span style="color:#66d9ef">return</span> np<span style="color:#f92672">.</span>sum(x, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)
</code></pre></div><h1 id="binomial-to-poisson-distribution">Binomial to Poisson distribution</h1>
<p>▽ Poisson distribution is a probability distribution according to &ldquo;the number of hits per unit time in a lottery where $\mu$ hits per unit time&rdquo;. The probability function is given by</p>
<pre><code class="language-math" data-lang="math">f(x;\mu) = \frac{\mu^x}{x!}\exp(-\mu)\ \ (x=0,1,\cdots)
</code></pre><p>As you can see below, the Poisson distribution is very similar to the binomial distribution.</p>
<table>
<thead>
<tr>
<th></th>
<th>Binomial distribution</th>
<th>Poisson distribution</th>
</tr>
</thead>
<tbody>
<tr>
<td>What do you see?</td>
<td>Wins</td>
<td>Wins</td>
</tr>
<tr>
<td>Under what conditions</td>
<td>Constant number of trials</td>
<td>Constant time</td>
</tr>
</tbody>
</table>
<p>If the $n$ of the binomial distribution with the number of trials $n$ and the probability $\frac{\mu}{n}$ is $n\to\infty$, it converges to the Poisson distribution with the average $\mu$. The implementation is as below.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-Python" data-lang="Python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">poisson</span>(mu, sampleSize):
    n <span style="color:#f92672">=</span> <span style="color:#ae81ff">1000</span> <span style="color:#75715e"># large enough number</span>
    p <span style="color:#f92672">=</span> mu <span style="color:#f92672">/</span> n
    <span style="color:#66d9ef">return</span> binom(n, p, sampleSize)
</code></pre></div><p>Larger $n$ is theoretically better, but it increases the amount of calculation.
A sample that follows the Poisson distribution was generated from the <code>binom function</code>. The <code>binom function</code> is based on the <code>bernoulli function</code>. In other words, you have generated the Poisson distribution from the Bernoulli distribution. We will continue to adopt this method in the future.</p>
<h1 id="bernoulli-to-geometric-distribution">Bernoulli to geometric distribution</h1>
<p>Geometric distribution is a probability distribution according to &ldquo;the number of trials when a lottery with a winning probability of $p$ is drawn until it hits&rdquo;. The probability function is given by</p>
<pre><code class="language-math" data-lang="math">f(x;p)= p(1-p)^{x-1}\ \ (x=1,2,\cdots)
</code></pre><p>The sample generated from the geometric distribution with probability $p$ can be made from the Bernoulli distribution with probability $p$. The implementation is as below.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-Python" data-lang="Python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">geom</span>(p, sampleSize):
    x <span style="color:#f92672">=</span> []
    <span style="color:#66d9ef">for</span> _ <span style="color:#f92672">in</span> range(sampleSize):
        t <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
        <span style="color:#66d9ef">while</span> bernoulli(<span style="color:#ae81ff">1</span><span style="color:#f92672">-</span>p, <span style="color:#ae81ff">1</span>):
            t <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>
        x<span style="color:#f92672">.</span>append(t)
    <span style="color:#66d9ef">return</span> np<span style="color:#f92672">.</span>array(x)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-Python" data-lang="Python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">geom</span>(p, sampleSize):
    n <span style="color:#f92672">=</span> <span style="color:#ae81ff">1000</span>
    x <span style="color:#f92672">=</span> []
    s <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array([<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>], dtype<span style="color:#f92672">=</span>int)
    <span style="color:#66d9ef">while</span> len(x) <span style="color:#f92672">&lt;</span>sampleSize:
        x_ <span style="color:#f92672">=</span> bernoulli(p, n) <span style="color:#75715e"># Generates n samples of Bernoulli distribution at the same time.</span>
        x_ <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>where(x_ <span style="color:#f92672">==</span> <span style="color:#ae81ff">1</span>)[<span style="color:#ae81ff">0</span>]
        x_ <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>concatenate([s, x_])
        x<span style="color:#f92672">.</span>extend(x_[<span style="color:#ae81ff">1</span>:]<span style="color:#f92672">-</span>x_[:<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>])
        s <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array([x_[<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>]<span style="color:#f92672">-</span>n])
    <span style="color:#66d9ef">return</span> np<span style="color:#f92672">.</span>array(x[:sampleSize])
</code></pre></div><p>The two functions do the same processing, but I think the former is easier to understand and the latter is faster.</p>
<h1 id="geometric-distribution-to-negative-binomial-distribution">Geometric distribution to negative binomial distribution</h1>
<p>▽ Negative binomial distribution is a probability distribution according to &ldquo;the number of deviations when a lottery with a winning probability of $p$ is drawn until it hits $n$ times&rdquo;. The probability function is given by</p>
<pre><code class="language-math" data-lang="math">f(x;n,p) = \left(
\begin{matrix}
n+x-1\\
x
\end{matrix}
\right) p^n(1-p)^{x}\ \ (x=0,1,\cdots,n)


</code></pre><p>The only essential difference from the geometric distribution is “how many times you win the lottery”. As shown below, a negative binomial distribution can be created from the geometric distribution.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-Python" data-lang="Python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">nbinom</span>(n, p, sampleSize):
    x <span style="color:#f92672">=</span> geom(p, sampleSize <span style="color:#f92672">*</span> n)<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>
    x <span style="color:#f92672">=</span> x<span style="color:#f92672">.</span>reshape([sampleSize, n])
    <span style="color:#66d9ef">return</span> np<span style="color:#f92672">.</span>sum(x, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</code></pre></div><h1 id="geometric-distribution-to-exponential-distribution">Geometric distribution to exponential distribution</h1>
<p>The exponential distribution is a probability distribution that follows the &ldquo;time until one hit occurs in lots where $\frac{1}{\lambda}$ hits per unit time are averaged&rdquo;. The probability density function is given by</p>
<pre><code class="language-math" data-lang="math">f(x,\lambda) = \lambda\exp(-\lambda x)
</code></pre><p>The exponential distribution is very similar to the geometric distribution as follows.</p>
<table>
<thead>
<tr>
<th></th>
<th>Geometric distribution</th>
<th>Exponential distribution</th>
</tr>
</thead>
<tbody>
<tr>
<td>What do you see?</td>
<td>Number of trials until one hit</td>
<td>Time until one hit</td>
</tr>
<tr>
<td>What kind of lottery?</td>
<td>Hit probability is constant for each trial</td>
<td>Average number of hits per unit time is constant</td>
</tr>
</tbody>
</table>
<p>The property that the winning probability does not change regardless of time or trial is called <strong>memorylessness</strong>. Both the geometric and exponential distributions have this property.
An exponential distribution can be created by setting $p\to0$ in the geometric distribution.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-Python" data-lang="Python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">expon</span>(lam, sampleSize):
    p <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.01</span> <span style="color:#75715e"># small enough number</span>
    x <span style="color:#f92672">=</span> geom(p, sampleSize)
    <span style="color:#66d9ef">return</span> x <span style="color:#f92672">*</span> p <span style="color:#f92672">*</span> lam
</code></pre></div><p>The smaller $p$ is theoretically better, but it increases the amount of calculation.</p>
<h1 id="exponential-distribution-to-poisson-distribution">Exponential distribution to Poisson distribution</h1>
<p>▽ Poisson distribution can be created not only from binomial distribution but also from exponential distribution. The slide of <a href="https://www.slideshare.net/teramonagi/ss-11296227">A bad relationship between exponential distribution and Poisson distribution</a> is very easy to understand. The slide shows the implementation of R, but here is the implementation in Python.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-Python" data-lang="Python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">poisson_</span>(mu, sampleSize):
    x <span style="color:#f92672">=</span> []
    <span style="color:#66d9ef">while</span> len(x) <span style="color:#f92672">&lt;</span>sampleSize:
        t <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
        n <span style="color:#f92672">=</span> <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>
        <span style="color:#66d9ef">while</span> t <span style="color:#f92672">&lt;=</span> <span style="color:#ae81ff">1</span>:
            t <span style="color:#f92672">+=</span> expon(<span style="color:#ae81ff">1</span> <span style="color:#f92672">/</span> mu, <span style="color:#ae81ff">1</span>)
            n <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>
        x<span style="color:#f92672">.</span>append(n)
    <span style="color:#66d9ef">return</span> np<span style="color:#f92672">.</span>array(x)
</code></pre></div><h1 id="exponential-distribution-to-gamma-distribution">Exponential distribution to gamma distribution</h1>
<p>The gamma distribution is a probability distribution that follows the &ldquo;time to get $\alpha$ times per lot in lottery with $\frac{1}{\lambda}$ per unit time on average&rdquo;. The probability density function is given by</p>
<pre><code class="language-math" data-lang="math">f(x;\alpha,\lambda)=\frac{\lambda^\alpha}{\Gamma(\alpha)}x^{\alpha-1}\exp(-\lambda x)\ \ (x\ge0 )
</code></pre><p>However, $\Gamma(\alpha)$ is given by the following formula.</p>
<pre><code class="language-math" data-lang="math">\Gamma(\alpha)=\int_0^\infty t^{\alpha-1}\exp(-t)dt
</code></pre><p>The only essential difference from the exponential distribution is &ldquo;how many hits do you see?&rdquo; The gamma distribution can be created from the exponential distribution.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-Python" data-lang="Python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">gamma</span>(alpha, lam, sampleSize):
    x <span style="color:#f92672">=</span> expon(lam, sampleSize <span style="color:#f92672">*</span> alpha)
    x <span style="color:#f92672">=</span> x<span style="color:#f92672">.</span>reshape([sampleSize, alpha])<span style="color:#66d9ef">return</span> np<span style="color:#f92672">.</span>sum(x, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</code></pre></div><p>In addition, the argument $\alpha$ of the above <code>gamma function</code> must be a natural number. Any general gamma distribution $\alpha$ is OK as long as it is a positive number, but if it is a non-natural number $\alpha$, it cannot be created from the Bernoulli distribution, and it is difficult to explain, so we limit it to a natural number here. did.</p>
<h1 id="negative-binomial-to-gamma-distribution">Negative binomial to gamma distribution</h1>
<p>The gamma distribution can also be created from the negative binomial distribution. The gamma distribution and the negative binomial distribution are very similar, as follows.</p>
<table>
<thead>
<tr>
<th></th>
<th>Negative binomial distribution</th>
<th>Gamma distribution</th>
</tr>
</thead>
<tbody>
<tr>
<td>What do you see?</td>
<td>$n$ Number of trials before winning</td>
<td>$\alpha$ Time until winning</td>
</tr>
<tr>
<td>What kind of lottery?</td>
<td>Hit probability is constant for each trial</td>
<td>Average number of hits per unit time is constant</td>
</tr>
</tbody>
</table>
<p>The method of making a gamma distribution from a negative binomial distribution is exactly the same as the method of making an exponential distribution from a geometric distribution.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-Python" data-lang="Python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">gamma_</span>(alpha, lam, sampleSize):
    p <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.01</span> <span style="color:#75715e"># small enough number</span>
    x <span style="color:#f92672">=</span> nbinom(alpha, p, sampleSize)
    <span style="color:#66d9ef">return</span> x <span style="color:#f92672">*</span> p <span style="color:#f92672">*</span> lam
</code></pre></div><p>Again, the argument $\alpha$ must be a natural number.</p>
<h1 id="binomial-to-normal">Binomial to normal</h1>
<p>Any distribution is added infinitely to form a normal distribution (central limit theorem). There is an example in my first article &ldquo;<a href="https://qiita.com/yutera12/items/e9dfe9f6aafe96f3c700">Check the asymptotic properties of the probability distribution with Python</a>&rdquo;.
The binomial distribution was a Bernoulli distribution of $n$ pieces. The binomial distribution follows the normal distribution by setting $n\to\infty$. The probability density function of the normal distribution with mean $\mu$ and variance $\sigma^2$ is given by</p>
<pre><code class="language-math" data-lang="math">f(x;\mu,\sigma^2)=\frac{1}{\sqrt{2\pi\sigma^2}}\exp\biggl\{-\frac{(x-\mu)^2} {2\sigma^2}\biggr\}
</code></pre><p>You can generate a normally distributed sample with mean $\mu$ and standard deviation $\sigma$ by</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-Python" data-lang="Python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">norm</span>(mu, sigma, sampleSize):
    n <span style="color:#f92672">=</span> <span style="color:#ae81ff">1000</span> <span style="color:#75715e"># large enough number</span>
    p <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.5</span>
    x <span style="color:#f92672">=</span> binom(n, p, sampleSize)
    sd <span style="color:#f92672">=</span> (n <span style="color:#f92672">*</span> p <span style="color:#f92672">*</span> (<span style="color:#ae81ff">1</span><span style="color:#f92672">-</span>p)) <span style="color:#f92672">**</span> <span style="color:#ae81ff">0.5</span>
    x <span style="color:#f92672">=</span> (x<span style="color:#f92672">-</span>n <span style="color:#f92672">*</span> p) <span style="color:#f92672">/</span> sd <span style="color:#f92672">*</span> sigma <span style="color:#f92672">+</span> mu
    <span style="color:#66d9ef">return</span> x
</code></pre></div><p>#Normal to chi-square distribution
I can&rsquo;t explain it like a lottery, but the hypothesis test often shows the $\chi^2$ distribution. When $X_1,X_2,\cdots,X_{df}$ independently follow the standard normal distribution (normal distribution with mean 0 and variance 1), $X_1^2+X_2^2+\cdots+X_{df}^ 2$ is called $\chi^2$ distribution with $df$ degrees of freedom. The implementation is as below.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-Python" data-lang="Python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">chi2</span>(df, sampleSize):
    x <span style="color:#f92672">=</span> norm(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, sampleSize <span style="color:#f92672">*</span> df) <span style="color:#f92672">**</span> <span style="color:#ae81ff">2</span>
    x <span style="color:#f92672">=</span> x<span style="color:#f92672">.</span>reshape([sampleSize, df])
    <span style="color:#66d9ef">return</span> np<span style="color:#f92672">.</span>sum(x, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</code></pre></div><h1 id="chi-square-to-gamma-distribution">Chi-square to gamma distribution</h1>
<p>Although this cannot be explained like a lottery, the $\chi^2$ distribution with one degree of freedom matches the gamma distribution with $\alpha=1/2$ and $\lambda=1/2$. Due to the <strong>regeneration</strong> property of the gamma distribution, it is possible to generate the gamma distribution when $\alpha$ is $n$ times $\frac{1}{2}$ ($n$ is a natural number). Playability is discussed last.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-Python" data-lang="Python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">gamma__</span>(alpha, lam, sampleSize):
    df <span style="color:#f92672">=</span> int(np<span style="color:#f92672">.</span>round(alpha <span style="color:#f92672">*</span> <span style="color:#ae81ff">2</span>))
    x <span style="color:#f92672">=</span> chi2(<span style="color:#ae81ff">1</span>, sampleSize <span style="color:#f92672">*</span> df)
    x <span style="color:#f92672">=</span> x<span style="color:#f92672">.</span>reshape([sampleSize, df])
    x <span style="color:#f92672">=</span> x <span style="color:#f92672">*</span> lam <span style="color:#f92672">/</span> <span style="color:#ae81ff">2</span>
    <span style="color:#66d9ef">return</span> np<span style="color:#f92672">.</span>sum(x, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</code></pre></div><p>The argument of this function, $\alpha$, must be $n$ times $\frac{1}{2}$ ($n$ is a natural number).</p>
<h1 id="gamma-distribution-to-beta-distribution">Gamma distribution to beta distribution</h1>
<p>This cannot be explained like a lottery, but based on &ldquo;gamma distribution with parameter $(\alpha,\lambda)$&rdquo; and &ldquo;gamma distribution with parameter $(\beta,\lambda)$&rdquo;, You can generate a beta distribution with $(\alpha,\beta)$.
The density function of beta distribution is given by the following formula.</p>
<pre><code class="language-math" data-lang="math">f(x;\alpha,\beta)=x^{\alpha-1}(1-x)^{\beta-1}\ \ (0\le x\le 1)
</code></pre><p>Since the range that can be taken is 0 to 1, it is often used as the prior distribution of the parameter expressing the probability in Bayesian statistics.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-Python" data-lang="Python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">beta</span>(alpha, beta, sampleSize):
    x1 <span style="color:#f92672">=</span> gamma(alpha, <span style="color:#ae81ff">1</span>, sampleSize)
    x2 <span style="color:#f92672">=</span> gamma(beta, <span style="color:#ae81ff">1</span>, sampleSize)
    <span style="color:#66d9ef">return</span> x1 <span style="color:#f92672">/</span> (x1 <span style="color:#f92672">+</span> x2)
</code></pre></div><h1 id="beta-to-uniform-distribution">Beta to uniform distribution</h1>
<p>As is clear from the density function of the beta distribution, when $\alpha,\beta=1$, the beta distribution matches the uniform distribution. Samples that follow a uniform distribution can be made from the beta distribution.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-Python" data-lang="Python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">uniform</span>(sampleSize):
    <span style="color:#66d9ef">return</span> beta(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, sampleSize)
</code></pre></div><p>#Summary
<img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/571330/29577e08-257d-fda3-85cb-12c6f300ffc3.png" alt="kankei2.png"></p>
<p>The relationship with each other is obvious.</p>
<p>▽Here, I will explain <strong>Playability</strong>. Reproducibility is the property that the addition of distributions can be replaced with the addition of parameters. For example,</p>
<ol>
<li>X is a binomial distribution with trials $n$ and probability $p$</li>
<li>Let Y be a binomial distribution with trials $m$ and probability $p$</li>
</ol>
<p>Then $X+Y$ follows a binomial distribution with $(n+m)$ trials and probability $p$. 1. is the sum of $n$ Bernoulli distributions, and 2. is equal to the sum of $m$ Bernoulli distributions, so $X+Y$ is the sum of $(n+m)$ Bernoulli distributions, That is, the number of trials agrees with the binomial distribution of $(n+m)$.
According to the same theory, the distribution in front of the <code>pluralizing</code> arrow in the figure above always has the property of reproducibility (binomial distribution, negative binomial distribution, gamma distribution, $\chi^2$ distribution). And, of course, the limit of the binomial distribution, the normal distribution and the Poisson distribution, also has reproducibility.</p>
<h1 id="finally-python-experiment">Finally Python experiment</h1>
<p>Try <code>Bernoulli distribution -&gt; Geometric distribution -&gt; Exponential distribution -&gt; Gamma distribution -&gt; Beta distribution -&gt; Uniform distribution -&gt; Bernoulli distribution</code>.</p>
<p>Define a function for plotting in advance.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-Python" data-lang="Python"><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#f92672">as</span> plt
<span style="color:#f92672">import</span> seaborn <span style="color:#f92672">as</span> sns
sns<span style="color:#f92672">.</span>set(style<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;whitegrid&#39;</span>)

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">plot_descreteDitribution</span>(sample, truePf, xmin, xmax):
    sampleSize <span style="color:#f92672">=</span> len(sample)
    x <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>arange(xmin, xmax <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>)
    pf <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array([np<span style="color:#f92672">.</span>sum(sample <span style="color:#f92672">==</span> i) <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> x]) <span style="color:#f92672">/</span> sampleSize <span style="color:#75715e"># Experimental distribution</span>
    
    <span style="color:#75715e"># Plot the distribution obtained in the experiment in blue</span>
    plt<span style="color:#f92672">.</span>plot(x<span style="color:#f92672">-</span><span style="color:#ae81ff">0.1</span>, pf,<span style="color:#e6db74">&#39;bo&#39;</span>, ms<span style="color:#f92672">=</span><span style="color:#ae81ff">8</span>)
    plt<span style="color:#f92672">.</span>vlines(x<span style="color:#f92672">-</span><span style="color:#ae81ff">0.1</span>, <span style="color:#ae81ff">0</span>, pf, colors<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;b&#39;</span>, lw<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.5</span>)

    <span style="color:#75715e"># Plot true distribution in red</span>
    plt<span style="color:#f92672">.</span>plot(x <span style="color:#f92672">+</span> <span style="color:#ae81ff">0.1</span>, truePf(x),<span style="color:#e6db74">&#39;ro&#39;</span>, ms<span style="color:#f92672">=</span><span style="color:#ae81ff">8</span>)
    plt<span style="color:#f92672">.</span>vlines(x <span style="color:#f92672">+</span> <span style="color:#ae81ff">0.1</span>, <span style="color:#ae81ff">0</span>, truePf(x), colors<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;r&#39;</span>, lw<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.5</span>)

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">plot_continuousDitribution</span>(sample, truePf, xmin, xmax):
    sampleSize <span style="color:#f92672">=</span> len(sample)
    x <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>linspace(xmin, xmax, <span style="color:#ae81ff">100</span>)

    <span style="color:#75715e"># Plot the distribution obtained in the experiment in blue</span>
    th <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>linspace(xmin, xmax, <span style="color:#ae81ff">30</span>)
    hi <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array([np<span style="color:#f92672">.</span>sum(np<span style="color:#f92672">.</span>logical_and(th[i] <span style="color:#f92672">&lt;</span>sample, sample <span style="color:#f92672">&lt;=</span> th[i <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>])) <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">30</span><span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>)]) <span style="color:#f92672">/</span> (sampleSize <span style="color:#f92672">*</span> (th [<span style="color:#ae81ff">1</span>]<span style="color:#f92672">-</span>th[<span style="color:#ae81ff">0</span>]))
    plt<span style="color:#f92672">.</span>bar((th[:<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>] <span style="color:#f92672">+</span> th[<span style="color:#ae81ff">1</span>:]) <span style="color:#f92672">/</span> <span style="color:#ae81ff">2</span>, hi, width<span style="color:#f92672">=</span>(th[<span style="color:#ae81ff">1</span>]<span style="color:#f92672">-</span>th[<span style="color:#ae81ff">0</span>]))

    <span style="color:#75715e"># Plot true distribution in red</span>
    plt<span style="color:#f92672">.</span>plot(x, truePf(x),<span style="color:#e6db74">&#39;r&#39;</span>, linewidth<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span>)

    plt<span style="color:#f92672">.</span>xlim(xmin, xmax)
</code></pre></div><h4 id="geometric-distribution-from-bernoulli-distribution">Geometric distribution (from Bernoulli distribution)</h4>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-Python" data-lang="Python">p <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.2</span>
xmin <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
xmax <span style="color:#f92672">=</span> <span style="color:#ae81ff">20</span>

sample <span style="color:#f92672">=</span> geom(p, sampleSize)
truePf <span style="color:#f92672">=</span> <span style="color:#66d9ef">lambda</span> x: stats<span style="color:#f92672">.</span>geom<span style="color:#f92672">.</span>pmf(x, p)
plot_descreteDitribution(sample, truePf, xmin, xmax)
</code></pre></div><ul>
<li>Result</li>
</ul>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/571330/4c53ba62-f5a8-d89d-b19c-ba5db1c3e0c2.png" alt="Geometric distribution.png"></p>
<p>The red color is the distribution created by scipy.stats, and the blue color is the distribution created by the function created this time. The sampleSize is 10,000. The same applies hereafter.</p>
<h4 id="exponential-distribution-from-bernoulli-distribution---geometric-distribution">Exponential distribution (from Bernoulli distribution -&gt; Geometric distribution)</h4>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-Python" data-lang="Python">lam <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>
xmin <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
xmax <span style="color:#f92672">=</span> <span style="color:#ae81ff">10</span>

sample <span style="color:#f92672">=</span> expon(lam, sampleSize)
truePf <span style="color:#f92672">=</span> <span style="color:#66d9ef">lambda</span> x: stats<span style="color:#f92672">.</span>expon<span style="color:#f92672">.</span>pdf(x, scale<span style="color:#f92672">=</span>lam)
plot_continuousDitribution(sample, truePf, xmin, xmax)
</code></pre></div><ul>
<li>Result</li>
</ul>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/571330/52a6b2ba-195e-6fbc-1386-a3cd2fd404cf.png" alt="Exponential distribution.png">####Gammadistribution(fromBernoullidistribution-&gt;Geometricdistribution-&gt;Exponentialdistribution)</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-Python" data-lang="Python">alpha <span style="color:#f92672">=</span> <span style="color:#ae81ff">3</span>
lam <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>
xmin <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
xmax <span style="color:#f92672">=</span> <span style="color:#ae81ff">20</span>

sample <span style="color:#f92672">=</span> gamma(alpha, lam, sampleSize)
truePf <span style="color:#f92672">=</span> <span style="color:#66d9ef">lambda</span> x: stats<span style="color:#f92672">.</span>gamma<span style="color:#f92672">.</span>pdf(x, alpha, scale<span style="color:#f92672">=</span>lam)
plot_continuousDitribution(sample, truePf, xmin, xmax)
</code></pre></div><ul>
<li>Result</li>
</ul>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/571330/b92b21e0-331b-f9fd-550a-78f7c65ba810.png" alt="Gamma distribution.png"></p>
<h4 id="beta-distribution-from-bernoulli-distribution------gamma-distribution">Beta distribution (from Bernoulli distribution -&gt; &hellip; -&gt; Gamma distribution)</h4>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-Python" data-lang="Python">alpha <span style="color:#f92672">=</span> <span style="color:#ae81ff">3</span>
bet <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>
xmin <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
xmax <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>

sample <span style="color:#f92672">=</span> beta(alpha, bet, sampleSize)
truePf <span style="color:#f92672">=</span> <span style="color:#66d9ef">lambda</span> x: stats<span style="color:#f92672">.</span>beta<span style="color:#f92672">.</span>pdf(x, alpha, bet)
plot_continuousDitribution(sample, truePf, xmin, xmax)
</code></pre></div><ul>
<li>Result</li>
</ul>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/571330/fe0da76e-17a9-8c64-d179-b5fc52e6ecf7.png" alt="Beta distribution.png"></p>
<h4 id="uniform-distribution-from-bernoulli-distribution------beta-distribution">Uniform distribution (from Bernoulli distribution -&gt; &hellip; -&gt; beta distribution)</h4>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-Python" data-lang="Python">xmin <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
xmax <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>

sample <span style="color:#f92672">=</span> uniform(sampleSize)
truePf <span style="color:#f92672">=</span> <span style="color:#66d9ef">lambda</span> x: stats<span style="color:#f92672">.</span>uniform<span style="color:#f92672">.</span>pdf(x)
plot_continuousDitribution(sample, truePf, xmin, xmax)
</code></pre></div><ul>
<li>Result</li>
</ul>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/571330/c61822e0-fa64-8c87-a9db-f59e698b0bfa.png" alt="Uniform distribution.png"></p>
<h4 id="bernoulli-distribution-from-bernoulli-distribution------uniform-distribution-">Bernoulli distribution (from Bernoulli distribution -&gt; &hellip; -&gt; uniform distribution)! ?</h4>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-Python" data-lang="Python">p <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.2</span>
xmin <span style="color:#f92672">=</span> <span style="color:#f92672">-</span><span style="color:#ae81ff">2</span>
xmax <span style="color:#f92672">=</span> <span style="color:#ae81ff">4</span>

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">bernoulli_</span>(p, sampleSize):
    x <span style="color:#f92672">=</span> uniform(sampleSize)
    <span style="color:#66d9ef">return</span> (x <span style="color:#f92672">&lt;</span>p)<span style="color:#f92672">.</span>astype(int)

sample <span style="color:#f92672">=</span> bernoulli_(p, sampleSize)
truePf <span style="color:#f92672">=</span> <span style="color:#66d9ef">lambda</span> x: stats<span style="color:#f92672">.</span>bernoulli<span style="color:#f92672">.</span>pmf(x, p)
plot_descreteDitribution(sample, truePf, xmin, xmax)
</code></pre></div><ul>
<li>Result</li>
</ul>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/571330/44be09ae-2606-ee70-577c-818314e3301e.png" alt="Bernoulli distribution.png"></p>
<p>You can see that it worked.</p>
<h1 id="references">References</h1>
<ul>
<li><a href="https://www.slideshare.net/hirokiiida165/ss-78477986">Various probability distributions and their relationships</a></li>
<li><a href="https://qiita.com/qiita_kuru/items/d9782185652351c78aac">Summary of features of typical probability distribution</a></li>
<li><a href="https://docs.scipy.org/doc/scipy/reference/stats.html">scipy.stats</a></li>
<li><a href="https://qiita.com/yutera12/items/e9dfe9f6aafe96f3c700">Check the asymptotic properties of the probability distribution with Python</a></li>
<li><a href="https://www.slideshare.net/teramonagi/ss-11296227">A bad relationship between exponential distribution and Poisson distribution</a></li>
<li><a href="https://qiita.com/drken/items/089b8443305df047b44e">How to pass the statistical test 1st grade</a></li>
</ul>

    </article>
  </div>

  
  
  
  <script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-169005401-1', 'auto');
  ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  

  
<link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.css" />
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#216942",
      "text": "#b2d192"
    },
    "button": {
      "background": "#afed71"
    }
  }
})});
</script>

</body>

</html>
