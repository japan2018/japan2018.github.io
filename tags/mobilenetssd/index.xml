<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>MobileNetSSD on Memo Tut</title>
    <link>https://memotut.com/tags/mobilenetssd/</link>
    <description>Recent content in MobileNetSSD on Memo Tut</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 04 Feb 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://memotut.com/tags/mobilenetssd/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>[Python] Learning with Pascal-VOC dataset of MobileNetV2-SSDLite [Docker version remake]</title>
      <link>https://memotut.com/learning-with-pascal-voc-dataset-of-mobilenetv2-ssdlite-docker-version-remake-107dd/</link>
      <pubDate>Tue, 04 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/learning-with-pascal-voc-dataset-of-mobilenetv2-ssdlite-docker-version-remake-107dd/</guid>
      <description>**PINTO_model_zoo** [![GitHub stars](https://img.shields.io/github/stars/PINTO0309/PINTO_model_zoo.svg?style=social&amp;amp;label=Stars)](https://github.com/PINTO0309/PINTO_model_zoo)  &amp;lt;img src=&amp;quot;https://github-link-card.s3.ap-northeast-1.amazonaws.com/PINTO0309/PINTO_model_zoo.png&amp;quot;width=&amp;quot;460px&amp;quot;&amp;gt;
1. Introduction I remade the MobileNet V2-SSD Lite training environment construction article that I wrote about a year ago into an ultra-simple specification. If you start work from the stage where the latest Docker for GPU is introduced, I think you can start training in about 15 minutes. I think there are almost no mistakes. After learning, I plan to do Integer Quantization of the trained model (.</description>
    </item>
    
  </channel>
</rss>