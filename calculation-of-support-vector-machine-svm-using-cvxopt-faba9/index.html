<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  <meta name="generator" content="Hugo 0.72.0" />

  
  <meta name="description" content="Some description">
  

  
  <link rel="apple-touch-icon" sizes="180x180" href="https://memotut.com/apple-touch-icon.png">

  
  <link rel="icon" type="image/png" sizes="32x32" href="https://memotut.com/favicon-32x32.png">

  
  <link rel="icon" type="image/png" sizes="16x16" href="https://memotut.com/favicon-16x16.png">

  
  <link rel="manifest" href="https://memotut.com/site.webmanifest">

  
  <link rel="mask-icon" href="https://memotut.com/safari-pinned-tab.svg" color="#5bbad5">

  <meta name="msapplication-TileColor" content="#da532c">

  <meta name="theme-color" content="#ffffff">

  
  <link rel="stylesheet" href="https://memotut.com/css/bootstrap.min.css" />

  
  <title>[Python] Calculation of support vector machine (SVM) (using cvxopt) | Memo Tut</title>
  

  <style>
body {
  min-width: 300px;
}

.custom-navbar {
  margin-bottom: 1em;
  height: 60px;
}

.custom-navbar a {
  display: inline-block; 
  padding: 18px 0;
  margin-right: 1em; 
  font-weight: bold; 
}

.custom-navbar a:hover,
.custom-navbar a:focus {
  text-decoration: none; 
}

@media print {
  .custom-navbar {
    display: none;
  }
}

article {
  padding-bottom: 1em;
}

img {
  max-width: 100%;
}


body {
  background-color: #fff;
}



body {
  color: #212529;
}



a {
  color: #007bff;
}



a:hover,
a:focus {
  color: #0056b3;
}



.custom-navbar {
  background-color: #212529;
}



.custom-navbar a {
  color: rgba(255, 255, 255, 0.75);
}



.custom-navbar a:hover,
.custom-navbar a:focus {
  color: rgba(255, 255, 255, 1);
}



.container {
  max-width: 800px;
}



pre {
  display: block;
  padding: 9.5px;
  word-break: break-all;
  word-wrap: break-word;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre code {
  padding: 0;
  font-size: inherit;
  color: inherit; 
  white-space: pre-wrap;
  background-color: transparent;
  border: none;
  border-radius: 0;
}

code {
  padding: 2px 4px;
  color: inherit; 
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
  font-size: .9em;
}



blockquote,
.blockquote {
  padding: 10px 20px;
  margin: 0 0 20px;
  font-size: 1em;
  border-left: 5px solid #6c757d;
}

</style>
</head>

<body>
  <nav class="custom-navbar">
  <div class="container">
    
    <a href="/">Posts</a>
    
    <a href="/tags/">Tags</a>
    
    <a href="/about/">About</a>
    
    <a href="/index.xml">RSS</a>
    
  </div>
</nav>
  
  <div class="container">
    <article>
      <h1>[Python] Calculation of support vector machine (SVM) (using cvxopt)</h1>
<p>
  <small class="text-secondary">
  
  
  Sep 26, 2014
  </small>
  

<small><code><a href="https://memotut.com/tags/python">Python</a></code></small>


<small><code><a href="https://memotut.com/tags/machine-learning"> machine learning</a></code></small>


<small><code><a href="https://memotut.com/tags/machinelearning"> MachineLearning</a></code></small>


<small><code><a href="https://memotut.com/tags/svm">svm</a></code></small>


<small><code><a href="https://memotut.com/tags/cvxopt">cvxopt</a></code></small>

</p>
<pre><code>Hello.
</code></pre>
<p>The calculation of the support vector machine (SVM) is based on the procedure (using cvxopt) of <a href="http://d.hatena.ne.jp/aidiary/20100503/1272889097">Discontinuation creation &ldquo;soft margin SVM&rdquo; about artificial intelligence</a>Ifyoufollowitexactly,youwillfeelalittlelikecalculatingthesolutionyourself.Inthefollowing<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>,theconvergentsolutionofLagrangemultiplieralpha,<a href="http://qiita.com/kkdd/items/7c146360730d2e2e50c4">tabplot</a>,etc.arealsoplotted(```class√óprediction==1``Highlightthedatathatbecomes`.prediction==0istheboundaryline).</p>
<pre><code class="language-console" data-lang="console">$ ./svm.py
file = classification.txt (len=200)

cvxopt result status: optimal
delta = 5.684342e-14
class = ('-1','+1')
confusion matrix:
 [[96 7]
 [34 63]]
</code></pre><p><img src="https://qiita-image-store.s3.amazonaws.com/0/54617/77e9f3f8-baa5-e4d4-778e-e8926c4bbf23.png" alt="contour.png">
<img src="https://qiita-image-store.s3.amazonaws.com/0/54617/16afbdeb-0628-5c33-0840-391c31eebb11.png" alt="tabplot.png">
<img src="https://qiita-image-store.s3.amazonaws.com/0/54617/56d33c9d-6a68-8c77-8b2e-49b45f924e80.jpeg" alt="alpha.jpg"></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-svm.py" data-lang="svm.py"><span style="color:#75715e">#!/usr/bin/env python</span>
<span style="color:#75715e"># -*- coding: utf-8 -*-</span>
<span style="color:#75715e"># support vector machine (SVM) calculation</span>
Use <span style="color:#75715e"># cvxopt.solvers.qp (Quadratic Programming)</span>

<span style="color:#f92672">from</span> __future__ <span style="color:#f92672">import</span> print_function
<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">import</span> cvxopt

Ccoeff <span style="color:#f92672">=</span> [<span style="color:#ae81ff">30</span>, <span style="color:#ae81ff">30</span>] <span style="color:#75715e"># soft margin coefficients of class</span>
SIGMA <span style="color:#f92672">=</span> <span style="color:#ae81ff">1.054</span> <span style="color:#75715e"># for non-linear kernel</span>
kname <span style="color:#f92672">=</span><span style="color:#e6db74">&#39;gaussian&#39;</span>

<span style="color:#75715e"># Gaussian RBF Kernel</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">gaussian_kernel</span>(x,y):
    gamma <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span> <span style="color:#f92672">/</span> (<span style="color:#ae81ff">2</span> <span style="color:#f92672">*</span> (SIGMA <span style="color:#f92672">**</span> <span style="color:#ae81ff">2</span>))
    <span style="color:#66d9ef">return</span> np<span style="color:#f92672">.</span>exp(<span style="color:#f92672">-</span>norm2(x<span style="color:#f92672">-</span>y) <span style="color:#f92672">*</span> gamma)

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">kernel</span>(x,y):
    <span style="color:#66d9ef">return</span> globals()[kname <span style="color:#f92672">+</span><span style="color:#e6db74">&#39;_kernel&#39;</span>](x,y)

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">norm2</span>(x):
    <span style="color:#66d9ef">return</span> np<span style="color:#f92672">.</span>dot(x, x)

<span style="color:#75715e"># Find Lagrange multiplier alpha by quadratic programming</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">QP</span>(dat, clas, Ccoeff):
    coeff <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array([Ccoeff[x<span style="color:#f92672">&gt;</span><span style="color:#ae81ff">0</span>] <span style="color:#66d9ef">for</span> x <span style="color:#f92672">in</span> clas])
    N, Z <span style="color:#f92672">=</span> len(dat), zip(clas, dat)
    Q <span style="color:#f92672">=</span> cvxopt<span style="color:#f92672">.</span>matrix(np<span style="color:#f92672">.</span>array([[c<span style="color:#f92672">*</span>c_<span style="color:#f92672">*</span>kernel(d,d_) <span style="color:#66d9ef">for</span> c, d <span style="color:#f92672">in</span> Z] <span style="color:#66d9ef">for</span> c_, d_ <span style="color:#f92672">in</span> Z]))
    p <span style="color:#f92672">=</span> cvxopt<span style="color:#f92672">.</span>matrix(<span style="color:#f92672">-</span>np<span style="color:#f92672">.</span>ones(N))
    G <span style="color:#f92672">=</span> cvxopt<span style="color:#f92672">.</span>matrix(np<span style="color:#f92672">.</span>vstack((np<span style="color:#f92672">.</span>diag([<span style="color:#f92672">-</span><span style="color:#ae81ff">1.0</span>]<span style="color:#f92672">*</span>N), np<span style="color:#f92672">.</span>identity(N))))
    h <span style="color:#f92672">=</span> cvxopt<span style="color:#f92672">.</span>matrix(np<span style="color:#f92672">.</span>hstack((np<span style="color:#f92672">.</span>zeros(N), coeff)))
    A <span style="color:#f92672">=</span> cvxopt<span style="color:#f92672">.</span>matrix(clas, (<span style="color:#ae81ff">1</span>,N))
    b <span style="color:#f92672">=</span> cvxopt<span style="color:#f92672">.</span>matrix(<span style="color:#ae81ff">0.0</span>)
    cvxopt<span style="color:#f92672">.</span>solvers<span style="color:#f92672">.</span>options[<span style="color:#e6db74">&#39;abstol&#39;</span>] <span style="color:#f92672">=</span> <span style="color:#ae81ff">1e-5</span>
    cvxopt<span style="color:#f92672">.</span>solvers<span style="color:#f92672">.</span>options[<span style="color:#e6db74">&#39;reltol&#39;</span>] <span style="color:#f92672">=</span> <span style="color:#ae81ff">1e-10</span>
    cvxopt<span style="color:#f92672">.</span>solvers<span style="color:#f92672">.</span>options[<span style="color:#e6db74">&#39;show_progress&#39;</span>] <span style="color:#f92672">=</span> False
    sol <span style="color:#f92672">=</span> cvxopt<span style="color:#f92672">.</span>solvers<span style="color:#f92672">.</span>qp(Q, p, G, h, A, b)
    alpha <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(sol[<span style="color:#e6db74">&#39;x&#39;</span>])<span style="color:#f92672">.</span>reshape(N)
    <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;cvxopt result status: </span><span style="color:#e6db74">%s</span><span style="color:#e6db74">&#39;</span> <span style="color:#f92672">%</span>sol[<span style="color:#e6db74">&#39;status&#39;</span>])
    <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;delta = </span><span style="color:#e6db74">%e</span><span style="color:#e6db74">&#39;</span> <span style="color:#f92672">%</span>np<span style="color:#f92672">.</span>dot(alpha, clas))
    <span style="color:#66d9ef">return</span> alpha

Find the index of <span style="color:#75715e"># support vectors</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">SV</span>(dat, clas, Ccoeff, alpha):
    supportVectors <span style="color:#f92672">=</span> []
    edgeVectors <span style="color:#f92672">=</span> []
    c <span style="color:#f92672">=</span> [Ccoeff[x<span style="color:#f92672">&gt;</span><span style="color:#ae81ff">0</span>] <span style="color:#66d9ef">for</span> x <span style="color:#f92672">in</span> clas]
    infinitesimal <span style="color:#f92672">=</span> <span style="color:#ae81ff">1e-3</span> <span style="color:#f92672">*</span> min(Ccoeff)
    <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(len(alpha)):
        <span style="color:#66d9ef">if</span> alpha[i] <span style="color:#f92672">&gt;</span>infinitesimal:
            supportVectors<span style="color:#f92672">.</span>append(i)
            <span style="color:#66d9ef">if</span> alpha[i] <span style="color:#f92672">&lt;</span>c[i]<span style="color:#f92672">-</span>infinitesimal:
                edgeVectors<span style="color:#f92672">.</span>append(i)
    bias <span style="color:#f92672">=</span> average([clas[i]<span style="color:#f92672">-</span>prediction(dat[i], alpha, clas, dat, supportVectors) <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> edgeVectors])
    <span style="color:#66d9ef">return</span> supportVectors, edgeVectors, bias

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">average</span>(x):
    <span style="color:#66d9ef">return</span> sum(x)<span style="color:#f92672">/</span>len(x)

<span style="color:#75715e"># Predicted value</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">prediction</span>(x, alpha, clas, dat, supportVectors, bias<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>):
    p <span style="color:#f92672">=</span> [alpha[i] <span style="color:#f92672">*</span> clas[i] <span style="color:#f92672">*</span> kernel(x, dat[i]) <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> supportVectors]
    <span style="color:#66d9ef">return</span> sum(p) <span style="color:#f92672">+</span> bias

<span style="color:#75715e"># Discriminant table confusion matrix</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">confusion_matrix</span>(clas, predict):
    mat <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>zeros([<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>], dtype<span style="color:#f92672">=</span>int)
    <span style="color:#66d9ef">for</span> c, p <span style="color:#f92672">in</span> zip(clas, predict):
        mat[c<span style="color:#f92672">&gt;</span><span style="color:#ae81ff">0</span>, p<span style="color:#f92672">&gt;</span><span style="color:#ae81ff">0</span>] <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>
    <span style="color:#66d9ef">return</span> mat

<span style="color:#75715e"># Supervised data classification.txt (N = 200)</span>
<span style="color:#75715e"># http://research.microsoft.com/en-us/um/people/cmbishop/prml/webdatasets/classification.txt</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">make_data</span>():
    filename <span style="color:#f92672">=</span><span style="color:#e6db74">&#39;classification.txt&#39;</span>
    dat_clas <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>genfromtxt(filename)
    dat, clas <span style="color:#f92672">=</span> dat_clas[:,<span style="color:#ae81ff">0</span>:<span style="color:#ae81ff">2</span>], dat_clas[:,<span style="color:#ae81ff">2</span>]
    clas <span style="color:#f92672">=</span> clas <span style="color:#f92672">*</span> <span style="color:#ae81ff">2</span><span style="color:#f92672">-</span><span style="color:#ae81ff">1.0</span> <span style="color:#75715e"># Convert teacher signal to -1 or 1</span>
    classname <span style="color:#f92672">=</span> (<span style="color:#e6db74">&#39;-1&#39;</span>,<span style="color:#e6db74">&#39;+1&#39;</span>)
    <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;file = </span><span style="color:#e6db74">%s</span><span style="color:#e6db74"> (len=</span><span style="color:#e6db74">%d</span><span style="color:#e6db74">)&#39;</span> <span style="color:#f92672">%</span>(filename, len(dat)))
    <span style="color:#66d9ef">return</span> dat, clas, classname


<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">main</span>():
    dat, clas, classname <span style="color:#f92672">=</span> make_data()

    <span style="color:#75715e">#SVM solution using quadratic programming</span>
    alpha <span style="color:#f92672">=</span> QP(dat, clas, Ccoeff)
    supportVectors, edgeVectors, bias <span style="color:#f92672">=</span> SV(dat, clas, Ccoeff, alpha)

    <span style="color:#75715e">#Predicted value, discrimination table</span>
    predict <span style="color:#f92672">=</span> [prediction(x, alpha, clas, dat, supportVectors, bias) <span style="color:#66d9ef">for</span> x <span style="color:#f92672">in</span> dat]
    <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;class =&#39;</span>, classname,<span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span>, confusion_matrix(clas, predict))

<span style="color:#66d9ef">if</span> __name__ <span style="color:#f92672">==</span><span style="color:#e6db74">&#39;__main__&#39;</span>:
    main()
</code></pre></div><hr>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>This is the same calculation as in PRML Chapter 7, but I feel that the plot result diagram in this book is a little unsuitable for solution convergence or contour line calculation. <a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>

    </article>
  </div>

  
  
  
  <script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-169005401-1', 'auto');
  ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  

  
<link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.css" />
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#216942",
      "text": "#b2d192"
    },
    "button": {
      "background": "#afed71"
    }
  }
})});
</script>

</body>

</html>
