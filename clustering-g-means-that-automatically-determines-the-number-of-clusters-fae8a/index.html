<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  <meta name="generator" content="Hugo 0.72.0" />

  
  <meta name="description" content="Some description">
  

  
  <link rel="apple-touch-icon" sizes="180x180" href="https://japan2018.github.io/apple-touch-icon.png">

  
  <link rel="icon" type="image/png" sizes="32x32" href="https://japan2018.github.io/favicon-32x32.png">

  
  <link rel="icon" type="image/png" sizes="16x16" href="https://japan2018.github.io/favicon-16x16.png">

  
  <link rel="manifest" href="https://japan2018.github.io/site.webmanifest">

  
  <link rel="mask-icon" href="https://japan2018.github.io/safari-pinned-tab.svg" color="#5bbad5">

  <meta name="msapplication-TileColor" content="#da532c">

  <meta name="theme-color" content="#ffffff">

  
  <link rel="stylesheet" href="https://japan2018.github.io/css/bootstrap.min.css" />

  
  <title>Clustering G-means that automatically determines the number of clusters | Some Title</title>
  

  <style>
body {
  min-width: 300px;
}

.custom-navbar {
  margin-bottom: 1em;
  height: 60px;
}

.custom-navbar a {
  display: inline-block; 
  padding: 18px 0;
  margin-right: 1em; 
  font-weight: bold; 
}

.custom-navbar a:hover,
.custom-navbar a:focus {
  text-decoration: none; 
}

@media print {
  .custom-navbar {
    display: none;
  }
}

article {
  padding-bottom: 1em;
}

img {
  max-width: 100%;
}


body {
  background-color: #fff;
}



body {
  color: #212529;
}



a {
  color: #007bff;
}



a:hover,
a:focus {
  color: #0056b3;
}



.custom-navbar {
  background-color: #212529;
}



.custom-navbar a {
  color: rgba(255, 255, 255, 0.75);
}



.custom-navbar a:hover,
.custom-navbar a:focus {
  color: rgba(255, 255, 255, 1);
}



.container {
  max-width: 800px;
}



pre {
  display: block;
  padding: 9.5px;
  word-break: break-all;
  word-wrap: break-word;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre code {
  padding: 0;
  font-size: inherit;
  color: inherit; 
  white-space: pre-wrap;
  background-color: transparent;
  border: none;
  border-radius: 0;
}

code {
  padding: 2px 4px;
  color: inherit; 
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
  font-size: .9em;
}



blockquote,
.blockquote {
  padding: 10px 20px;
  margin: 0 0 20px;
  font-size: 1em;
  border-left: 5px solid #6c757d;
}

</style>
</head>

<body>
  <nav class="custom-navbar">
  <div class="container">
    
    <a href="/">Posts</a>
    
    <a href="/tags/">Tags</a>
    
    <a href="/about/">About</a>
    
    <a href="/index.xml">RSS</a>
    
  </div>
</nav>
  
  <div class="container">
    <article>
      <h1>Clustering G-means that automatically determines the number of clusters</h1>
<p>
  <small class="text-secondary">
  
  
  Dec 6, 2019
  </small>
  

<small><code><a href="https://japan2018.github.io/tags/python">Python</a></code></small>


<small><code><a href="https://japan2018.github.io/tags/clustering"> clustering</a></code></small>


<small><code><a href="https://japan2018.github.io/tags/pyclustering"> pyclustering</a></code></small>

</p>
<pre><code>This article is the 6th day entry for [Advent Calendar 2019 for Freee People](https://adventar.org/calendars/4414).
</code></pre>
<p>I started writing in the middle of the night the day before and I was writing while saying hi-hee.</p>
<p>#Introduction
Do you all know the library <a href="https://pyclustering.github.io/">PyClustering</a>?PyClusteringisaclustering-specificlibraryavailablefromPythonandC++.ThealgorithmcalledG-meansisnewlyimplementedinsuchPyClustering<a href="https://github.com/annoviko/pyclustering/releases/tag/0.9.2">v0.9.2</a>. I saw the name G-means for the first time + I couldn&rsquo;t find an article in Japanese, so I looked it up and put it together.
The algorithm itself is simple, so it may be easiest to read <a href="https://papers.nips.cc/paper/2526-learning-the-k-in-k-means.pdf">Paper</a> directly. not.</p>
<h1 id="g-means">G-means</h1>
<p>G-means is an extension of K-means and is an algorithm that automatically determines the number of clusters that was a parameter of K-means.
There is a similar method called X-means, but there is &ldquo;<a href="https://qiita.com/deaikei/items/8615362d320c76e2ce0b">I examined the X-means method that automatically estimates the number of clusters</a>&ldquo;Itisintroducedwiththecodeclearly.(Bytheway,inPyclustering<a href="https://pyclustering.github.io/docs/0.9.2/html/d2/d8b/namespacepyclustering_1_1cluster_1_1xmeans.html">X-meanscanalsobeused</a>)</p>
<h2 id="algorithm">Algorithm</h2>
<p>The algorithm is as follows. It is the same as X-means that it starts with a small number of clusters and subdivides it with different stop conditions.</p>
<ol>
<li>Decide some center points appropriately.</li>
<li>Perform clustering by K-means using the center point determined in 1. as the initial value.</li>
<li>Perform a statistical test (Andersonâ€“Darling test) on the sample in each cluster created in step 2 to determine if it follows the Gaussian distribution. <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></li>
<li>If the null hypothesis is rejected, divide the cluster into two. If the null hypothesis is not rejected, the cluster is confirmed. <sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup></li>
<li>Repeat steps 2 to 4 until the cluster is no longer split.</li>
</ol>
<p>The algorithm is above, but in the paper</p>
<ul>
<li>How to decide a new center point when the cluster is divided in 4.</li>
<li>Device to facilitate Anderson-Darling test</li>
</ul>
<p>Is also mentioned.</p>
<h3 id="how-to-determine-a-new-initial-value-for-the-center-point-when-dividing-a-cluster">How to determine a new initial value for the center point when dividing a cluster</h3>
<ul>
<li>When the center point in the cluster is $\mathbf{c}$, two new points, $\mathbf{c} \pm \mathbf{m}$, are used as new center point initial values.</li>
<li>Two types of $\mathbf{m}$ have been proposed.
-Randomly decide.
-Principal component analysis is performed on the samples in the cluster, and the first principal component is $\mathbf{s}$, and the eigenvalue (principal component variance) of the principal component is $\lambda$ $\mathbf{m} = \mathbf{s} \sqrt{2 \lambda / \pi}$. <sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup></li>
</ul>
<p>In the paper, the method that uses the second principal component was adopted, but in Pyclustering, <a href="https://github.com/annoviko/pyclustering/blob/3457a2457c9aa385f625d628cec19dd6fada8326/pyclustering/cluster/gmeans.py#L331">it seems that the first method is used</a>.</p>
<h3 id="anderson-a-device-to-make-the-darling-test-easier">Anderson-A device to make the Darling test easier</h3>
<p>If the sample to be clustered is left as it is, it is difficult to test statistically in a high dimension, so it is projected in one dimension. Specifically, the sample $\mathbf{x}$ is projected to one-dimensional $x^{\prime}$ as follows.</p>
<pre><code class="language-math" data-lang="math">x^{\prime} = \frac{\langle \mathbf{x}, \mathbf{v} \rangle}{\| \mathbf{v} \|^2}
</code></pre><p>However, $\mathbf{v}$ is the two points determined by the above &ldquo;How to determine the new initial value of the center point when dividing the cluster&rdquo;, $\mathbf{c}_1$, $\mathbf{c}\ It is $\mathbf{c}_1$-$\mathbf{c}_2$ when _2$ is set. It means projecting on the first principal component (the axis of the direction that has the spread) and testing whether it follows the normal distribution.</p>
<h2 id="practice">Practice</h2>
<p>Now that we know the algorithm, let&rsquo;s actually use Pyclustering to perform clustering. For the time being <a href="https://qiita.com/deaikei/items/8615362d320c76e2ce0b#%E3%81%95%E3%82%89%E3%81%AB%E3%83%A2%E3%83%A4%E3%83%83%E3%81%A8%E3%81%97%E3%81%9F%E3%83%87%E3%83%BC%E3%82%BF%E3%82%92%E3%82%AF%E3%83%A9%E3%82%B9%E3%82%BF%E3%83%AA%E3%83%B3%E3%82%B0%E3%81%95%E3%81%9B%E3%81%A6%E3%81%BF%E3%82%8B">here</a> and the same data was tried.</p>
<details>
<summary>Dummy data generation</summary>
<div>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> sklearn.datasets <span style="color:#f92672">import</span> make_blobs

X, Y <span style="color:#f92672">=</span> make_blobs(n_samples<span style="color:#f92672">=</span><span style="color:#ae81ff">500</span>,
                  n_features<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>,
                  centers<span style="color:#f92672">=</span><span style="color:#ae81ff">8</span>,
                  cluster_std<span style="color:#f92672">=</span><span style="color:#ae81ff">1.5</span>,
                  center_box<span style="color:#f92672">=</span>(<span style="color:#f92672">-</span><span style="color:#ae81ff">10.0</span>, <span style="color:#ae81ff">10.0</span>),
                  shuffle<span style="color:#f92672">=</span>True,
                  random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</code></pre></div></div>
</details>
<h3 id="correct-answer-label">Correct answer label</h3>
<details>
<summary>correct label plot</summary>
<div>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> seaborn <span style="color:#f92672">as</span> sns
sns<span style="color:#f92672">.</span>set(style<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;whitegrid&#34;</span>)
sns<span style="color:#f92672">.</span>scatterplot(
    X[:, <span style="color:#ae81ff">0</span>], X[:, <span style="color:#ae81ff">1</span>], hue<span style="color:#f92672">=</span>Y, legend<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;full&#34;</span>
);
</code></pre></div></div>
</details>
<p>Since <code>centers=8</code>, naturally 8 colors will appear.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/260932/aab3bd67-8f7e-0890-cda0-1f1d2a152df8.png" alt="Correct label"></p>
<h3 id="g-means-1">G-means</h3>
<p>Well, here is the main subject. What will it look like when I try to use G-means?</p>
<details>
<summary>gmeans result plot</summary>
<div>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> pyclustering.cluster <span style="color:#f92672">import</span> gmeans
<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">import</span> itertools

gmeans_instance <span style="color:#f92672">=</span> gmeans<span style="color:#f92672">.</span>gmeans(X)<span style="color:#f92672">.</span>process()

clusters <span style="color:#f92672">=</span> gmeans_instance<span style="color:#f92672">.</span>get_clusters()
centers <span style="color:#f92672">=</span> gmeans_instance<span style="color:#f92672">.</span>get_centers()

labels_size <span style="color:#f92672">=</span> len(
    list(itertools<span style="color:#f92672">.</span>chain<span style="color:#f92672">.</span>from_iterable(clusters))
)
labels <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>zeros((<span style="color:#ae81ff">1</span>, labels_size))
<span style="color:#66d9ef">for</span> n, n_th_cluster <span style="color:#f92672">in</span> np<span style="color:#f92672">.</span>ndenumerate(clusters):
    <span style="color:#66d9ef">for</span> img_num <span style="color:#f92672">in</span> n_th_cluster:
        labels[<span style="color:#ae81ff">0</span>][img_num] <span style="color:#f92672">=</span> n[<span style="color:#ae81ff">0</span>]
labels <span style="color:#f92672">=</span> labels<span style="color:#f92672">.</span>ravel()

sns<span style="color:#f92672">.</span>scatterplot(
    X[:, <span style="color:#ae81ff">0</span>], X[:, <span style="color:#ae81ff">1</span>], hue<span style="color:#f92672">=</span>labels, legend<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;full&#34;</span>
)

</code></pre></div></div>
</details>
<p>Oh. The number of clusters is not eight, but they are clustered in a way that makes you feel comfortable. Isn&rsquo;t this pretty cool?</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/260932/50ccc32f-9272-fa17-498d-a2294074bac6.png" alt="G-means"></p>
<p>If you want to create clusters where you have no idea what the number of clusters is, using G-means seems like a nice option.</p>
<h3 id="the-x-means-of-the-opposing-horse-is">The X-means of the opposing horse is&hellip;</h3>
<p>Finally I would like to try using Pyclustering&rsquo;s X-means as a counter horse and compare the results.</p>
<details>
<summary>xmeans result plot</summary>
<div>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> pyclustering.cluster <span style="color:#f92672">import</span> xmeans
<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">import</span> itertools

xmeans_instance <span style="color:#f92672">=</span> xmeans<span style="color:#f92672">.</span>xmeans(X)<span style="color:#f92672">.</span>process()

clusters <span style="color:#f92672">=</span> xmeans_instance<span style="color:#f92672">.</span>get_clusters()
centers <span style="color:#f92672">=</span> xmeans_instance<span style="color:#f92672">.</span>get_centers()

labels_size <span style="color:#f92672">=</span> len(
    list(itertools<span style="color:#f92672">.</span>chain<span style="color:#f92672">.</span>from_iterable(clusters))
)
labels <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>zeros((<span style="color:#ae81ff">1</span>, labels_size))<span style="color:#66d9ef">for</span> n, n_th_cluster <span style="color:#f92672">in</span> np<span style="color:#f92672">.</span>ndenumerate(clusters):
    <span style="color:#66d9ef">for</span> img_num <span style="color:#f92672">in</span> n_th_cluster:
        labels[<span style="color:#ae81ff">0</span>][img_num] <span style="color:#f92672">=</span> n[<span style="color:#ae81ff">0</span>]
labels <span style="color:#f92672">=</span> labels<span style="color:#f92672">.</span>ravel()

sns<span style="color:#f92672">.</span>scatterplot(
    X[:, <span style="color:#ae81ff">0</span>], X[:, <span style="color:#ae81ff">1</span>], hue<span style="color:#f92672">=</span>labels, legend<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;full&#34;</span>
)
</code></pre></div></div>
</details>
<p>Oh? <a href="https://qiita.com/deaikei/items/8615362d320c76e2ce0b#%E3%81%95%E3%82%89%E3%81%AB%E3%83%A2%E3%83%A4%E3%83%83%E3%81%A8%E3%81%97%E3%81%9F%E3%83%87%E3%83%BC%E3%82%BF%E3%82%92%E3%82%AF%E3%83%A9%E3%82%B9%E3%82%BF%E3%83%AA%E3%83%B3%E3%82%B0%E3%81%95%E3%81%9B%E3%81%A6%E3%81%BF%E3%82%8B">Referenced X-means article</a> is completely different&hellip;</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/260932/d5faf3cd-8176-333e-352b-07916f46b204.png" alt="X-means"></p>
<p>The G-means paper also contains experimental results that X-means overfits and overestimates the number of clusters, so the results are uncomfortable&hellip; (This is not deeply digging)
As far as Pyclustering is used, it seems better to use G-means than X-means.</p>
<h1 id="in-conclusion">in conclusion</h1>
<p>I have introduced the algorithm of G-means recently (?) implemented in Pyclustering and summarized the results of actually using it. G-means gave better results than X-means when I used it lightly, so it might be better to use G-means when you want to try clustering for the time being.</p>
<p>Huh. The Advent Calendar was in time&hellip; Let&rsquo;s go to bed&hellip; It&rsquo;s early morning! ! !</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>G-means is like Gaussian G. <a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>The paper uses $\alpha=0.0001$, but <a href="https://github.com/annoviko/pyclustering/blob/3457a2457c9aa385f625d628cec19dd6fada8326/pyclustering/cluster/gmeans.py#L292-L296">Pyclustering</a>Thenitseemsthat$\alpha=0.01$.ThepapersaysthatitisbettertoreducetheprobabilitythatTypeIError(falsepositive) occurs, so is this implementation okay? I will think. <a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>Is it an image when dividing the axis in the direction where the samples are scattered? <a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>

    </article>
  </div>

  
  
  
  <script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-123456789-1', 'auto');
  ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  

  
<link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.css" />
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#216942",
      "text": "#b2d192"
    },
    "button": {
      "background": "#afed71"
    }
  }
})});
</script>

</body>

</html>
