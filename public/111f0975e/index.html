<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  <meta name="generator" content="Hugo 0.72.0" />

  
  <meta name="description" content="Some description">
  

  
  <link rel="apple-touch-icon" sizes="180x180" href="https://memotut.com/apple-touch-icon.png">

  
  <link rel="icon" type="image/png" sizes="32x32" href="https://memotut.com/favicon-32x32.png">

  
  <link rel="icon" type="image/png" sizes="16x16" href="https://memotut.com/favicon-16x16.png">

  
  <link rel="manifest" href="https://memotut.com/site.webmanifest">

  
  <link rel="mask-icon" href="https://memotut.com/safari-pinned-tab.svg" color="#5bbad5">

  <meta name="msapplication-TileColor" content="#da532c">

  <meta name="theme-color" content="#ffffff">

  
  <link rel="stylesheet" href="https://memotut.com/css/bootstrap.min.css" />

  
  <title>[Python] opencv-python image processing introduction | Memo Tut</title>
  

  <style>
body {
  min-width: 300px;
}

.custom-navbar {
  margin-bottom: 1em;
  height: 60px;
}

.custom-navbar a {
  display: inline-block; 
  padding: 18px 0;
  margin-right: 1em; 
  font-weight: bold; 
}

.custom-navbar a:hover,
.custom-navbar a:focus {
  text-decoration: none; 
}

@media print {
  .custom-navbar {
    display: none;
  }
}

article {
  padding-bottom: 1em;
}

img {
  max-width: 100%;
}


body {
  background-color: #fff;
}



body {
  color: #212529;
}



a {
  color: #007bff;
}



a:hover,
a:focus {
  color: #0056b3;
}



.custom-navbar {
  background-color: #212529;
}



.custom-navbar a {
  color: rgba(255, 255, 255, 0.75);
}



.custom-navbar a:hover,
.custom-navbar a:focus {
  color: rgba(255, 255, 255, 1);
}



.container {
  max-width: 800px;
}



pre {
  display: block;
  padding: 9.5px;
  word-break: break-all;
  word-wrap: break-word;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre code {
  padding: 0;
  font-size: inherit;
  color: inherit; 
  white-space: pre-wrap;
  background-color: transparent;
  border: none;
  border-radius: 0;
}

code {
  padding: 2px 4px;
  color: inherit; 
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
  font-size: .9em;
}



blockquote,
.blockquote {
  padding: 10px 20px;
  margin: 0 0 20px;
  font-size: 1em;
  border-left: 5px solid #6c757d;
}

</style>
</head>

<body>
  <nav class="custom-navbar">
  <div class="container">
    
    <a href="/">Posts</a>
    
    <a href="/tags/">Tags</a>
    
    <a href="/about/">About</a>
    
    <a href="/index.xml">RSS</a>
    
  </div>
</nav>
  
  <div class="container">
    <article>
      <h1>[Python] opencv-python image processing introduction</h1>
<p>
  <small class="text-secondary">
  
  
  Jan 23, 2020
  </small>
  

<small><code><a href="https://memotut.com/tags/python">Python</a></code></small>


<small><code><a href="https://memotut.com/tags/opencv">OpenCV</a></code></small>

</p>
<pre><code>I will write that I investigated the preprocessing method of images for machine learning.
</code></pre>
<p>The content is halfway, but I think I will add it in the future.</p>
<h1 id="trial-environment">Trial environment</h1>
<p>Windows10
python 3.6
opencv-python 4.1.2.30</p>
<h1 id="thresholding-cvthresholdsrc-threshold-maxvalue-thresholdtype">Thresholding: cv.Threshold(src, threshold, maxValue, thresholdType)</h1>
<p>opencv documentation
<a href="http://labs.eecs.tottori-u.ac.jp/sd/Member/oyamada/OpenCV/html/py_tutorials/py_imgproc/py_thresholding/py_thresholding.html">http://labs.eecs.tottori-u.ac.jp/sd/Member/oyamada/OpenCV/html/py_tutorials/py_imgproc/py_thresholding/py_thresholding.html</a></p>
<h3 id="binarize-by-specifying-threshold">Binarize by specifying threshold</h3>
<p>I will make an appropriate gradation image and binarize it
<img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/277233/9c81460b-5477-4a62-9f83-cdf38bfc4d6c.png" alt="image.png"></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># make gray scale picture</span>
im_gray <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array([np<span style="color:#f92672">.</span>arange(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">256</span>, <span style="color:#ae81ff">2</span>) <span style="color:#66d9ef">for</span> k <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">100</span>)])
im_gray <span style="color:#f92672">=</span> im_gray<span style="color:#f92672">.</span>astype(<span style="color:#e6db74">&#39;uint8&#39;</span>)
<span style="color:#66d9ef">print</span>(im_gray<span style="color:#f92672">.</span>shape)

<span style="color:#75715e"># apply threshold</span>
ret, thresh1 <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>threshold(im_gray,<span style="color:#ae81ff">127</span>,<span style="color:#ae81ff">255</span>,cv2<span style="color:#f92672">.</span>THRESH_BINARY)

<span style="color:#75715e"># show picture</span>
plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">7</span>, <span style="color:#ae81ff">6</span>))

ax <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">1</span>)
ax<span style="color:#f92672">.</span>imshow(im_gray,<span style="color:#e6db74">&#39;gray&#39;</span>)
ax<span style="color:#f92672">.</span>set_xticks([])
ax<span style="color:#f92672">.</span>set_yticks([])
ax<span style="color:#f92672">.</span>set_title(<span style="color:#e6db74">&#39;ORIGINAL&#39;</span>)

ax <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>)
ax<span style="color:#f92672">.</span>imshow(thresh1,<span style="color:#e6db74">&#39;gray&#39;</span>)
ax<span style="color:#f92672">.</span>set_xticks([])
ax<span style="color:#f92672">.</span>set_yticks([])
ax<span style="color:#f92672">.</span>set_title(<span style="color:#e6db74">&#39;BINARY&#39;</span>)

plt<span style="color:#f92672">.</span>show()
</code></pre></div><h3 id="threshold-is-automatically-set-and-binarized">Threshold is automatically set and binarized</h3>
<p>Binarize using Otsu&rsquo;s method
<img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/277233/fd15b018-63d3-498c-22d7-344fd929144c.png" alt="image.png"></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># make gray scale picture</span>
im_gray <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array([np<span style="color:#f92672">.</span>arange(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">256</span>, <span style="color:#ae81ff">2</span>) <span style="color:#66d9ef">for</span> k <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">100</span>)])
im_gray <span style="color:#f92672">=</span> im_gray<span style="color:#f92672">.</span>astype(<span style="color:#e6db74">&#39;uint8&#39;</span>)
<span style="color:#66d9ef">print</span>(im_gray<span style="color:#f92672">.</span>shape)

<span style="color:#75715e"># global thresholding</span>
ret1,th1 <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>threshold(im_gray,<span style="color:#ae81ff">127</span>,<span style="color:#ae81ff">255</span>,cv2<span style="color:#f92672">.</span>THRESH_BINARY)

<span style="color:#75715e"># Otsu&#39;s thresholding</span>
ret2,th2 <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>threshold(im_gray,<span style="color:#ae81ff">0</span>,<span style="color:#ae81ff">255</span>,cv2<span style="color:#f92672">.</span>THRESH_BINARY<span style="color:#f92672">+</span>cv2<span style="color:#f92672">.</span>THRESH_OTSU)


<span style="color:#75715e"># show picture</span>
plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">7</span>, <span style="color:#ae81ff">6</span>))

ax <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">1</span>)
ax<span style="color:#f92672">.</span>imshow(im_gray,<span style="color:#e6db74">&#39;gray&#39;</span>)
ax<span style="color:#f92672">.</span>set_xticks([])
ax<span style="color:#f92672">.</span>set_yticks([])
ax<span style="color:#f92672">.</span>set_title(<span style="color:#e6db74">&#39;ORIGINAL&#39;</span>)

ax <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>)
ax<span style="color:#f92672">.</span>imshow(thresh1,<span style="color:#e6db74">&#39;gray&#39;</span>)
ax<span style="color:#f92672">.</span>set_xticks([])
ax<span style="color:#f92672">.</span>set_yticks([])
ax<span style="color:#f92672">.</span>set_title(<span style="color:#e6db74">&#39;OTSU&#39;</span>)

plt<span style="color:#f92672">.</span>show()
</code></pre></div><h3 id="binarization-with-dynamic-threshold-adaptivethresholdsrc-maxvalue-adaptivemethod-thresholdtype-blocksize-c-dst">Binarization with dynamic threshold: adaptiveThreshold(src, maxValue, adaptiveMethod, thresholdType, blockSize, C[, dst])</h3>
<p>It is used when there is a gradation of lightness such as a photographic image and it is not possible to binarize the entire image with one threshold value.
<img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/277233/24b3290f-b326-e8d6-33ea-00244c40f313.png" alt="image.png">
<a href="http://labs.eecs.tottori-u.ac.jp/sd/Member/oyamada/OpenCV/html/py_tutorials/py_imgproc/py_thresholding/py_thresholding.html">http://labs.eecs.tottori-u.ac.jp/sd/Member/oyamada/OpenCV/html/py_tutorials/py_imgproc/py_thresholding/py_thresholding.html</a></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> cv2
<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">from</span> matplotlib <span style="color:#f92672">import</span> pyplot <span style="color:#66d9ef">as</span> plt

img <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>imread(<span style="color:#e6db74">&#39;../input/dave.jpg&#39;</span>,<span style="color:#ae81ff">0</span>)
img <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>medianBlur(img,<span style="color:#ae81ff">5</span>)

ret,th1 <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>threshold(img,<span style="color:#ae81ff">127</span>,<span style="color:#ae81ff">255</span>,cv2<span style="color:#f92672">.</span>THRESH_BINARY)
th2 <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>adaptiveThreshold(img,<span style="color:#ae81ff">255</span>,cv2<span style="color:#f92672">.</span>ADAPTIVE_THRESH_MEAN_C,\
            cv2<span style="color:#f92672">.</span>THRESH_BINARY,<span style="color:#ae81ff">11</span>,<span style="color:#ae81ff">2</span>)
th3 <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>adaptiveThreshold(img,<span style="color:#ae81ff">255</span>,cv2<span style="color:#f92672">.</span>ADAPTIVE_THRESH_GAUSSIAN_C,\
            cv2<span style="color:#f92672">.</span>THRESH_BINARY,<span style="color:#ae81ff">11</span>,<span style="color:#ae81ff">2</span>)

titles <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;Original Image&#39;</span>,<span style="color:#e6db74">&#39;Global Thresholding (v = 127)&#39;</span>,
            <span style="color:#e6db74">&#39;Adaptive Mean Thresholding&#39;</span>,<span style="color:#e6db74">&#39;Adaptive Gaussian Thresholding&#39;</span>]
images <span style="color:#f92672">=</span> [img, th1, th2, th3]

plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">6.5</span>, <span style="color:#ae81ff">6</span>))
<span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">4</span>):
    plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">2</span>,i<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>),plt<span style="color:#f92672">.</span>imshow(images[i],<span style="color:#e6db74">&#39;gray&#39;</span>)
    plt<span style="color:#f92672">.</span>title(titles[i])
    plt<span style="color:#f92672">.</span>xticks([]), plt<span style="color:#f92672">.</span>yticks([])
plt<span style="color:#f92672">.</span>show()
</code></pre></div><h3 id="other-threshold-processing">Other threshold processing</h3>
<p>There are various thresholdTypes other than the frequently used binarization.
<img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/277233/95392469-78f4-b3b1-3800-2181673a9695.png" alt="image.png"></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># make gray scale picture</span>
im_gray <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array([np<span style="color:#f92672">.</span>arange(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">256</span>, <span style="color:#ae81ff">2</span>) <span style="color:#66d9ef">for</span> k <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">100</span>)])
im_gray <span style="color:#f92672">=</span> im_gray<span style="color:#f92672">.</span>astype(<span style="color:#e6db74">&#39;uint8&#39;</span>)
<span style="color:#66d9ef">print</span>(im_gray<span style="color:#f92672">.</span>shape)

<span style="color:#75715e"># apply threshold</span>
ret,thresh1 <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>threshold(im_gray,<span style="color:#ae81ff">127</span>,<span style="color:#ae81ff">255</span>,cv2<span style="color:#f92672">.</span>THRESH_BINARY)
ret,thresh2 <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>threshold(im_gray,<span style="color:#ae81ff">127</span>,<span style="color:#ae81ff">255</span>,cv2<span style="color:#f92672">.</span>THRESH_BINARY_INV)
ret,thresh3 <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>threshold(im_gray,<span style="color:#ae81ff">127</span>,<span style="color:#ae81ff">255</span>,cv2<span style="color:#f92672">.</span>THRESH_TRUNC)
ret,thresh4 <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>threshold(im_gray,<span style="color:#ae81ff">127</span>,<span style="color:#ae81ff">255</span>,cv2<span style="color:#f92672">.</span>THRESH_TOZERO)
ret,thresh5 <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>threshold(im_gray,<span style="color:#ae81ff">127</span>,<span style="color:#ae81ff">255</span>,cv2<span style="color:#f92672">.</span>THRESH_TOZERO_INV)

<span style="color:#75715e"># show result</span>
titles <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;Original Image&#39;</span>,<span style="color:#e6db74">&#39;BINARY&#39;</span>,<span style="color:#e6db74">&#39;BINARY_INV&#39;</span>,<span style="color:#e6db74">&#39;TRUNC&#39;</span>,<span style="color:#e6db74">&#39;TOZERO&#39;</span>,<span style="color:#e6db74">&#39;TOZERO_INV&#39;</span>]
images <span style="color:#f92672">=</span> [im_gray, thresh1, thresh2, thresh3, thresh4, thresh5]

<span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">6</span>):
    plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">3</span>,i<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>)
    plt<span style="color:#f92672">.</span>imshow(images[i],<span style="color:#e6db74">&#39;gray&#39;</span>)
    plt<span style="color:#f92672">.</span>title(titles[i])
    plt<span style="color:#f92672">.</span>xticks([]), plt<span style="color:#f92672">.</span>yticks([])
plt<span style="color:#f92672">.</span>show()
</code></pre></div><h1 id="image-reading-cv2imread">Image reading: cv2.imread()</h1>
<p>From here, I will load an appropriate image file and use it. You can read the image as numpy.array by cv2.imread(). Image display uses cv2.imshow() or plt.imshow(), but cv2.imshow() does not seem to work with jupyter notebook, so I will display it with plt.imshow(). However, while opencv traditionally reads the value with BGR, plt.imshow() displays it as RGB, so after replacing R and B with cv2.cvtColor(src, cv2.COLOR_BGR2RGB) I will display it.</p>
<pre><code class="language-python:python" data-lang="python:python">import cv2
import matplotlib.pyplot as plt

im = cv2.imread('../input/opencv.png')

plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))
plt.xticks([])
plt.yticks([])
plt.show()
</code></pre><p>This time I will do it with this image
<img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/277233/d0e2ae78-b3b1-f8f7-2455-bd2ff0560ae4.png" width=20%></p>
<h1 id="blur-image-cv2gaussianblursrc-size-size-sigma">Blur image: cv2.GaussianBlur(src, (size, size), sigma)</h1>
<p>opencv documentation
<a href="http://labs.eecs.tottori-u.ac.jp/sd/Member/oyamada/OpenCV/html/py_tutorials/py_imgproc/py_filtering/py_filtering.html">http://labs.eecs.tottori-u.ac.jp/sd/Member/oyamada/OpenCV/html/py_tutorials/py_imgproc/py_filtering/py_filtering.html</a></p>
<p>This is a filter that blurs the image.
size is the horizontal and vertical size, and sigma is the vertical and horizontal standard deviation. The sigma can also be specified vertically and horizontally, but if omitted, the same standard deviation is used for both height and width. The larger the size and sigma, the stronger the blur.</p>
<pre><code class="language-python:python" data-lang="python:python">plt.figure(figsize=(8, 10.4))

for k, size in enumerate([3, 9, 27]):for k2, sigma in enumerate([0, 10, 40]):
        blur = cv2.GaussianBlur(im, (size, size), sigma)
        ax = plt.subplot(3, 3, k2*3+k+1)
        ax.imshow(cv2.cvtColor(blur, cv2.COLOR_BGR2RGB))
        ax.set_xticks([])
        ax.set_yticks([])
        ax.set_title('blur size: %d\nsigma: %d' %(size, sigma))
plt.show()
</code></pre><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/277233/b0347a79-bcd7-46ff-c4af-7fdd5b0008b5.png" width=50%>
<h1 id="alpha-compositing-addweightedsrc1-alpha-src2-beta-gamma">Alpha compositing: addWeighted(src1, alpha, src2, beta, gamma)</h1>
<p>opencv documentation
<a href="https://docs.opencv.org/2.4/modules/core/doc/operations_on_arrays.html">https://docs.opencv.org/2.4/modules/core/doc/operations_on_arrays.html</a></p>
<p>You can make a mixed image like this. In addition, you can put a value larger than 1 into alpha and beta, but the pixel with a large value will shake off the value, so it will be a bit strange mixing like the image at the right end.</p>
<pre><code class="language-python:python" data-lang="python:python">im2 = cv2.imread('../input/black_white.png')[:,:,::-1]
plt.imshow(cv2.cvtColor(im2, cv2.COLOR_BGR2RGB))
</code></pre><pre><code class="language-python:python" data-lang="python:python">plt.figure(figsize=(15, 20))
for k, alpha in enumerate([0, 0.25, 0.5, 0.75, 1]):
    for k2, gamma in enumerate([0, 0.5, 1, 2, 4]):
        beta = 1-alpha
        im3 = cv2.addWeighted(im, alpha, im2, beta, gamma)

        ax = plt.subplot(5, 5, 5*k2+k+1)
        ax.imshow(cv2.cvtColor(im3, cv2.COLOR_BGR2RGB))
        ax.set_title('alpha: %1.2f\nbeta: %1.2f\ngamma: %1.2f' %(alpha, beta, gamma))
        ax.set_xticks([])
        ax.set_yticks([])
plt.show()
</code></pre><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/277233/66ffb67b-e1b4-f225-2e81-16f198c46fe2.png" width=50%>
<h1 id="contour-enhancement-using-blur-and-alpha-compositing">Contour enhancement using blur and alpha compositing</h1>
<p>The outline can be emphasized by subtracting the blurred image from the original image.</p>
<pre><code class="language-python:python" data-lang="python:python">blur = cv2.GaussianBlur(im, (9, 9), 27)
im3 = cv2.addWeighted(im, 1.5, blur, -0.5, 1)

plt.figure(figsize=(10, 5))

ax = plt.subplot(1, 3, 1)
ax.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))
ax.set_title('base image')
ax.set_xticks([])
ax.set_yticks([])

ax = plt.subplot(1, 3, 2)
ax.imshow(cv2.cvtColor(blur, cv2.COLOR_BGR2RGB))
ax.set_title('gaussianBlur')
ax.set_xticks([])
ax.set_yticks([])

ax = plt.subplot(1, 3, 3)
ax.imshow(cv2.cvtColor(im3, cv2.COLOR_BGR2RGB))
ax.set_title('addWeighted')
ax.set_xticks([])
ax.set_yticks([])

plt.show()
</code></pre><p>When the original image is mixed with alpha=1.5 and the blurred image is mixed with beta=-0.5, the image becomes the outline enhanced.
<img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/277233/deac0d79-c4f9-8049-7ace-7285f5ce1632.png" width=50%></p>
<h1 id="filtering-cv2filter2dsrc-kernel">Filtering: cv2.filter2D(src, kernel)</h1>
<p>The convolution filter function. It seems that various filtering can be implemented by changing the array value. The gaussianBlur() used above can also be implemented with this function.</p>
<h3 id="translation">Translation</h3>
<p>If you set the kernel to [1], you can get the same as the original image.
Also, if you set somewhere in the large array to 1 and all others to 0, you can move it in parallel as follows.</p>
<pre><code class="language-python:python" data-lang="python:python">size = 21
kernel = np.zeros(size**2).reshape(size, size)
kernel[0, 0] = 1
kernel = kernel / np.sum(kernel)
print(kernel)

im4 = cv2.filter2D(im, -1, kernel)


# show picture
plt.figure(figsize=(7, 6))

ax = plt.subplot(1, 2, 1)
ax.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))
ax.set_xticks([])
ax.set_yticks([])
ax.set_title('base image')

ax = plt.subplot(1, 2, 2)
ax.imshow(cv2.cvtColor(im4, cv2.COLOR_BGR2RGB))
ax.set_xticks([])
ax.set_yticks([])
ax.set_title('moved')

plt.show()
</code></pre><p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/277233/9ba7dfaa-1d5b-bc75-d9f8-127852aef356.png" alt="image.png">
The mirror image will appear in reverse if there is not enough.</p>
<h3 id="average-filter">Average filter</h3>
<p>If you set all kernels to the same value and total 1, it will be an average filter.
Same as cv2.blur().</p>
<pre><code class="language-python:python" data-lang="python:python">def average_filter(size, im):
    kernel = np.ones(size**2).reshape(size, size)
    kernel = kernel / np.sum(kernel)
    im4 = cv2.filter2D(im, -1, kernel)
    return im4

plt.figure(figsize=(10, 5))
for k, size in enumerate([1, 21, 101]):
    im4 = average_filter(size, im)
    ax = plt.subplot(1, 3, k+1)

    ax.imshow(cv2.cvtColor(im4, cv2.COLOR_BGR2RGB))
    ax.set_title('size: %d' %size)
    ax.set_xticks([])
    ax.set_yticks([])
plt.show()
</code></pre><p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/277233/35edc629-1e8a-f4ff-b191-992d5451fe26.png" alt="image.png"></p>
<h3 id="edge-enhancement-filter">Edge enhancement filter</h3>
<p>As shown below, if you add 1 in all and minus 1 in all but the center, you can use the edge enhancement filter.</p>
<pre><code class="language-math" data-lang="math">\begin{pmatrix}
- 1 &amp; -1 &amp; -1 &amp; -1 &amp; -1 &amp; -1 &amp; -1 \\
- 1 &amp; -1 &amp; -1 &amp; -1 &amp; -1 &amp; -1 &amp; -1 \\
- 1 &amp; -1 &amp; -1 &amp; -1 &amp; -1 &amp; -1 &amp; -1 \\
- 1 &amp; -1 &amp; -1 &amp; 49 &amp; -1 &amp; -1 &amp; -1 \\
- 1 &amp; -1 &amp; -1 &amp; -1 &amp; -1 &amp; -1 &amp; -1 \\
- 1 &amp; -1 &amp; -1 &amp; -1 &amp; -1 &amp; -1 &amp; -1 \\
- 1 &amp; -1 &amp; -1 &amp; -1 &amp; -1 &amp; -1 &amp; -1
\end{pmatrix}
</code></pre><p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/277233/953f62d0-6d6a-c4d1-0331-e1d8465e28e5.png" alt="image.png"></p>
<pre><code class="language-python:python" data-lang="python:python">def edge_filter(size, im):
    kernel = np.full(size**2, -1).reshape(size, size)
    pos = int((size-1)/2)
    kernel[pos, pos] = size**2
    print(kernel)
    im4 = cv2.filter2D(im, -1, kernel)
    return im4

im4 = edge_filter(7, im)

plt.figure(figsize=(6, 5))

ax = plt.subplot(1, 2, 1)
ax.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))
ax.set_title('base image')
ax.set_xticks([])
ax.set_yticks([])

ax = plt.subplot(1, 2, 2)
ax.imshow(cv2.cvtColor(im4, cv2.COLOR_BGR2RGB))
ax.set_title('edge added')
ax.set_xticks([])
ax.set_yticks([])

plt.show()
</code></pre><h3 id="contour-extraction-filter">Contour extraction filter</h3>
<p>Similar to the above filter, but if you set it so that the sum is zero, it will be a filter that extracts only the contour.<img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/277233/6c6b8577-4e3f-3a30-4f42-91e7a673c3ca.png" alt="image.png"></p>
<pre><code class="language-python:python" data-lang="python:python">def laplacian_filter(size, im):
    kernel = np.ones(size**2).reshape(size, size)
    pos = int((size-1)/2)
    kernel[pos, pos] = -(size**2-1)
    print(kernel)
    im4 = cv2.filter2D(im, -1, kernel)
    return im4

im4 = laplacian_filter(7, im)

plt.figure(figsize=(6, 5))

ax = plt.subplot(1, 2, 1)
ax.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))
ax.set_title('base image')
ax.set_xticks([])
ax.set_yticks([])

ax = plt.subplot(1, 2, 2)
ax.imshow(cv2.cvtColor(im4, cv2.COLOR_BGR2RGB))
ax.set_title('laplacian filter')
ax.set_xticks([])
ax.set_yticks([])

plt.show()
</code></pre><h1 id="追記予定">(追記予定)</h1>

    </article>
  </div>

  
  
  
  <script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-169005401-1', 'auto');
  ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  

  
<link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.css" />
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#216942",
      "text": "#b2d192"
    },
    "button": {
      "background": "#afed71"
    }
  }
})});
</script>

</body>

</html>
