<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  <meta name="generator" content="Hugo 0.72.0" />

  
  <meta name="description" content="Some description">
  

  
  <link rel="apple-touch-icon" sizes="180x180" href="https://memotut.com/apple-touch-icon.png">

  
  <link rel="icon" type="image/png" sizes="32x32" href="https://memotut.com/favicon-32x32.png">

  
  <link rel="icon" type="image/png" sizes="16x16" href="https://memotut.com/favicon-16x16.png">

  
  <link rel="manifest" href="https://memotut.com/site.webmanifest">

  
  <link rel="mask-icon" href="https://memotut.com/safari-pinned-tab.svg" color="#5bbad5">

  <meta name="msapplication-TileColor" content="#da532c">

  <meta name="theme-color" content="#ffffff">

  
  <link rel="stylesheet" href="https://memotut.com/css/bootstrap.min.css" />

  
  <title>Bayesian hypothesis test | Memo Tut</title>
  

  <style>
body {
  min-width: 300px;
}

.custom-navbar {
  margin-bottom: 1em;
  height: 60px;
}

.custom-navbar a {
  display: inline-block; 
  padding: 18px 0;
  margin-right: 1em; 
  font-weight: bold; 
}

.custom-navbar a:hover,
.custom-navbar a:focus {
  text-decoration: none; 
}

@media print {
  .custom-navbar {
    display: none;
  }
}

article {
  padding-bottom: 1em;
}

img {
  max-width: 100%;
}


body {
  background-color: #fff;
}



body {
  color: #212529;
}



a {
  color: #007bff;
}



a:hover,
a:focus {
  color: #0056b3;
}



.custom-navbar {
  background-color: #212529;
}



.custom-navbar a {
  color: rgba(255, 255, 255, 0.75);
}



.custom-navbar a:hover,
.custom-navbar a:focus {
  color: rgba(255, 255, 255, 1);
}



.container {
  max-width: 800px;
}



pre {
  display: block;
  padding: 9.5px;
  word-break: break-all;
  word-wrap: break-word;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre code {
  padding: 0;
  font-size: inherit;
  color: inherit; 
  white-space: pre-wrap;
  background-color: transparent;
  border: none;
  border-radius: 0;
}

code {
  padding: 2px 4px;
  color: inherit; 
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
  font-size: .9em;
}



blockquote,
.blockquote {
  padding: 10px 20px;
  margin: 0 0 20px;
  font-size: 1em;
  border-left: 5px solid #6c757d;
}

</style>
</head>

<body>
  <nav class="custom-navbar">
  <div class="container">
    
    <a href="/">Posts</a>
    
    <a href="/tags/">Tags</a>
    
    <a href="/about/">About</a>
    
    <a href="/index.xml">RSS</a>
    
  </div>
</nav>
  
  <div class="container">
    <article>
      <h1>Bayesian hypothesis test</h1>
<p>
  <small class="text-secondary">
  
  
  Apr 25, 2020
  </small>
  

<small><code><a href="https://memotut.com/tags/python">Python</a></code></small>


<small><code><a href="https://memotut.com/tags/odds-ratio"> odds ratio</a></code></small>


<small><code><a href="https://memotut.com/tags/bayesian-statistics"> Bayesian statistics</a></code></small>


<small><code><a href="https://memotut.com/tags/posterior-probability"> posterior probability</a></code></small>


<small><code><a href="https://memotut.com/tags/bayes-factor"> Bayes factor</a></code></small>

</p>
<pre><code># Bayesian hypothesis test
</code></pre>
<p>In this article, I will introduce a method of hypothesis testing with Bayesian statistics, and finally I will actually test using python. The author is a beginner in Bayesian statistics and python, so please comment if the contents are incomplete.</p>
<hr>
<h2 id="1-what-is-hypothesis-testing">1. What is hypothesis testing?</h2>
<p>$ $ Roughly speaking, the hypothesis test is that it is possible to adopt the hypothesis $H_i$ by establishing the hypothesis $H_i$ that the unknown parameter $\theta$ belongs to the interval $I_i$ with some unknown parameter. This is a method to analyze whether it can be said that $\theta$ belongs to the section $I_i$.</p>
<p>The following three methods are mainly representative in Bayesian statistics.</p>
<ul>
<li>Test by posterior probability</li>
<li>Post-hoc odds ratio test</li>
<li>Bayes factor test</li>
</ul>
<p>Below $$, the probability density function of the random variable $X$ is represented by $p(X)$, and the probability of occurrence of the event $X$ is represented by $P(X)$. Also, using $\Omega$ as the sample space, the fact that $A \cap B = \phi$ holds for the sets $A and B$ is represented by $A \bot B$.</p>
<h2 id="2-test-by-posterior-probability">2. Test by posterior probability</h2>
<p>The idea of a test by evaluating posterior probabilities is very simple. For example, consider the following hypothesis.</p>
<pre><code class="language-math" data-lang="math">\left\{
\begin{split}
    H_0: &amp;q \in I_0 \\
    H_1: &amp;q \in I_0 \\
    &amp;\vdots \\
    H_k: &amp;q \in I_k
\end{split}
\right.
</code></pre><p>$ $ (However, note that $I_i \subset \Omega$ and $I_i$ may share areas.)</p>
<p>$$ At this time, the posterior probability that the hypothesis $H_i (i = 0, 1, \dots k )$ holds when the event $X$ is realized is</p>
<pre><code class="language-math" data-lang="math"> P(H_i|X) = P(\theta \in I_i|X) = \int_{I_i} p(\theta|X) d\theta
</code></pre><p>Will be.</p>
<p>If $P(H_i|X)$ is sufficiently large (close to 1), hypothesis $H_i$ is adopted, and if small (close to 0), hypothesis $H_i$ is rejected.</p>
<h2 id="3-post-hoc-odds-ratio-test">3. Post-hoc odds ratio test</h2>
<p>Next is a test using the posterior odds ratio. The posterior probability test allowed us to create as many hypotheses as we like, but the posterior odds ratio test uses only two hypotheses.</p>
<p>Consider the following hypothesis.</p>
<pre><code class="language-math" data-lang="math">\left\{
\begin{split}
    H_0: q \in I_0 \\
    H_1: q \in I_1
\end{split}
\right.
</code></pre><p>$ $ Where $I_0$ and $I_1$ are set so that $I_0 \bot I_1 ,I_0 \cup I_1 = \Omega$ holds. By doing so, one of $H_0$ and $H_1$ can be the null hypothesis and the other can be the alternative hypothesis.</p>
<p>The posterior odds ratio is</p>
<pre><code class="language-math" data-lang="math">\begin{split}
 Post-hoc odds ratio &amp;= \frac{P(H_0|X)}{P(H_1|X)} \\
&amp;= \frac{P(\theta \in I_0|X)}{P(\theta \in I_1|X)} \\
&amp;= \frac{\int_{I_0}p(\theta|X)d\theta}{\int_{I_1}p(\theta|X)d\theta}
\end{split}
</code></pre><p>It is defined by $ $. If the posterior odds ratio is sufficiently larger than 1, $H_0$ is adopted, and if it is sufficiently small, $H_1$ is adopted.</p>
<p>Although $ $ or more is a test method using the posterior odds ratio, it is a little problem considering that the posterior distribution is affected by the prior distribution. If the prior distribution is extremely favorable to either hypothesis, the posterior distribution may not test correctly because it reflects the influence of the prior distribution. For example, assuming that $H_1$ is really correct but we assume a prior distribution that is overwhelmingly favorable to $H_0$, then $P(H_0|X)$ is larger than actual and $P(H_1|X)$ is larger than actual. Underestimated odds ratios can be overestimated. In order to avoid such a thing, it may test using a Bayes factor.</p>
<h2 id="4-bayes-factor-test">4. Bayes factor test</h2>
<p>$ $ Immediately, the Bayes factor $B_{01}$ is defined by the following formula.</p>
<pre><code class="language-math" data-lang="math">\begin{split} B_{01} &amp;= ex post odds ratio \div pre odds ratio \\
          &amp;= \frac{P(H_0|X)}{P(H_1|X)} \div \frac{P(H_0)}{P(H_1)} \\
          &amp;=\frac{\int_{I_0}p(\theta|X)d\theta}{\int_{I_1}p(\theta|X)d\theta} \div \frac{\int_{I_0}p( \theta)d\theta}{\int_{I_1}p(\theta)d\theta}
\end{split}
</code></pre><p>Now let&rsquo;s consider why this Bayes factor evaluation avoids the problem of posterior odds ratio tests.</p>
<p>Suppose that the $ $ prior distribution settings are overwhelmingly advantageous to $ H_0$, with a prior odds ratio of 100 and a posterior odds ratio of 20. At this time, $H_0$ will be adopted in the test based on the posterior odds ratio. Also, just in case, if you think about what happens with the test by post-establishment, it will be $P(H_0|X) \simeq 0.95$ and it can be said that $H_0$ is also adopted here. But when we calculate the Bayes factor $B_{01}$, we get $B_{01} = 0.2$. The Bayes factor value is evaluated using the evaluation criteria by Jeffreys shown below. Since it is $1/10 \le 0.2 \le 1/3$, it fully supports the alternative hypothesis $H_1$.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/624454/e40f091e-ef49-09fe-16ba-433d4dd9ddb5.png" alt="Untitled.png"></p>
<p>[Source: https://www.slideshare.net/masarutokuoka/mcmc-35640699]</p>
<p>Although the above example is extreme, it may be possible to reach a conclusion different from the case of using the posterior odds ratio by actually performing the test using the Bayes factor, and the test using the Bayes factor is more effective than the prior distribution. It may be difficult to draw false conclusions by reducing the.</p>
<h2 id="5-test-sample-data-using-python">5. Test sample data using python</h2>
<p>I actually calculated posterior probability, posterior odds ratio, and Bayes factor, and tried hypothesis test. This time, for the sake of simplicity, we assumed a beta distribution as the prior distribution and tried hypothesis testing for a model that follows the Bernoulli distribution.</p>
<p>First, we define a function that takes sample data (data), hyperparameters (a0, b0) of prior distribution, and interval (I) as arguments and returns posterior probability (post_prob), posterior odds ratio (post_odds_ratio), and Bayes factor (BF). Did.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-.py" data-lang=".py"><span style="color:#f92672">import</span> scipy.stats <span style="color:#f92672">as</span> st

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">ppb</span>(data, a0, b0, I):
    n <span style="color:#f92672">=</span> data<span style="color:#f92672">.</span>size
    y <span style="color:#f92672">=</span> data<span style="color:#f92672">.</span>sum()
    pre_p0 <span style="color:#f92672">=</span> st<span style="color:#f92672">.</span>beta<span style="color:#f92672">.</span>cdf(I[<span style="color:#ae81ff">1</span>], a0, b0)<span style="color:#f92672">-</span>st<span style="color:#f92672">.</span>beta<span style="color:#f92672">.</span>cdf(I[<span style="color:#ae81ff">0</span>], a0, b0)
    pre_p1 <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span><span style="color:#f92672">-</span>pre_p0
    post_p0 <span style="color:#f92672">=</span> st<span style="color:#f92672">.</span>beta<span style="color:#f92672">.</span>cdf(I[<span style="color:#ae81ff">1</span>], y <span style="color:#f92672">+</span> a0, n<span style="color:#f92672">-</span>y <span style="color:#f92672">+</span> b0)<span style="color:#f92672">-</span>st<span style="color:#f92672">.</span>beta<span style="color:#f92672">.</span>cdf(I[<span style="color:#ae81ff">0</span>], y <span style="color:#f92672">+</span> a0, n<span style="color:#f92672">-</span>y <span style="color:#f92672">+</span> b0)
    post_p1 <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span><span style="color:#f92672">-</span>post_p0
    post_prob <span style="color:#f92672">=</span> post_p0
    post_odds_ratio <span style="color:#f92672">=</span> post_p0 <span style="color:#f92672">/</span> post_p1
    BF <span style="color:#f92672">=</span> post_odds_ratio <span style="color:#f92672">*</span> pre_p1 <span style="color:#f92672">/</span> pre_p0
    <span style="color:#66d9ef">return</span> post_prob, post_odds_ratio, BF
</code></pre></div><p>We then randomly generated data from a Bernoulli distribution with parameter p = 0.7 to generate a sample size 100.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-.py" data-lang=".py"><span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np

p <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.7</span>
n <span style="color:#f92672">=</span> <span style="color:#ae81ff">100</span>
np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>seed(<span style="color:#ae81ff">0</span>)
data <span style="color:#f92672">=</span> st<span style="color:#f92672">.</span>bernoulli<span style="color:#f92672">.</span>rvs(q, size<span style="color:#f92672">=</span>n)
</code></pre></div><p>For this data, the hyperparameter is</p>
<ul>
<li>A) a0 = b0 = 1</li>
<li>B) a0 = 2 ,b0 = 5</li>
<li>C) a0 = 3 ,b0 = 2</li>
</ul>
<p>We analyzed the case. The interval (I) used as the null hypothesis is I = [0.6, 0.8].</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-.py" data-lang=".py">a0 <span style="color:#f92672">=</span> [<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">3</span>]
b0 <span style="color:#f92672">=</span> [<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">5</span>,<span style="color:#ae81ff">2</span>]
I <span style="color:#f92672">=</span> [<span style="color:#ae81ff">0.6</span>,<span style="color:#ae81ff">0.8</span>]
s <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;A&#39;</span>,<span style="color:#e6db74">&#39;I&#39;</span>,<span style="color:#e6db74">&#39;U&#39;</span>]

<span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(len(a0)):
    a, b, c <span style="color:#f92672">=</span> ppb(data, a0[i], b0[i], I)
    <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;{}) </span><span style="color:#ae81ff">\n</span><span style="color:#e6db74"> Posterior probability: {:.5f} </span><span style="color:#ae81ff">\n</span><span style="color:#e6db74"> Posterior odds ratio: {:.5f} </span><span style="color:#ae81ff">\n</span><span style="color:#e6db74"> Bayes factor: {:.5f}&#39;</span><span style="color:#f92672">.</span>format(s[i],a,b, c))
</code></pre></div><p>Execution result</p>
<pre><code>A)
 Posterior probability: 0.79632
 Post-hoc odds ratio: 3.90973
 Bayes Factor: 15.63891
I)
 Posterior probability: 0.93228
 Post-hoc odds ratio: 13.76698
 Bayes Factor: 336.00387
C)
 Posterior probability: 0.81888
 Post-hoc odds ratio: 4.52127
 Bayes Factor: 8.62195
</code></pre><p>Here, when tested with reference to the Bayes factor evaluation criteria by Jeffreys shown earlier, it is concluded that a) strongly supports the null hypothesis, b) very strongly supports the null hypothesis, and c) fully supports the null hypothesis. It was done. Since we set the true value of p to 0.7, we can conclude that we have reached a reasonable conclusion.</p>
<p>Also, looking at the graph of beta distribution below, b) is most likely to be affected by the prior distribution.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/624454/c672a075-a38b-6b58-931a-d8ccb144e8b7.png" alt="beta.png"></p>
<p>The following image is the actual posterior distribution graph. Certainly, it seems that a) is more affected by the prior distribution than a) and c).</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/624454/4edb7670-4148-676a-b344-7e0011729a1b.png" alt="Posterior distribution.png"></p>
<p>Furthermore, changing only the interval of the null hypothesis to [0.65, 0.75], the result is as follows.</p>
<pre><code>A)
 Posterior probability: 0.34440
 Post-hoc odds ratio: 0.52532
 Bayes Factor: 4.72784
I)
 Posterior probability: 0.57232
 Post-hoc odds ratio: 1.33818
 Bayes Factor: 74.33720
C)
 Posterior probability: 0.36755Post-hoc odds ratio: 0.58115
 Bayes Factor: 2.73401

</code></pre><p>It becomes difficult to judge only by the posterior probability and posterior odds ratio because the condition becomes strict, but it seems that the null hypothesis cannot be supported in any case by using the Bayes factor.</p>
<p>Finally, I experimented with the null hypothesis interval [0.4, 0.6] and what kind of conclusion would be obtained if the true value was not included in the interval.</p>
<pre><code>A)
 Posterior probability: 0.00019
 Post-hoc odds ratio: 0.00019
 Bayes Factor: 0.00078
I)
 Posterior probability: 0.00123
 Post-hoc odds ratio: 0.00123
 Bayes Factor: 0.00515
C)
 Posterior probability: 0.00020
 Post-hoc odds ratio: 0.00020
 Bayes Factor: 0.00049
77
</code></pre><p>There is no need to use the Bayes factor, but in each case the null hypothesis is properly rejected.</p>
<h2 id="6-finally">6. Finally</h2>
<p>I assumed only the prior distribution with the beta distribution and only deal with models that follow the Bernoulli distribution, but I would like to deal with more various models in the future.
If you have any deficiencies or mistakes, I would like to ask a professor.
Thank you for reading until the end.</p>
<hr>
<h2 id="references">References</h2>
<p><a href="https://www.amazon.co.jp/ByPython-IntroductiontoBayesianStatistics-PracticalPythonLibrary-Nakazuma-Teruo/dp/4254128983">Nakazuma Teruo; Introduction to Bayesian Statistics with Python, Asakura Shoten, 2019</a></p>
<p><a href="https://www.slideshare.net/masarutokuoka/mcmc-35640699">Research Report at MCMC (Ref. 2020-4-24)</a></p>

    </article>
  </div>

  
  
  
  <script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-169005401-1', 'auto');
  ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  

  
<link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.css" />
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#216942",
      "text": "#b2d192"
    },
    "button": {
      "background": "#afed71"
    }
  }
})});
</script>

</body>

</html>
