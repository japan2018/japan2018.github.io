<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  <meta name="generator" content="Hugo 0.72.0" />

  
  <meta name="description" content="Some description">
  

  
  <link rel="apple-touch-icon" sizes="180x180" href="https://memotut.com/apple-touch-icon.png">

  
  <link rel="icon" type="image/png" sizes="32x32" href="https://memotut.com/favicon-32x32.png">

  
  <link rel="icon" type="image/png" sizes="16x16" href="https://memotut.com/favicon-16x16.png">

  
  <link rel="manifest" href="https://memotut.com/site.webmanifest">

  
  <link rel="mask-icon" href="https://memotut.com/safari-pinned-tab.svg" color="#5bbad5">

  <meta name="msapplication-TileColor" content="#da532c">

  <meta name="theme-color" content="#ffffff">

  
  <link rel="stylesheet" href="https://memotut.com/css/bootstrap.min.css" />

  
  <title>Summary of Markov chain and Monte Carlo method | Memo Tut</title>
  

  <style>
body {
  min-width: 300px;
}

.custom-navbar {
  margin-bottom: 1em;
  height: 60px;
}

.custom-navbar a {
  display: inline-block; 
  padding: 18px 0;
  margin-right: 1em; 
  font-weight: bold; 
}

.custom-navbar a:hover,
.custom-navbar a:focus {
  text-decoration: none; 
}

@media print {
  .custom-navbar {
    display: none;
  }
}

article {
  padding-bottom: 1em;
}

img {
  max-width: 100%;
}


body {
  background-color: #fff;
}



body {
  color: #212529;
}



a {
  color: #007bff;
}



a:hover,
a:focus {
  color: #0056b3;
}



.custom-navbar {
  background-color: #212529;
}



.custom-navbar a {
  color: rgba(255, 255, 255, 0.75);
}



.custom-navbar a:hover,
.custom-navbar a:focus {
  color: rgba(255, 255, 255, 1);
}



.container {
  max-width: 800px;
}



pre {
  display: block;
  padding: 9.5px;
  word-break: break-all;
  word-wrap: break-word;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre code {
  padding: 0;
  font-size: inherit;
  color: inherit; 
  white-space: pre-wrap;
  background-color: transparent;
  border: none;
  border-radius: 0;
}

code {
  padding: 2px 4px;
  color: inherit; 
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
  font-size: .9em;
}



blockquote,
.blockquote {
  padding: 10px 20px;
  margin: 0 0 20px;
  font-size: 1em;
  border-left: 5px solid #6c757d;
}

</style>
</head>

<body>
  <nav class="custom-navbar">
  <div class="container">
    
    <a href="/">Posts</a>
    
    <a href="/tags/">Tags</a>
    
    <a href="/about/">About</a>
    
    <a href="/index.xml">RSS</a>
    
  </div>
</nav>
  
  <div class="container">
    <article>
      <h1>Summary of Markov chain and Monte Carlo method</h1>
<p>
  <small class="text-secondary">
  
  
  May 15, 2020
  </small>
  

<small><code><a href="https://memotut.com/tags/python">Python</a></code></small>


<small><code><a href="https://memotut.com/tags/machine-learning"> machine learning</a></code></small>


<small><code><a href="https://memotut.com/tags/statistics"> statistics</a></code></small>

</p>
<pre><code>#Introduction
</code></pre>
<p>Currently, I am learning about Bayesian statistics. From that, I will summarize the Markov chain Monte Carlo method. In this article, I will explain the outline of Markov chain and Monte Carlo method as an entrance.</p>
<p><a href="https://qiita.com/Fumio-eisan/items/6e8bad9977e945ddb2fc">Next article</a></p>
<p>Here is the book that I referred to this time.</p>
<ul>
<li><a href="https://www.amazon.co.jp/%E5%9F%BA%E7%A4%8E%E3%81%8B%E3%82%89%E3%81%AE%E3%83%99%E3%82%A4%E3%82%BA%E7%B5%B1%E8%A8%88%E5%AD%A6-%E3%83%8F%E3%83%9F%E3%83%AB%E3%83%88%E3%83%8B%E3%82%A2%E3%83%B3%E3%83%A2%E3%83%B3%E3%83%86%E3%82%AB%E3%83%AB%E3%83%AD%E6%B3%95%E3%81%AB%E3%82%88%E3%82%8B%E5%AE%9F%E8%B7%B5%E7%9A%84%E5%85%A5%E9%96%80-%E8%B1%8A%E7%94%B0-%E7%A7%80%E6%A8%B9/dp/4254122128">Bayes statistics from the basics: a practical introduction to the Hamiltonian Monte Carlo method</a></li>
</ul>
<h2 id="what-is-markov-chain-monte-carlo">What is Markov chain Monte Carlo</h2>
<p>In Bayesian inference, when the observed data is $X$ and the set of unobserved variables such as parameters and latent variables is $Z$, consider the probabilistic model $P(X,Z)$. At this time, it is necessary to calculate the posterior distribution of $P(Z|X)$ in order to solve specific problems such as learning and prediction.
By the way, there are problems that this posterior distribution cannot be solved analytically or that numerical solution is very computationally intensive.
Then, I try to investigate the characteristics of this desired distribution by obtaining multiple samples from $P(Z|X)$. This Markov chain Monte Carlo method** is one of the sampling methods.</p>
<p>Briefly explaining each term,</p>
<ul>
<li>Markov chain: next state is <strong>only</strong> from previous state</li>
<li>Monte Carlo method: A method of finding an approximate solution by trial using random numbers</li>
</ul>
<p>Will be. Below is a brief summary of each.</p>
<h3 id="monte-carlo-methods">Monte Carlo Methods</h3>
<p>It is a method to obtain an approximate solution by trial using random numbers. A well-known example is an approximate solution with a pi of $π$. This considers a circle of radius $R$ and a square that covers it.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/567823/80a4d05d-cc09-35ce-61b7-bb54d47bb788.png" alt="image.png"></p>
<p>At this time, if the area of the circle is $So$ and the area of the square minus the area of the circle is $Ss$,</p>
<pre><code class="language-math" data-lang="math">So = πR^2\\
Ss = 4R^2-πR^2\\
</code></pre><p>Can be expressed as
Now, add these two expressions and express $π$ using $So$ and $Ss$.</p>
<pre><code class="language-math" data-lang="math">π = \frac {4So}{So + Ss}
</code></pre><p>Will be.
Now consider the radius to $1$.
By generating a random number in the interval $[0,1]$, we calculate the probability of being $1$ when entering the circle and $1$ when not entering the circle.
We will implement it in python as an example.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> random
inner <span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>
<span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">1000000</span>):
    x, y <span style="color:#f92672">=</span> random<span style="color:#f92672">.</span>random(), random<span style="color:#f92672">.</span>random()
    <span style="color:#66d9ef">if</span> x<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span> <span style="color:#f92672">+</span> y<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span> <span style="color:#f92672">&lt;</span><span style="color:#ae81ff">1</span>:
        inner <span style="color:#f92672">+=</span><span style="color:#ae81ff">1</span>
<span style="color:#66d9ef">print</span> (inner <span style="color:#f92672">*</span> <span style="color:#ae81ff">4</span><span style="color:#f92672">/</span><span style="color:#ae81ff">1000000</span>)

</code></pre></div><p>It became $3.141072$. It turns out that the value is close to about $3.1415$. We have confirmed the Monte Carlo method that performs approximation by random numbers.</p>
<h3 id="markov-chain">Markov Chain</h3>
<p>Markov chain means that the next state is determined only by the previous state. If you know the recurrence formula that you learn in high school mathematics, I think that you should think of it.
It is hard to imagine an event that is determined from the previous state in an actual example, but here is an example I saw in a textbook or web page.</p>
<ul>
<li>Weather example: Tomorrow&rsquo;s weather is assumed to depend only on today&rsquo;s weather</li>
<li>Clothing example: Assuming that the type of uniform you wear tomorrow depends only on the type of uniform you have today</li>
<li>Example of bento: Assuming that the type of bento to eat tomorrow depends only on the type of bento to eat today</li>
</ul>
<p>There is no end if you start raising etc. ‥</p>
<p>Now consider an example.</p>
<p>Tie Issues: One high school officially offers three different types of uniform ties. Red, green and blue. Suppose there are 100 first graders. It is empirically known that on the first day, students wear red, green, and blue ties with a probability of $0.6,0.25,0.15$ to attend school. **Students at this high school base their tie patterns on the day based only on the tie patterns they narrowed down the day before. **
Probability is shown below. Now, what is the probability of wearing each color one day or 10 days later?</p>
<table>
<thead>
<tr>
<th align="center">Table</th>
<th>Today: Zhu</th>
<th>Today: green</th>
<th>Today: blue</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">The day before: Zhu</td>
<td>0.3</td>
<td>0.3</td>
<td>0.4</td>
<td></td>
</tr>
<tr>
<td align="center">The day before: Green</td>
<td>0.1</td>
<td>0.5</td>
<td>0.4</td>
<td></td>
</tr>
<tr>
<td align="center">The day before: Blue</td>
<td>0.2</td>
<td>0.6</td>
<td>0.2</td>
<td></td>
</tr>
</tbody>
</table>
<p>A random variable that represents the tie pattern on the day of $t$ is set to $X^{t}$ using the subscript $t(=1,&hellip;.,T)$. A random variable that changes over time is called a <strong>stochastic process</strong>. The general stochastic process is</p>
<pre><code class="language-math" data-lang="math">P(X^t|X^{t-1},...,X^1)
</code></pre><p>Like, the conditional probability is based on the history before that.
However, in this case,</p>
<pre><code class="language-math" data-lang="math">P(X^t|X^{t-1},...,X^1) = P(X^t|X^{t-1})
</code></pre><p>A stochastic process that is affected only by the probability of the previous day is called a Markov chain.</p>
<p>The conditional probability that defines this Markov chain can be expressed as This is called a <strong>transition kernel or a transition kernel</strong>.</p>
<pre><code class="language-math" data-lang="math">
{\bf{P}}=\begin{pmatrix} 0.3 &amp; 0.3 &amp; 0.4 \\
0.1 &amp; 0.5 &amp; 0.4 \\
 0.2 &amp; 0.6 &amp; 0.2 \end{pmatrix}
</code></pre><h4 id="convergence-to-stationary-distribution">Convergence to stationary distribution</h4>
<p>Now, let&rsquo;s find the probability distribution after several days. If we write $p_hu ^{t} = p(X^{t} = hu)$, the probability distribution of $X^{t}$ is $\textbf p^{t} =(p_1^{t} ,p_2^{t},p_3^{t})$ and $\textbf p^{1} =(0.6,0.25,0.15)$.
The probability of wearing a red tie on the second day is
$\textbf p(X^2 = vermillion) = 0.3 × 0.6 + 0.1 × 0.25 + 0.2 × 0.15 = 0.235$
Will be.</p>
<p>Repeated calculations with the same idea can be obtained as follows.
<img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/567823/01dcaa3d-2c15-4958-21fd-4a43d57412e2.png" alt="image.png"></p>
<p>You can see that there is almost no change after the 4th day. The answer from earlier is, &ldquo;From the 4th day onwards, verm: green: blue = 1/6: 1/2: 1/3 is stable.&rdquo;</p>
<p>The probability distribution $\bf p$ that has stopped changing at this time is called a <strong>stationary distribution or invariant distribution</strong>. In addition, the period until this steady distribution is replaced is called the <strong>burn-in period</strong>.</p>
<h4 id="detailed-balance-condition-fusion-of-markov-chain-and-monte-carlo-method">Detailed balance condition (fusion of Markov chain and Monte Carlo method)</h4>
<p>In this tie problem, the purpose was to find the steady state, which is the final wearing state. However, this time I want to get a random number that fits the posterior distribution with the posterior distribution being clear.
In other words, consider designing a transition nucleus so that the posterior distribution becomes a stationary distribution.
In this way, the method of constructing a Markov chain with a distribution that you want to sample as a <strong>stationary distribution</strong> is called the Markov chain Monte Carlo method** (commonly known as the MCMC method).</p>
<p>In MCMC method, although the stationary distribution is known, the transition nucleus is unknown (the opposite of the tie problem).</p>
<p>Here, we use the concept of <strong>detailed balance condition</strong> as a condition for the Markov chain to converge to a stationary distribution. For the random variables $θ,θ'$, it means the following formula.</p>
<pre><code class="language-math" data-lang="math">f(θ'|θ)f(θ) = f(θ|θ')f(θ')
</code></pre><p>In the case of the tie problem,</p>
<pre><code class="language-math" data-lang="math">p (red | green) × \frac {1}{6} = p (green | red) × \frac {1}{2}
</code></pre><p>Will be.
$f(θ'|θ)$ and $f(θ|θ&rsquo;)$ are the transition nuclei.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/567823/e2e90370-9442-662f-294b-cd4ac4d89ab4.png" alt="image.png"></p>
<p>Here is an outline of the detailed balance conditions. The point $θ$ is near the center of the distribution, and the point $θ'$ is the periphery of the distribution. At this time, what the detailed balance condition means is</p>
<pre><code class="language-math" data-lang="math">f(θ'): If f(θ) = 1:a, then \\
f(θ|θ'): f(θ'|θ) = a :1
</code></pre><p>Will be.</p>
<p>It is said that the movement of $θ'$ → $θ$ is $a$ times more likely than the movement of $θ$ → $θ'$. In other words, it means that you can easily move to the center.</p>
<p>If this detailed balance condition is broken, it means that the random number sequence will eventually be drawn to the center even if the initial state is random.</p>
<h1 id="at-the-end">At the end</h1>
<p>After summarizing Markov chain and Monte Carlo method respectively, I summarized the tie problem as an example of Markov chain Monte Carlo method.
Since the outline is complete, I would like to handle the explanation of the algorithm that utilizes this MCMC method next time.</p>
<p>Next article.</p>
<blockquote>
<p>Understand the implementation of the metropolitan hasting method (one of the methods in the Markov chain Monte Carlo method)
<a href="https://qiita.com/Fumio-eisan/items/6e8bad9977e945ddb2fc">https://qiita.com/Fumio-eisan/items/6e8bad9977e945ddb2fc</a></p>
</blockquote>
<p>I have also listed below as a blog. I have a role to gather in more detail.</p>
<p><a href="https://fumio-eisan.hatenablog.com/">https://fumio-eisan.hatenablog.com/</a></p>

    </article>
  </div>

  
  
  
  <script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-169005401-1', 'auto');
  ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  

  
<link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.css" />
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#216942",
      "text": "#b2d192"
    },
    "button": {
      "background": "#afed71"
    }
  }
})});
</script>

</body>

</html>
