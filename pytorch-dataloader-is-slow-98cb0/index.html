<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  <meta name="generator" content="Hugo 0.72.0" />

  
  <meta name="description" content="Some description">
  

  
  <link rel="apple-touch-icon" sizes="180x180" href="https://memotut.com/apple-touch-icon.png">

  
  <link rel="icon" type="image/png" sizes="32x32" href="https://memotut.com/favicon-32x32.png">

  
  <link rel="icon" type="image/png" sizes="16x16" href="https://memotut.com/favicon-16x16.png">

  
  <link rel="manifest" href="https://memotut.com/site.webmanifest">

  
  <link rel="mask-icon" href="https://memotut.com/safari-pinned-tab.svg" color="#5bbad5">

  <meta name="msapplication-TileColor" content="#da532c">

  <meta name="theme-color" content="#ffffff">

  
  <link rel="stylesheet" href="https://memotut.com/css/bootstrap.min.css" />

  
  <title>PyTorch DataLoader is slow | Memo Tut</title>
  

  <style>
body {
  min-width: 300px;
}

.custom-navbar {
  margin-bottom: 1em;
  height: 60px;
}

.custom-navbar a {
  display: inline-block; 
  padding: 18px 0;
  margin-right: 1em; 
  font-weight: bold; 
}

.custom-navbar a:hover,
.custom-navbar a:focus {
  text-decoration: none; 
}

@media print {
  .custom-navbar {
    display: none;
  }
}

article {
  padding-bottom: 1em;
}

img {
  max-width: 100%;
}


body {
  background-color: #fff;
}



body {
  color: #212529;
}



a {
  color: #007bff;
}



a:hover,
a:focus {
  color: #0056b3;
}



.custom-navbar {
  background-color: #212529;
}



.custom-navbar a {
  color: rgba(255, 255, 255, 0.75);
}



.custom-navbar a:hover,
.custom-navbar a:focus {
  color: rgba(255, 255, 255, 1);
}



.container {
  max-width: 800px;
}



pre {
  display: block;
  padding: 9.5px;
  word-break: break-all;
  word-wrap: break-word;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre code {
  padding: 0;
  font-size: inherit;
  color: inherit; 
  white-space: pre-wrap;
  background-color: transparent;
  border: none;
  border-radius: 0;
}

code {
  padding: 2px 4px;
  color: inherit; 
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
  font-size: .9em;
}



blockquote,
.blockquote {
  padding: 10px 20px;
  margin: 0 0 20px;
  font-size: 1em;
  border-left: 5px solid #6c757d;
}

</style>
</head>

<body>
  <nav class="custom-navbar">
  <div class="container">
    
    <a href="/">Posts</a>
    
    <a href="/tags/">Tags</a>
    
    <a href="/about/">About</a>
    
    <a href="/index.xml">RSS</a>
    
  </div>
</nav>
  
  <div class="container">
    <article>
      <h1>PyTorch DataLoader is slow</h1>
<p>
  <small class="text-secondary">
  
  
  Mar 13, 2020
  </small>
  

<small><code><a href="https://memotut.com/tags/python">Python</a></code></small>


<small><code><a href="https://memotut.com/tags/pytorch">PyTorch</a></code></small>

</p>
<pre><code>In PyTorch, DataLoader(`torch.utils.data.DataLoader`) is often used to extract a mini-batch from a dataset, but when experimenting with large size data, using PyTorch's DataLoader It turns out to be very time consuming. For comparison, I made and tried an iterator that retrieves mini-batches from a dataset, but I found that Pytorch's DataLoader was much slower. In particular, this can be a bottleneck when using large size data.
</code></pre>
<p>[Postscript: 2020/03/23] We received a comment that the slow cause is BatchSampler used by default in DataLoader. See comments for details.</p>
<h1 id="configuration">Configuration</h1>
<p>In the following, it is assumed that a mini-batch with a batch size of 10,000 is repeatedly fetched from <code>label</code> and <code>target</code> with 1 million data. The calculation environment used Google Colaboratory.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> torch

label <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>randn(<span style="color:#ae81ff">1000000</span>,<span style="color:#ae81ff">10</span>)
target <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>randn(<span style="color:#ae81ff">1000000</span>,<span style="color:#ae81ff">10</span>)
batch_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">10000</span>
</code></pre></div><p>Create a <code>loader</code> to take out the mini-batch, and simply repeat taking out the mini-batch and measure the execution time using the following function.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">run_loader</span>(loader):
    <span style="color:#66d9ef">for</span> label,target <span style="color:#f92672">in</span> loader:
        <span style="color:#66d9ef">pass</span>
</code></pre></div><h1 id="pytorchs-dataloader">Pytorch&rsquo;s DataLoader</h1>
<p>When loader was created using <code>torch.utils.data.DataLoader</code> (when not shuffled) and the execution time was measured, it was 6.8 seconds. It seems that it is taking time just to retrieve the data.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">dataset <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>utils<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>TensorDataset(label,target)
loader1 <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>utils<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>DataLoader(dataset,batch_size<span style="color:#f92672">=</span>batch_size,shuffle<span style="color:#f92672">=</span>False)

<span style="color:#f92672">%</span>timeit <span style="color:#f92672">-</span>n1 <span style="color:#f92672">-</span>r1 run_loader(loader1)

<span style="color:#75715e"># 1 loop, best of 1: 6.83 s per loop</span>
</code></pre></div><p>When doing shuffle, it was 7.0 seconds.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">dataset <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>utils<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>TensorDataset(label,target)
loader2 <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>utils<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>DataLoader(dataset,batch_size<span style="color:#f92672">=</span>batch_size,shuffle<span style="color:#f92672">=</span>True)

<span style="color:#f92672">%</span>timeit <span style="color:#f92672">-</span>n1 <span style="color:#f92672">-</span>r1 run_loader(loader2)

<span style="color:#75715e"># 1 loop, best of 1: 6.97 s per loop</span>
</code></pre></div><h1 id="your-own-data-loader">Your own Data Loader</h1>
<p>For comparison, we made an iterator to extract mini-batch from the data set and conducted the same experiment.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">DataLoader</span>:

    <span style="color:#66d9ef">def</span> __init__(self,dataset,batch_size<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,shuffle<span style="color:#f92672">=</span>False):
        self<span style="color:#f92672">.</span>dataset <span style="color:#f92672">=</span> dataset
        self<span style="color:#f92672">.</span>batch_size <span style="color:#f92672">=</span> batch_size
        self<span style="color:#f92672">.</span>shuffle <span style="color:#f92672">=</span> shuffle
        <span style="color:#66d9ef">assert</span> all([ dataset[i]<span style="color:#f92672">.</span>size(<span style="color:#ae81ff">0</span>) <span style="color:#f92672">==</span> dataset[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>size(<span style="color:#ae81ff">0</span>) <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(len(dataset)) ]),<span style="color:#e6db74">&#39;all the elemtnes must have the same length&#39;</span>
        self<span style="color:#f92672">.</span>data_size <span style="color:#f92672">=</span> dataset[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>size(<span style="color:#ae81ff">0</span>)

    <span style="color:#66d9ef">def</span> __iter__(self):
        self<span style="color:#f92672">.</span>_i <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
        
        <span style="color:#66d9ef">if</span> self<span style="color:#f92672">.</span>shuffle:
            index_shuffle <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>randperm(self<span style="color:#f92672">.</span>data_size)
            self<span style="color:#f92672">.</span>dataset <span style="color:#f92672">=</span> [v[index_shuffle] <span style="color:#66d9ef">for</span> v <span style="color:#f92672">in</span> self<span style="color:#f92672">.</span>dataset]

        <span style="color:#66d9ef">return</span> self

    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">__next__</span>(self):

        i1 <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>batch_size <span style="color:#f92672">*</span> self<span style="color:#f92672">.</span>_i
        i2 <span style="color:#f92672">=</span> min( self<span style="color:#f92672">.</span>batch_size <span style="color:#f92672">*</span> (self<span style="color:#f92672">.</span>_i <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span> ), self<span style="color:#f92672">.</span>data_size)
        
        <span style="color:#66d9ef">if</span> i1 <span style="color:#f92672">&gt;=</span> self<span style="color:#f92672">.</span>data_size:
            <span style="color:#66d9ef">raise</span> <span style="color:#a6e22e">StopIteration</span>()

        value <span style="color:#f92672">=</span> [v[i1:i2] <span style="color:#66d9ef">for</span> v <span style="color:#f92672">in</span> self<span style="color:#f92672">.</span>dataset]

        self<span style="color:#f92672">.</span>_i <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>

        <span style="color:#66d9ef">return</span> value
</code></pre></div><p>If you use your own DataLoader (do not shuffle), you can see that the execution time is 500 microseconds and it takes almost no time to retrieve.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">loader3 <span style="color:#f92672">=</span> DataLoader([label,target],batch_size<span style="color:#f92672">=</span>batch_size,shuffle<span style="color:#f92672">=</span>False)

<span style="color:#f92672">%</span>timeit <span style="color:#f92672">-</span>n1 <span style="color:#f92672">-</span>r1 run_loader(loader3)

<span style="color:#75715e"># 1 loop, best of 1: 468 µs per loop</span>
</code></pre></div><p>The execution time is 300 milliseconds when shuffle is performed, and it takes more time than when it is not shuffled, but it is negligible compared to when using Pytorch&rsquo;s DataLoader.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">loader4 <span style="color:#f92672">=</span> DataLoader([label,target],batch_size<span style="color:#f92672">=</span>batch_size,shuffle<span style="color:#f92672">=</span>True)

<span style="color:#f92672">%</span>timeit <span style="color:#f92672">-</span>n1 <span style="color:#f92672">-</span>r1 run_loader(loader4)

<span style="color:#75715e"># 1 loop, best of 1: 296 ms per loop</span>
</code></pre></div><p>#Summary</p>
<p>I&rsquo;ve found that it takes a lot of time to retrieve a mini-batch using PyTorch&rsquo;s DataLoader. Especially when dealing with large size data, this effect is very large.</p>

    </article>
  </div>

  
  
  
  <script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-169005401-1', 'auto');
  ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  

  
<link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.css" />
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#216942",
      "text": "#b2d192"
    },
    "button": {
      "background": "#afed71"
    }
  }
})});
</script>

</body>

</html>
