<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  <meta name="generator" content="Hugo 0.72.0" />

  
  <meta name="description" content="Some description">
  

  
  <link rel="apple-touch-icon" sizes="180x180" href="https://japan2018.github.io/apple-touch-icon.png">

  
  <link rel="icon" type="image/png" sizes="32x32" href="https://japan2018.github.io/favicon-32x32.png">

  
  <link rel="icon" type="image/png" sizes="16x16" href="https://japan2018.github.io/favicon-16x16.png">

  
  <link rel="manifest" href="https://japan2018.github.io/site.webmanifest">

  
  <link rel="mask-icon" href="https://japan2018.github.io/safari-pinned-tab.svg" color="#5bbad5">

  <meta name="msapplication-TileColor" content="#da532c">

  <meta name="theme-color" content="#ffffff">

  
  <link rel="stylesheet" href="https://japan2018.github.io/css/bootstrap.min.css" />

  
  <title>You are shown a plot such as principal component analysis, and the distributions of these two data do not differ greatly? | Some Title</title>
  

  <style>
body {
  min-width: 300px;
}

.custom-navbar {
  margin-bottom: 1em;
  height: 60px;
}

.custom-navbar a {
  display: inline-block; 
  padding: 18px 0;
  margin-right: 1em; 
  font-weight: bold; 
}

.custom-navbar a:hover,
.custom-navbar a:focus {
  text-decoration: none; 
}

@media print {
  .custom-navbar {
    display: none;
  }
}

article {
  padding-bottom: 1em;
}

img {
  max-width: 100%;
}


body {
  background-color: #fff;
}



body {
  color: #212529;
}



a {
  color: #007bff;
}



a:hover,
a:focus {
  color: #0056b3;
}



.custom-navbar {
  background-color: #212529;
}



.custom-navbar a {
  color: rgba(255, 255, 255, 0.75);
}



.custom-navbar a:hover,
.custom-navbar a:focus {
  color: rgba(255, 255, 255, 1);
}



.container {
  max-width: 800px;
}



pre {
  display: block;
  padding: 9.5px;
  word-break: break-all;
  word-wrap: break-word;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre code {
  padding: 0;
  font-size: inherit;
  color: inherit; 
  white-space: pre-wrap;
  background-color: transparent;
  border: none;
  border-radius: 0;
}

code {
  padding: 2px 4px;
  color: inherit; 
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
  font-size: .9em;
}



blockquote,
.blockquote {
  padding: 10px 20px;
  margin: 0 0 20px;
  font-size: 1em;
  border-left: 5px solid #6c757d;
}

</style>
</head>

<body>
  <nav class="custom-navbar">
  <div class="container">
    
    <a href="/">Posts</a>
    
    <a href="/tags/">Tags</a>
    
    <a href="/about/">About</a>
    
    <a href="/index.xml">RSS</a>
    
  </div>
</nav>
  
  <div class="container">
    <article>
      <h1>You are shown a plot such as principal component analysis, and the distributions of these two data do not differ greatly?</h1>
<p>
  <small class="text-secondary">
  
  
  Feb 3, 2020
  </small>
  

<small><code><a href="https://japan2018.github.io/tags/python">Python</a></code></small>


<small><code><a href="https://japan2018.github.io/tags/scikit-learn">scikit-learn</a></code></small>

</p>
<pre><code>When I was shown a plot from a principal component analysis, etc. and received an explanation that the distributions of these two data did not differ greatly, I had the opportunity to think &quot;Is this really true?&quot; It was.
</code></pre>
<p>#Create data</p>
<p>Create two kinds of data data1 and data2 consisting of three dimensions of x, y and z as follows.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np

x <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>normal(<span style="color:#ae81ff">50</span>,<span style="color:#ae81ff">10</span>, size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">500</span>))
y <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>normal(<span style="color:#ae81ff">50</span>,<span style="color:#ae81ff">10</span>, size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">500</span>))
z <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>normal(<span style="color:#ae81ff">50</span>, <span style="color:#ae81ff">1</span>, size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">500</span>))

x1 <span style="color:#f92672">=</span> x[np<span style="color:#f92672">.</span>where(z <span style="color:#f92672">&gt;</span><span style="color:#ae81ff">51</span>, True, False)]
y1 <span style="color:#f92672">=</span> y[np<span style="color:#f92672">.</span>where(z<span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">51</span>, True, False)]
z1 <span style="color:#f92672">=</span> z[np<span style="color:#f92672">.</span>where(z <span style="color:#f92672">&gt;</span><span style="color:#ae81ff">51</span>, True, False)]

x2 <span style="color:#f92672">=</span> x[np<span style="color:#f92672">.</span>where(z <span style="color:#f92672">&lt;</span><span style="color:#ae81ff">49</span>, True, False)]
y2 <span style="color:#f92672">=</span> y[np<span style="color:#f92672">.</span>where(z <span style="color:#f92672">&lt;</span><span style="color:#ae81ff">49</span>, True, False)]
z2 <span style="color:#f92672">=</span> z[np<span style="color:#f92672">.</span>where(z <span style="color:#f92672">&lt;</span><span style="color:#ae81ff">49</span>, True, False)]

data1 <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>concatenate([x1, y1, z1])<span style="color:#f92672">.</span>reshape(<span style="color:#ae81ff">3</span>, (len(x1)))<span style="color:#f92672">.</span>transpose(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">0</span>)
data2 <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>concatenate([x2, y2, z2])<span style="color:#f92672">.</span>reshape(<span style="color:#ae81ff">3</span>, (len(x2)))<span style="color:#f92672">.</span>transpose(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">0</span>)

data <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>concatenate([data1, data2])

colors <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#34;red&#34;</span> <span style="color:#66d9ef">if</span> i <span style="color:#f92672">&gt;</span>len(data1) <span style="color:#66d9ef">else</span> <span style="color:#e6db74">&#34;blue&#34;</span> <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(len(data1)<span style="color:#f92672">+</span>len(data2))]
</code></pre></div><h1 id="principal-component-analysis">Principal component analysis</h1>
<p>Principal component analysis was performed and said, &ldquo;Oh, aren&rsquo;t these two data sets very different in distribution?&rdquo; (Doya face)</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">%</span>matplotlib inline
<span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#f92672">as</span> plt
<span style="color:#f92672">from</span> sklearn.decomposition <span style="color:#f92672">import</span> PCA <span style="color:#75715e"># principal component analyzer</span>

<span style="color:#75715e">#Perform principal component analysis</span>
pca <span style="color:#f92672">=</span> PCA()
pca<span style="color:#f92672">.</span>fit(data)
<span style="color:#75715e"># Map data to principal component space = dimensional compression</span>
feature <span style="color:#f92672">=</span> pca<span style="color:#f92672">.</span>transform(data)
<span style="color:#75715e"># Plot with first and second principal components</span>
plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">8</span>, <span style="color:#ae81ff">8</span>))
plt<span style="color:#f92672">.</span>scatter(feature[:len(data1), <span style="color:#ae81ff">0</span>], feature[:len(data1), <span style="color:#ae81ff">1</span>], alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.8</span>)
plt<span style="color:#f92672">.</span>scatter(feature[len(data1):, <span style="color:#ae81ff">0</span>], feature[len(data1):, <span style="color:#ae81ff">1</span>], alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.8</span>)
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#39;PC1&#39;</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#39;PC2&#39;</span>)
plt<span style="color:#f92672">.</span>grid()
plt<span style="color:#f92672">.</span>show()
</code></pre></div><p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/211162/904b5f59-15a3-dae1-f671-b5f69f996420.png" alt="output_3_0.png"></p>
<h1 id="cumulative-contribution-rate">Cumulative contribution rate</h1>
<p>&ldquo;If so, the cumulative contribution rate is also shown. Is the cumulative contribution rate up to the second principal component (PC2) almost 100%?&rdquo; (Doya face)</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Illustrate cumulative contribution</span>
<span style="color:#f92672">import</span> matplotlib.ticker <span style="color:#f92672">as</span> ticker
<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
plt<span style="color:#f92672">.</span>gca()<span style="color:#f92672">.</span>get_xaxis()<span style="color:#f92672">.</span>set_major_locator(ticker<span style="color:#f92672">.</span>MaxNLocator(integer<span style="color:#f92672">=</span>True))
plt<span style="color:#f92672">.</span>plot([<span style="color:#ae81ff">0</span>] <span style="color:#f92672">+</span> list( np<span style="color:#f92672">.</span>cumsum(pca<span style="color:#f92672">.</span>explained_variance_ratio_)), <span style="color:#e6db74">&#34;-o&#34;</span>)
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;Number of principal components&#34;</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;Cumulative contribution ratio&#34;</span>)
plt<span style="color:#f92672">.</span>grid()
plt<span style="color:#f92672">.</span>show()
</code></pre></div><p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/211162/f7eb6b4a-e830-8912-bd99-44dc5bfaa268.png" alt="output_5_0.png"></p>
<p>#Scatter matrix</p>
<p>&ldquo;Can you show me the scatter plot matrix?&rdquo;</p>
<p>(Dockin!)</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> pandas <span style="color:#f92672">as</span> pd
<span style="color:#f92672">from</span> pandas.tools <span style="color:#f92672">import</span> plotting
plotting<span style="color:#f92672">.</span>scatter_matrix(pd<span style="color:#f92672">.</span>DataFrame(feature, columns<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;PC1&#39;</span>,<span style="color:#e6db74">&#39;PC2&#39;</span>,<span style="color:#e6db74">&#39;PC3&#39;</span>]), figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">8</span>, <span style="color:#ae81ff">8</span>), color<span style="color:#f92672">=</span>colors)
plt<span style="color:#f92672">.</span>show()
</code></pre></div><p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/211162/92713013-c1ae-76fb-17b0-ae2257bcb312.png" alt="output_7_1.png"></p>
<p>&ldquo;Isn&rsquo;t it all different?! Show the scatterplot matrix of the original data!&rdquo;</p>
<p>&ldquo;Sustainable&rdquo;</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> pandas <span style="color:#f92672">as</span> pd
<span style="color:#f92672">from</span> pandas.tools <span style="color:#f92672">import</span> plotting
plotting<span style="color:#f92672">.</span>scatter_matrix(pd<span style="color:#f92672">.</span>DataFrame(data, columns<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;x&#39;</span>,<span style="color:#e6db74">&#39;y&#39;</span>,<span style="color:#e6db74">&#39;z&#39;</span>]), figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">8</span>, <span style="color:#ae81ff">8</span>), color<span style="color:#f92672">=</span>colors)
plt<span style="color:#f92672">.</span>show()
</code></pre></div><p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/211162/d8147a45-3b78-adb1-e600-b33c9064a2af.png" alt="output_9_1.png"></p>
<h1 id="data-standardization">Data standardization</h1>
<p>You have to look at the data from multiple angles. One of the methods is standardization of data. Just doing that will change the way the data looks.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">zscore</span>(x, axis <span style="color:#f92672">=</span> None):
    xmean <span style="color:#f92672">=</span> x<span style="color:#f92672">.</span>mean(axis<span style="color:#f92672">=</span>axis, keepdims<span style="color:#f92672">=</span>True)
    xstd <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>std(x, axis<span style="color:#f92672">=</span>axis, keepdims<span style="color:#f92672">=</span>True)
    zscore <span style="color:#f92672">=</span> (x<span style="color:#f92672">-</span>xmean)<span style="color:#f92672">/</span>xstd
    <span style="color:#66d9ef">return</span> zscore
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">%</span>matplotlib inline
<span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#f92672">as</span> plt
<span style="color:#f92672">from</span> sklearn.decomposition <span style="color:#f92672">import</span> PCA <span style="color:#75715e"># principal component analyzer</span>

<span style="color:#75715e">#Perform principal component analysis</span>
pca <span style="color:#f92672">=</span> PCA()
pca<span style="color:#f92672">.</span>fit(zscore(data, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>))
<span style="color:#75715e"># Map data to principal component space = dimensional compression</span>
feature <span style="color:#f92672">=</span> pca<span style="color:#f92672">.</span>transform(zscore(data, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>))
<span style="color:#75715e"># Plot with first and second principal components</span>
plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">8</span>, <span style="color:#ae81ff">8</span>))
plt<span style="color:#f92672">.</span>scatter(feature[:len(data1), <span style="color:#ae81ff">0</span>], feature[:len(data1), <span style="color:#ae81ff">1</span>], alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.8</span>)
plt<span style="color:#f92672">.</span>scatter(feature[len(data1):, <span style="color:#ae81ff">0</span>], feature[len(data1):, <span style="color:#ae81ff">1</span>], alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.8</span>)
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#39;PC1&#39;</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#39;PC2&#39;</span>)
plt<span style="color:#f92672">.</span>grid()
plt<span style="color:#f92672">.</span>show()
</code></pre></div><p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/211162/6055e57e-f82b-05ae-beea-e5b5a03ab92d.png" alt="output_12_0.png"></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Illustrate cumulative contribution</span>
<span style="color:#f92672">import</span> matplotlib.ticker <span style="color:#f92672">as</span> ticker
<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
plt<span style="color:#f92672">.</span>gca()<span style="color:#f92672">.</span>get_xaxis()<span style="color:#f92672">.</span>set_major_locator(ticker<span style="color:#f92672">.</span>MaxNLocator(integer<span style="color:#f92672">=</span>True))
plt<span style="color:#f92672">.</span>plot([<span style="color:#ae81ff">0</span>] <span style="color:#f92672">+</span> list( np<span style="color:#f92672">.</span>cumsum(pca<span style="color:#f92672">.</span>explained_variance_ratio_)), <span style="color:#e6db74">&#34;-o&#34;</span>)
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;Number of principal components&#34;</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;Cumulative contribution ratio&#34;</span>)
plt<span style="color:#f92672">.</span>grid()
plt<span style="color:#f92672">.</span>show()
</code></pre></div><p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/211162/d6906118-8793-1184-7f4e-1c50d25e4cb0.png" alt="output_13_0.png"></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> pandas <span style="color:#f92672">as</span> pd
<span style="color:#f92672">from</span> pandas.tools <span style="color:#f92672">import</span> plotting
plotting<span style="color:#f92672">.</span>scatter_matrix(pd<span style="color:#f92672">.</span>DataFrame(feature, columns<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;PC1&#39;</span>,<span style="color:#e6db74">&#39;PC2&#39;</span>,<span style="color:#e6db74">&#39;PC3&#39;</span>]), figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">8</span>, <span style="color:#ae81ff">8</span>), color<span style="color:#f92672">=</span>colors)
plt<span style="color:#f92672">.</span>show()
</code></pre></div><p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/211162/b5e1891e-424f-914d-240b-eb1377431331.png" alt="output_14_1.png"></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> pandas <span style="color:#f92672">as</span> pd
<span style="color:#f92672">from</span> pandas.tools <span style="color:#f92672">import</span> plotting
plotting<span style="color:#f92672">.</span>scatter_matrix(pd<span style="color:#f92672">.</span>DataFrame(zscore(data, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>), columns<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;x&#39;</span>,<span style="color:#e6db74">&#39;y&#39;</span>,<span style="color:#e6db74">&#39;z&#39;</span>]), figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">8</span>, <span style="color:#ae81ff">8</span>), color<span style="color:#f92672">=</span>colors)
plt<span style="color:#f92672">.</span>show()
</code></pre></div><pre><code>/Users/kot/miniconda3/envs/py3new/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning:'pandas.tools.plotting.scatter_matrix' is deprecated, import'pandas.plotting.scatter_matrix' instead .
  This is separate from the ipykernel package so we can avoid doing imports until![output_15_1.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/211162/9782fac6-4942-67c5-b720-128669da5425.png)</code></pre>

    </article>
  </div>

  
  
  
  <script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-123456789-1', 'auto');
  ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  

  
<link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.css" />
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#216942",
      "text": "#b2d192"
    },
    "button": {
      "background": "#afed71"
    }
  }
})});
</script>

</body>

</html>
