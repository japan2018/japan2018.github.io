<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  <meta name="generator" content="Hugo 0.72.0" />

  
  <meta name="description" content="Some description">
  

  
  <link rel="apple-touch-icon" sizes="180x180" href="https://memotut.com/apple-touch-icon.png">

  
  <link rel="icon" type="image/png" sizes="32x32" href="https://memotut.com/favicon-32x32.png">

  
  <link rel="icon" type="image/png" sizes="16x16" href="https://memotut.com/favicon-16x16.png">

  
  <link rel="manifest" href="https://memotut.com/site.webmanifest">

  
  <link rel="mask-icon" href="https://memotut.com/safari-pinned-tab.svg" color="#5bbad5">

  <meta name="msapplication-TileColor" content="#da532c">

  <meta name="theme-color" content="#ffffff">

  
  <link rel="stylesheet" href="https://memotut.com/css/bootstrap.min.css" />

  
  <title>The image is binarized. Furthermore, the shortest distance between two regions can be calculated (ver1.0). | Memo Tut</title>
  

  <style>
body {
  min-width: 300px;
}

.custom-navbar {
  margin-bottom: 1em;
  height: 60px;
}

.custom-navbar a {
  display: inline-block; 
  padding: 18px 0;
  margin-right: 1em; 
  font-weight: bold; 
}

.custom-navbar a:hover,
.custom-navbar a:focus {
  text-decoration: none; 
}

@media print {
  .custom-navbar {
    display: none;
  }
}

article {
  padding-bottom: 1em;
}

img {
  max-width: 100%;
}


body {
  background-color: #fff;
}



body {
  color: #212529;
}



a {
  color: #007bff;
}



a:hover,
a:focus {
  color: #0056b3;
}



.custom-navbar {
  background-color: #212529;
}



.custom-navbar a {
  color: rgba(255, 255, 255, 0.75);
}



.custom-navbar a:hover,
.custom-navbar a:focus {
  color: rgba(255, 255, 255, 1);
}



.container {
  max-width: 800px;
}



pre {
  display: block;
  padding: 9.5px;
  word-break: break-all;
  word-wrap: break-word;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre code {
  padding: 0;
  font-size: inherit;
  color: inherit; 
  white-space: pre-wrap;
  background-color: transparent;
  border: none;
  border-radius: 0;
}

code {
  padding: 2px 4px;
  color: inherit; 
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
  font-size: .9em;
}



blockquote,
.blockquote {
  padding: 10px 20px;
  margin: 0 0 20px;
  font-size: 1em;
  border-left: 5px solid #6c757d;
}

</style>
</head>

<body>
  <nav class="custom-navbar">
  <div class="container">
    
    <a href="/">Posts</a>
    
    <a href="/tags/">Tags</a>
    
    <a href="/about/">About</a>
    
    <a href="/index.xml">RSS</a>
    
  </div>
</nav>
  
  <div class="container">
    <article>
      <h1>The image is binarized. Furthermore, the shortest distance between two regions can be calculated (ver1.0).</h1>
<p>
  <small class="text-secondary">
  
  
  Mar 15, 2020
  </small>
  

<small><code><a href="https://memotut.com/tags/python">Python</a></code></small>


<small><code><a href="https://memotut.com/tags/image-processing"> image processing</a></code></small>


<small><code><a href="https://memotut.com/tags/opencv"> OpenCV</a></code></small>


<small><code><a href="https://memotut.com/tags/iot"> IoT</a></code></small>

</p>
<pre><code>#Introduction
</code></pre>
<p>*A revised version has been created.
<a href="https://qiita.com/Fumio-eisan/items/10c54af7a925b403f59f">https://qiita.com/Fumio-eisan/items/10c54af7a925b403f59f</a></p>
<p>I am working in the manufacturing industry, but I feel the flow of actively introducing IoT and AI technologies. I do not belong to the system department that mainly handles these technologies. However, I want to feel the flow myself! I think. There is a Raspberry Pi as a tool that is relatively easy to handle, so I am tentatively planning what can be done with this.</p>
<p>Although it has already been applied in various places, we are considering whether it can be used as a low-priced sensor with a function to perform camera shooting + image processing in real time.
The image to introduce is as follows.
<img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/567823/42a4931c-1703-5c48-4ef9-a8b0800537f7.png" alt="001.png"></p>
<p>The procedure is as follows.</p>
<ol>
<li>Create a program for image processing (image ver.)</li>
<li>Create a program for image processing (video ver.)</li>
<li>Build environment + store program in Raspberry Pi</li>
<li>Check if the captured image can be processed in real time</li>
<li>Search for good treatment methods that lead to factory improvement</li>
<li>Improve KPI value and achieve</li>
</ol>
<p>First of all, I made the contents of the program that processes image 1. This time, I would like to summarize it.</p>
<p>The main points of this article are as follows.</p>
<ul>
<li>Binary image processing with Python/OpenCV</li>
<li>Contour processing of binarized area</li>
<li>Draw a line to the shortest distance in the area and calculate the distance</li>
</ul>
<h2 id="library-and-version-used">Library and version used</h2>
<ul>
<li>Python 3.7.4</li>
<li>numpy 1.16.5</li>
<li>Opencv-contrib-python 4.2.0.32</li>
<li>matplotlib 3.1.1</li>
</ul>
<p>Binary image processing with #Python/OpenCV</p>
<p>Here is a sample image to be processed this time.</p>
<pre><code class="language-Python:img.ipynb" data-lang="Python:img.ipynb">import cv2
import matplotlib.pyplot as plt

img = cv2.imread('IMG.JPG')
fig = plt.figure(figsize=(8,8))
ax = fig.add_subplot(1,1,1)
ax.imshow(img)
ax.axis(&quot;off&quot;)

</code></pre><p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/567823/7d4c7c24-2294-87a8-3352-7398fdfbea11.png" alt="010.png"></p>
<p>‥
Since it is not possible to handle images that you want to process in actual work, use the supplement image purchased before. This time, I would like to binarize this to create two large areas and find the distance there.</p>
<p>Impact of binarization processing by ##threshold
‥
This time, the image is processed by binarization. The binarization process is to convert a color image that exceeds a certain pixel value threshold value to white, and a value that is lower than the threshold value to black to make a black and white image. The difference with so-called monochrome processing is that monochrome images also allow gray between black and white.</p>
<pre><code class="language-Python:img.ipynb" data-lang="Python:img.ipynb">img = cv2.imread(&quot;IMG.jpg&quot;, 0)


threshold = 10 # threshold setting

ret, img_thresh = cv2.threshold(img, threshold, 255, cv2.THRESH_BINARY)# Binarization (255 above threshold, 0 below)
fig = plt.figure(figsize=(8,8))
ax = fig.add_subplot(1,1,1)
ax.imshow(img_thresh)
ax.axis(&quot;off&quot;)

</code></pre><p>By changing this threshold value (threshold value), you can change the threshold value of the pixel value to be converted to black and white. Here is the result of changing the threshold.
<img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/567823/155cda83-2c59-9dd0-fef9-fde665be7281.png" alt="003.png"></p>
<p>In the original image, where white is strong (≒high pixel value), it can be seen that the original image remains until the end even if the threshold value is raised. On the other hand, where the black is originally strong (≒pixel value is low), it can be seen that the original image is used to the end even if the threshold value is lowered.
It is necessary to carefully consider this method when classifying the images you want to divide. This time, we will process the subsequent images with a threshold of 100.
There are other methods that can be used to characterize only the points where you want to adjust the RGB values and binarize them.</p>
<p>I referred to this.
<a href="http://labs.eecs.tottori-u.ac.jp/sd/Member/oyamada/OpenCV/html/py_tutorials/py_imgproc/py_thresholding/py_thresholding.html">http://labs.eecs.tottori-u.ac.jp/sd/Member/oyamada/OpenCV/html/py_tutorials/py_imgproc/py_thresholding/py_thresholding.html</a></p>
<p>#Extract contours</p>
<p>The cv2.findContours() method can be used to extract the boundary (≒ outline) of the binarized image. The coordinates of the extracted boundaries are put into the arrays of contours. The array in this contours was a little complicated, so I will summarize it below.</p>
<pre><code class="language-Python:img.ipynb" data-lang="Python:img.ipynb">
img1 = cv2.imread(&quot;IMG_re.jpg&quot;)#Read the image you want to binarize
gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)

contours, hierarchy = cv2.findContours(gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
import matplotlib.pyplot as plt
from matplotlib.patches import Polygon

def draw_contours(ax, img, contours):
    ax.imshow(img) # Show the image.
    ax.set_axis_off()
    
    for i, cnt in enumerate(contours):
        cnt = cnt.squeeze(axis=1)
        ax.add_patch(Polygon(cnt, color=&quot;b&quot;, fill=None, lw=2))
        ax.plot(cnt[:, 0], cnt[:, 1], &quot;ro&quot;, mew=0, ms=4)
        ax.text(cnt[0][0], cnt[0][1], i, color=&quot;orange&quot;, size=&quot;10&quot;)
        

fig, ax = plt.subplots(figsize=(8, 8))
draw_contours(ax, img1, contours)

plt.show()
</code></pre><p>The image obtained is shown here.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/567823/b7738bb8-8a62-84aa-dd73-3c2e67a1b4a1.png" alt="005.png"></p>
<p>Because there were many boundaries, there were many numbers and it was difficult to see.
At this time, each boundary is stored in array. By performing the sort shown below, it is possible to divide the boundary array in order of area.</p>
<pre><code class="language-Python:img.ipynb" data-lang="Python:img.ipynb">contours.sort(key=lambda x: cv2.contourArea(x), reverse=True)
target_contour = max(contours, key=lambda x: cv2.contourArea(x))

fig, ax = plt.subplots(figsize=(8, 8))
draw_contours(ax, img1, [target_contour])
</code></pre><p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/567823/e5381615-1599-5cea-010c-0a82a076a28b.png" alt="006.png"></p>
<p>The list stored in this contours is a little confusing at first, so I have summarized it in the image below, including my own understanding.
<img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/567823/8e420296-b56a-eaf3-6eec-3dc76a6a9a2f.png" alt="004.png"></p>
<h2 id="define-a-function-that-calculates-the-distance">Define a function that calculates the distance.</h2>
<p>Next, define a function that calculates the distance between two points. There is also a so-called distance method, but this time I made it myself. It is simply the square root of the square of the difference between the x and y coordinates of two points in the x and y coordinates.</p>
<pre><code class="language-Python:img.ipynb" data-lang="Python:img.ipynb">
import math
def get_distance(x1, y1, x2, y2):
    d = math.sqrt((x2-x1) ** 2 + (y2-y1) ** 2)
    return d

</code></pre><h2 id="find-the-shortest-distance-between-regions">Find the shortest distance between regions</h2>
<p>Next, write a program to find the shortest distance between areas. This time, find the shortest distance between the largest area and the second largest area. As an overview, you will find the distances shown in the figure below.
<img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/567823/b8236eea-1691-547e-92cd-b3f8cdd92673.png" alt="007.png">
In other words, the distance between the point where the x coordinate of contours[0] is the smallest and the point where the x coordinate of contours[1] is the largest is calculated.
I wish I could have read this coordinate directly, but once I read this index value with argmax and argmin, I gave the x and y coordinates of that index value as variables to calculate the distance.</p>
<h2 id="find-the-maximum-and-minimum-indices">Find the maximum and minimum indices.</h2>
<pre><code class="language-Python:img.ipynb" data-lang="Python:img.ipynb">
import numpy as np
aa=np.argmin(contours[0][0:len(contours[0])],axis=0)
bb=np.argmax(contours[1][0:len(contours[1])],axis=0)

</code></pre><h1 id="find-the-shortest-distance-between-areas-and-draw-a-line">Find the shortest distance between areas and draw a line</h1>
<pre><code class="language-Python:img.ipynb" data-lang="Python:img.ipynb">x3 = contours[0][aa[0][0]][0][0]
y3 = contours[0][aa[0][0]][0][1]
x4 = contours[1][bb[0][0]][0][0]
y4 = contours[1][bb[0][0]][0][1]

fig, ax = plt.subplots(figsize=(8, 8))cv2.line(img1, (x3, y3), (x4, y4), (25, 255, 255), thickness=10, lineType=cv2.LINE_4)
draw_contours(ax, img1, [contours[0]])
draw_contours(ax, img1, [contours[1]])
</code></pre><p>I was able to draw a line safely to the shortest distance.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/567823/c7ffde17-355f-dace-0592-ccd8b659435f.png" alt="008.png"></p>
<h1 id="at-the-end">At the end</h1>
<p>ㆍI was able to process smoothly up to the place where the binarization process was performed. However, I had a bit of trouble dealing with an array of contours to extract some points in the region.
Next, I would like to display this processing in real time in the video.</p>
<p>The full text of the program is stored here.
<a href="https://github.com/Fumio-eisan/img_distance20200315">https://github.com/Fumio-eisan/img_distance20200315</a></p>

    </article>
  </div>

  
  
  
  <script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-169005401-1', 'auto');
  ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  

  
<link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.css" />
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#216942",
      "text": "#b2d192"
    },
    "button": {
      "background": "#afed71"
    }
  }
})});
</script>

</body>

</html>
