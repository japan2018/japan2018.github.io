<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  <meta name="generator" content="Hugo 0.72.0" />

  
  <meta name="description" content="Some description">
  

  
  <link rel="apple-touch-icon" sizes="180x180" href="https://memotut.com/apple-touch-icon.png">

  
  <link rel="icon" type="image/png" sizes="32x32" href="https://memotut.com/favicon-32x32.png">

  
  <link rel="icon" type="image/png" sizes="16x16" href="https://memotut.com/favicon-16x16.png">

  
  <link rel="manifest" href="https://memotut.com/site.webmanifest">

  
  <link rel="mask-icon" href="https://memotut.com/safari-pinned-tab.svg" color="#5bbad5">

  <meta name="msapplication-TileColor" content="#da532c">

  <meta name="theme-color" content="#ffffff">

  
  <link rel="stylesheet" href="https://memotut.com/css/bootstrap.min.css" />

  
  <title>[Python] Released a web service for handwriting scoring using DeepLearning | Memo Tut</title>
  

  <style>
body {
  min-width: 300px;
}

.custom-navbar {
  margin-bottom: 1em;
  height: 60px;
}

.custom-navbar a {
  display: inline-block; 
  padding: 18px 0;
  margin-right: 1em; 
  font-weight: bold; 
}

.custom-navbar a:hover,
.custom-navbar a:focus {
  text-decoration: none; 
}

@media print {
  .custom-navbar {
    display: none;
  }
}

article {
  padding-bottom: 1em;
}

img {
  max-width: 100%;
}


body {
  background-color: #fff;
}



body {
  color: #212529;
}



a {
  color: #007bff;
}



a:hover,
a:focus {
  color: #0056b3;
}



.custom-navbar {
  background-color: #212529;
}



.custom-navbar a {
  color: rgba(255, 255, 255, 0.75);
}



.custom-navbar a:hover,
.custom-navbar a:focus {
  color: rgba(255, 255, 255, 1);
}



.container {
  max-width: 800px;
}



pre {
  display: block;
  padding: 9.5px;
  word-break: break-all;
  word-wrap: break-word;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre code {
  padding: 0;
  font-size: inherit;
  color: inherit; 
  white-space: pre-wrap;
  background-color: transparent;
  border: none;
  border-radius: 0;
}

code {
  padding: 2px 4px;
  color: inherit; 
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
  font-size: .9em;
}



blockquote,
.blockquote {
  padding: 10px 20px;
  margin: 0 0 20px;
  font-size: 1em;
  border-left: 5px solid #6c757d;
}

</style>
</head>

<body>
  <nav class="custom-navbar">
  <div class="container">
    
    <a href="/">Posts</a>
    
    <a href="/tags/">Tags</a>
    
    <a href="/about/">About</a>
    
    <a href="/index.xml">RSS</a>
    
  </div>
</nav>
  
  <div class="container">
    <article>
      <h1>[Python] Released a web service for handwriting scoring using DeepLearning</h1>
<p>
  <small class="text-secondary">
  
  
  Mar 29, 2020
  </small>
  

<small><code><a href="https://memotut.com/tags/python">Python</a></code></small>


<small><code><a href="https://memotut.com/tags/javascript">JavaScript</a></code></small>


<small><code><a href="https://memotut.com/tags/deeplearning">DeepLearning</a></code></small>


<small><code><a href="https://memotut.com/tags/gcp">gcp</a></code></small>


<small><code><a href="https://memotut.com/tags/react">React</a></code></small>

</p>
<pre><code>As a hobby, I personally developed a web service that AI automatically marks the readability of characters when I write them in a browser, and released it about 2 weeks ago: relaxed:
</code></pre>
<p>[<img width=500 src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/138646/3fba9bb2-e3e8-80bc-6762-ecf0a2c3830a.png">]((<a href="https://letters.choo.works/">https://letters.choo.works/</a>)
<a href="https://letters.choo.works/">Letters-AI handwriting scoring app</a></p>
<p>The core technology is front-end implementation with DeepLearning image recognition and Preact.
In this article, we will describe <strong>Service outline, technical details, and impressions</strong> regarding the developed application.</p>
<h1 id="service-overview">Service overview</h1>
<h3 id="function-introduction">Function introduction</h3>
<p>Since it has a small number of pages and is lightweight, it is probably faster to see the application regarding the function, but I will explain the function including an overview of the technology used with screenshots.</p>
<h5 id="handwriting-from-the-top-page">Handwriting from the top page</h5>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/138646/cd21d20f-9d9b-7977-4e13-239eead9f5b8.gif" alt="letters_demo_01.gif"></p>
<ul>
<li>On the top page, a frame where you can write characters is displayed, and you can write characters.
-I am able to write characters with HTML5 Canvas.</li>
<li>Write a letter and click the &ldquo;scoring button&rdquo; to display candidates.
-Convert what is written on Canvas into PNG file and send it to the server
-Machine learning inference is performed on the received image on the server
-Return inference results with a high written probability to the client</li>
<li>When you select the written character, the scoring result (maximum 100 points) will be displayed.
-Based on the probability value of the inference result, calculate the score by applying an intuitive formula</li>
<li>It is more likely that you will get a high score if you write polite and easy-to-read characters.</li>
<li>You can also change the thickness of the line you write (the scoring result may change greatly depending on the thickness of the line)</li>
</ul>
<h5 id="displaying-the-scoring-results-of-the-characters-written-so-far">Displaying the scoring results of the characters written so far</h5>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/138646/c6853414-9209-bd5d-8a93-6fbd02fcd188.gif" alt="letters_demo_02_2.gif"></p>
<ul>
<li>You can see a list of the characters that have been written (marked characters).
-The written character list is stored as a log on the server
-Get list of characters written with cookie as key
-If you use another terminal or browser, or if you use a secret browser, the history of the written characters will not remain because the cookie changes.</li>
<li>Other users cannot see the written characters themselves or the list of written characters at all.</li>
</ul>
<h5 id="view-example-of-high-scores">View example of high scores</h5>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/138646/e8f3f861-0506-fa0f-fb94-5f7ce30eeb83.gif" alt="letters_demo_03.gif"></p>
<ul>
<li>If you can not get a high score, you can display an example of what character you write to get a high score.</li>
<li>An example in which a high score is obtained by the inference process actually executed on the server is extracted from the training data and test data, and the image is displayed together with the score when inferred.</li>
</ul>
<h3 id="background-and-purpose-of-development">Background and purpose of development</h3>
<p>The purpose of this development is twofold.</p>
<ol>
<li>It would be fun to have an app that scores handwritten characters</li>
<li>I wanted to create a web application that applied DeepLearning</li>
</ol>
<p>As a result of developing it, I am satisfied because I met both of them for the time being.
I don&rsquo;t think there is a service that offers the same functions as the one we developed this time yet. (No, I haven&rsquo;t investigated other services to that extent&hellip;)</p>
<h3 id="special-points">Special points</h3>
<h5 id="light-movement">Light movement</h5>
<p>Basically it is supposed to be used on smartphones and tablets, so I tried hard to make the initial display etc. crisp.
Specifically, we are trying to make the front-end files as light as possible.</p>
<h5 id="guaranteeing-the-number-of-scoring-characters">Guaranteeing the number of scoring characters</h5>
<p>The scoring target is a total of 3175 characters, which are commonly used in Japanese, such as hiragana, katakana, kanji, romaji, and numbers, and are designed to cover almost all the characters commonly used in Japan <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>.</p>
<p>If it is only numbers, it can be easily prepared by using the MNIST dataset, and there are various datasets that contain only alphanumeric characters. It was troublesome to create a data set that included upper and lower case letters.</p>
<h1 id="technical-details">Technical details</h1>
<h3 id="architecture-overview">Architecture overview</h3>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/138646/50322bf0-45eb-b124-d672-1e6f1a1d077e.png" alt="Letters_architecture (1).png"></p>
<h3 id="technology-language-and-tools-used">Technology, language and tools used</h3>
<h5 id="front-end">front end</h5>
<ul>
<li>Preact</li>
<li>JavaScript/HTML/CSS</li>
</ul>
<p><a href="https://preactjs.com/">Preact</a> is a lightweight framework for React. It&rsquo;s a very lightweight implementation, while allowing you to use most of React&rsquo;s main APIs as is <sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>.
I wasn&rsquo;t too crazy about React, so I didn&rsquo;t have any problems with Preact <sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>.</p>
<h5 id="backend">backend</h5>
<ul>
<li>Nginx</li>
<li>uWSGI</li>
<li>Flask</li>
<li>Python3</li>
</ul>
<p>Since the machine learning part uses Python3 + Keras, Python is selected as the backend that needs to execute inference processing in real time because of its affinity and convenience.
Flask is selected because it is simply light and easy to use, but since there are times when I want to perform asynchronous processing even with an application server on Python, I went to <a href="https://github.com/tiangolo/fastapi">FastAPI</a>. I&rsquo;m thinking of replacing.
There is no particular reason to choose Nginx, uWSGI, but basically application servers such as Flask are not optimized for the operation of the front end of the web in the production environment, so they are the best for those applications and Flask. It&rsquo;s just that you are using one with a high affinity.</p>
<h5 id="machine-learning-part">Machine learning part</h5>
<ul>
<li>Keras</li>
<li>Python3</li>
</ul>
<p>Both learning and reasoning use deep learning framework Keras.</p>
<h5 id="infrastructure-such-as-execution-environment">Infrastructure such as execution environment</h5>
<ul>
<li>Google Cloud Platform (GCP)</li>
<li>Google Domains</li>
<li>Docker</li>
</ul>
<p>I generally use GCP (I don&rsquo;t use any cloud services other than GCP).
The back-end server uses <code>Google Compute Engine</code>, the storage location of image files etc. is <code>Google Cloud Storage</code>, and the load balancer is <code>Google Cloud Load Balancing</code>.
<code>Google Cloud Load Balancing</code> is quite expensive because it costs only JPY 2700 (as of March 23, 2020) per month for basic usage fees. I was relieved to be able to increase the number of instances when the number of accesses increased, so I decided to use it once.</p>
<p>Deployment is executed in the following flow, with Docker container as a release unit.</p>
<ol>
<li>Build the front end in the development environment</li>
<li>Create a container image containing pre-built and executable code</li>
<li>Push the created container image to the private container registry</li>
<li>Create an instance template based on the pushed container image</li>
<li>Update instance group based on instance template</li>
</ol>
<p>There are many katakana&hellip;w
Since we are not thinking of updating the training data so far, we are using a model that has already been trained.</p>
<h5 id="other-tools-and-services-you-have-taken-care-of">Other tools and services you have taken care of</h5>
<p><strong><a href="https://inkscape.org/">Inkscape</a></strong>
Free software that provides almost the same functions as Adobe Illustrator.
I used it to create logos and icons.</p>
<p><strong><a href="https://ao-system.net/favicon/">Let&rsquo;s make favicon favicon.ico!</a></strong>
It is very convenient when creating favicons in various sizes and formats all at once.</p>
<p><strong><a href="https://ezgif.com/video-to-gif">EZGIF.COM-Animated GIF editor and GIF maker</a></strong>
It is a convenient service to convert the application demo video to GIF when you want to upload it to Twitter on Qiita.
I have tried several similar services, but I personally found this to be the easiest to use because of the flexibility of the conversion and the processing time.</p>
<p><strong>Wikitionary</strong>
I collected data because I wanted to classify by the grades that I learned at school to make a list of kanji.
We have already acquired data such as readings, total strokes, and radicals, but currently we have not implemented display classification/search functions using them.</p>
<h3 id="data-used-to-train-the-machine-learning-model">Data used to train the machine learning model</h3>
<p><strong><a href="http://etlcdb.db.aist.go.jp/?lang=ja">ETL Character Database (ETL CDB)</a></strong>
It is a data set of handwritten character (+ small amount of printed character) image data.
It is a data set consisting of about 3200 characters used in Japan, with 1,115,065 image data.
The type of characters consists of Hiragana, Katakana, Kanji, alphanumeric characters and symbols, but does not include the lowercase letters of the Latin alphabet (Roman alphabet).
In addition, ETLDB is a data set that is a little difficult to handle from the following points.-Each dataset is binary data with fixed length and fixed format, not modern JSON or XML</p>
<ul>
<li>The internally stored character code is JIX X 0201, or the CO-59 (character code for the six-sha agreement newspaper) Nazoi character code</li>
</ul>
<p><a href="https://github.com/choo/etlcdb-image-extractor">ETLCDB Python script to retrieve images of all datasets</a> has been created and published. Get the raw image data from the binary data on the dataset and save each code as a directory in PNG so that it can be treated as Unicode code point labels.
The dataset can be used free of charge, but please note that it says <code>Please inquire about the conditions for commercial use</code>.</p>
<p><strong><a href="https://www.nist.gov/itl/products-and-services/emnist-dataset">The EMNIST Datset</a></strong>
A handwritten character data set provided by NIST (National Institute of Standards and Technology).
There are 814,255 images for all 62 characters including Romaji case and numbers.
Note that MNIST, which often appears in deep learning tutorials, is a subset of this dataset.
The ETL CDB above contains many characters, but there is no Roman lower case data. However, since I really wanted to include all alphanumeric characters as a scoring target, I added a dataset containing all Roman letters as training data.</p>
<h3 id="source-code-etc">Source code etc.</h3>
<p>The basic source is available at <a href="https://github.com/choo/handwriting-scorer">GitHub repository</a>.
However, some files necessary for executing the application such as the learned model are not placed on GitHub, so the execution environment cannot be reproduced as it is as a development environment.</p>
<h1 id="impression">Impression</h1>
<h3 id="what-i-felt-while-playing-with-the-app">What I felt while playing with the app</h3>
<p>Well, suddenly it&rsquo;s not a topic, but can you decipher the meaning of the following sentence?
(*Slightly changed from the time of posting)</p>
<p>** &ldquo;Uchiguchi Uriki Niiki Koyu&rdquo; **</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/138646/fc1092a6-d0ef-1dd2-3463-763212c4e2dc.png" alt="mushimegane_boy.png"></p>
<p>*Since it will be displayed again, you may understand it if you carefully read it.
** &ldquo;Uchiguchi Uriki Niiki Koyu&rdquo; **</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/138646/07ac151a-2daa-9414-7b0a-d496c8939afd.png" alt="sashimi_maguro_ootoro.png">
<img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/138646/e1bb81d0-744b-6996-4e22-548ff684dbe3.png" alt="kani_ashi.png"></p>
<p>I put a useless image so that I could not see the correct answer immediately. Sorry: sweat:</p>
<p>And the image is completely hooked, and if you think that it is the katakana notation of &ldquo;it was changed,&rdquo; there is no character&hellip;
The correct answer is as follows, which is actually just an enumeration of characters that do not hold as sentences.</p>
<p>Utter: Water ** Utah ** Ana&rsquo;s ** &ldquo;Utah&rdquo; **
Mouth: **Mouth **Inflammation, **Mouth <strong>Corner <strong>&ldquo;Mouth&rdquo;</strong>
Power: <strong>Power</strong> Master, <strong>Power</strong>&rsquo;s &ldquo;Power&rdquo;</strong>
Second: **Second **Kotamagawa, <strong>Second</strong>Term distribution <strong>&ldquo;Second&rdquo;</strong>
Engineering: <strong>Engineering</strong>, **Engineering **ba, Saito <strong>Engineering</strong>&rsquo;s <strong>“Engineering”</strong>
Evening: <strong>evening</strong>, <strong>evening</strong>, <strong>evening</strong> food <strong>&ldquo;evening&rdquo;</strong>
(If you copy and paste it and do a Google search, you can see that all are Kanji.)</p>
<p>Perhaps not many people were able to recognize all the characters correctly.
If so, it can be seen that <strong>&ldquo;any character is legible and readable by humans&rdquo; is not true</strong> <sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>.
For example, when I was asked to read the word &ldquo;work&rdquo;, if there were no hints, I could only say &ldquo;either &ldquo;work&rdquo; for construction or &ldquo;e&rdquo; (e) for katakana&rdquo;. I think you can <sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>. In other words, <strong>discrimination by character alone can be very difficult</strong>.</p>
<p>Also, if the question &ldquo;Can you interpret the meaning of the following text&rdquo; at the beginning of this section ** &ldquo;What is written in each character of the next character string?&rdquo; I think many people are different.</p>
<p>It&rsquo;s often said that while studying and experimenting with machine learning, especially deep learning, we often feel that <strong>human perception is often context dependent</strong>. There is. The character recognition this time is a typical example, and when we read the characters, we *** do not recognize and recognize only the figure of the character itself. It depends on &ldquo;information that can be called context&rdquo; such as &ldquo;what kind of word or morpheme element is it?&rdquo; &ldquo;What kind of word is natural in it?&quot;** You can see that.</p>
<p>In the newly developed app, image recognition is used without any context information for scoring, so there are many characters that do not give high scores. The typical example is the above 5 characters, but other characters such as 0 (the number zero) and O (the Latin alphabet O) are difficult to recognize because they are single characters, so it is not so easy. There are a number of.</p>
<p>In the development related to machine learning, I often work while thinking about &ldquo;how humans perceive&rdquo;, but it is very interesting to delve into it purely, and I am surprised at how good the human brain is. Often. Also, I think that there are many hints from the perspective of &ldquo;what AI can do and what it cannot do at this point&rdquo;.</p>
<p>In addition, personally, contextual information that is not only words is becoming analyzable by natural language processing, and I think that multimodal deep learning etc. will develop significantly in the next few years, so I think AI will naturally be able to make highly accurate inferences after reading the context. With these advances, I think that so-called &ldquo;quiet AI&rdquo; will be realized in the not too distant future.</p>
<h3 id="difficulty-of-release-in-personal-development">Difficulty of release in personal development</h3>
<p>In personal development, making a decision about how much to make and release should be very difficult, unlike the case where the delivery date is fixed by contracts like business.
Whether it&rsquo;s a business or a hobby, I think that anyone who has done software development firmly can understand, but in the middle of development, in addition to bugs that need to be fixed, improvements and features that I think should be there Comes out innumerably. Even in this personal development, there are still many points that we should add or improve.</p>
<p>Under such circumstances, it is very difficult to decide &ldquo;how far to release it&rdquo;. I think that the most important thing in such a situation is a strong will to &ldquo;exist in the world&rdquo;**.</p>
<p><strong>&ldquo;Done is better than perfect&rdquo;</strong>, which seems to be used as a slogan within Facebook, says ** &ldquo;There is no such thing as software being in perfect condition. That is why we launch it with a sense of speed and keep improving little by little It&rsquo;s important to keep going.”** It seems that the intention is &ldquo;[facebook].
As typified by these words, some release is required for release.
However, on the other hand, it is often said that a user who has left once will take a long time to come back, and it is easy to put out poor quality products to the world, and it is difficult to pride as an engineer. It&rsquo;s difficult.</p>
<p>After all, it is best to set a release date for individual development (decide a release date in advance so that anything is released there **) I&rsquo;m wondering if this is possible recently (there may be other good ways&hellip;if you know, I really want to know so I&rsquo;d love to know&hellip;!)</p>
<p>There are many more things to think and think about regarding this &ldquo;difficulty of release timing,&rdquo; so I&rsquo;d like to write a separate Poem for this article.</p>
<h1 id="finally">Finally</h1>
<p>In Tokyo, it is hard to get out of my house due to heavy snowfall, as well as a demand for refraining from going out, and I hope you can play a little if you like.
There are still many incomplete points and it may not be functionally sufficient, but I hope you enjoy it!</p>
<p>Recently, Twitter has started to do small things, so if you like, please follow <a href="https://twitter.com/choo_s">Twitter account</a>m(__)m</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>The breakdown is 75 hiragana characters, 71 katakana characters, 2967 kanji characters, 52 roman characters, and 10 numbers. <a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>About 3KB as gzipped. Amazing. <a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>The functional component hook API can be used normally in Preact, and there is also a router for Preact. <a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4" role="doc-endnote">
<p>Unless it&rsquo;s just a mistake&hellip; <a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5" role="doc-endnote">
<p>Depending on the font, there may be some fonts/people that can distinguish between kanji and katakana. <a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>

    </article>
  </div>

  
  
  
  <script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-169005401-1', 'auto');
  ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  

  
<link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.css" />
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#216942",
      "text": "#b2d192"
    },
    "button": {
      "background": "#afed71"
    }
  }
})});
</script>

</body>

</html>
