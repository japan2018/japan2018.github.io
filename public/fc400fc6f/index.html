<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  <meta name="generator" content="Hugo 0.72.0" />

  
  <meta name="description" content="Some description">
  

  
  <link rel="apple-touch-icon" sizes="180x180" href="https://memotut.com/apple-touch-icon.png">

  
  <link rel="icon" type="image/png" sizes="32x32" href="https://memotut.com/favicon-32x32.png">

  
  <link rel="icon" type="image/png" sizes="16x16" href="https://memotut.com/favicon-16x16.png">

  
  <link rel="manifest" href="https://memotut.com/site.webmanifest">

  
  <link rel="mask-icon" href="https://memotut.com/safari-pinned-tab.svg" color="#5bbad5">

  <meta name="msapplication-TileColor" content="#da532c">

  <meta name="theme-color" content="#ffffff">

  
  <link rel="stylesheet" href="https://memotut.com/css/bootstrap.min.css" />

  
  <title>[Python] [TF] How to save and load Tensorflow learning parameters | Memo Tut</title>
  

  <style>
body {
  min-width: 300px;
}

.custom-navbar {
  margin-bottom: 1em;
  height: 60px;
}

.custom-navbar a {
  display: inline-block; 
  padding: 18px 0;
  margin-right: 1em; 
  font-weight: bold; 
}

.custom-navbar a:hover,
.custom-navbar a:focus {
  text-decoration: none; 
}

@media print {
  .custom-navbar {
    display: none;
  }
}

article {
  padding-bottom: 1em;
}

img {
  max-width: 100%;
}


body {
  background-color: #fff;
}



body {
  color: #212529;
}



a {
  color: #007bff;
}



a:hover,
a:focus {
  color: #0056b3;
}



.custom-navbar {
  background-color: #212529;
}



.custom-navbar a {
  color: rgba(255, 255, 255, 0.75);
}



.custom-navbar a:hover,
.custom-navbar a:focus {
  color: rgba(255, 255, 255, 1);
}



.container {
  max-width: 800px;
}



pre {
  display: block;
  padding: 9.5px;
  word-break: break-all;
  word-wrap: break-word;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre code {
  padding: 0;
  font-size: inherit;
  color: inherit; 
  white-space: pre-wrap;
  background-color: transparent;
  border: none;
  border-radius: 0;
}

code {
  padding: 2px 4px;
  color: inherit; 
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
  font-size: .9em;
}



blockquote,
.blockquote {
  padding: 10px 20px;
  margin: 0 0 20px;
  font-size: 1em;
  border-left: 5px solid #6c757d;
}

</style>
</head>

<body>
  <nav class="custom-navbar">
  <div class="container">
    
    <a href="/">Posts</a>
    
    <a href="/tags/">Tags</a>
    
    <a href="/about/">About</a>
    
    <a href="/index.xml">RSS</a>
    
  </div>
</nav>
  
  <div class="container">
    <article>
      <h1>[Python] [TF] How to save and load Tensorflow learning parameters</h1>
<p>
  <small class="text-secondary">
  
  
  Apr 3, 2016
  </small>
  

<small><code><a href="https://memotut.com/tags/python">Python</a></code></small>


<small><code><a href="https://memotut.com/tags/tensorflow">TensorFlow</a></code></small>

</p>
<pre><code>Use **tf.train.Saver** to save and load the parameters learned by Tensorflow.
</code></pre>
<h2 id="save">Save</h2>
<p>To save, use the <strong>save</strong> method of the saver class you created.</p>
<pre><code class="language-lang:python" data-lang="lang:python">saver = tf.train.Saver()

Some processing
 
#Save
saver.save(sess, &quot;model.ckpt&quot;)
</code></pre><p>Saving can be done at the end of learning or at a timing in the middle of learning.</p>
<h2 id="read">read</h2>
<p>When loading, use the <strong>restore</strong> method of the saver class you created.
You need a session, so load it after creating the session.
When running on ipython, create a session with tf.InteractiveSession(), usually tf.Session().</p>
<pre><code class="language-lang:python" data-lang="lang:python">sess=tf.InteractiveSession()

saver.restore(sess, &quot;model.ckpt&quot;)
</code></pre><p>The following shows the actual saving and loading.</p>
<p>The flow is as follows.</p>
<ol>
<li>Model creation</li>
<li>Learning</li>
<li>Save parameter to another variable for later comparison</li>
<li>Save parameters to file</li>
<li>Session Close</li>
<li>Session creation</li>
<li>Initialization (Originally this is not necessary. It was intentionally initialized for comparison.)</li>
<li>Compare with the saved parameter (This is different because it was initialized before)</li>
<li>Read parameters from file</li>
<li>Compare with saved parameters (this matches)</li>
<li>Learning</li>
</ol>
<p><img src="https://qiita-image-store.s3.amazonaws.com/0/100523/4085ff55-e977-8686-c7a7-1b05904c8ca0.png" alt="TF_SaveAndRestoreModel-20-1-html.png"></p>
<p>code</p>
<pre><code class="language-lang:python" data-lang="lang:python"># # import

# In[1]:

import tensorflow as tf
import numpy as np
from tensorflow.examples.tutorials.mnist import input_data


# # load dataset

# In[2]:

mnist = input_data.read_data_sets(&quot;./data/mnist/&quot;, one_hot=True)


# # build model

# In[3]:

def mlp(x, output_dim, reuse=False):
        
    w1 = tf.get_variable(&quot;w1&quot;, [x.get_shape()[1], 1024], initializer=tf.random_normal_initializer())
    b1 = tf.get_variable(&quot;b1&quot;, [1024], initializer=tf.constant_initializer(0.0))
    w2 = tf.get_variable(&quot;w2&quot;, [1024, output_dim], initializer=tf.random_normal_initializer())
    b2 = tf.get_variable(&quot;b2&quot;, [output_dim], initializer=tf.constant_initializer(0.0))
    
    fc1 = tf.nn.relu(tf.matmul(x, w1) + b1)
    fc2 = tf.matmul(fc1, w2) + b2

    return fc2, [w1, b1, w2, b2]

def slp(x, output_dim):
    w1 = tf.get_variable(&quot;w1&quot;, [x.get_shape()[1], output_dim], initializer=tf.random_normal_initializer())
    b1 = tf.get_variable(&quot;b1&quot;, [output_dim], initializer=tf.constant_initializer(0.0))
    
    fc1 = tf.nn.relu(tf.matmul(x, w1) + b1)
    return fc1, [w1, b1]

n_batch = 32
n_label = 10
n_train = 10000
imagesize = 28
learning_rate = 0.5

x_node = tf.placeholder(tf.float32, shape=(n_batch, imagesize*imagesize))
y_node = tf.placeholder(tf.float32, shape=(n_batch, n_label))

with tf.variable_scope(&quot;MLP&quot;) as scope:
    out_m, theta_m = mlp(x_node, n_label)
           
loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(out_m, y_node))
opt = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)
tr_pred = tf.nn.softmax(out_m)

test_data = mnist.test.images
test_labels = mnist.test.labels
tx = tf.constant(test_data)
ty_ = tf.constant(test_labels)

with tf.variable_scope(&quot;MLP&quot;) as scope:
    scope.reuse_variables()
    ty, _ = mlp(tx, n_label)
    
te_pred = tf.nn.softmax(ty)


# In[4]:

def accuracy(y, y_):
    return 100.0 * np.sum(np.argmax(y, 1) == np.argmax(y_, 1)) / y.shape[0]


# In[5]:

saver = tf.train.Saver()

sess=tf.InteractiveSession()

init = tf.initialize_all_variables()
sess.run(init)


# In[6]:

for step in xrange(n_train):
    bx, by = mnist.train.next_batch(n_batch)
    feed_dict = {x_node: bx, y_node: by}
    _, _loss, _tr_pred = sess.run([opt, loss, tr_pred], feed_dict=feed_dict)
    if step %500 == 0:
        _accuracy = accuracy(_tr_pred, by)
        print'step = %d, loss=%.2f, accuracy=%.2f' %(step, _loss, _accuracy)

print'test accuracy=%.2f'% accuracy(te_pred.eval(), test_labels)


# In[8]:

old_theta_m = [p.eval() for p in theta_m] # for comparing


# In[9]:

saver.save(sess, &quot;model.ckpt&quot;)


# In[10]:

sess.close()


# In[11]:

sess=tf.InteractiveSession()

# for clear
init = tf.initialize_all_variables()
sess.run(init)


# In[12]:

for prm, prm_o in zip(theta_m, old_theta_m):
    p1 = prm.eval()
    p2 = prm_o
    print np.sum(p1 != p2)


# In[13]:

saver.restore(sess, &quot;model.ckpt&quot;)


# In[14]:

for prm, prm_o in zip(theta_m, old_theta_m):
    p1 = prm.eval()
    p2 = prm_o
    print np.sum(p1 != p2)


# In[15]:

print'test accuracy=%.2f'% accuracy(te_pred.eval(), test_labels)


# In[16]:

for step in xrange(n_train):
    bx, by = mnist.train.next_batch(n_batch)
    feed_dict = {x_node: bx, y_node: by}
    _, _loss, _tr_pred = sess.run([opt, loss, tr_pred], feed_dict=feed_dict)
    if step %500 == 0:
        _accuracy = accuracy(_tr_pred, by)
        print'step = %d, loss=%.2f, accuracy=%.2f' %(step, _loss, _accuracy)

print'test accuracy=%.2f'% accuracy(te_pred.eval(), test_labels)


# In[17]:

sess.close()


# In[ ]:

tf.reset_default_graph()
</code></pre>
    </article>
  </div>

  
  
  
  <script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-169005401-1', 'auto');
  ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  

  
<link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.css" />
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#216942",
      "text": "#b2d192"
    },
    "button": {
      "background": "#afed71"
    }
  }
})});
</script>

</body>

</html>
