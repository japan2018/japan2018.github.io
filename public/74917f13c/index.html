<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  <meta name="generator" content="Hugo 0.72.0" />

  
  <meta name="description" content="Some description">
  

  
  <link rel="apple-touch-icon" sizes="180x180" href="https://memotut.com/apple-touch-icon.png">

  
  <link rel="icon" type="image/png" sizes="32x32" href="https://memotut.com/favicon-32x32.png">

  
  <link rel="icon" type="image/png" sizes="16x16" href="https://memotut.com/favicon-16x16.png">

  
  <link rel="manifest" href="https://memotut.com/site.webmanifest">

  
  <link rel="mask-icon" href="https://memotut.com/safari-pinned-tab.svg" color="#5bbad5">

  <meta name="msapplication-TileColor" content="#da532c">

  <meta name="theme-color" content="#ffffff">

  
  <link rel="stylesheet" href="https://memotut.com/css/bootstrap.min.css" />

  
  <title>[Python] [Paper and Implementation] When asked, Is this data set difficult?... | Memo Tut</title>
  

  <style>
body {
  min-width: 300px;
}

.custom-navbar {
  margin-bottom: 1em;
  height: 60px;
}

.custom-navbar a {
  display: inline-block; 
  padding: 18px 0;
  margin-right: 1em; 
  font-weight: bold; 
}

.custom-navbar a:hover,
.custom-navbar a:focus {
  text-decoration: none; 
}

@media print {
  .custom-navbar {
    display: none;
  }
}

article {
  padding-bottom: 1em;
}

img {
  max-width: 100%;
}


body {
  background-color: #fff;
}



body {
  color: #212529;
}



a {
  color: #007bff;
}



a:hover,
a:focus {
  color: #0056b3;
}



.custom-navbar {
  background-color: #212529;
}



.custom-navbar a {
  color: rgba(255, 255, 255, 0.75);
}



.custom-navbar a:hover,
.custom-navbar a:focus {
  color: rgba(255, 255, 255, 1);
}



.container {
  max-width: 800px;
}



pre {
  display: block;
  padding: 9.5px;
  word-break: break-all;
  word-wrap: break-word;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre code {
  padding: 0;
  font-size: inherit;
  color: inherit; 
  white-space: pre-wrap;
  background-color: transparent;
  border: none;
  border-radius: 0;
}

code {
  padding: 2px 4px;
  color: inherit; 
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
  font-size: .9em;
}



blockquote,
.blockquote {
  padding: 10px 20px;
  margin: 0 0 20px;
  font-size: 1em;
  border-left: 5px solid #6c757d;
}

</style>
</head>

<body>
  <nav class="custom-navbar">
  <div class="container">
    
    <a href="/">Posts</a>
    
    <a href="/tags/">Tags</a>
    
    <a href="/about/">About</a>
    
    <a href="/index.xml">RSS</a>
    
  </div>
</nav>
  
  <div class="container">
    <article>
      <h1>[Python] [Paper and Implementation] When asked, Is this data set difficult?&hellip;</h1>
<p>
  <small class="text-secondary">
  
  
  Nov 13, 2019
  </small>
  

<small><code><a href="https://memotut.com/tags/python">Python</a></code></small>


<small><code><a href="https://memotut.com/tags/machinelearning">MachineLearning</a></code></small>


<small><code><a href="https://memotut.com/tags/deeplearning">DeepLearning</a></code></small>


<small><code><a href="https://memotut.com/tags/keras">Keras</a></code></small>


<small><code><a href="https://memotut.com/tags/paper-reading"> Paper reading</a></code></small>

</p>
<pre><code>Learning a convolutional neural network (CNN) takes time.
</code></pre>
<p>Especially, if you try to get accuracy without transfer learning, it takes about 5 days**
There are times. The paper introduced in this paper quantitatively describes the difficulty of datasets.
By evaluating, classification accuracy can be estimated quickly without learning CNN.
Is that.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/264781/a00827e4-829f-74e1-704e-a10d972a0890.png" alt="Download (1).png"></p>
<p>*The entire code was placed on <a href="https://github.com/shinmura0/Spectral_Metric_for_Dataset_Complexity_Assessment-Keras/blob/master/Spectral_Metric.ipynb">here</a>.
*The figures in this paper are basically taken from the paper (<a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Branchaud-Charron_Spectral_Metric_for_Dataset_Complexity_Assessment_CVPR_2019_paper.pdf">Spectral Metric for Dataset Complexity Assessment</a>).
*This material is the presentation material of <a href="https://pythondata.connpass.com/event/150387/">[Online] Python Data Analysis Study Group #13 Part 2</a>.</p>
<p>#paper
##Overview</p>
<ul>
<li>For CNN classification problem, propose CSG that can estimate the classification accuracy of **CNN without learning **CNN</li>
<li>Faster than the conventional method (about 2 times), and further increased the correlation coefficient (0.77 → 0.97)</li>
</ul>
<h2 id="class-overlap">Class overlap</h2>
<p>The key to this paper is that in the image classification task, &ldquo;If the overlap between two classes is large,
That classification problem is a difficult problem.&rdquo;</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/264781/f27f454b-c30d-b33f-de85-03c4d62c20f3.png" alt="image.png"></p>
<p>The above figure is my own work. Now, using CNN to embed an image in a two-dimensional space
To do.</p>
<p>And assuming that it is a task to classify orange points and blue points, for the left figure,
It seems that the problem on the right is easier to classify. In other words,
It can be said that the more difficult the classification problem is, the greater the overlap between classes.</p>
<p>According to the mathematical formula, if there are many points in the same group as yourself near a certain point, duplication will occur.
Small (easy classification problem), and if there are many points in a group different from yourself, the duplication is large
It seems to be a (difficult classification problem).</p>
<p>The paper presents the following formula:</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/264781/bfe6ef1a-2002-4117-334b-8aad74321cac.png" alt="image.png"></p>
<p>This expression represents the degree of duplication of class $C_j$ as seen from class $C_i$.</p>
<p>Since M and V are constant values, let&rsquo;s leave them for the time being. $K_{C_j}$ is in the image x of class $C_i$
The number of classes $C_j$ in the neighborhood. That is, if $K_{C_j}$ is large, the overlap is large.
I can say.</p>
<p>Where $\phi(x)\in R^d$ is the vector that embedded the image x of $C_i$, M is from $C_j$
The number of samples taken, V is the size of the hypercube. Finally
Expression (4) is applied to the image of class $C_i$ and the sum is taken.</p>
<ul>
<li>To be clear, both M and V will be canceled by the formula (5) that appears later, so
I think that it is safe to put M=V=1.</li>
</ul>
<p>Since equation (4) can only calculate the degree of overlap between two classes,
If you have multiple classes, calculate the degree of overlap for each class.
is needed.</p>
<p>If the number of classes is K, then the similarity matrix $S\in R^{K\times K}$ is
Is defined. $S_{ij}$ is calculated by the sum of equation (4).</p>
<p>The fact that each element of $S$ is large means that Equation (4) has a large value.
From the point of view of class i, there are many class j nearby.
So it&rsquo;s a difficult classification problem.</p>
<h2 id="spectral-clustering">Spectral clustering</h2>
<p>After that, how to use $S$ to quantify the difficulty of the classification problem
Is a problem.</p>
<p>The paper uses spectral clustering.</p>
<p>Spectral clustering was originally unsupervised learning clustering.
Seems like the method used. Split where each graph is weakly connected
By doing so, even if it is a difficult division problem with k-means method, etc.
It is possible to. Please see the link below for details.
<a href="https://www.slideshare.net/pecorarista/ss-51761860">https://www.slideshare.net/pecorarista/ss-51761860</a>
<a href="https://qiita.com/sakami/items/9b3d57d4be3ff1c70e1d">https://qiita.com/sakami/items/9b3d57d4be3ff1c70e1d</a></p>
<p>In spectral clustering, the following Laplacian L
Quantify the difficulty of dividing the graph by finding the eigenvalue
can do.</p>
<pre><code class="language-math" data-lang="math">L=D-W
</code></pre><p>When applied to this paper, $S_{ij}$ is regarded as a graph, and it is difficult to divide it.
It quantifies (difficulty of classification). Generally, the eigenvalue of L is
It seems that the larger the size, the more difficult it is to split, but in this paper,
Not only the magnitude of eigenvalues, but also the tendency of eigenvalues can be captured and digitized.
More **accurate digitization** is possible.</p>
<p>For the expression in L, D is defined as $D_i=\sum_jw_{i,j}$.
I want to directly assign $S$ to W, but W has a constraint that it is a symmetric matrix.
Therefore, it is symmetrized using the following formula.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/264781/b30b774a-9cd9-f5cf-f640-0adfbd7f7567.png" alt="image.png"></p>
<p>If you show the experimental results first, you can see the difficulty of the dataset even with W alone.
Can be estimated The figure below shows the experimental results using CIFAR10.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/264781/fe6a4c70-1d28-519f-1e65-df27558e8dca.png" alt="image.png"></p>
<p>The upper row shows the experimental results for W. The confusion matrix by the inference of AlexNet that the lower part learned.
You can see that the W estimation is very similar to the AlexNet inference result.
The situation in which it is difficult to distinguish between &ldquo;dogs&rdquo; and &ldquo;cats&rdquo; is also correct.</p>
<h2 id="laplacian-l">Laplacian L</h2>
<p>Confirm the processing up to this point.
Image → Embedding → Calculate the overlap between classes with formula (4) → Calculate the eigenvalue of L</p>
<p>As mentioned above, just looking at the maximum eigenvalue of Laplacian L
The difficulty of dividing the graph (in this paper, the difficulty of the dataset)
Can be estimated</p>
<p>If we show the experimental results first, we can calculate the maximum value or sum of eigenvalues.
You can estimate the difficulty of a dataset just by looking at it.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/264781/d6566c4d-f10b-2476-c5bb-31c6b73da8ee.png" alt="image.png"></p>
<p>The table above shows the experimental results using CIFAR10.</p>
<ul>
<li>Green frame is the conventional method. The correlation coefficient is <strong>0.773</strong> even if it is high.</li>
<li>The red frame is the result calculated using the eigenvalues of L. Using the maximum eigenvalue, the correlation coefficient is 0.88, and the sum is <strong>0.94</strong>.</li>
<li>The blue frame is the result of using CSG described later. The correlation coefficient is the highest <strong>0.968</strong>.</li>
</ul>
<p>Even just looking at the sum of the eigenvalues, the performance exceeds the conventional method.</p>
<p>In the table above, the following four &ldquo;embedding methods&rdquo; are prepared.</p>
<ul>
<li>RAW: Data as it is. For CIFAR10 1,024 dimensions</li>
<li>$CNN_{AE}$: Latent variable acquired by auto encoder (dimensions unknown)</li>
<li>t-SNE: Data is dimensionally compressed by t-sne. For CIFAR10 1,024 → 2D</li>
<li>$CNN_{AE}$t-SNE: t-SNE is applied to latent variable by auto encoder</li>
</ul>
<p>By the way, the method in this paper claims &ldquo;high speed&rdquo;, but it requires learning the auto encoder.
A good CSG cannot be calculated. The time in parentheses in the table above is the learning time for the auto encoder.
As you can see, it is about twice as fast as the conventional method. (It&rsquo;s still great though.)</p>
<p>##CSG
Finally, I will explain about CSG.
When the eigenvalues are arranged in order from the smallest, i=0,1,2&hellip;, first standardize with the following formula.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/264781/192c35a7-4a6c-7e2e-c6ab-72ca743a7cc4.png" alt="image.png"></p>
<p>Then calculate CSG.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/264781/8181f5eb-1746-80cc-b4c4-b4cf1c1e1971.png" alt="image.png"></p>
<p>Here, assuming that there is an array called [1,4,3,2] with cummax,</p>
<pre><code>cummax[1,4,3,2] = [1,4,4,4]
</code></pre><p>Means In other words, when reading from left to right,
A function that records the maximum value of a number.</p>
<p>##Experimental result
The table below shows the experimental results using MNIST.
<img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/264781/a65e11c9-2a3e-4fb8-0673-a2828c374cef.png" alt="image.png"></p>
<p>As you can see, as the number of classes included in mnist increases, so does CSG and error rate.
You can see that (correlation). By the way, light blue mnist means “mnist1”.
That is, there is only one class.</p>
<p>The table below shows the results of experiments using different datasets (10 classes).</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/264781/bc24bfcd-930c-3003-7115-81b9680297aa.png" alt="image.png"></p>
<p>It should be noted that the CSG (red) and the AlexNet error rate (blue) are correlated.
You can see that the CSG is working correctly even if the datasets are different.</p>
<p>The figure below shows the results of experiments using a dataset called MioTCD.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/264781/74afc547-f169-af96-c522-37e725e3428c.png" alt="image.png">Here, CSG is calculated while reducing the number of data. And to CSG
The error rate will increase proportionally. In this dataset,
You can see that there is no problem even if you reduce the data by about 80%.</p>
<ul>
<li>In this figure, since CSG was used at first glance, the error rate should remain horizontal.
As you can see, it seems that the data reduction method was chosen randomly.</li>
</ul>
<p>On the other hand, as CIFAR10 reduces the data as shown in the table below,
The error rate will increase.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/264781/3fc9e8a1-4e8c-e24f-f5d2-c7bc16609783.png" alt="image.png"></p>
<p>Again, it can be seen that CSG increases in proportion to the error rate.</p>
<p>Also, by using the matrix W and applying MDS to the following equation, the similarity between classes can be calculated.
Can be visualized.</p>
<pre><code class="language-math" data-lang="math">S=1-W
</code></pre><p>The figure below is the figure which applied MDS.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/264781/11cd2385-069b-1180-3e13-2f0b231da79f.png" alt="image.png"></p>
<p>MNIST has a clean distance between classes, but in the case of CIFAR10,
&ldquo;Dog&rdquo; and &ldquo;cat&rdquo;, &ldquo;deer&rdquo; and &ldquo;bird&rdquo; are close and similar things
I understand. In other words, these are relatively difficult to distinguish.</p>
<p>#Implementation
From the conclusion, MDS and W managed to get the result, but the important thing is
**CSG did not reproduce well. **</p>
<p>*The entire code was placed on <a href="https://github.com/shinmura0/Spectral_Metric_for_Dataset_Complexity_Assessment-Keras/blob/master/Spectral_Metric.ipynb">here</a>.</p>
<h2 id="mounting-conditions">Mounting conditions</h2>
<p>The purpose of the experiment is &ldquo;Watch CSG transition while reducing CIFAR10 data.&rdquo;
That is, Table 6 is reproduced.</p>
<p>The embedded auto encoder was tested under the following conditions.</p>
<ul>
<li>Auto encoder has 11 layers (9 layers in the paper)</li>
<li>Optimization method is Adam (default)</li>
<li>Batch size is 128</li>
<li>The epoch is basically 50, and the epoch is changed according to the data size (fixed at 100 in the paper)</li>
</ul>
<h2 id="embedding-method">Embedding method</h2>
<p>For the embedding method, the method with the highest score in the paper will be used.
The method is CSG $CNN_{AE}$ t-SNE.</p>
<p>This is calculated as follows:</p>
<ul>
<li>Train auto encoder (encoder + decoder) with learning data</li>
<li>Put test data in encoder and get output</li>
<li>Input output to t-sne and get embedded data</li>
<li>Calculate CSG with embedded data</li>
</ul>
<h2 id="stabilization-of-suffering">Stabilization of suffering</h2>
<p>The CSG produced in the experiment is not very stable. In the first place, the eigenvalues in the paper are
Since I have not reproduced it, I feel that somewhere in the implementation is wrong,
I didn&rsquo;t understand it.</p>
<p>The following measures are being taken to stabilize it somehow.</p>
<ul>
<li>
<p>Extraction of test data
In the paper, it is sufficient to extract 100 test data from each class.
It says. However, CSG varies considerably depending on what is included in these 100 pieces.
Therefore, extraction is performed **5 times, **CSG is calculated, and the average value is taken.</p>
</li>
<li>
<p>t-sne
The result of t-sne is different each time, so we execute it 5 times, calculate CSG, and take the average value.</p>
</li>
</ul>
<p>As a result of the above measures, CSG calculation was performed 5 x 5 = 25 times for each data size, and the average value was calculated.</p>
<h2 id="implementation-result">Implementation result</h2>
<p>I calculated CSG, but in some cases the correlation coefficient is about 0.9 and sometimes it becomes 0.
I can&rsquo;t trust it at all.</p>
<p>However, W and MDS have similar results to the paper, so I will report them.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/264781/e3b5de7c-62db-8a63-dcfb-1aec3db63b9d.png" alt="Download.png"></p>
<p>Although W has similar results, the similarity between &ldquo;dog&rdquo; and &ldquo;cat&rdquo; is similar to that in the paper.
It did not become a big value.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/264781/a00827e4-829f-74e1-704e-a10d972a0890.png" alt="Download (1).png"></p>
<p>The MDS results look similar to the paper.
Properly, &ldquo;cat&rdquo; and &ldquo;dog&rdquo;, &ldquo;deer&rdquo; and &ldquo;berd&rdquo; are near each other.</p>
<h2 id="execution-speed">Execution speed</h2>
<p>This time, I verified using GPU of Colaboratory.
As for the GPU, <code>Tesla P100</code> of <strong>No way</strong> came out, so when using <code>Tesla K80</code> in brackets,
I will also write the time to hang out.</p>
<ul>
<li>Auto encoder learning time: 3 minutes 30 seconds (30 minutes)</li>
<li>t-SNE learning time: 7 minutes (1 hour)</li>
</ul>
<p>The above time is the time when all the data of CIFAR10 is used.
As you can see, the execution speed is faster than learning the CNN and seeing the classification accuracy directly.
I understand.</p>
<p>#Summary</p>
<ul>
<li>By implementation, I found that it is faster to calculate <strong>CSG</strong> than to learn CNN and see the classification accuracy directly.
Although CSG could not be reproduced by the implementation, it is possible to grasp the tendency of the image data by applying the auto encoder +t-SNE.</li>
</ul>
<p>Applying the above findings ** Effectively reduces the amount of classified data and data cleansing **
It may work. I&rsquo;ll write more about them in the next article.</p>

    </article>
  </div>

  
  
  
  <script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-169005401-1', 'auto');
  ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  

  
<link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.css" />
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#216942",
      "text": "#b2d192"
    },
    "button": {
      "background": "#afed71"
    }
  }
})});
</script>

</body>

</html>
