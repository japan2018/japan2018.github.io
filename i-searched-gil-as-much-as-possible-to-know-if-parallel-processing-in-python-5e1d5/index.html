<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  <meta name="generator" content="Hugo 0.72.0" />

  
  <meta name="description" content="Some description">
  

  
  <link rel="apple-touch-icon" sizes="180x180" href="https://memotut.com/apple-touch-icon.png">

  
  <link rel="icon" type="image/png" sizes="32x32" href="https://memotut.com/favicon-32x32.png">

  
  <link rel="icon" type="image/png" sizes="16x16" href="https://memotut.com/favicon-16x16.png">

  
  <link rel="manifest" href="https://memotut.com/site.webmanifest">

  
  <link rel="mask-icon" href="https://memotut.com/safari-pinned-tab.svg" color="#5bbad5">

  <meta name="msapplication-TileColor" content="#da532c">

  <meta name="theme-color" content="#ffffff">

  
  <link rel="stylesheet" href="https://memotut.com/css/bootstrap.min.css" />

  
  <title>I searched GIL as much as possible to know if parallel processing in Python | Memo Tut</title>
  

  <style>
body {
  min-width: 300px;
}

.custom-navbar {
  margin-bottom: 1em;
  height: 60px;
}

.custom-navbar a {
  display: inline-block; 
  padding: 18px 0;
  margin-right: 1em; 
  font-weight: bold; 
}

.custom-navbar a:hover,
.custom-navbar a:focus {
  text-decoration: none; 
}

@media print {
  .custom-navbar {
    display: none;
  }
}

article {
  padding-bottom: 1em;
}

img {
  max-width: 100%;
}


body {
  background-color: #fff;
}



body {
  color: #212529;
}



a {
  color: #007bff;
}



a:hover,
a:focus {
  color: #0056b3;
}



.custom-navbar {
  background-color: #212529;
}



.custom-navbar a {
  color: rgba(255, 255, 255, 0.75);
}



.custom-navbar a:hover,
.custom-navbar a:focus {
  color: rgba(255, 255, 255, 1);
}



.container {
  max-width: 800px;
}



pre {
  display: block;
  padding: 9.5px;
  word-break: break-all;
  word-wrap: break-word;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre code {
  padding: 0;
  font-size: inherit;
  color: inherit; 
  white-space: pre-wrap;
  background-color: transparent;
  border: none;
  border-radius: 0;
}

code {
  padding: 2px 4px;
  color: inherit; 
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
  font-size: .9em;
}



blockquote,
.blockquote {
  padding: 10px 20px;
  margin: 0 0 20px;
  font-size: 1em;
  border-left: 5px solid #6c757d;
}

</style>
</head>

<body>
  <nav class="custom-navbar">
  <div class="container">
    
    <a href="/">Posts</a>
    
    <a href="/tags/">Tags</a>
    
    <a href="/about/">About</a>
    
    <a href="/index.xml">RSS</a>
    
  </div>
</nav>
  
  <div class="container">
    <article>
      <h1>I searched GIL as much as possible to know if parallel processing in Python</h1>
<p>
  <small class="text-secondary">
  
  
  Nov 11, 2019
  </small>
  

<small><code><a href="https://memotut.com/tags/python">Python</a></code></small>


<small><code><a href="https://memotut.com/tags/python3"> Python3</a></code></small>


<small><code><a href="https://memotut.com/tags/coroutine"> coroutine</a></code></small>


<small><code><a href="https://memotut.com/tags/thread"> thread</a></code></small>


<small><code><a href="https://memotut.com/tags/parallel-processing"> parallel processing</a></code></small>

</p>
<pre><code>Recently I had the opportunity to write an orchestration layer (BFF) application in Python.
</code></pre>
<p>Although asyncio was introduced from Python 3.4, I/O bound processing can be handled efficiently even with a single thread, but since GIL still exists for CPU bound processing, parallel processing is possible under a single process. It is limited.</p>
<p>From this, it can be seen as a language characteristic that it is more suitable for handling multiple I/O bound processes than CPU bound processes. It is an important factor when making a language selection decision, but I thought that it is necessary to know the mechanism of GIL again for that purpose, so I investigated it.</p>
<h2 id="what-is-gil-global-interpreter-lock">What is GIL (Global Interpreter Lock)</h2>
<p>What is GIL in the first place?</p>
<p>Officially called Global Interpreter Lock, it is an exclusive lock mechanism found in languages such as Python and Ruby. Looking at these two languages alone may seem characteristic of dynamically typed languages, but rather, they are more involved in cooperating with the C language.</p>
<h3 id="python-is-widely-used-cpython-implemented-in-c-language">Python is widely used CPython implemented in C language</h3>
<p>Before going into the GIL explanation, it would be wrong to explain that &ldquo;GIL exists in Python&rdquo;, so let&rsquo;s pick it up a little more carefully.</p>
<p>There are multiple implementations of the Python language in the first place. The most widely used is CPython, which is implemented in C and probably implies this CPython when describing the language characteristics of Python.</p>
<p>Other typical ones are Jython implemented in Java and IronPython which operates in .Net Framework, but GIL does not exist in these. Why is CPython used when I hear only that? As you might think, major libraries such as NumPy are often implemented in C language, and CPython is often used because of the frequency of updating the language implementation.</p>
<p>Based on these, GIL will be explained based on the CPython specifications.</p>
<h3 id="gil-exclusive-lock">GIL exclusive lock</h3>
<p>Now, let&rsquo;s get back to the subject of GIL, but roughly speaking, ** &ldquo;Under multiple threads, only a single thread that has a lock can execute bytecode, and other threads are in a waiting state&rdquo; ** That is. The lock is released at regular intervals, and another thread that newly acquires the lock executes the program.</p>
<p>The mechanism of the lock will be described later, but it should be recognized that CPU bound processing can be executed by only one thread and parallelization of processing is limited.</p>
<p>Now let&rsquo;s actually see the effect of GIL in code. First, run a simple program that counts large numbers.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python:countdown.py" data-lang="python:countdown.py"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">countdown</span>():
    n <span style="color:#f92672">=</span> <span style="color:#ae81ff">10000000</span>
    <span style="color:#66d9ef">while</span> n<span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0</span>:
        n <span style="color:#f92672">-=</span> <span style="color:#ae81ff">1</span>

<span style="color:#66d9ef">if</span> __name__ <span style="color:#f92672">==</span><span style="color:#e6db74">&#39;__main__&#39;</span>:
    start <span style="color:#f92672">=</span> datetime<span style="color:#f92672">.</span>now()

    t1 <span style="color:#f92672">=</span> Thread(target<span style="color:#f92672">=</span>countdown)
    t2 <span style="color:#f92672">=</span> Thread(target<span style="color:#f92672">=</span>countdown)
    t1<span style="color:#f92672">.</span>start()
    t2<span style="color:#f92672">.</span>start()
    t1<span style="color:#f92672">.</span>join()
    t2<span style="color:#f92672">.</span>join()

    end <span style="color:#f92672">=</span> datetime<span style="color:#f92672">.</span>now()
    <span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#34;Time: {end-start}&#34;</span>)
</code></pre></div><p>It is a program that counts down to 10 million with 2 threads, but the execution time was about 1.1 seconds in my environment. So what about running in one thread?</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">if</span> __name__ <span style="color:#f92672">==</span><span style="color:#e6db74">&#39;__main__&#39;</span>:
    start <span style="color:#f92672">=</span> datetime<span style="color:#f92672">.</span>now()
    countdown()
    end <span style="color:#f92672">=</span> datetime<span style="color:#f92672">.</span>now()
    <span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#34;Time: {end-start}&#34;</span>)
</code></pre></div><p>This finished in about 0.53 seconds. Approximately half that of two threads means that each thread is not running in parallel. CPU bound processing can be executed by only one thread.</p>
<p>But what about processing that is not CPU bound? Replace the countdown part with sleep and run it with 2 threads.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python:sleep.py" data-lang="python:sleep.py"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">sleep</span>():
    time<span style="color:#f92672">.</span>sleep(<span style="color:#ae81ff">2.0</span>)
</code></pre></div><p>At this time, the processing is completed in about 2 seconds. If it was CPU bound, it would take 4 seconds in 2 Ã— 2 seconds, but in sleep it will be half in 2 seconds. This is because the lock is released when the sleep is executed, and the waiting thread immediately enters the sleep state, which is effectively processed in parallel.</p>
<p>By the way, locks occur when executing Python bytecode, not necessarily when using the CPU.</p>
<h2 id="why-gil-exists">Why GIL exists</h2>
<p>So why does GIL exist that constrains parallel processing in the first place? This is not the solution I derived by reading the CPython code myself, but the following seem to be the main factors.</p>
<ul>
<li>To simplify low-level mechanisms such as memory management and C cooperation.</li>
<li>CPython is easy to work with libraries implemented in C, but they are usually not thread safe.</li>
</ul>
<p>For the above reason, in order to execute CPython, only one thread needs to be able to operate the byte code, and there is a mechanism called GIL to realize that.</p>
<p>However, this is not a property of the Python language itself, but an attribute of CPython implemented in C. For example, Jython implemented in Java does not have GIL because thread management by the JVM does not cause contention even under multithreading.</p>
<p>It is considered that CPython is widely used, probably because it is judged that the advantage of being able to utilize C language assets and active updates is greater than the advantage of avoiding GIL.</p>
<h2 id="gil-release-and-acquisition">GIL release and acquisition</h2>
<p>(The explanation of this item is based on <a href="http://www.dabeaz.com/python/UnderstandingGIL.pdf">Understanding the Python GIL</a>)</p>
<p>CPython&rsquo;s GIL mechanism was changed in version 3.2, and the starting point was the lock release request called <code>gil_drop_request</code>.</p>
<p>For example, if there is only one thread, execution continues until a single thread finishes processing. This is because the unlock request has not arrived from anywhere.</p>
<p>On the other hand, it is different when there are multiple threads. Suspended threads wait 5ms by default, then set <code>gil_drop_request</code> to &lsquo;1&rsquo;. The running thread then releases the lock and emits a signal to that effect.</p>
<p>![Screenshot 2019-11-09 11.04.04.jpg](<a href="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/17370/18b4a199-563e-c2d2-79a5-(2654d2cca166.jpeg)">https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/17370/18b4a199-563e-c2d2-79a5-(2654d2cca166.jpeg)</a></p>
<p>When the thread waiting for the lock receives the signal, it acquires the lock, but at that time it emits a signal indicating that the lock has been acquired. When the thread that released the lock receives the signal, it enters the suspended state.</p>
<p><img src="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/17370/3cc0d16d-6f18-4c8a-d4de-a81f80450a7f.jpeg" alt="Screenshot 2019-11-09 11.04.33.jpg">
(*All images are taken from <a href="http://www.dabeaz.com/python/UnderstandingGIL.pdf">Understanding the Python GIL</a>)</p>
<p>After the timeout, as before, multiple threads will repeatedly acquire and release the lock by the process of setting the <code>gil_drop_request</code> and trying to acquire the lock again.</p>
<h3 id="you-can-change-the-timeout-time">You can change the timeout time</h3>
<p>A thread waiting for a lock will wait 5ms by default, but this can be seen from the Python code <code>sys.getcheckinterval()</code>.
You can also change the interval time with <code>sys.setcheckinterval(time)</code>.</p>
<h3 id="why-did-you-send-a-lock-release-request">Why did you send a lock release request?</h3>
<p>From Python 3.2, the lock is released by <code>gil_drop_request</code>, but before that, the lock was released for each execution unit called tick.</p>
<p>By the way, this can be referred by <code>sys.getcheckinterval()</code>, but since it is no longer used due to the change of the lock method, the following warning message is displayed.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#a6e22e">DeprecationWarning</span>: sys<span style="color:#f92672">.</span>getcheckinterval() <span style="color:#f92672">and</span> sys<span style="color:#f92672">.</span>setcheckinterval() are deprecated<span style="color:#f92672">.</span>Use sys<span style="color:#f92672">.</span>getswitchinterval() instead<span style="color:#f92672">.</span>
</code></pre></div><p>So why did the lock release method change?</p>
<p>As I mentioned earlier, currently waiting threads send lock release requests, but in the past the running threads released locks by default after 100 tick execution units. But this has some problems under multi-core conditions.</p>
<p>First, let&rsquo;s look at the single core case. When a running thread releases a lock, it sends a signal to notify one of the waiting threads. The thread that received the signal is queued for execution, but the OS scheduler selects whether the thread that has just released the lock or the thread that received the signal will be executed next based on the priority. To do.</p>
<p>(The same thread may continue to acquire locks, but sometimes it is desirable given the overhead of context switching.)</p>
<p>However, in the case of multi-core, both for executable thread there is more than one also trying to acquire the lock, one will fail to acquire the lock. Trying to grab the lock unnecessarily adds overhead, and the annoyance is that the waiting thread can barely grab the lock.</p>
<p>Waiting threads have a time lag before resuming, so when you try to acquire a lock, the thread that you just released has already acquired the lock. It seems that one thread may continue to hold the lock for more than tens of minutes for long processing.</p>
<p>In the case of frequent I/O processing that ends immediately because the OS is buffering, there is also a demerit that the load increases because locks are released and acquired one after another each time I wait for I/O. ..</p>
<p>Given the above issues, the current method by which waiting threads send requests is superior.</p>
<h2 id="disadvantages-of-current-gilthen-if-there-is-a-problem-with-the-current-gil-that-is-not-the-case-two-disadvantages-are-introduced-in-the-document-understanding-the-python-gilhttpwwwdabeazcompythonunderstandinggilpdf">Disadvantages of current GILThen, if there is a problem with the current GIL, that is not the case. Two disadvantages are introduced in the document <a href="http://www.dabeaz.com/python/UnderstandingGIL.pdf">Understanding the Python GIL</a>.</h2>
<h3 id="1-unfair-lock-acquisition-can-happen">1. Unfair lock acquisition can happen</h3>
<p>First, if there are three or more threads, the thread requesting the lock release may not be able to acquire the lock, and the delayed thread may be taken.</p>
<p>![Screenshot 2019-11-09 12.23.39.jpg](<a href="https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/17370/643a29ba-2fc1-c498-7a87-(479a891d529d.jpeg)">https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/17370/643a29ba-2fc1-c498-7a87-(479a891d529d.jpeg)</a>
(*Quoted from <a href="http://www.dabeaz.com/python/UnderstandingGIL.pdf">Understanding the Python GIL</a>)</p>
<p>In the image above, thread 2 requests a lock release after a timeout, and thread 1 sends a signal with the lock released. Originally, thread 2 should acquire the lock, but during that time, thread 3 gets queued later, so the lock is acquired preferentially.</p>
<p>In this way, depending on the timing, lock acquisition may be biased to a specific thread, and parallel processing may become inefficient.</p>
<h3 id="2-convoy-effect-may-cause-inefficiency">2. Convoy Effect may cause inefficiency</h3>
<p>Also, if a CPU bound thread and an I/O bound thread are running at the same time, an inefficient state called Convoy Effect may occur.</p>
<p>From the point of view of the entire processing, I/O bound threads are given priority to have locks, and when waiting for I/O, they are moved to CPU bound threads, and when I/O ends, they are given priority to lock again It is efficient to let On the other hand, if only CPU-bound threads have locks, I/O bound processing will remain, and it will be easy to understand considering that the execution time is prolonged by the waiting time for I/O.</p>
<p>However, threads do not have a priority, so you cannot control which thread gets the lock preferentially. If two threads are waiting, the CPU bound thread may acquire the lock first.</p>
<p>You also have to wait until the timeout, even if the I/O ends immediately. If a large number of I/O waits occur, CPU-bound processing may end while waiting for successive timeouts, and I/O waits may remain.</p>
<p>This is called &ldquo;Convoy Effect&rdquo;, but since it requires lock release only after a timeout, there may be cases where it becomes inefficient from the perspective of overall optimization.</p>
<h2 id="perform-parallel-processing-in-multiple-processes">Perform parallel processing in multiple processes</h2>
<p>As many people know, it is possible to execute CPU bound processing in parallel by using multiple processes. This is because each process has an interpreter, and GIL exists in each interpreter.</p>
<p>Let&rsquo;s execute the part that was processed by multi-threading as a trial in a multi-process.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python:countdown.py" data-lang="python:countdown.py"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">countdown</span>():
    n <span style="color:#f92672">=</span> <span style="color:#ae81ff">10000000</span>
    <span style="color:#66d9ef">while</span> n<span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0</span>:
        n <span style="color:#f92672">-=</span> <span style="color:#ae81ff">1</span>

<span style="color:#66d9ef">if</span> __name__ <span style="color:#f92672">==</span><span style="color:#e6db74">&#39;__main__&#39;</span>:
    start <span style="color:#f92672">=</span> datetime<span style="color:#f92672">.</span>now()

    t1 <span style="color:#f92672">=</span> Process(target<span style="color:#f92672">=</span>countdown)
    t2 <span style="color:#f92672">=</span> Process(target<span style="color:#f92672">=</span>countdown)
    t1<span style="color:#f92672">.</span>start()
    t2<span style="color:#f92672">.</span>start()
    t1<span style="color:#f92672">.</span>join()
    t2<span style="color:#f92672">.</span>join()

    end <span style="color:#f92672">=</span> datetime<span style="color:#f92672">.</span>now()
    <span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#34;Time: {end-start}&#34;</span>)
</code></pre></div><p>It took about 1.1 seconds under multi-process, but about 0.65 seconds under multi-process. You can see that even CPU bound can be executed in parallel.</p>
<p>Although it has a higher overhead than threads, it can share values between processes and is useful when performing CPU-bound processing in parallel.</p>
<h3 id="subinterpreter-introduced-in-python-38">Subinterpreter introduced in Python 3.8</h3>
<p>At the time of this writing, the sub-interpreter was provisionally implemented in Python 3.8, which was just released. A sub-interpreter is proposed in <a href="https://www.python.org/dev/peps/pep-0554/">PEP 554</a> but has not been merged yet.</p>
<p>As mentioned earlier, GIL exists for each interpreter, but a sub-interpreter can hold multiple interpreters in the same process.</p>
<p>It&rsquo;s an idea with potential in the future, but since CPython has state in Runtime, it seems that it still has a lot of problems keeping state in the interpreter.</p>
<p>You can use it by actually raising it to Python 3.8 and importing <code>_xxsubinterpreters</code>, but it may still be difficult to use at the production level.</p>
<h2 id="utilizing-the-event-loop-by-asyncio">Utilizing the event loop by asyncio</h2>
<p>Although it is a methodological story outside the main explanation of GIL, it may be more practical to utilize the event loop by <code>asyncio</code> in the case where multiple I/O waits occur in current Python.</p>
<p>By using I/O multiplexing, <code>asyncio</code> can efficiently handle multiple I/O operations with a single thread, and is close to the benefits obtained by multithreading.</p>
<p>In addition to saving memory compared to multithreading, it is not necessary to consider lock acquisition/release of multiple threads, and the native coroutine by async/await can be written intuitively, which will reduce the burden of thinking on the programmer.</p>
<p>We will introduce Python coroutines in detail in a separate article.</p>
<h2 id="finally">Finally</h2>
<p>Although the story has spread in the latter half, this article has comprehensively described topics related to GIL.</p>
<p>It may not be the point to be aware of every day when writing application level code, but I think that it will be useful for language selection by knowing what kind of restrictions exist when performing parallel processing It was.</p>
<h3 id="reference-materials">Reference materials</h3>
<ul>
<li><a href="https://callhub.io/understanding-python-gil/">Understanding Python GIL</a></li>
<li><a href="https://softwareengineering.stackexchange.com/questions/186889/why-was-python-written-with-the-gil">Why Was Python Written with the GIL?</a></li>
<li><a href="http://www.dabeaz.com/python/UnderstandingGIL.pdf">Understanding the Python GIL</a></li>
<li><a href="https://medium.com/hackernoon/has-the-python-gil-been-slain-9440d28fa93d">Has the Python GIL been slain?</a></li>
</ul>

    </article>
  </div>

  
  
  
  <script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-169005401-1', 'auto');
  ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  

  
<link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.css" />
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#216942",
      "text": "#b2d192"
    },
    "button": {
      "background": "#afed71"
    }
  }
})});
</script>

</body>

</html>
