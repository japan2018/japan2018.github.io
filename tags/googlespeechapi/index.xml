<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title> GoogleSpeechAPI on Memo Tut</title>
    <link>https://memotut.com/tags/googlespeechapi/</link>
    <description>Recent content in  GoogleSpeechAPI on Memo Tut</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 11 Jan 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://memotut.com/tags/googlespeechapi/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>[Python] Google Cloud Speech API vs. Amazon Transcribe</title>
      <link>https://memotut.com/google-cloud-speech-api-vs.-amazon-transcribe-03729/</link>
      <pubDate>Sat, 11 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/google-cloud-speech-api-vs.-amazon-transcribe-03729/</guid>
      <description>## Transcription API Gachinko Battle  In the range of &amp;ldquo;Transcription API comparison&amp;rdquo; that is easy to see in Gugu, there are many articles that say good/bad by performing very short transcription at the level of several lines (or minutes). Or, there are many things we do for &amp;ldquo;too clear sound sources&amp;rdquo; such as news videos. The Blog that buzzed about Amazon Transcribe also tells highly accurate transcriptions in English. It is well known that English is highly accurate in the field of natural language processing, but I am worried about how it is Japanese.</description>
    </item>
    
    <item>
      <title>[Python] Investigation of relationship between voice preprocessing and transcription accuracy in Google Cloud Speech API</title>
      <link>https://memotut.com/investigation-of-relationship-between-voice-preprocessing-and-transcription-accuracy-in-google-cloud-speech-api-cfbfa/</link>
      <pubDate>Thu, 02 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/investigation-of-relationship-between-voice-preprocessing-and-transcription-accuracy-in-google-cloud-speech-api-cfbfa/</guid>
      <description>## Transcription accuracy is lower than expected  As I mentioned at the end of the previous article that summarized How to use Google Speech API, I encountered a problem that the character recognition accuracy is lower than I expected. It was.
It seems that about 80% can be transcribed in rebuild.fm, but in my case not even half recognized by experience It&amp;rsquo;s an impression. Even though it wasn&amp;rsquo;t perfect, I was hoping that reading the transcribed text would give me a sense of what the conversation was about, but it was pretty devastating.</description>
    </item>
    
    <item>
      <title>[Python] Speech transcription procedure using Python and Google Cloud Speech API</title>
      <link>https://memotut.com/speech-transcription-procedure-using-python-and-google-cloud-speech-api-bc22e/</link>
      <pubDate>Sun, 15 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/speech-transcription-procedure-using-python-and-google-cloud-speech-api-bc22e/</guid>
      <description>![Screenshot 2019-12-15 16.20.07.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/100780/160e795f-1baf-4446-2331-(eb4d0e37dbeb.png)  I have a podcast called Platinum Mining Industry.FM, so I tried Google Cloud Speech API this time to transcribe the voice data. (*Google&amp;rsquo;s transcription API is officially shaking with the names &amp;ldquo;Google Cloud Speech API&amp;rdquo; and &amp;ldquo;Cloud Speech-to-Text. Maybe they are together. Mystery.&amp;quot;)
Please refer to here for the procedure to create recording and audio data.
 [Fiscal 2019 version] Introduction to Podcast distribution for those who aim for the minimum beautiful sound quality with the minimum effort-Qiita  The following blogs are the most detailed on how to use the Google Cloud Speech API.</description>
    </item>
    
  </channel>
</rss>