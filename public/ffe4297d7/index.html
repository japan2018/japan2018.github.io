<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  <meta name="generator" content="Hugo 0.72.0" />

  
  <meta name="description" content="Some description">
  

  
  <link rel="apple-touch-icon" sizes="180x180" href="https://memotut.com/apple-touch-icon.png">

  
  <link rel="icon" type="image/png" sizes="32x32" href="https://memotut.com/favicon-32x32.png">

  
  <link rel="icon" type="image/png" sizes="16x16" href="https://memotut.com/favicon-16x16.png">

  
  <link rel="manifest" href="https://memotut.com/site.webmanifest">

  
  <link rel="mask-icon" href="https://memotut.com/safari-pinned-tab.svg" color="#5bbad5">

  <meta name="msapplication-TileColor" content="#da532c">

  <meta name="theme-color" content="#ffffff">

  
  <link rel="stylesheet" href="https://memotut.com/css/bootstrap.min.css" />

  
  <title>[Python] [Learning Memo] Deep Learning [Chapter 4] | Memo Tut</title>
  

  <style>
body {
  min-width: 300px;
}

.custom-navbar {
  margin-bottom: 1em;
  height: 60px;
}

.custom-navbar a {
  display: inline-block; 
  padding: 18px 0;
  margin-right: 1em; 
  font-weight: bold; 
}

.custom-navbar a:hover,
.custom-navbar a:focus {
  text-decoration: none; 
}

@media print {
  .custom-navbar {
    display: none;
  }
}

article {
  padding-bottom: 1em;
}

img {
  max-width: 100%;
}


body {
  background-color: #fff;
}



body {
  color: #212529;
}



a {
  color: #007bff;
}



a:hover,
a:focus {
  color: #0056b3;
}



.custom-navbar {
  background-color: #212529;
}



.custom-navbar a {
  color: rgba(255, 255, 255, 0.75);
}



.custom-navbar a:hover,
.custom-navbar a:focus {
  color: rgba(255, 255, 255, 1);
}



.container {
  max-width: 800px;
}



pre {
  display: block;
  padding: 9.5px;
  word-break: break-all;
  word-wrap: break-word;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre code {
  padding: 0;
  font-size: inherit;
  color: inherit; 
  white-space: pre-wrap;
  background-color: transparent;
  border: none;
  border-radius: 0;
}

code {
  padding: 2px 4px;
  color: inherit; 
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
  font-size: .9em;
}



blockquote,
.blockquote {
  padding: 10px 20px;
  margin: 0 0 20px;
  font-size: 1em;
  border-left: 5px solid #6c757d;
}

</style>
</head>

<body>
  <nav class="custom-navbar">
  <div class="container">
    
    <a href="/">Posts</a>
    
    <a href="/tags/">Tags</a>
    
    <a href="/about/">About</a>
    
    <a href="/index.xml">RSS</a>
    
  </div>
</nav>
  
  <div class="container">
    <article>
      <h1>[Python] [Learning Memo] Deep Learning [Chapter 4]</h1>
<p>
  <small class="text-secondary">
  
  
  Aug 16, 2017
  </small>
  

<small><code><a href="https://memotut.com/tags/python">Python</a></code></small>

</p>
<pre><code># Learning memo Deep learning made from scratch
</code></pre>
<p><a href="https://www.amazon.co.jp/dp/4873117585/">https://www.amazon.co.jp/dp/4873117585/</a></p>
<h2 id="function-notes-that-you-might-use">Function notes that you might use</h2>
<h3 id="sigmoid-function-sigmoid">Sigmoid function: sigmoid</h3>
<p>Key properties: Returns between 0 and 1, smooth, monotonically increasing (not mentioned in the book)</p>
<pre><code class="language-math:" data-lang="math:">h(x) = \frac{1}{1+\exp(-x)}
</code></pre><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">sigmoid</span>(x):
    <span style="color:#66d9ef">return</span> <span style="color:#ae81ff">1</span><span style="color:#f92672">/</span>(<span style="color:#ae81ff">1</span><span style="color:#f92672">+</span>np<span style="color:#f92672">.</span>exp(<span style="color:#f92672">-</span>x))
</code></pre></div><p><img src="https://qiita-image-store.s3.amazonaws.com/0/197508/7efe876e-c63d-fb00-ae7f-03aaba7fbc57.png" alt="sigmoid.png"></p>
<h3 id="softmax-function">Softmax function</h3>
<p>After all, it is common to omit the softmax function of the output layer because the maximum value is searched for whether or not it is adapted.</p>
<pre><code class="language-math:" data-lang="math:">y_k = \frac{\exp(a_k)}{\sum_{i=1}^{n}\exp(a_i)} = \frac{\exp(a_k + C')}{\sum_{i=1} ^{n}\exp(a_i + C')}
</code></pre><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">softmax</span>(a):
    c <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>max(a)
    exp_a <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>exp(a<span style="color:#f92672">-</span>c)
    sum_exp_a <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>sum(exp_a)
    y <span style="color:#f92672">=</span> exp_a <span style="color:#f92672">/</span> sum_exp_a
    <span style="color:#66d9ef">return</span> y
</code></pre></div><h2 id="loss-function">Loss function</h2>
<p>Reasons for setting a loss function
When indexing the recognition accuracy, the parameter differentiation becomes 0 (it stops working) in most places</p>
<p>###2 Mean squared error</p>
<pre><code class="language-math" data-lang="math">E = \frac{1}{2}\sum_{k=1} (y_k-t_k)^2
</code></pre><pre><code class="language-python:" data-lang="python:">def mean_squared_error(y,t):
    return 0.5 * np.sum((y-t)**2)
</code></pre><h3 id="cross-entropy-error">cross entropy error</h3>
<p>Point: one-hot expression 1 for correct answer label, 0 for others (label is t)</p>
<pre><code class="language-math" data-lang="math">E=\sum_{k=1}-t_k \log y_k
</code></pre><pre><code class="language-python:" data-lang="python:">def cross_entropy_error(y, t):
    delta = le-7
    return -np.sum(t*np.log(y+delta))
</code></pre><h3 id="mini-batch-compatible-version-cross-entropy-error">Mini batch compatible version: cross entropy error</h3>
<p>Mini-batch (small lump): Select a part of the data and use that part of the data as an &ldquo;approximation&rdquo; of the whole
Point: In one-hot, the label of incorrect answer is 0 (= error is 0) and can be ignored.
Divide by N so that a unified index can be obtained regardless of the number of training data</p>
<pre><code class="language-math" data-lang="math">E=-\frac{1}{N}\sum_{n}\sum_{k=1} t_{nk} \log y_{nk}
</code></pre><pre><code class="language-python:" data-lang="python:">def cross_entropy_error(y, t):
    if y.ndim == 1:
        t = t.reshape(1, t.size)
        y = y.reshape(1, y.size)
        
    batch_size = y.shape[0]
    return -np.sum(t*np.log(y[np.arange(bathch_size), t])) / bathc_size
</code></pre><p>##differential</p>
<h3 id="numerical-differentiation">Numerical differentiation</h3>
<p>Point: Use about 1e-4 to avoid rounding error</p>
<pre><code class="language-python:" data-lang="python:">def numerical_diff(f, x):
    h = 1e-4
    return (f(x+h)-f(x-h))/(2*h)
</code></pre><h3 id="partial-derivative">partial derivative</h3>
<pre><code class="language-python:" data-lang="python:"># when x1=4

def function_tmp1(x0):
    return x0*x0 + 4.0*2.0

numerical_diff(function_tmp1, 3.0)
</code></pre><p>###Slope
Gradient: A collection of partial derivatives of all variables as a vector</p>
<pre><code class="language-python:" data-lang="python:">def numerical_gradient(f, x):
    h = 1e-4 # 0.0001
    grad = np.zeros_like(x) Generate an array of the same shape as #x and fill the values here

    #The point is to just differentiate the variables one by one
    for idx in range(x.size):
        tmp_val = x[idx]
        x[idx] = float(tmp_val) + h
        fxh1 = f(x) # f(x+h)
        
        x[idx] = tmp_val-h
        fxh2 = f(x) # f(x-h)
        grad[idx] = (fxh1-fxh2) / (2*h)
        
        x[idx] = tmp_val # undo value
        
    return grad
</code></pre><h3 id="gradient-method">gradient method</h3>
<p>Gradient method: Repeatedly move in the gradient direction and gradually decrease the value of the function
Point: The gradient method reaches the minimum value, not the minimum value
The image is easy to understand by Professor Andrew Ng of Coursera, Machine Learning Week5, Lecture9 p.31.</p>
<pre><code class="language-math" data-lang="math">x_0=x_0-\eta\frac{\partial f}{\partial x_0} \\
x_1=x_1-\eta\frac{\partial f}{\partial x_1} \\
\\
\eta: Learning rate (how much you learn in one learning, neither too big nor too small)
</code></pre><pre><code class="language-python:" data-lang="python:">def gradient_descent(f, init_x, lr=0.01, step_num=100):
    x = init_x
    
    for i in range(step_num):
        grad = numerical_gradient(f, x)
        x -= lr * grad
        
    return x

def function_2(x):
    return x[0]**2 + x[1]**2

init_x = np.array([-3.0, 4.0])
gradient_descent(function_2, init_x=init_x, lr=0.1, step_num=100)
</code></pre><p>A parameter that is manually set like the learning rate as described above is called a hyper parameter.</p>
<h3 id="gradient-for-neural-network">gradient for neural network</h3>
<pre><code class="language-math" data-lang="math">W = \biggl(\begin{matrix}
w_{11} &amp; w_{21} &amp; w_{31} \\
w_{12} &amp; w_{22} &amp; w_{32}
\end{matrix}\biggr)\\


\frac{\partial L}{\partial W} = \Biggl(\begin{matrix}
\frac{\partial L}{\partial w_{11}} &amp; \frac{\partial L}{\partial w_{21}} &amp; \frac{\partial L}{\partial w_{31}}\\
\frac{\partial L}{\partial w_{12}} &amp; \frac{\partial L}{\partial w_{22}} &amp; \frac{\partial L}{\partial w_{32}}
\end{matrix}\Biggr)\\

\frac{\partial L}{\partial w_{11}}: Shows how much the loss function L changes when w_{11} is slightly changed
</code></pre><pre><code class="language-python:" data-lang="python:"># coding: utf-8
import sys, os
sys.path.append(os.pardir) # Settings for importing files in the parent directory
import numpy as np
from common.functions import softmax, cross_entropy_error
from common.gradient import numerical_gradient


class simpleNet:
    def __init__(self):
        self.W = np.random.randn(2,3)

    def predict(self, x):
        return np.dot(x, self.W)

    def loss(self, x, t):
        z = self.predict(x)
        y = softmax(z)
        loss = cross_entropy_error(y, t)

        return loss
</code></pre><pre><code class="language-python:" data-lang="python:"># Try
# Parameter
x = np.array([0.6, 0.9])
#Label
t = np.array([0, 0, 1])

net = simpleNet()

f = lambda w: net.loss(x, t)
# In short, we are running the gradient method to search for the minimum loss function
dW = numerical_gradient(f, net.W)

print(dW)
</code></pre><p>[[ 0.10181684 0.35488728 -0.45670412]
[0.15272526 0.53233092 -0.68505618]]
The above result shows that increasing w_11 by h increases by 0.10181684.
W_23 is the largest contribution</p>
<pre><code class="language-python:" data-lang="python:"># Lambda expression
myfunc = lambda x: x ** 2

myfunc(5) #25
myfunc(6) # 36

#This is the same as below
def myfunc(x):
    return x ** 2
</code></pre><h2 id="implementation-of-learning-algorithm">Implementation of learning algorithm</h2>
<h3 id="overview-of-learning">Overview of learning</h3>
<p>Learning Neural Networks: Adjusting Weights and Bias to Adapt to Training Data</p>
<p>###procedure
<b>Step 1: Mini batch</b>
Select some data randomly from the training data. (Mini batch)
The purpose is to reduce the value of the loss function of this mini-batch</p>
<p><b>Step 2: Gradient calculation</b>
Calculate the gradient of each weighting parameter to reduce the loss function of mini-batch.
▽Slope shows the direction to reduce the value of the loss function most</p>
<p><b>Step 3: Update parameters</b>
▽ Update the weight parameter in the gradient direction by a very small amount.</p>
<p><b>Step 4: Repeat</b>
Repeat steps 1 to 3</p>
<p>###the term
Stochastic gradient descent:
Probabilistic: &ldquo;Probabilistically selected at random&rdquo;
Gradient descent*: &ldquo;Find minimum value&rdquo;</p>
<p>*There is also a gradient ascent method, and if you reverse the sign, it is essentially the same problem because it is the same problem.</p>
<p>Epoch: epoch1 epoch corresponds to the number of times all training data has been used up during learning
Example: Training data with 10,000 data, 100 stochastic gradient descent for 100 mini-batches</p>
<h3 id="implementation-and-explanation">Implementation and explanation</h3>
<pre><code class="language-python:" data-lang="python:"># coding: utf-8
import sys, os
sys.path.append(os.pardir) # Settings for importing files in the parent directory
from common.functions import *
from common.gradient import numerical_gradient


class TwoLayerNet:

    # Initialization
    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):
        # Weight initialization
        self.params = {}
        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)
        self.params['b1'] = np.zeros(hidden_size)
        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)
        self.params['b2'] = np.zeros(output_size)

    # Perform recognition (reasoning). The argument x is image data
    def predict(self, x):
        W1, W2 = self.params['W1'], self.params['W2']
        b1, b2 = self.params['b1'], self.params['b2']
    
        a1 = np.dot(x, W1) + b1
        z1 = sigmoid(a1)
        a2 = np.dot(z1, W2) + b2
        y = softmax(a2)
        
        return y

    # Find the loss function
    # x: input data, t: teacher data
    def loss(self, x, t):
        y = self.predict(x)
        
        return cross_entropy_error(y, t)
    
    # Seeking recognition accuracy
    def accuracy(self, x, t):
        y = self.predict(x)
        y = np.argmax(y, axis=1)
        t = np.argmax(t, axis=1)
        
        accuracy = np.sum(y == t) / float(x.shape[0])
        return accuracy
        
    # Find the gradient for the weight parameter
    # x: input data, t: teacher data
    def numerical_gradient(self, x, t):
        loss_W = lambda W: self.loss(x, t)
        
        grads = {}
        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])
        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])
        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])
        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])
        
        return grads

</code></pre><p>Illustrations that are difficult to understand
I&rsquo;m just doing matrix calculations at once in this picture-like calculation
The picture is easier to understand by Mr. Andrew Ng of Coursera, Machine Learning Week5, Lecture9 p.13.
<img src="https://qiita-image-store.s3.amazonaws.com/0/197508/a4b73a84-fc00-254e-e2b1-992c8cf9f371.png" alt="memo.png"></p>
<h3 id="mini-batch-learning-evaluation-with-test-data">Mini-batch learning, evaluation with test data</h3>
<p>Omitted because it only increases the accuracy by repeating the gradient method
Omitted because the accuracy of the test data is only shown in an attempt to determine whether the evaluation with test data is overlearning</p>

    </article>
  </div>

  
  
  
  <script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-169005401-1', 'auto');
  ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  

  
<link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.css" />
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#216942",
      "text": "#b2d192"
    },
    "button": {
      "background": "#afed71"
    }
  }
})});
</script>

</body>

</html>
