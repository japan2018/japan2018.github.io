<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  <meta name="generator" content="Hugo 0.72.0" />

  
  <meta name="description" content="Some description">
  

  
  <link rel="apple-touch-icon" sizes="180x180" href="https://memotut.com/apple-touch-icon.png">

  
  <link rel="icon" type="image/png" sizes="32x32" href="https://memotut.com/favicon-32x32.png">

  
  <link rel="icon" type="image/png" sizes="16x16" href="https://memotut.com/favicon-16x16.png">

  
  <link rel="manifest" href="https://memotut.com/site.webmanifest">

  
  <link rel="mask-icon" href="https://memotut.com/safari-pinned-tab.svg" color="#5bbad5">

  <meta name="msapplication-TileColor" content="#da532c">

  <meta name="theme-color" content="#ffffff">

  
  <link rel="stylesheet" href="https://memotut.com/css/bootstrap.min.css" />

  
  <title>10 Open Source Web Crawlers for 2020 | Memo Tut</title>
  

  <style>
body {
  min-width: 300px;
}

.custom-navbar {
  margin-bottom: 1em;
  height: 60px;
}

.custom-navbar a {
  display: inline-block; 
  padding: 18px 0;
  margin-right: 1em; 
  font-weight: bold; 
}

.custom-navbar a:hover,
.custom-navbar a:focus {
  text-decoration: none; 
}

@media print {
  .custom-navbar {
    display: none;
  }
}

article {
  padding-bottom: 1em;
}

img {
  max-width: 100%;
}


body {
  background-color: #fff;
}



body {
  color: #212529;
}



a {
  color: #007bff;
}



a:hover,
a:focus {
  color: #0056b3;
}



.custom-navbar {
  background-color: #212529;
}



.custom-navbar a {
  color: rgba(255, 255, 255, 0.75);
}



.custom-navbar a:hover,
.custom-navbar a:focus {
  color: rgba(255, 255, 255, 1);
}



.container {
  max-width: 800px;
}



pre {
  display: block;
  padding: 9.5px;
  word-break: break-all;
  word-wrap: break-word;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre code {
  padding: 0;
  font-size: inherit;
  color: inherit; 
  white-space: pre-wrap;
  background-color: transparent;
  border: none;
  border-radius: 0;
}

code {
  padding: 2px 4px;
  color: inherit; 
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 4px;
  font-size: .9em;
}



blockquote,
.blockquote {
  padding: 10px 20px;
  margin: 0 0 20px;
  font-size: 1em;
  border-left: 5px solid #6c757d;
}

</style>
</head>

<body>
  <nav class="custom-navbar">
  <div class="container">
    
    <a href="/">Posts</a>
    
    <a href="/tags/">Tags</a>
    
    <a href="/about/">About</a>
    
    <a href="/index.xml">RSS</a>
    
  </div>
</nav>
  
  <div class="container">
    <article>
      <h1>10 Open Source Web Crawlers for 2020</h1>
<p>
  <small class="text-secondary">
  
  
  Feb 11, 2020
  </small>
  

<small><code><a href="https://memotut.com/tags/java">Java</a></code></small>


<small><code><a href="https://memotut.com/tags/python"> Python</a></code></small>


<small><code><a href="https://memotut.com/tags/javascript"> JavaScript</a></code></small>


<small><code><a href="https://memotut.com/tags/framework"> framework</a></code></small>


<small><code><a href="https://memotut.com/tags/open-source"> open source</a></code></small>

</p>
<pre><code>[Web crawler](https://www.octoparse.jp/blog/what-is-web-crawler/) is a database that automatically collects information such as texts, images and videos published on the Internet. It is a program stored in. Various web crawlers play an important role in the big data boom, making it easy for people to scrape data.
</code></pre>
<p>Among the various web crawlers, there are many open source web crawler frameworks. Open source web crawlers allow users to program based on source code or frameworks, also provide resources to assist with scraping, and simplify data extraction. In this article, we will introduce you to 10 recommended open source web crawlers.</p>
<p>#1. Scrapy</p>
<p><strong>Language: Python</strong></p>
<p>Scrapy is Python&rsquo;s most popular open source web crawler framework. It helps you to efficiently extract data from your website, process it as needed, and save it in your preferred format (JSON, XML, CSV). Built on the twisted asynchronous network framework, it can accept requests and process them faster. You can create Scrapy projects to make large scale crawling and scraping efficient and flexible.</p>
<p><strong>Characteristic:</strong></p>
<ul>
<li>Fast and powerful</li>
<li><a href="http://doc.scrapy.org/en/latest/">Detailed document</a></li>
<li>Add new features without touching the core</li>
<li>Has a community and a wealth of resources</li>
<li>Can run in cloud environment</li>
</ul>
<p>#2. Heritrix</p>
<p><strong>Language: JAVA</strong></p>
<p><a href="https://webarchive.jira.com/wiki/spaces/Heritrix/overview">Heritrix</a> is a highly extensible, Java-based open source web crawler designed for web archives. It respects robot.txt exclusion directives and meta-robot tags very much and collects data at a measured and adaptive pace that does not disrupt normal website activity. Provides a web-based user interface accessible by a web browser for operator control and monitoring of crawling.</p>
<p><strong>Characteristic:</strong></p>
<ul>
<li>Replaceable pluggable module</li>
<li>Web-based interface</li>
<li>Respect robot.txt and meta robot tags</li>
<li>Excellent expandability</li>
</ul>
<p>#3. Web-Harvest</p>
<p><strong>Language: JAVA</strong></p>
<p><a href="http://web-harvest.sourceforge.net/">Web-Harvest</a> is an open source web crawler written in Java. You can collect data from specified pages. To that end, we mainly utilize technologies and techniques such as XSLT, XQuery, regular expressions to manipulate or filter the content of HTML/XML based websites. You can easily supplement it by customizing the Java library to enhance the extraction capabilities.</p>
<p><strong>Characteristic:</strong></p>
<ul>
<li>Powerful text and XML manipulation processor for data processing and control flow</li>
<li>Variable context for storing and using variables</li>
<li>Supports actual scripting language and can be easily integrated into web crawlers</li>
</ul>
<p>#4. MechanicalSoup</p>
<p><strong>Language: Python</strong></p>
<p><a href="https://mechanicalsoup.readthedocs.io/en/stable/">MechanicalSoup</a>isaPythonlibraryforautomatinginteractionswithwebsites.MechanicalSoupisaPythongiant<a href="http://docs.python-requests.org/en/latest/">Requests</a>(forHTTPsessions)and<a href="http://www.crummy.com/software/BeautifulSoup/">BeautifulSoup</a>ProvidesasimilarAPIbuiltfor(fordocumentnavigation). You can automatically save and send cookies, follow redirects, follow links and submit forms. Mechanical Soup is very useful when you want to simulate human behavior rather than just scraping your data.</p>
<p><strong>Characteristic:</strong></p>
<ul>
<li>Function to simulate human behavior</li>
<li>Fast scraping of fairly simple websites</li>
<li>Support CSS and XPath selector</li>
</ul>
<p>#5. Apify SDK</p>
<p><strong>Language: JavaScript</strong></p>
<p><a href="https://sdk.apify.com/">Apify SDK</a> is one of the best web crawlers built in JavaScript. A scalable scraping library enables data extraction and web automation job development on headless Chrome and Puppeteer. With its own powerful tools like RequestQueue and AutoscaledPool, you can start from multiple URLs and recursively follow links to other pages, each performing scraping tasks with maximum capacity on your system.</p>
<p><strong>Characteristic:</strong></p>
<ul>
<li>Large scale &amp; high performance scraping</li>
<li>Has a pool of proxies to avoid detection</li>
<li>Supports Node.js plugins such as Cheerio and Puppeteer</li>
</ul>
<p>#6. Apache Nutch</p>
<p><strong>Language: JAVA</strong></p>
<p><a href="https://nutch.apache.org/">Apache Nutch</a> is an open source web crawler framework written in Java. With an advanced modular architecture, developers can create plugins for media type parsing, data retrieval, queries and clustering. As a pluggable modular, Nutch also provides an extensible interface for custom implementations.</p>
<p><strong>Characteristic:</strong></p>
<ul>
<li>Highly scalable</li>
<li>follow txt rules</li>
<li>Vibrant community and active development</li>
<li>Pluggable parsing, protocol, storage and indexing</li>
</ul>
<p>#7. Jaunt</p>
<p><strong>Language: JAVA</strong></p>
<p><a href="https://jaunt-api.com/">Jaunt</a> is based on JAVA and is designed for web scraping, web automation, and JSON queries. It provides a fast, ultra-lightweight headless browser that provides web scraping functionality, access to the DOM, and control of each HTTP request/response, but does not support JavaScript.</p>
<p><strong>Characteristic:</strong></p>
<ul>
<li>Handle individual HTTP requests/responses</li>
<li>Easy connection with REST API</li>
<li>Supports HTTP, HTTPS, and basic authentication</li>
<li>Supports RegEx queries in DOM and JSON</li>
</ul>
<p>#8. Node-crawler</p>
<p><strong>Language: JavaScript</strong></p>
<p><a href="http://nodecrawler.org/">Node-crawler</a>isapowerfulandpopularproductionwebcrawlerbasedonNode.js.WrittenentirelyinNode.jsandsupportingnon-blockingI/O,it&rsquo;sveryusefulforcrawlerpipelinemanipulationmechanisms.Atthesametime,itsupportsquickDOMselection(noneedtowriteregularexpressions), which makes the crawler development more efficient.</p>
<p><strong>Characteristic:</strong></p>
<ul>
<li>Rate control</li>
<li>URL request has priority</li>
<li>Configurable pool size and retries</li>
<li>Automatic jQuery insertion via server side DOM and Cheerio (default) or JSDOM</li>
</ul>
<p>#9. PySpider</p>
<p><strong>Language: Python</strong></p>
<p><a href="http://docs.pyspider.org/en/latest/">PySpider</a> is a powerful web crawler framework written in Python. With an easy-to-use web UI and a distributed architecture with components such as scheduler, fetcher, and processor, you can now easily track multiple crawls. Supports various databases for data storage such as MongoDB and MySQL.</p>
<p><strong>Characteristic:</strong></p>
<ul>
<li>User friendly interface</li>
<li>RabbitMQ, Beanstalk, Redis, and Kombu message queues</li>
<li>Distributed architecture</li>
</ul>
<p>#10. StormCrawler</p>
<p><strong>Language: JAVA</strong></p>
<p><a href="http://stormcrawler.net/">StormCrawler</a> is an open source SDK for building distributed web crawlers using Apache Storm. This project is under the Apache License v2 and consists of a collection of reusable resources and components written mostly in Java. Great for use when the URL to retrieve and parse is provided as a stream, but is also a good solution especially for large recursive crawls that require low latency. .</p>
<p><strong>Characteristic:</strong></p>
<ul>
<li>Highly scalable and can be used for large scale recursive crawls</li>
<li>Easy extension of additional libraries</li>
<li>Excellent thread management to reduce crawl latency</li>
</ul>
<p>#Summary</p>
<p>Open source web crawlers are very powerful and extensible, but limited to developers. Lots of <a href="https://www.octoparse.jp/blog/the-10-best-web-scraping-tools/">scraping tools</a>like<a href="https://www.octoparse.jp/">Octoparse</a> Yes, you can easily extract the data without writing code. If you are new to programming, these tools are more appropriate and will make scraping easier.</p>
<p>Original article: <a href="https://www.octoparse.jp/blog/10-best-open-source-web-crawler">https://www.octoparse.jp/blog/10-best-open-source-web-crawler</a></p>

    </article>
  </div>

  
  
  
  <script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-169005401-1', 'auto');
  ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  

  
<link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.css" />
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#216942",
      "text": "#b2d192"
    },
    "button": {
      "background": "#afed71"
    }
  }
})});
</script>

</body>

</html>
