<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title> data pipeline on Memo Tut</title>
    <link>https://memotut.com/tags/data-pipeline/</link>
    <description>Recent content in  data pipeline on Memo Tut</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 09 Dec 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://memotut.com/tags/data-pipeline/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>[Python] Things I stumbled upon using Airflow</title>
      <link>https://memotut.com/2188d5d33/</link>
      <pubDate>Mon, 09 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/2188d5d33/</guid>
      <description>## Introduction  We used Airflow as a data pipeline when constructing our data infrastructure. At that time, there were some stumbling blocks, so write them down.
Our Airflow We are developing and operating multiple systems using machine learning. In order to increase the number of projects and the operation, it is necessary to meet the following requirements in common.
 Access multiple required data sources with a single endpoint The same query always returns the same result Queries don&amp;rsquo;t get stuck  Therefore, we decided that the data infrastructure was a necessary phase, and came to build it.</description>
    </item>
    
  </channel>
</rss>