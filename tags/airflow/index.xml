<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>airflow on Memo Tut</title>
    <link>https://memotut.com/tags/airflow/</link>
    <description>Recent content in airflow on Memo Tut</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 12 Dec 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://memotut.com/tags/airflow/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>[Python] Solving the frequent Fernet Key cryptography error for containerized Apache-Airflow</title>
      <link>https://memotut.com/solving-the-frequent-fernet-key-cryptography-error-for-containerized-apache-airflow-068a2/</link>
      <pubDate>Thu, 12 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/solving-the-frequent-fernet-key-cryptography-error-for-containerized-apache-airflow-068a2/</guid>
      <description>![AirflowLogo.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/538885/a8895a6d-3950-c59f-420f-68f2b4e51a69.png)  The Issue For security purposes, sensitive connection and administrative information is encrypted with a Fernet key before being stored in Airflow&amp;rsquo;s backend database. This includes any passwords for your connection objects as well as service account keys for e.g. Google Cloud.
However, if you have built Airflow webserver as a containerized service, then every time you modify and rebuild your container you run the risk of invalidating your Fernet key and losing access to your connections.</description>
    </item>
    
    <item>
      <title>[Python] Things I stumbled upon using Airflow</title>
      <link>https://memotut.com/things-i-stumbled-upon-using-airflow-2188d/</link>
      <pubDate>Mon, 09 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://memotut.com/things-i-stumbled-upon-using-airflow-2188d/</guid>
      <description>## Introduction  We used Airflow as a data pipeline when constructing our data infrastructure. At that time, there were some stumbling blocks, so write them down.
Our Airflow We are developing and operating multiple systems using machine learning. In order to increase the number of projects and the operation, it is necessary to meet the following requirements in common.
 Access multiple required data sources with a single endpoint The same query always returns the same result Queries don&amp;rsquo;t get stuck  Therefore, we decided that the data infrastructure was a necessary phase, and came to build it.</description>
    </item>
    
  </channel>
</rss>